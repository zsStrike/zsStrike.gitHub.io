---
title: 机器学习分类算法
date: 2020-01-26 16:53:55
tags: ["机器学习"]
mathjax: true
---

介绍最早以算法方式描述的分类机器学习算法：**感知器**和**自适应线性神经元**。同时我们也会使用Python来实现一个感知器。



<!-- More -->



## 早期机器学习概述

罗森布拉特基于MCP模型提出了第一个感知器学习法则。在这个感知器规则中，他提出了一个自学习算法，此算法通过优化得到权重系数，此系数和输入值的乘机决定了神经元是否被激活。在监督学习中，类似算法可以用于预测样本所属的类别。

我们将类别问题看作是二值分类问题，为了简单起见，分为`1`(正类别)和`-1`（负类别）。同时定义一个激励函数$ \phi(z) $，这个函数将会以特定的输入值**x**和相应的权值向量**w**的线性组合作为输入，也就是说：$ z=w_1x_1 + \cdots + w_nx_n $。此时定义法治函数为阶跃函数：
$$
\begin{equation}
\phi(z)=
\begin{cases}
	1, & z \ge \theta \\
	-1, & z \lt \theta
\end{cases}
\end{equation}
$$
其中，我们称$\theta$是阈值。

为了简单起见，可以将阈值移动到等式的左边，同时初始权重是$w_0=-\theta$同时$x_0=1$，这样激励函数就变为
$$
\begin{equation}
\phi(z)=
\begin{cases}
	1, & z \ge 0 \\
	-1, & z \lt 0
\end{cases}
\end{equation}
$$
同时感知器最初的规则很简单，可以归纳为如下几步：

1. 将权重初始化为零或者一个极小的随机数。
2. 迭代所有训练样本$x^i$,执行如下操作：
   1. 计算输出值$\hat{y}$。
   2. 更新权值。

每次对权重向量$w$的更新方式为：
$$
w_j:=w_j+\Delta{w_j}
$$
而对于$\Delta{w_j}$,可以通过感知器的学习规划计算获得：
$$
\Delta{w_j}=\eta(y^i-\hat{y^i})x_j^i
$$
其中，$\eta$是学习速率，一个在0到1之间的常数，$y^i$是第i个样本的真实样标，$\hat{y^i}$是相应的预测值。对于一个二维数据，可以得到如下更新公式：
$$
\Delta{w_0} = \eta(y^i-\hat{output^i})\\
\Delta{w_1} = \eta(y^i-\hat{output^i})x_1^i\\
\cdots
$$
需要注意的是，感知器收敛的前提是两个类别必须是线性可分的，并且学习速率足够小。

## 使用Python实现感知器学习算法

使用面向对象的方法实现感知器的接口，同时按照Python开发惯例，对于那些并非在初始化对象时创建但是又被对象中其他方法调用的属性，可以在后面加上一个下划线，如`self.w_`。

Python算法如下：

```python
import numpy as np

class Perceptron(object):
    def __init__(self, eta=0.01, n_iter=10):
        self.eta = eta
        self.n_iter = n_iter
        
    def fit(self, X, y):
        self.w_ = np.zeros(1 + X.shape[1])
        self.errors_ = []
        for _ in range(self.n_iter):
            errors = 0
            for xi, target in zip(X, y):
                update = self.eta * (target - self.predict(xi))
                self.w_[1:] += update * xi
                self.w_[0] += update
                errors += int(update != 0.0)
            self.errors_.append(errors)
        return self
    
    def net_input(self, X):
        return np.dot(X, self.w[1:]) + self.w_[0]
    
    def predict(self, X):
        return np.where(self.net_input(X) >= 0.0, 1, -1)
```

接下来就可以使用相关的数据集来训练我们的感知器模型。

首先我们从`pandas`库直接从UCI机器学习库中将鸢尾花数据集转化为`DataFrame`对象并且加载到内存中，并且使用`tail`方法显示数据确保数据加载正确。

```python
import pandas as pd

df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data', header=None)
df.tail()
```

|      | 0    | 1    | 2    | 3    | 4              |
| ---- | ---- | ---- | ---- | ---- | -------------- |
| 145  | 6.7  | 3.0  | 5.2  | 2.3  | Iris-virginica |
| 146  | 6.3  | 2.5  | 5.0  | 1.9  | Iris-virginica |
| 147  | 6.5  | 3.0  | 5.2  | 2.0  | Iris-virginica |
| 148  | 6.2  | 3.4  | 5.4  | 2.3  | Iris-virginica |
| 149  | 5.9  | 3.0  | 5.1  | 1.8  | Iris-virginica |

> 鸢尾花数据集时机器学习中一个经典的实例，它包含了Setosa，Versicolor和Virginica三个品种总共150个鸢尾花的测量数据，每个品种的数量是50个。每个数据项包括序号，萼片长度，萼片宽度，花瓣长度，花瓣宽度，类标。

接下来提取前100个类标，其中分别包含50个山鸢尾类标和50个变色鸢尾类标，并且将变色鸢尾表示为1，山鸢尾表示为-1。同时提取萼片长度和花瓣长度作为输入变量$X$。

首先可视化$X$：

```python
import matplotlib.pyplot as plt
import numpy as np

y = df.iloc[0:100, 4].values
y = np.where(y == 'Iris-setosa', -1, 1)
X = df.iloc[0:100, [0, 2]].values
plt.scatter(X[:50, 0], X[:50, 1], color='red', marker='o', label='setosa')
plt.scatter(X[50:100, 0], X[50:100, 1], color='blue', marker='x', label='versicolor')
plt.xlabel('petal length')
plt.ylabel('sepal length')
plt.legend(loc='upper left')
plt.show()
```

可视化的图形如下：

![img](./Mon,%2027%20Jan%202020%20113718.png)