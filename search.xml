<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>《深入浅出MySQL》笔记</title>
      <link href="2020/12/20/%E3%80%8A%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAMySQL%E3%80%8B%E7%AC%94%E8%AE%B0/"/>
      <url>2020/12/20/%E3%80%8A%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAMySQL%E3%80%8B%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<p>本文用于记录《深入浅出MySQL》里面的知识要点，以备再次查阅。</p><h2 id="第二章-SQL基础"><a href="#第二章-SQL基础" class="headerlink" title="第二章 SQL基础"></a>第二章 SQL基础</h2><p>MySQL使用入门：</p><ul><li><p>SQL语句分类：DDL，DML，DCL。</p></li><li><p>DDL：数据定义语言，对数据库内部的对象进行创建，删除，修改等操作。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; 数据库</span><br><span class="line">CREATE DATABASE dbname;</span><br><span class="line">SHOW DATABASES;</span><br><span class="line">USE dbname;</span><br><span class="line">DROP DATABASE dbname;</span><br><span class="line">&#x2F;&#x2F; 表</span><br><span class="line">CREATE TABLE tablename (</span><br><span class="line">column_name1, type1 constraints,</span><br><span class="line">...</span><br><span class="line">column_namen, typen constraints);</span><br><span class="line">DESC tablename;</span><br><span class="line">SHOW CREATE TABLE tablename;</span><br><span class="line">DROP TBALE database;</span><br><span class="line">ALTER TABLE tablename MODIFY [COLUMN] column_definition [FIRST | AFTER col_name];</span><br><span class="line">ALTER TABLE tablename ADD [COLUMN] column_difinition [FIRST | AFTER col_name];</span><br><span class="line">ALTER TABLE tablename DROP [COLUMN] col_name;</span><br><span class="line">ALTER TABLE tablename CHANGE [COLUMN] old_col_name column_definition;</span><br><span class="line">ALTER TABLE tablename RENAME new_tablename;</span><br></pre></td></tr></table></figure></li><li><p>DML：数据操作，主要包括表记录的增删查改。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">INSERT INTO tablename(field1, field2, ..., fieldn)</span><br><span class="line">VALUES</span><br><span class="line">(value1, value2, ..., valuen),</span><br><span class="line">(value1, value2, ..., valuen);</span><br><span class="line">UPDATE tablename SET field1&#x3D;value1 [WHERE CONDITION];</span><br><span class="line">DELETE FROM tablename [WHERE CONDITION];</span><br><span class="line">SELECT * FROM tablename [WHERE CONDITION] [LIMIT offset_start, row_count];</span><br></pre></td></tr></table></figure><ul><li>查询不重复记录：distinct</li><li>条件查询：WHERE CONDITION</li><li>排序和限制：ORDER BY 和 LIMIT offset_start, row_count</li><li>聚合：GROUP BY column_name HAVING condition</li><li>表连接：内连接，外连接（左连接，右连接）</li><li>子查询：可能需要 in，not in，exists 等</li><li>记录联合：UNION，UNION ALL</li></ul></li><li><p>DCL：DBA 用来管理系统中的对象权限时使用。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">GRANT SELECT, INSERT on dbname.* to &#39;z1&#39;@&#39;localhost&#39; identified by &#39;123&#39;;</span><br><span class="line">REVOKE INSERT on dbname.* from &#39;z1&#39;@&#39;localhost&#39;;</span><br></pre></td></tr></table></figure></li></ul><p>帮助的使用：</p><ul><li>按照层次查看帮助：<code>? contents</code></li><li>快速查阅帮助：<code>? select</code></li></ul><h2 id="第三章-MySQL支持的数据类型"><a href="#第三章-MySQL支持的数据类型" class="headerlink" title="第三章 MySQL支持的数据类型"></a>第三章 MySQL支持的数据类型</h2><p>数值类型：</p><table><thead><tr><th align="left">类型</th><th align="left">大小</th><th align="left">范围（有符号）</th><th align="left">范围（无符号）</th></tr></thead><tbody><tr><td align="left">TINYINT</td><td align="left">1 byte</td><td align="left">(-128，127)</td><td align="left">(0，255)</td></tr><tr><td align="left">SMALLINT</td><td align="left">2 bytes</td><td align="left">(-32 768，32 767)</td><td align="left">(0，65 535)</td></tr><tr><td align="left">MEDIUMINT</td><td align="left">3 bytes</td><td align="left">(-8 388 608，8 388 607)</td><td align="left">(0，16 777 215)</td></tr><tr><td align="left">INT或INTEGER</td><td align="left">4 bytes</td><td align="left">(-2 147 483 648，2 147 483 647)</td><td align="left">(0，4 294 967 295)</td></tr><tr><td align="left">BIGINT</td><td align="left">8 bytes</td><td align="left">(-9,223,372,036,854,775,808，9 223 372 036 854 775 807)</td><td align="left">(0，18 446 744 073 709 551 615)</td></tr><tr><td align="left">FLOAT</td><td align="left">4 bytes</td><td align="left">(-3.402 823 466 E+38，-1.175 494 351 E-38)，0，(1.175 494 351 E-38，3.402 823 466 351 E+38)</td><td align="left">0，(1.175 494 351 E-38，3.402 823 466 E+38)</td></tr><tr><td align="left">DOUBLE</td><td align="left">8 bytes</td><td align="left">(-1.797 693 134 862 315 7 E+308，-2.225 073 858 507 201 4 E-308)，0，(2.225 073 858 507 201 4 E-308，1.797 693 134 862 315 7 E+308)</td><td align="left">0，(2.225 073 858 507 201 4 E-308，1.797 693 134 862 315 7 E+308)</td></tr><tr><td align="left">DECIMAL</td><td align="left">对DECIMAL(M,D) ，如果M&gt;D，为M+2否则为D+2</td><td align="left">依赖于M和D的值</td><td align="left">依赖于M和D的值</td></tr></tbody></table><p>对于整形数据，MySQL还支持在类型名称后面的小括号内指定显式宽度。</p><p>日期时间类型：</p><table><thead><tr><th align="left">类型</th><th align="left">大小 ( bytes)</th><th align="left">范围</th><th align="left">格式</th><th align="left">用途</th></tr></thead><tbody><tr><td align="left">DATE</td><td align="left">3</td><td align="left">1000-01-01/9999-12-31</td><td align="left">YYYY-MM-DD</td><td align="left">日期值</td></tr><tr><td align="left">TIME</td><td align="left">3</td><td align="left">‘-838:59:59’/‘838:59:59’</td><td align="left">HH:MM:SS</td><td align="left">时间值或持续时间</td></tr><tr><td align="left">YEAR</td><td align="left">1</td><td align="left">1901/2155</td><td align="left">YYYY</td><td align="left">年份值</td></tr><tr><td align="left">DATETIME</td><td align="left">8</td><td align="left">1000-01-01 00:00:00/9999-12-31 23:59:59</td><td align="left">YYYY-MM-DD HH:MM:SS</td><td align="left">混合日期和时间值</td></tr><tr><td align="left">TIMESTAMP</td><td align="left">4</td><td align="left">1970-01-01 00:00:00/2038</td><td align="left">YYYYMMDD HHMMSS</td><td align="left">混合日期和时间值，时间戳</td></tr></tbody></table><p>字符串类型：</p><table><thead><tr><th align="left">类型</th><th align="left">大小</th><th align="left">用途</th></tr></thead><tbody><tr><td align="left">CHAR</td><td align="left">0-255 bytes</td><td align="left">定长字符串</td></tr><tr><td align="left">VARCHAR</td><td align="left">0-65535 bytes</td><td align="left">变长字符串</td></tr><tr><td align="left">TINYBLOB</td><td align="left">0-255 bytes</td><td align="left">不超过 255 个字符的二进制字符串</td></tr><tr><td align="left">TINYTEXT</td><td align="left">0-255 bytes</td><td align="left">短文本字符串</td></tr><tr><td align="left">BLOB</td><td align="left">0-65 535 bytes</td><td align="left">二进制形式的长文本数据</td></tr><tr><td align="left">TEXT</td><td align="left">0-65 535 bytes</td><td align="left">长文本数据</td></tr><tr><td align="left">MEDIUMBLOB</td><td align="left">0-16 777 215 bytes</td><td align="left">二进制形式的中等长度文本数据</td></tr><tr><td align="left">MEDIUMTEXT</td><td align="left">0-16 777 215 bytes</td><td align="left">中等长度文本数据</td></tr><tr><td align="left">LONGBLOB</td><td align="left">0-4 294 967 295 bytes</td><td align="left">二进制形式的极大文本数据</td></tr><tr><td align="left">LONGTEXT</td><td align="left">0-4 294 967 295 bytes</td><td align="left">极大文本数据</td></tr></tbody></table><ul><li>ENUM：值范围需要在创建表时通过枚举方式显式指定，对于插入不在 ENUM指定范围内的值时，并没有返回警告，而是插入了 enum 定义中的第一个值</li><li>SET：从允许值集合中选择任意1个或多个元素进行组合来赋值</li></ul><h2 id="第四章-MySQL中的运算符"><a href="#第四章-MySQL中的运算符" class="headerlink" title="第四章 MySQL中的运算符"></a>第四章 MySQL中的运算符</h2><p>算术运算符：</p><table><thead><tr><th align="left">运算符</th><th align="left">作用</th></tr></thead><tbody><tr><td align="left">+</td><td align="left">加法</td></tr><tr><td align="left">-</td><td align="left">减法</td></tr><tr><td align="left">*</td><td align="left">乘法</td></tr><tr><td align="left">/ 或 DIV</td><td align="left">除法</td></tr><tr><td align="left">% 或 MOD</td><td align="left">取余</td></tr></tbody></table><p>在除法运算和模运算中，如果除数为0，将是非法除数，返回结果为NULL。</p><p>比较运算符：</p><table><thead><tr><th></th><th></th><th></th></tr></thead><tbody><tr><td>=</td><td>等于</td><td></td></tr><tr><td>&lt;&gt;, !=</td><td>不等于</td><td></td></tr><tr><td>&gt;</td><td>大于</td><td></td></tr><tr><td>&lt;</td><td>小于</td><td></td></tr><tr><td>&lt;=</td><td>小于等于</td><td></td></tr><tr><td>&gt;=</td><td>大于等于</td><td></td></tr><tr><td>BETWEEN</td><td>在两值之间</td><td>&gt;=min&amp;&amp;&lt;=max</td></tr><tr><td>NOT BETWEEN</td><td>不在两值之间</td><td></td></tr><tr><td>IN</td><td>在集合中</td><td></td></tr><tr><td>NOT IN</td><td>不在集合中</td><td></td></tr><tr><td>&lt;=&gt;</td><td>严格比较两个NULL值是否相等</td><td>两个操作码均为NULL时，其所得值为1；而当一个操作码为NULL时，其所得值为0</td></tr><tr><td>LIKE</td><td>模糊匹配</td><td></td></tr><tr><td>REGEXP 或 RLIKE</td><td>正则式匹配</td><td></td></tr><tr><td>IS NULL</td><td>为空</td><td></td></tr><tr><td>IS NOT NULL</td><td>不为空</td><td></td></tr></tbody></table><p>逻辑运算符：</p><table><thead><tr><th align="left">运算符号</th><th align="left">作用</th></tr></thead><tbody><tr><td align="left">NOT 或 !</td><td align="left">逻辑非</td></tr><tr><td align="left">AND</td><td align="left">逻辑与</td></tr><tr><td align="left">OR</td><td align="left">逻辑或</td></tr><tr><td align="left">XOR</td><td align="left">逻辑异或</td></tr></tbody></table><p>位运算符：</p><table><thead><tr><th align="left">运算符号</th><th align="left">作用</th></tr></thead><tbody><tr><td align="left">&amp;</td><td align="left">按位与</td></tr><tr><td align="left">|</td><td align="left">按位或</td></tr><tr><td align="left">^</td><td align="left">按位异或</td></tr><tr><td align="left">!</td><td align="left">取反</td></tr><tr><td align="left">&lt;&lt;</td><td align="left">左移</td></tr><tr><td align="left">&gt;&gt;</td><td align="left">右移</td></tr></tbody></table><h2 id="第五章-常用函数"><a href="#第五章-常用函数" class="headerlink" title="第五章 常用函数"></a>第五章 常用函数</h2><p>字符串函数：</p><table><thead><tr><th><strong>编号</strong></th><th><strong>函数名</strong></th><th><strong>作用</strong></th></tr></thead><tbody><tr><td>1</td><td>LEFT(s,n)</td><td>返回字符串s前n个字符</td></tr><tr><td>2</td><td>RIGHT(s,n)</td><td>返回字符串s后n个字符</td></tr><tr><td>3</td><td>LENGTH(s)</td><td>返回字符串s的长度</td></tr><tr><td>4</td><td>LOCATE(s1,s2)</td><td>从字符串 s2 中获取 子串s1 的开始位置</td></tr><tr><td>5</td><td>LOWER(s)</td><td>大写转小写</td></tr><tr><td>6</td><td>UPPER(s)</td><td>小写转大写</td></tr><tr><td>7</td><td>LTRIM(s)</td><td>去掉字符串s左面的空格</td></tr><tr><td>8</td><td>RTRIM(s)</td><td>去掉字符串s右面的空格</td></tr><tr><td>9</td><td>TRIM(s)</td><td>去掉字符串s两边的空格</td></tr><tr><td>10</td><td>ASCII(s)</td><td>返回字符串s的第一个字符的 ASCII 码</td></tr><tr><td>11</td><td>CONCAT(s1,s2…sn)</td><td>字符串 s1,s2 等多个字符串合并为一个字符串</td></tr><tr><td>12</td><td>FIND_IN_SET(s1,s2)</td><td>返回在字符串s2中与s1匹配的字符串的位置(多句话)</td></tr><tr><td>13</td><td>FORMAT(x,n)</td><td>可以将数字 x 进行格式化 “#,###.##”, 将 x 保留到小数点后 n 位，最后一位四舍五入</td></tr><tr><td>14</td><td>INSERT(s1,x,len,s2)</td><td>字符串 s2 替换 s1 的 x 位置开始长度为 len 的字符串</td></tr><tr><td>15</td><td>SUBSTR(s, start, length)</td><td>从字符串 s 的 start 位置截取长度为 length 的子字符串</td></tr><tr><td>16</td><td>POSITION(s1 IN s)</td><td>从字符串 s 中获取 s1 的开始位置</td></tr><tr><td>17</td><td>REPEAT(s,n)</td><td>将字符串 s 重复 n 次</td></tr><tr><td>18</td><td>REVERSE(s)</td><td>将字符串s的顺序反过来</td></tr><tr><td>19</td><td>STRCMP(s1,s2)</td><td>比较字符串 s1 和 s2，如果 s1 与 s2 相等返回 0 ，如果 s1&gt;s2 返回 1，如果 s1&lt;s2 返回 -1（比较的是字符串首字母的 ASCII 码）</td></tr><tr><td>20</td><td>REPLACE (s1,s2,s3)</td><td>替换字符串；将s1中的s2内容替换为s3</td></tr></tbody></table><p>数值函数：</p><table><thead><tr><th><strong>编号</strong></th><th><strong>函数名</strong></th><th><strong>作用</strong></th></tr></thead><tbody><tr><td>1</td><td>ABS(x)</td><td>返回x的绝对值</td></tr><tr><td>2</td><td>AVG(expression)</td><td>返回一个表达式的平均值，expression 是一个字段</td></tr><tr><td>3</td><td>CEIL(x)/CEILING(x)</td><td>返回大于或等于 x 的最小整数</td></tr><tr><td>4</td><td>FLOOR(x)</td><td>返回小于或等于 x 的最大整数</td></tr><tr><td>5</td><td>EXP(x)</td><td>返回 e 的 x 次方</td></tr><tr><td>6</td><td>GREATEST(expr1, expr2, expr3, …)</td><td>返回列表中的最大值</td></tr><tr><td>7</td><td>LEAST(expr1, expr2, expr3, …)</td><td>返回列表中的最小值</td></tr><tr><td>8</td><td>LN</td><td>返回数字的自然对数</td></tr><tr><td>9</td><td>LOG(x)</td><td>返回自然对数(以 e 为底的对数)</td></tr><tr><td>10</td><td>MAX(expression)</td><td>返回字段 expression 中的最大值</td></tr><tr><td>11</td><td>MIN(expression)</td><td>返回字段 expression 中的最大值</td></tr><tr><td>12</td><td>POW(x,y)/POWER(x,y)</td><td>返回 x 的 y 次方</td></tr><tr><td>13</td><td>RAND()</td><td>返回 0 到 1 的随机数</td></tr><tr><td>14</td><td>ROUND(x)</td><td>返回离 x 最近的整数</td></tr><tr><td>15</td><td>SIGN(x)</td><td>返回 x 的符号，x 是负数、0、正数分别返回 -1、0 和 1</td></tr><tr><td>16</td><td>SQRT(x)</td><td>返回x的平方根</td></tr><tr><td>17</td><td>SUM(expression)</td><td>返回指定字段的总和</td></tr><tr><td>18</td><td>TRUNCATE(x,y)</td><td>返回数值 x 保留到小数点后 y 位的值（与 ROUND 最大的区别是不会进行四舍五入）</td></tr></tbody></table><p>日期和时间函数：</p><table><thead><tr><th><strong>编号</strong></th><th><strong>函数名</strong></th><th><strong>作用</strong></th></tr></thead><tbody><tr><td>1</td><td>CURDATE()/CURRENT_DATE()</td><td>返回当前日期</td></tr><tr><td>2</td><td>CURRENT_TIME()/CURTIME()</td><td>返回当前时间</td></tr><tr><td>3</td><td>CURRENT_TIMESTAMP()</td><td>返回当前日期和时间</td></tr><tr><td>4</td><td>ADDDATE(d,n)</td><td>计算起始日期 d 加上 n 天的日期</td></tr><tr><td>5</td><td>ADDTIME(t,n)</td><td>时间 t 加上 n 秒的时间</td></tr><tr><td>6</td><td>DATE()</td><td>从日期或日期时间表达式中提取日期值</td></tr><tr><td>7</td><td>DAY(d)</td><td>返回日期值 d 的日期部分</td></tr><tr><td>8</td><td>DATEDIFF(d1,d2)</td><td>计算日期 d1-&gt;d2 之间相隔的天数</td></tr><tr><td>9</td><td>DATE_FORMAT</td><td>按表达式 f的要求显示日期 d</td></tr><tr><td>10</td><td>DAYNAME(d)</td><td>返回日期 d 是星期几，如 Monday,Tuesday</td></tr><tr><td>11</td><td>DAYOFMONTH(d)</td><td>计算日期 d 是本月的第几天</td></tr><tr><td>12</td><td>DAYOFWEEK(d)</td><td>日期 d 今天是星期几，1 星期日，2 星期一，以此类推</td></tr><tr><td>13</td><td>DAYOFYEAR(d)</td><td>计算日期 d 是本年的第几天</td></tr><tr><td>14</td><td>UNIX_TIMESTAMP()</td><td>得到时间戳</td></tr><tr><td>15</td><td>FROM_UNIXTIME()</td><td>时间戳转日期</td></tr><tr><td>16</td><td>NOW()</td><td>返回当前的日期和时间</td></tr><tr><td>17</td><td>STR_TO_DATE()</td><td>将日期格式的字符转换成指定格式的日期</td></tr><tr><td>18</td><td>DATE_FORMAT()</td><td>将日期转换成字符(支持：- . /分割年月日)</td></tr></tbody></table><p>流程函数：</p><table><thead><tr><th>函数</th><th>功能</th></tr></thead><tbody><tr><td>IF(cond, t, f)</td><td>如果 cond 为真，返回 t，否则fanhui f</td></tr><tr><td>CASE cond WHEN value1 THEN result … END</td><td>多重选择</td></tr></tbody></table><p>其他常用函数：</p><table><thead><tr><th>函数</th><th>功能</th></tr></thead><tbody><tr><td>DATABASE()</td><td>返回当前数据库名</td></tr><tr><td>VERSION()</td><td>返回数据库版本</td></tr><tr><td>USER()</td><td>返回当前登录用户名</td></tr><tr><td>INET_ATON(IP)</td><td>返回 IP 代表的 num</td></tr><tr><td>INET_NTOA(num)</td><td>返回 num 代表的 IP</td></tr><tr><td>PASSWORD()</td><td>返回加密版本</td></tr><tr><td>MD5()</td><td>返回 MD5 的值</td></tr></tbody></table><h2 id="第六章-图形化工具的使用"><a href="#第六章-图形化工具的使用" class="headerlink" title="第六章 图形化工具的使用"></a>第六章 图形化工具的使用</h2><p>MySQL Workbench：</p><ul><li>SQL 开发</li><li>数据建模</li><li>服务器管理</li><li>MySQL Utilities</li></ul><p>phpMyAdmin：</p><ul><li>数据库管理</li><li>数据库对象管理</li><li>权限管理</li><li>导入导出数据</li></ul><h2 id="第七章-存储引擎（表类型）的选择"><a href="#第七章-存储引擎（表类型）的选择" class="headerlink" title="第七章 存储引擎（表类型）的选择"></a>第七章 存储引擎（表类型）的选择</h2><p>存储引擎概述：根据不同领域的需要选择合适的存储引擎，可以更好地提高数据库的效率。在诸多的引擎中，支持事务安全的只有 InnoDB 和 BDB。默认的存储引擎可以通过 default-table-type 配置。使用  <code>SHOW ENGINES</code> 可以查看当前数据库支持的引擎。</p><p>各种存储引擎的特性：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201220142420583.png" class="lazyload" data-srcset="image-20201220142420583.png" srcset="data:image/png;base64,666" alt="image-20201220142420583"/></div><span class="image-caption">image-20201220142420583</span></div><ul><li>MyISAM：不支持事务、也不支持外键，其优势是访问的速度快，对事务完整性没有要求或者以 SELECT、INSERT 为主的应用基本上都可以使用这个引擎创建表。</li><li>InnoDB：提供了具有提交、回滚和崩溃恢复能力的事务安全。但是对比MyISAM的存储引擎，InnoDB写的处理效率差一些，并且会占用更多的磁盘空间以保留数据和索引。</li><li>MEMORY：使用存在于内存中的内容来创建表。每个MEMORY 表只实际对应一个磁盘文件，格式是.frm。MEMORY 类型的表访问非常地快，因为它的数据是放在内存中的，并且默认使用 HASH 索引，但是一旦服务关闭，表中的数据就会丢失掉。</li><li>MERGE：是一组 MyISAM 表的组合，这些 MyISAM 表必须结构完全相同，MERGE 表本身并没有数据，对 MERGE 类型的表可以进行查询、更新、删除操作，这些操作实际上是对内部 MyISAM 表进行的。</li><li>TokuDB：第三方引擎，是一个高性能、支持事务处理的MySQL和MariaDB的存储引擎，具有高扩展性、高压缩率、高效的写入性能，支持大多数在线DDL操作。</li></ul><h2 id="第八章-选择合适的数据类型"><a href="#第八章-选择合适的数据类型" class="headerlink" title="第八章 选择合适的数据类型"></a>第八章 选择合适的数据类型</h2><p>CHAR 与 VARCHAR：下表是它们之间的对比，最后一行只适用于 MySQL 运行在非严格模式下面。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201220145107981.png" class="lazyload" data-srcset="image-20201220145107981.png" srcset="data:image/png;base64,666" alt="image-20201220145107981"/></div><span class="image-caption">image-20201220145107981</span></div><p>CHAR 长度固定，处理速度快，但是浪费空间存储。对于 MyISAM 和 MEMORY 来说，首选 CHAR，而对于 InnoDB 来说，建议使用VARCHAR类型。</p><p>TEXT 与 BLOB：在保存较大文本时，通常会选择使用TEXT或者BLOB。二者之间的主要差别是BLOB能用来保存二进制数据，比如照片；而TEXT只能保存字符数据，比如一篇文章或者日记。</p><ul><li>BLOB 和 TEXT 值会造成性能问题，在执行删除操作之后，会在数据表中留下很大的空洞，可以定期使用 <code>OPTIMIZE TABLE</code> 来进行碎片整理。</li><li>使用合成索引来提高大文本字段的查询性能。合成索引就是根据大文本字段的内容建立一个散列值，并把这个值存储在单独的数据列中，接下来就可以通过检索散列值找到数据行了。注意只能用于精确匹配。</li><li>在不必要的时候避免检索大型的 BLOB 或 TEXT 值。</li><li>把 BLOB 或 TEXT 列分离到单独的表中，以减少主表的碎片</li></ul><p>浮点数与定点数：浮点数不是精确的，定点数更加精确。float，doble 都是浮点数，decimal 则是定点数。</p><p>日期类型选择：根据实际需要选择能够满足应用的最小存储的日期类型。如果记录的日期需要让不同时区的用户使用，那么最好使用 TIMESTAMP，因为日期类型中只有它能够和实际时区相对应。</p><h2 id="第九章-字符集"><a href="#第九章-字符集" class="headerlink" title="第九章 字符集"></a>第九章 字符集</h2><p>常用字符集比较：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201220170248401.png" class="lazyload" data-srcset="image-20201220170248401.png" srcset="data:image/png;base64,666" alt="image-20201220170248401"/></div><span class="image-caption">image-20201220170248401</span></div><p>选择字符集标准：</p><ul><li>如果应用要处理各种各样的文字，首选 utf-8</li><li>如果应用中涉及已有数据的导入，就要充分考虑数据库字符集对已有数据的兼容性</li><li>如果数据库只需要支持一般中文，数据量很大，性能要求也很高，那就应该选择双字节定长编码的中文字符集，比如 GBK</li><li>如果数据库需要做大量的字符运算，如比较、排序等，那么选择定长字符集可能更好</li></ul><p>MySQL 支持的字符集简介：查看所有可用的字符集的命令是 <code>show character set</code>，MySQL 的字符集包含字符集（CHARACTER）和校对规则（COLLATION）两个概念。其中字符集用来定义 MySQL 存储字符串的方式，校对规则用来定义比较字符串的方式。校对规则命名约定：以其相关的字符集名开始，通常包括一个语言名，并且以<code>_ci</code>（大小写不敏感）、<code>_cs</code>（大小写敏感）或<code>_bin</code>（比较是基于字符编码的值而与language无关）结束。</p><p>MySQL 字符集设置：有4个级别的默认设置：服务器级、数据库级、表级和字段级。</p><ul><li>服务器字符集：可以在 my.cnf 中配置<code>character-set-server</code>来设置。</li><li>数据库字符集：可以在创建数据库的时候指定，也可以在创建完数据库后通过“alter database”命令进行修改。后者并不能修改之前已经插入的数据的字符集。</li><li>表字符集：可以在创建表的时候指定，可以通过 alter table 命令进行修改，同样，如果表中已有记录，修改字符集对原有的记录并没有影响，不会按照新的字符集进行存放。</li><li>列字符集：可以定义列级别的字符集和校对规则，主要是针对相同的表不同字段需要使用不同的字符集的情况。</li></ul><p>字符集的修改步骤：如果原来的数据库中已经存在数据，那么通过 alter database 或者 alter tablename 的方式并不能修改之前已经插入的数据的字符集。最好先使用 mysqldump 导出表定义，然后手动修改数据集<code>将SET NAMES character</code>，最后再次导入数据。</p><h2 id="第十章-索引的设计和使用"><a href="#第十章-索引的设计和使用" class="headerlink" title="第十章 索引的设计和使用"></a>第十章 索引的设计和使用</h2><p>索引概述：索引用于快速找出在某个列中有一特定值的行，对相关列使用索引能提高 SELECT 操作性能的最佳途径，MySQL 支持前缀索引，还支持全文索引。</p><ul><li><p>创建索引：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">CREATE [UNIQUE|FULLTEXT|SPATIAL] INDEX index_name</span><br><span class="line">[USING index_type]</span><br><span class="line">ON tbl_name (index_col_name,. .);</span><br></pre></td></tr></table></figure></li><li><p>删除索引：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DROP INDEX index_name ON tbl_name;</span><br></pre></td></tr></table></figure></li></ul><p>索引设计原则：</p><ul><li>最适合索引的列是出现在 WHERE 子句中的列，或连接子句中指定的列</li><li>使用唯一索引</li><li>使用短索引</li><li>不过度使用索引</li></ul><p>BTREE 索引与 HASH 索引：</p><ul><li>使用 HASH 索引的时候，只能用于 = 或者 &lt;&gt; 操作符比较，MySQL 不能确定两个值之间大约有多少行数据</li><li>对于 BTREE 索引，当使用 &gt;、&lt;、&gt;=、&lt;=、BETWEEN、!= 或者 &lt;&gt;，或者LIKE ‘pattern’ 操作符时，都可以使用相关列上的索引</li></ul><h2 id="第十一章-视图"><a href="#第十一章-视图" class="headerlink" title="第十一章 视图"></a>第十一章 视图</h2><p>视图：一种虚拟存在的表，对于使用视图的用户来说透明，视图相对于表的优点有：简单，安全和数据独立。</p><p>视图操作：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; 创建视图</span><br><span class="line">CREATE [OR REPLACE] VIEW view_name [(column_list)]</span><br><span class="line">AS select_statement</span><br><span class="line">[WITH [CASCADED | LOCAL] CHECK OPTION]</span><br><span class="line">&#x2F;&#x2F; 修改视图</span><br><span class="line">ALTER VIEW view_name [(column_list)]</span><br><span class="line">AS select_statement</span><br><span class="line">[WITH [CASCADED | LOCAL] CHECK OPTION]</span><br><span class="line">&#x2F;&#x2F; 删除视图</span><br><span class="line">DROP VIEW [IF EXISTS] view_name [, view_name] . .[RESTRICT | CASCADE]</span><br><span class="line">&#x2F;&#x2F; 查看视图</span><br><span class="line">SHOW TABLES;</span><br><span class="line">SHOW CREATE VIEW view_name;</span><br></pre></td></tr></table></figure><p><code>WITH [CASCADED | LOCAL] CHECK OPTION</code>决定了是否允许更新数据使记录不再满足视图的条件，其中<code>LOCAL</code>只要满足本视图的条件就可以更新，而<code>CASCADED</code>则必须满足所有针对该视图的所有视图的条件才可以更新。</p><h2 id="第十二章-存储过程和函数"><a href="#第十二章-存储过程和函数" class="headerlink" title="第十二章 存储过程和函数"></a>第十二章 存储过程和函数</h2><p>存储过程和函数：它们都是一段 SQL 语句的集合，不同之处在于函数必须有返回值，并且其参数只能是 IN 类型的，合理使用它们可以减少数据传输量，但是在服务器上进行大量的运算也会占用服务器的 CPU，需要综合考虑。</p><p>存储过程和函数的相关操作：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; 创建</span><br><span class="line">CREATE PROCUDURE p_name ([proc_parameter[,...]])</span><br><span class="line">[characteristic ..] routine_body</span><br><span class="line"></span><br><span class="line">CREATE FUNCTION f_name ([func_parameter[,. .]])</span><br><span class="line">RETURNS type</span><br><span class="line">[characteristic ..] routine_body</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 修改</span><br><span class="line">ALTER &#123;PROCEDURE | FUNCTION&#125; sp_name [characteristic . .]</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 调用</span><br><span class="line">CALL sp_name([parameter[,...]])</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 删除</span><br><span class="line">DROP &#123;PROCEDURE | FUNCTION&#125; [IF EXISTS] sp_name</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 查看</span><br><span class="line">SHOW &#123;PROCEDURE | FUNCTION&#125; STATUS [LIKE &#39;pattern&#39;]</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>通常，<code>routine_body</code>包含多条语句，为了不出现错误，我们可以使用<code>DELIMITER $$</code>命令将语句的结束符从“;”修改成其他符号（$$）。</p><p><code>characteristic</code>特征值说明如下：</p><ul><li>LANGUAGE SQL：说明 BODY 是使用 SQL 语言编写的</li><li>[NOT] DETERMINISTIC：DETERMINISTIC确定的,即每次输入一样输出也一样的程序，NOT DETERMINISTIC非确定的，默认是非确定的</li><li>{ CONTAINS SQL | NO SQL | READS SQL DATA | MODIFIES SQL DATA }：提供额外信息给服务器</li><li>SQL SECURITY { DEFINER | INVOKER }：可以用来指定子程序该用创建子程序者的许可来执行，还是使用调用者的许可来执行。默认值是DEFINER</li></ul><p>变量的使用：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; 定义</span><br><span class="line">DECLARE var_name[,. .] type [DEFAULT value]</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 赋值</span><br><span class="line">SET var_name &#x3D; expr [, var_name &#x3D; expr] ..</span><br><span class="line">SELECT col_name[,. .] INTO var_name[,. .] table_expr</span><br></pre></td></tr></table></figure><p>条件的使用：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; 定义</span><br><span class="line">DECLARE condition_name CONDITION FOR condition_value</span><br><span class="line">condition_value: SQLSTATE [VALUE] sqlstate_value | mysql_error_code</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 条件处理</span><br><span class="line">DECLARE handler_type HANDLER FOR condition_value[,...] sp_statement</span><br><span class="line">handler_type: CONTINUE | EXIT | UNDO</span><br><span class="line">condition_value: SQLSTATE [VALUE] sqlstate_value</span><br><span class="line">| condition_name</span><br><span class="line">| SQLWARNING</span><br><span class="line">| NOT FOUND</span><br><span class="line">| SQLEXCEPTION</span><br><span class="line">| mysql_error_code</span><br></pre></td></tr></table></figure><p>光标使用：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; 声明</span><br><span class="line">DECLARE cursor_name CURSOR FOR select_statement</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; OPEN -&gt; FETCH -&gt; CLOSE</span><br><span class="line">OPEN cursor_name</span><br><span class="line">FETCH cursor_name INTO var_name[, var_name]..</span><br><span class="line">CLOSE cursor_name</span><br></pre></td></tr></table></figure><p>流程控制：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; IF</span><br><span class="line">IF condition THEN statement_list</span><br><span class="line">[ELSEIF condition THEN statement_list] ...</span><br><span class="line">[ELSE statement_list]</span><br><span class="line">END IF</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; CASE</span><br><span class="line">CASE case_value</span><br><span class="line">WHEN when_value THEN statement_list</span><br><span class="line">[WHEN when_value THEN statement_list] ...</span><br><span class="line">[ELSE statement_list]</span><br><span class="line">END CASE</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; LOOP，通常结合 LEAVE 使用，LEAVE 作用类似于 BREAK</span><br><span class="line">[begin_label:] LOOP</span><br><span class="line">statement_list</span><br><span class="line">END LOOP [end_label]</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; ITERATE：跳过当前循环的剩下的语句，直接进入下一轮循环，类似 CONTINUE</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; REPEAT</span><br><span class="line">[begin_label:] REPEAT</span><br><span class="line">statement_list</span><br><span class="line">UNTIL condition</span><br><span class="line">END REPEAT [end_label]</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; WHILE</span><br><span class="line">[begin_label:] WHILE condition DO</span><br><span class="line">statement_list</span><br><span class="line">END WHILE [end_label]</span><br></pre></td></tr></table></figure><p>事件调度器：可以在某个时间点触发操作，或者每隔一段时间执行固定代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; 时间点</span><br><span class="line">CREATE EVENT myevent</span><br><span class="line">ON SCHEDULE AT CURRENT_TIMESTAMP + INTERVAL 1 HOUR</span><br><span class="line">DO</span><br><span class="line">UPDATE myschema.mytable SET mycol &#x3D; mycol + 1;</span><br><span class="line">&#x2F;&#x2F; 时间间隔</span><br><span class="line">CREATE EVENT myevent</span><br><span class="line">ON SCHEDULE EVERY 5 SECOND</span><br><span class="line">DO</span><br><span class="line">UPDATE myschema.mytable SET mycol &#x3D; mycol + 1;</span><br></pre></td></tr></table></figure><h2 id="第十三章-触发器"><a href="#第十三章-触发器" class="headerlink" title="第十三章 触发器"></a>第十三章 触发器</h2><p>触发器操作：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; 创建</span><br><span class="line">CREATE TRIGGER trigger_name [BEFORE | AFTER] [INSERT | DELETE | UPDATE]</span><br><span class="line">ON table_name FOR EACH ROW trigger_stmt</span><br><span class="line">&#x2F;&#x2F; 删除</span><br><span class="line">DROP TRIGGER [schema_name.]trigger_name</span><br><span class="line">&#x2F;&#x2F; 查看</span><br><span class="line">show triggers</span><br></pre></td></tr></table></figure><p>触发器使用：在触发器中，使用别名 OLD 和 NEW 来引用发生变化的记录内容。另外，触发器存在如下限制：</p><ul><li>触发程序不能调用将数据返回客户端的存储程序</li><li>不能在触发器中使用以显式或隐式方式开始或结束事务的语句</li></ul><h2 id="第十四章-事务控制和锁定语句"><a href="#第十四章-事务控制和锁定语句" class="headerlink" title="第十四章 事务控制和锁定语句"></a>第十四章 事务控制和锁定语句</h2><p>锁定级别：MySQL 支持对 MyISAM 和 MEMORY 存储引擎的表进行表级锁定，对 BDB 存储引擎的表进行页级锁定，对 InnoDB 存储引擎的表进行行级锁定。</p><p>表锁定：当所需要的锁已经被其他线程获取，此时该线程会进行等待，其操作如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">LOCK TABLES</span><br><span class="line">tbl_name &#123;READ [LOCAL] | [LOW_PRIORITY] WRITE&#125;</span><br><span class="line">[, tbl_name  &#123;READ [LOCAL] | [LOW_PRIORITY] WRITE&#125;] ...</span><br><span class="line"></span><br><span class="line">UNLOCK TABLES</span><br></pre></td></tr></table></figure><p>事务控制：默认情况，MySQL 是自动提交的，CHAIN 会立即启动一个新事物，并且和刚才的事务具有相同的隔离级别，RELEASE 则会断开和客户端的连接。另外，所有的 DDL 语句都是不能回滚的。在事务中可以通过定义 SAVEPOINT，指定回滚事务的一个部分，但是不能指定提交事务的一个部分。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">START TRANSACTION | BEGIN [WORK]</span><br><span class="line">COMMIT [WORK] [AND [NO] CHAIN] [[NO] RELEASE]</span><br><span class="line">ROLLBACK [WORK] [AND [NO] CHAIN] [[NO] RELEASE]</span><br><span class="line">SET AUTOCOMMIT &#x3D; &#123;0 | 1&#125;</span><br></pre></td></tr></table></figure><p>分布式事务：分布式事务通常涉及到一个事务管理器和多个资源管理器，采用两阶段提交。</p><h2 id="第十五章-SQL中的安全问题"><a href="#第十五章-SQL中的安全问题" class="headerlink" title="第十五章 SQL中的安全问题"></a>第十五章 SQL中的安全问题</h2><p>SQL 注入：利用数据库的外部接口将用户数据插入到实际的 SQL 语言中，从而达到入侵的目的。常见的语句：<code>SELECT * FROM user WHERE username=&#39;$username&#39; AND password= &#39;$password&#39;;</code>，此时对 username 赋值为<code>angel&#39; or &#39;1=1</code>，<code>angel&#39;/*</code>或<code>angel&#39;#</code>都会导致注入成功，前者使用逻辑，后者使用注释。</p><p>应对方式：</p><ul><li>PrepareStatement + Bind-Variable：通过转义用户输入的参数防护</li><li>使用应用程序提供的转换函数：如<code>mysql_real_escape_string() </code></li><li>自定义：正则校验，特殊字符转义等</li></ul><h2 id="第十六章-SQL-Mode及其相关问题"><a href="#第十六章-SQL-Mode及其相关问题" class="headerlink" title="第十六章 SQL Mode及其相关问题"></a>第十六章 SQL Mode及其相关问题</h2><p>SQL Mode 简介：SQL Mode 通常用来解决以下问题：</p><ul><li>设置不同的 SQL Mode，可以设置不同程度的数据校验，保证准确性</li><li>通过设置为 ANSI 模式，便于迁移</li><li>在数据迁移之前，改变 SQL Mode，可以便于数据迁移</li></ul><p>SQL Mode 功能：</p><ul><li>校验日期数据合法性</li><li>MOD(X, 0) 在 TRADITIONAL 模式下会直接产生错误</li><li>启用 NO_BACKSLASH_ESCAPE 使得反斜线成为普通字符</li><li>启用 PIPES_AS_CONCAT 模式，将<code>|</code>视作字符串的链接操作符</li></ul><p>常见的 SQL Mode：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20210305190614244.png" class="lazyload" data-srcset="image-20210305190614244.png" srcset="data:image/png;base64,666" alt="image-20210305190614244"/></div><span class="image-caption">image-20210305190614244</span></div><p>SQL Mode 在迁移中使用方式：可以通过组合不同的 sql_mode 来构成适合于其他数据库的数据格式，这样就可以使得导出的数据更容易导入到对应的数据库。</p><h2 id="第十七章-MySQL分区"><a href="#第十七章-MySQL分区" class="headerlink" title="第十七章 MySQL分区"></a>第十七章 MySQL分区</h2><p>概述：分区有利于管理非常大的表，采用分而治之的思想，将表分成一系列的分区，分区对于应用来说是完全透明的，具体而言，使用分区的好处有：</p><ul><li>和单个磁盘相比，能存储更多的数据</li><li>优化查询</li><li>通过删除分区直接删除相关的数据</li><li>跨多个磁盘，能获得更大的吞吐量</li></ul><p>分区类型：无论那种分区，都只能使用主键或者唯一键</p><ul><li>RANGE 分区：给予一个给定的连续区间范围，将数据分配到不同分区。使用<code>VALUES LESS THAN</code>划定范围。</li><li>LIST 分区：类似 RANGE 分区，不过 LIST 对应的是枚举值。使用<code>VALUES IN</code>划定分区。</li><li>COLUMNS 分区：支持分区的键的数据类型更广，并且支持多列分区（多列排序）。又分为<code>RANGE COLUMNS</code>和<code>LIST COLUMNS</code>。</li><li>HASH 分区：给予给定的分区个数，将数据分区。主要用于分散热点读，确保负载均衡。使用<code>PARTITION BY HASH(expr) PARTITIONS num</code>进行分区，底层采用的是 MOD 算法。常规的 HASH 算法挺不错，但是需要增加分区或者合并分区的时候，问题就出现了，即需要重新 MOD 计算。为此，可以使用线性 HASH 分区，其优点在于存在分区维护的时候，MySQL 能够处理得更加迅速。</li><li>KEY 分区：类似于 HASH 分区，只不过 HASH 分区允许使用用户自定义的表达式，而 Key 分区不允许使用用户自定义的表达式，需要使用 MySQL 服务器提供的 HASH 函数。</li><li>子分区：指对每个分区的再次分割，使用<code>SUBPARTITION BY</code>语句实现。</li></ul><p>分区管理：</p><ul><li><p>RANGE &amp; LIST 分区管理：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; 删除</span><br><span class="line">ALTER TABLE tbl_name DROP PARTITION p_name;</span><br><span class="line">&#x2F;&#x2F; 添加</span><br><span class="line">ALTER TABLE tbl_name ADD PARTITION (patition_stmt);</span><br><span class="line">&#x2F;&#x2F; 重新组织</span><br><span class="line">ALTER TABLE tbl_name REORGANIZE PARTITION p_name into (patition_stmt);</span><br></pre></td></tr></table></figure></li><li><p>HASH &amp; KEY 分区管理：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; 合并</span><br><span class="line">ALTER TABLE tbl_name COALESCE PARTITION p_num;</span><br><span class="line">&#x2F;&#x2F; 增加</span><br><span class="line">ALTER TABLE tbl_name ADD PARTITIONS p_num;</span><br></pre></td></tr></table></figure></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> MySQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>《Java并发编程实战》笔记</title>
      <link href="2020/12/17/%E3%80%8AJava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98%E3%80%8B%E7%AC%94%E8%AE%B0/"/>
      <url>2020/12/17/%E3%80%8AJava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98%E3%80%8B%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<p>本文总结了《Java并发编程实战》中的关键点，可以用于查阅其中的知识点。</p><a id="more"></a><h2 id="第二章-线程安全性"><a href="#第二章-线程安全性" class="headerlink" title="第二章 线程安全性"></a>第二章 线程安全性</h2><p>线程安全性：当多个类访问同一个类的时候，这个类始终都能表现出正确的行为，就称该线程是线程安全的。</p><p>原子性：</p><ul><li>竞态条件（Race Condition）：当某个计算的正确性取决于多个线程的交替执行时序时，那么就会发生竞态条件。比如懒汉式单例模式中的 getInstance 方法，基于先检查后执行，由于需要检查 instance 是否为 null，再判断是否需要实例化，此时就存在竞态条件。</li><li>复合操作：指的是将一系列的操作合并成一个，使其满足原子性，比如 AtomicLong 里面的 incrementAndGet 方法。</li></ul><p>加锁机制：</p><ul><li><p>内置锁：使用关键字 synchronized  实现同步锁，修饰方法的时候锁就是方法调用所在的对象，静态的 synchronized 方法以 Class 对象为锁。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">synchronized</span> (lock) &#123;</span><br><span class="line"><span class="comment">// 访问或者修改由锁保护的共享对象</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>重入：当某个线程请求一个由其他线程持有的锁的时候，发出请求的线程会阻塞。但是如果一个线程试图获得一个已经由它自己持有的锁，那么这个请求就会成功。</p></li></ul><h2 id="第三章-对象的共享"><a href="#第三章-对象的共享" class="headerlink" title="第三章 对象的共享"></a>第三章 对象的共享</h2><p>可见性：</p><ul><li>失效数据：一个线程修改某个数据后，如果没有进行同步操作，另外一个线程再去读的话，可能就会读到之前的数据。</li><li>非原子的 64 位操作：Java 内存模型要求，变量的读取和写入都是原子操作，但是对于非 volatile 类型的 long 和 double 变量，JVM 允许将其分解为两个 32 位的操作。此时就可能发生失效数据的读取。</li><li>加锁与可见性：加锁的含义不仅在于互斥行为，还在于内存可见性，为了确保所有的线程能看到共享变量的最新值，所有执行读操作或者写操作的线程必须在同一个锁上同步。</li><li>volatile 变量：对变量的更新操作将会通知到其他线程。不建议过度使用 volatile 变量，因为volatile 变量只能保证可见性，不能确保原子性。</li></ul><p>发布与逸出：发布指对象能够在当前作用域之外的代码中使用；逸出指的是当某个不应该被发布的对象被发布。不要在构造过程中使得 this 逸出，常见错误是在构造函数中启动一个线程。</p><p>线程封闭：避免同步的方式就是不共享数据，如果仅在单线程内访问数据，就不需要同步，这就是线程封闭。</p><ul><li>Ad-hoc 线程封闭：维护线程封闭的职责完全由程序实现来承担。</li><li>栈封闭：是线程封闭的一种特例，在栈封闭中，只能通过局部变量才能访问到对象。</li><li>ThreadLocal 类：能使线程中的某个值与保存值的对象关联起来。ThreadLocal 提供 get 和 set 方法，这些方法为每个使用该变量的线程都存有一份独立副本，因此是线程独立的。通常用于防止对可变的单例变量或全局变量进行共享。</li></ul><p>不变性：不可变对象一定是线程安全的。</p><ul><li>final 域：用于构造不可变性对象，使用 final 修饰的域是不可更改的。另外，final 域可以确保初始化过程的安全性。</li></ul><h2 id="第四章-对象的组合"><a href="#第四章-对象的组合" class="headerlink" title="第四章 对象的组合"></a>第四章 对象的组合</h2><p>设计线程安全的类：收集同步需求，以来状态的操作，状态的所有权。</p><p>实例封闭：封装简化了线程安全类的实现过程，当一个对象封装到另外一个对象中的时候，能够访问被封装对象的代码路径都是已知的，这样更适合对代码进行分析和加锁。</p><ul><li><p>Java 监视器模式：使用私有锁对象而不是对象的内置锁的优点有，私有的锁对象可以将锁封装起来，但是客户端还是可以获取到共有方法来访问锁。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ProvateLock</span> </span>&#123;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> Object myLock = <span class="keyword">new</span> Object();</span><br><span class="line">Widget widget;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">someMethod</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="keyword">synchronized</span> (myLock) &#123;</span><br><span class="line"><span class="comment">// 访问修改Widget的状态</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><p>在现有的线程安全类中添加功能：</p><ul><li>客户端加锁机制：对于使用某个对象 X 的客户端代码，使用 X 本身用于保护其状态的锁来保护这段客户端代码。</li><li>组合：使用组合方法构建对象，同时在上层再次加锁，实现同步。</li></ul><h2 id="第五章-基础构建模块"><a href="#第五章-基础构建模块" class="headerlink" title="第五章 基础构建模块"></a>第五章 基础构建模块</h2><p>同步容器类：</p><ul><li>问题：同步容器类都是线程安全的，但是在某些情况需要额外的客户端加锁实现复合操作。</li><li>迭代器与 ConcurrentModificationException：如果在迭代期间对迭代对象进行了修改，可能就会抛出该异常。可以使用加锁来解决该问题，但是可能会带来验证 的性能问题。如果不想在迭代期间对对象进行加锁操作，可以先克隆容器，并在副本上迭代。</li><li>隐藏迭代器：比如打印一个 set 的时候就隐式用到了迭代器。</li></ul><p>并发容器：</p><ul><li>ConcurrentHashMap：同步容器类在执行期间都持有一个锁，而并发容器类则使用了一种不同的加锁策略：使用粒度更细的加锁机制实现最大程度的共享，称为分段锁。该策略能够在并发编程的环境中实现更大的吞吐量。另外，并发容器类提供的迭代器不会抛出 ConcurrentModificationException，因此不需要在迭代过程中对容器加锁。由于他们返回的迭代器具有弱一致性，也即可以容忍并发的修改，当创建迭代器会遍历已有的元素，并可以（不保证）在迭代器构造后将修改反映给容器。</li><li>额外的原子 Map 操作：由于并发容器不支持加锁，因此我们不能基于加锁来实现复合操作。但是，一些复合原子操作已经内置提供：<code>putifAbsent</code>，<code>remove</code>和<code>replace</code>。</li><li>CopyOnWriteArrayList：用于替代 List，提供更好的并发性能，并且迭代器件不需要对容器加锁或者复制。每次修改容器的时候都会复制底层数组，需要一定开销。</li></ul><p>阻塞队列和生产者-消费者模式：</p><ul><li>阻塞队列：提供了可阻塞的 put 和 take 方法，以及支持定时的 offer 和 poll 方法。如果队列满了，那么 put 方法阻塞直到有空间可用。阻塞队列提供了 offer 方法，如果数据项不能添加到队列中，将返回失败状态，客户端可以根据此来调整生产者的数量。类库有 LinkedBlockingQueue 和 ArrayBlockingQueue。</li><li>串行线程封闭：对于可变对象，生产者-消费者和阻塞队列一起，促进了穿行线程封闭，从而将对象所有权从生产者交付给消费者。</li><li>双端队列：ArrayDeque 和 LinkedBlockingDeque。双端队列可用于另外一种工作模式，工作密取。在该模式下，每个消费者有自己的双端队列，如果一个消费者完成了自己双端队列中的全部工作，那么它可以从其他消费者双端队列末尾秘密获取工作。</li></ul><p>阻塞方法与中断方法：线程可能会被阻塞，阻塞原因有：等待 IO 操作，等待一个锁，等待从 sleep 中醒来。阻塞的线程只有得到外部某个事件发生的时候，才能脱离阻塞，回到Runnable 状态。而中断是一种协作机制，一个线程不能强制要求其他线程停止正在执行的操作而去执行其他的操作。</p><p>同步工具类：</p><ul><li>闭锁（Latch）：闭锁的作用相当于一扇门：在闭锁到达结束状态之前，这扇门一直关闭，并且没有任何线程能通过，当到达结束状态时，这扇门会打开并且允许所有线程通过。一旦到达结束状态后，就再也不会改变状态。在 Java 中可以使用 CountDownLatch。</li><li>FutureTask：也可用作闭锁。其状态有三种：等待执行，正在运行，运行完成。Future.get 的行为取决于任务的状态，如果任务完成，立即返回结果，否则将阻塞直到任务完成。</li><li>信号量（Semaphore）：计数信号量用来控制访问某个特定资源的操作数量，或者同时执行某个指定操作的数量。可以通过 acquire 和 release 来进行获取和释放信号量的操作。</li><li>栅栏（Barrier）：栅栏类似闭锁，它能阻塞一组线程直到某个时间发生。栅栏和闭锁的关键区别在于，所有线程必须同事到达栅栏位置，才能继续执行。闭锁用于等待事件，栅栏则用于等待其他线程。CyclicBarrier 可以使一定数量的参与方反复在栅栏处汇集。当线程达到栅栏的时候，调用 await 方法，这个方法将阻塞直到所有线程都到达栅栏位置。如果所有线程都到达，那么栅栏将会打开，此时所有线程将被释放，而栅栏被重置以便下次使用。如果对 await 的调用超时，那么栅栏就被认为是打破了，所有阻塞的 await 调用将终止并且抛出 BrokenBarrierException。</li></ul><h2 id="第六章-任务执行"><a href="#第六章-任务执行" class="headerlink" title="第六章 任务执行"></a>第六章 任务执行</h2><p>在线程中执行任务：</p><ul><li>串行地执行任务：每次只会执行一个任务，但是执行的性能低下。</li><li>显式地为任务创建线程：通过为每个请求提供一个新的线程提供服务，实现更高的响应性。</li><li>无限制创建线程的不足：线程生命周期开销高，资源消耗，稳定性。</li></ul><p>Executor 框架：Java 中，任务执行的主要抽象是 Executor，而不是 Thread。Executor 基于生产者-消费者模式。其接口定义：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Executor</span> </span>&#123;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">execute</span><span class="params">(Runnable command)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>线程池：指的是管理一组同构工作线程的资源池。通过重用现有的线程而不是创建新的线程来处理新的请求，可以减少新的线程的创建和销毁的开销。通常需要配置一个合适大小的线程池，使得提高处理器的效率和防止过多线程竞争资源使得内存耗尽。在 Java 中可以通过调用静态工厂方法来创建一个线程池：<code>newFixedThreadPool</code>，<code>newCachedThreadPool</code>，<code>newSingleThreadPool</code>，<code>newScheduledThreadPool</code>。</li><li>Executor 生命周期：添加了 ExecutorService 接口，其中包含了3种状态：运行，关闭和已终止。shutdown 方法将会执行平缓的关闭过程：不再接受新的任务，同时等待已经提交的任务执行完成。而 shutdownNow 方法则执行粗暴的关闭过程：它将尝试取消所有运行中的任务，同时不再启动队列中尚未开始的任务。</li><li>延迟任务和周期管理：Timer 类负责管理延迟任务以及周期任务。Timer 在执行所有的定时任务的时候只会创建一个线程。如果某个任务的执行时间过长，那么将会破坏其他 TimerTask 的定时精确性。基于以上原因，建议使用 <code>ScheduledThreadPoolExecutor</code>。</li></ul><p>找出可利用的并行性：</p><ul><li><p>携带结果的任务 Callable 和 Future：Runnable 是一种有很大局限的抽象，虽然 run 能写入到日志文件或者某个共享的数据结构，但是它不能返回一个值或者抛出一个异常。Callable 则是一种更好的抽象，他认为主入口点将返回一个值，并可能抛出一个异常。而 Future 则表示一个任务的生命周期，并且提供相应的方法来判断是否完成，以及获取任务的结果等。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Callable</span>&lt;<span class="title">V</span>&gt; </span>&#123;</span><br><span class="line"><span class="function">V <span class="title">call</span><span class="params">()</span> <span class="keyword">throws</span> Exception</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Future</span>&lt;<span class="title">V</span>&gt; </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">boolean</span> <span class="title">cancel</span><span class="params">(<span class="keyword">boolean</span> mayInterruptIfRunning)</span></span>;</span><br><span class="line">  <span class="function"><span class="keyword">boolean</span> <span class="title">isCancelled</span><span class="params">()</span></span>;</span><br><span class="line">  <span class="function"><span class="keyword">boolean</span> <span class="title">isDone</span><span class="params">()</span></span>;</span><br><span class="line">  <span class="function">V <span class="title">get</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException, ExecutionException, CancellationException</span>;</span><br><span class="line">  <span class="function">V <span class="title">get</span><span class="params">(<span class="keyword">long</span> timeout, TimeUnit unit)</span> <span class="keyword">throws</span> InterruptedException, ExecutionException, CancellationException, TimeoutException</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>CompletionService：将 Executor 与 BlockingQueue 的功能结合在一起，通过将一组 Callable 任务提交给它来执行，然后使用 take 和 poll 等方法来获得已经完成的结果，这些结果会被封装成 Future。ExecutorCompletionService 实现了 CompletionService。</p></li><li><p>为任务设置时限：可以通过 Future.get 来支持该需求。</p></li></ul><h2 id="第七章-取消与关闭"><a href="#第七章-取消与关闭" class="headerlink" title="第七章 取消与关闭"></a>第七章 取消与关闭</h2><p>任务取消：</p><ul><li><p>中断：线程中断是一种协作机制，每个线程都有一个 boolean 类型的中断状态。当这个线程被被中断的时候，其状态设置为 true。对于中断操作的正确理解：它不会真正地中断一个正在运行的线程，而只是发出中断请求，然后由线程在下一个合适的时刻中断自己。</p></li><li><p>中断策略：合理的中断策略应该是某种形式的线程级取消操作或者是服务级取消操作。如果需要恢复中断状态：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Thread.currentThread().interrupt();</span><br></pre></td></tr></table></figure></li><li><p>响应中断：当调用可中断的阻塞函数时，如  Thread.sleep，有两种策略用于处理 InterruptException。其一是传递异常，其二是恢复中断状态。</p></li><li><p>通过 Future 实现取消：ExecutorService.submit 将返回一个 Future 来描述任务。Future 拥有一个 cancel 方法，该方法带有一个 boolean 类型的参数 mayInterruptIfRunning。</p></li><li><p>采用 newTaskFor 来封装非标准的取消：newTaskFor 是一个工厂方法，它将创建 Future 代表任务，通过定制表示任务的 Future 可以改表 Future.cancel 的行为。</p></li></ul><p>停止基于线程的服务：</p><ul><li>关闭 ExecutorService：使用 shutdown 或者 shutdownNow。</li><li>毒丸对象：另外一种关闭生产者-消费者的方法就是使用毒丸对象：毒丸是指一个放在队列上的对象，当消费者得到这个对象的时候，立刻停止执行。</li><li>shutdownNow 的局限性：使用该方法的时候，它将会取消所有正在执行的任务，并且返回所有已经提交但尚未开始的任务。然而，我们并不知道那些任务已经开始但是尚未正常结束。</li></ul><p>处理非正常的线程中止：导致线程提前死亡的原因主要就是 RuntimeException。如果没有捕获该异常，程序就会在控制台打印栈信息，然后退出执行。在 Thread 中提供了 UncaughtExceptionHandler，它能检测出某个线程由于未捕获的异常而终结的情况。</p><p>JVM 关闭：</p><ul><li>关闭钩子：在正常的关闭中，JVM 首先调用所有已注册过的关闭钩子（Shutdown Hook）。JVM 不保证关闭钩子的调用顺序。</li><li>守护线程：守护线程不会阻碍 JVM 的关闭。应该尽量少使用守护线程。</li><li>终结期：在回收器释放对象之前，会调用它们的 finalize 方法，从而保证一些持久化的资源被释放。最好不要使用 finalize 方法进行资源回收。</li></ul><h2 id="第八章-线程池的使用"><a href="#第八章-线程池的使用" class="headerlink" title="第八章 线程池的使用"></a>第八章 线程池的使用</h2><p>在任务与执行策略之间的隐性耦合：</p><ul><li>线程饥饿死锁：如果两个线程相互依赖对方的执行结果，那么就会发生饥饿死锁。</li><li>运行时间较长的任务：如果任务的执行时间较长，那么即使不出现死锁，线程池的响应性也会变得很糟糕。可以限定任务等待资源的事件，而不是无限制的等待。如果等待超时，那么需要中止任务或者将任务重新放回队列中。</li></ul><p>设置线程池的大小：配置合适的线程池的大小既不会造成资源的浪费，也不会产生线程频繁切换的代价。</p><p>配置 ThreadPoolExecutor：可以使用它的通用构造函数来自定义：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">ThreadPoolExecutor</span><span class="params">(<span class="keyword">int</span> corePoolSize,</span></span></span><br><span class="line"><span class="function"><span class="params">                          <span class="keyword">int</span> maximumPoolSize,</span></span></span><br><span class="line"><span class="function"><span class="params">                          <span class="keyword">long</span> keepAliveTime,</span></span></span><br><span class="line"><span class="function"><span class="params">                          TimeUnit unit,</span></span></span><br><span class="line"><span class="function"><span class="params">                          BlockingQueue&lt;Runnable&gt; workQueue,</span></span></span><br><span class="line"><span class="function"><span class="params">                          ThreadFactory threadFactory,</span></span></span><br><span class="line"><span class="function"><span class="params">                          RejectedExecutionHandler handler)</span> </span>&#123; ... &#125;</span><br></pre></td></tr></table></figure><ul><li>线程的创建和销毁：线程池的基本大小，最大大小以及存活时间等因素共同负责线程的创建与销毁。</li><li>管理任务队列：ThreadPoolExecutor 允许提供一个 BlockingQueue 来保存等待执行的任务。基本的任务排队方式有三种：无界队列，有界队列和同步移交。</li><li>饱和策略：当有界队列被填满后，饱和策略开始发挥作用。如中止，抛弃，抛弃最旧的。调用者运行策略既不会抛弃任务，也不会抛出异常，而是将某些任务会退到调用者，从而降低新任务的流量。</li><li>线程工厂：每当线程池需要创建一个线程的时候，都是通过线程工厂方法来完成的。通过实现 ThreadFactory 接口，可以进行定制化的工作。</li></ul><p>扩展 ThreadPoolExecutor：可以在子类中改写 beforeExecute，afterExecute 和 terminated 方法来实现定制。</p><h2 id="第十章-避免活跃性危险"><a href="#第十章-避免活跃性危险" class="headerlink" title="第十章 避免活跃性危险"></a>第十章 避免活跃性危险</h2><p>死锁：</p><ul><li>锁顺序死锁：两个线程试图以不同的顺序获得相同的锁。通过固定顺序获得锁，可以消除该问题。</li><li>动态的锁顺序死锁：考虑 <code>transfer(from, to, amount)</code>，如果存在<code>transfer(A, B, 10)</code> 和 <code>transfer(B, A, 10)</code> ，那么就可能发生死锁。</li><li>开放调用：如果在调用某个方法的时候不需要持有锁，那么称其为开放调用。</li><li>资源死锁：当多个线程相互持有彼此正在等待的锁而又不释放自己已经持有的锁的时候，就会发生死锁。</li></ul><p>死锁的避免和检测：</p><ul><li>支持定时的锁：可以使用 Lock 类的定时 tryLock 功能来代替内置锁机制。当使用内置锁的时候，只要没有获得锁就会一直等待下去，而显式锁则可以指明一个超时时限。</li><li>通过线程转储信息来分析死锁：线程转储信息中包含了加锁信息，例如每个线程持有了哪些锁，在那些栈帧中获得了这些锁，以及被阻塞的线程正在等待哪一个锁。</li></ul><p>其他活跃性危险：</p><ul><li>饥饿：当线程无法访问它所需要的资源而不能继续执行的时候，就会发生饥饿。引发饥饿的最常见资源就是 CPU 时钟周期。</li><li>糟糕的响应性：不良的锁管理也会导致糟糕的响应性。如果某个线程长时间占用锁（容器的迭代），其他想访问该容器的线程就必须等待很长时间。</li><li>活锁：该问题尽管不会阻塞线程，但也不能继续执行，因为线程将不断重复执行相同的操作，而且总会失败。可以通过引入随机性来解决该问题。</li></ul><h2 id="第十一章-性能与可伸缩性"><a href="#第十一章-性能与可伸缩性" class="headerlink" title="第十一章 性能与可伸缩性"></a>第十一章 性能与可伸缩性</h2><p>对性能的思考：</p><ul><li>性能与可伸缩性：性能可以通过服务时间，延迟时间，吞吐率，效率等指标衡量。可伸缩性指的是当增加计算资源时，程序的吞吐量或者处理能力相应增加。</li><li>Amdahl 定律</li></ul><p>线程引入的开销：</p><ul><li>上下文切换</li><li>内存同步：同步可能使用特殊指令，即内存栅栏，该指令可以刷新缓存，使得缓存无效，从而使得各个线程都能看到最新的值。内存栅栏会抑制一些编译器的优化操作。</li><li>阻塞：当在锁上发生竞争的时候，竞争失败的线程就会阻塞。JVM 实现阻塞的行为有自旋等待，或者通过操作系统挂起。</li></ul><p>减少锁的竞争：</p><ul><li>缩小锁的范围</li><li>减少锁的粒度</li><li>锁分段：如 ConcurrentHashMap</li><li>一些替代独占锁的方法：使用并发容器，ReadWriteLock，不可变对象以及原子变量</li></ul><h2 id="第十二章-并发程序的测试"><a href="#第十二章-并发程序的测试" class="headerlink" title="第十二章 并发程序的测试"></a>第十二章 并发程序的测试</h2><p>正确性测试：</p><ul><li>基本的单元测试</li><li>对阻塞操作的测试</li><li>安全性的测试</li><li>资源管理的测试</li></ul><p>性能测试：</p><ul><li>增加计时功能</li><li>多种算法比较</li><li>响应性衡量</li></ul><p>避免性能测试的陷阱：</p><ul><li>垃圾回收：垃圾回收的执行时序是无法预测的</li><li>动态编译</li><li>对代码路径的不真实采样</li><li>不真实的竞争程度</li><li>无用代码消除</li></ul><p>其他的测试方法：</p><ul><li>代码审查</li><li>静态分析工具</li><li>分析与检测工具</li></ul><h2 id="第十三章-显式锁"><a href="#第十三章-显式锁" class="headerlink" title="第十三章 显式锁"></a>第十三章 显式锁</h2><p>Lock 与 ReentrantLock：Lock 接口提供了一种无条件的，可轮询的，定时的以及可中断的锁获取操作。ReentrantLock 则实现了 Lock 接口。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Lock</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">lock</span><span class="params">()</span></span>;</span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">lockInterruptibly</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException</span>;</span><br><span class="line">  <span class="function"><span class="keyword">boolean</span> <span class="title">tryLock</span><span class="params">()</span></span>;</span><br><span class="line">  <span class="function"><span class="keyword">boolean</span> <span class="title">tryLock</span><span class="params">(<span class="keyword">long</span> timeout, TimeUnit unit)</span> <span class="keyword">throws</span> InterruptedException</span>;</span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">unlock</span><span class="params">()</span></span>;</span><br><span class="line">  <span class="function">Condition <span class="title">newCondition</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>轮询锁与定时锁：由 tryLock 方法实现，同时具有完善的错误恢复机制，使用这两种锁可以避免死锁的发生。</li><li>可中断的锁获取操作：lockInterruptibly 方法能够在获得锁的同时保持对中断的响应。</li><li>非块结构的加锁：内置锁中，锁的获取和释放操作都是基于代码块的。而分段锁技术则不是块结构的锁。</li></ul><p>性能考虑因素：在 Java5 中，当线程数增大的时候，内置锁的性能急剧下降，而 ReentrantLock 的性能下降更加平缓。在 Java6 中，两者的可伸缩性基本相同。</p><p>公平性：ReentrantLock 的构造函数中提供了两种公平性的选择：创建一个非公平的锁（默认）或者一个公平的锁。在公平的锁上，线程将按照他们发出请求的顺序来获得锁，但是在非公平的锁上，则允许插队。大多数的情况下，非公平锁的性能高于公平锁的性能。</p><p>在 synchronized 和 ReentrantLock 之间进行选择：ReentrantLock 在加锁和内存上提供的语义与内置锁相同，另外，它还实现了其他功能，如定时的锁等待，公平性以及非块结构的加锁。内置锁则更加简洁，同时能在线程转储中给出哪些栈帧获得了哪些锁。</p><p>读写锁：ReentrantLock 实现了一种标准的互斥锁，互斥通常是一种过硬的加锁规则，因此限制了并发性。可以使用读写锁来改善：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">ReadWriteLock</span> </span>&#123;</span><br><span class="line"><span class="function">Lock <span class="title">readLock</span><span class="params">()</span></span>;</span><br><span class="line"><span class="function">Lock <span class="title">writeLock</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在读写锁的加锁策略中，允许多个操作同时执行，但每次最多只允许一个写操作。ReentrantReadWriteLock 实现了上述接口，提供可重入的语义，同时构造的时候可以选择是否公平锁。</p><h2 id="第十四章-构建自定义的同步工具"><a href="#第十四章-构建自定义的同步工具" class="headerlink" title="第十四章 构建自定义的同步工具"></a>第十四章 构建自定义的同步工具</h2><p>状态依赖性的管理：如 BlockingQueue 中的 put 和 take 操作的前提分别时队列不为空或者满的状态，当前提没有满足的时候，可以抛出异常，或者保持阻塞直到条件被满足。</p><ul><li>条件队列：使得一组线程（等待线程集合）能够通过某种方式来等待特定的条件变成真。Object 中的 wait，notify 和 notifyAll 方法就构成了内部条件队列的 API。Object.wait 会自动释放锁，并且请求操作系统挂起当前线程。当被挂起的线程醒来的时候，它将在返回之前重新获取锁。</li></ul><p>使用条件队列：</p><ul><li>条件谓词：指的是操作正常执行的前提条件，如队列不为空</li><li>过早唤醒：wait 方法的返回并不意味着线程正在等待的条件谓词已经变成真的了。因为可能被其他线程通过 notifyAll 唤醒，但是它的条件为此可能并未变为真的，此时就需要再次进行条件判断。</li><li>丢失的信号：也是一种活跃性故障。指的是线程必须等待一个已经为真的条件，但在开始等待之前没有检查条件谓词。</li><li>通知：在 put 方法成功执行后，将会调用 notifyAll，向任何等待“不为空”条件的线程发出通知。只使用 notify 可能会造成信号丢失的情况。</li></ul><p>显式的 Condition 对象：正如 Lock 是一种广义的内置锁，Condition 也是一种广义的内置条件队列。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Condition</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">await</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException</span>;</span><br><span class="line">  <span class="function"><span class="keyword">boolean</span> <span class="title">await</span><span class="params">(<span class="keyword">long</span> time, TimeUnit unit)</span> <span class="keyword">throws</span> InterruptedException</span>;</span><br><span class="line">  <span class="function"><span class="keyword">long</span> <span class="title">awaitNanos</span><span class="params">(<span class="keyword">long</span> nanosTimeout)</span> <span class="keyword">throws</span> InterruptedException</span>;</span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">awaitUninterruptibly</span><span class="params">()</span></span>;</span><br><span class="line">  <span class="function"><span class="keyword">boolean</span> <span class="title">awaitUntil</span><span class="params">(Date deadline)</span> <span class="keyword">throws</span> InterruptedException</span>;</span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">signal</span><span class="params">()</span></span>;</span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">signalAll</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>内置锁的缺陷在于每个内置锁都只能有一个相关联的条件队列。而 Condition 和 Lock 一起使用就可以消除该问题。和内置条件队列不同的是，对于每个 Lock，可以有任意数量的 Condition 对象。在 Condition 中相应的方法是 await，signal 和 signalAll。</p><p>Synchronizer 剖析：在 ReentrantLock 和 Semaphore 两个接口存在许多共同点，如都可以用作阀门，即每次只允许一定数量的线程通过；都支持可中断；都支持公平和非公平的队列操作。事实上，它们的实现都使用了一个共同的基类，AbstractQueuedSynchronizer（AQS）。AQS 是一个用于构建锁和同步器的框架，CountDownLatch，ReentrantReadWriteLock 和 FutureTask 都是基于 AQS 实现。</p><p>同步容器中的 AQS：</p><ul><li>ReentrantLock：支持独占，实现了 tryAcquire，tryRelease 和 isHeldExclusively。将同步状态用于保存锁获取操作的次数，还维护一些 owner 的变量保存当前所有者线程的标识符。</li><li>Semaphore 和 CountDownLatch：前者将同步状态用于保存当前可用许可的数量，后者保存当前的计数值。</li><li>FutureTask：同步状态用来保存任务的状态。</li></ul><h2 id="第十五章-原子变量与非阻塞同步机制"><a href="#第十五章-原子变量与非阻塞同步机制" class="headerlink" title="第十五章 原子变量与非阻塞同步机制"></a>第十五章 原子变量与非阻塞同步机制</h2><p>锁的劣势：重量级的同步方式，使用 volatile 变量可以同步，但是不支持原子操作，另外，当一个线程正在等待锁的时候，不能做任何有用的事情。</p><p>原子变量类：</p><ul><li>原子变量是一种更好的 volatile：原子变量不但支持同步操作，还提供部分原子操作支持。</li><li>锁与原子变量的性能比较：在高度竞争的情况下，锁的性能超过原子变量的性能；而在适度竞争情况下，原子变量的性能超过锁的性能。</li></ul><p>非阻塞算法：如果在某个算法中，一个线程的失败挥着挂起不会造成其他线程的失败或挂起，俺么该算法就是非阻塞算法。</p><ul><li>非阻塞的栈</li><li>非阻塞的链表</li><li>原子的域更新器：compareAndSet 保证了操作的原子性</li></ul><h2 id="第十六章-Java-内存模型"><a href="#第十六章-Java-内存模型" class="headerlink" title="第十六章 Java 内存模型"></a>第十六章 Java 内存模型</h2><p>内存模型：</p><ul><li><p>在共享内存的多处理器体系结构中，每个处理器有自己的缓存，并且定期的与主内存进行协调。在需要进行内存同步的时候，就可以执行内存栅栏指令，来保证数据的一致性。JVM 通过在合适的位置上插入内存栅栏来屏蔽 JMM 与底层平台内存模型的差异。</p></li><li><p>重排序</p></li><li><p>Java 内存模型：如果两个操作之间缺乏 Happens-Before 关系，那么 JVM 就可以对他们进行任意重排序。</p><blockquote><p>Happens-Before 的规则包括：</p><ul><li>程序顺序规则</li><li>监视器锁规则</li><li>volatile 变量规则</li><li>线程启动规则</li><li>线程结束规则</li><li>中断规则</li><li>终结期规则</li><li>传递性</li></ul></blockquote></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>《Effective Java》笔记</title>
      <link href="2020/12/06/%E3%80%8AEffective-Java%E3%80%8B%E7%AC%94%E8%AE%B0/"/>
      <url>2020/12/06/%E3%80%8AEffective-Java%E3%80%8B%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<p>本文是《Effective Java》第三版的读书笔记。</p><a id="more"></a><h2 id="第二章-创建和销毁对象"><a href="#第二章-创建和销毁对象" class="headerlink" title="第二章 创建和销毁对象"></a>第二章 创建和销毁对象</h2><ol><li><p>考虑使用静态工厂方法代替构造函数：获取一个类的实例的传统方式是使用类提供的公开构造函数，另外一种方法是类提供公开静态工厂方法，用于返回实例。使用静态工厂方法优点：</p><ul><li>静态工厂方法有确切名称，便于阅读</li><li>静态工厂方法不需要在每次调用时创建新对象</li><li>可以通过静态工厂方法获取返回类型的任何子类的对象，提供灵活性</li><li>返回对象的类可以随调用的不同而变化，作为输入参数的函数，声明的返回类型的任何子类型都是允许的</li><li>当编写包含方法的类时，返回对象的类不需要存在，如JDBC</li></ul><p>静态工厂方法缺点：</p><ul><li>没有公共或受保护构造函数的类不能被子类化</li><li>程序员很难找到它们，下面是一些静态工厂方法的常用名称：<ul><li>from：一种类型转换方法，接收单个参数并且返回相应实例</li><li>of：一个聚合方法，接受多个参数返回一个实例</li><li>valueOf：替代from和of但是更加冗长的方法</li><li>instance或getInstance：返回一个实例，该实例由参数描述，但具有不同的值（可能会缓存）</li><li>create或newInstance：该方法保证每个调用都返回一个新实例</li><li>getType：类似于 getInstance，但如果工厂方法位于不同的类中，则使用此方法</li><li>newType：与 newInstance 类似，但是如果工厂方法在不同的类中使用</li><li>type：一个用来替代 getType 和 newType 的比较简单的方式</li></ul></li></ul></li><li><p>当构造函数有多个参数的时候，考虑使用构造器：静态工厂和构造函数都有一个局限，就是不能对大量可选参数做很好的扩展。当我们的可选参数个数大于4个时，往往需要重载很多个构造函数，会降低代码的可维护性。另外一种选择是JavaBean模式，但是JavaBean可能在构建的过程中处于不一致状态。此时我们可以使用构造器来生成所需对象。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Builder Pattern</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">NutritionFacts</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> servingSize;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> servings;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> calories;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> fat;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> sodium;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> carbohydrate;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Builder</span> </span>&#123;</span><br><span class="line">        <span class="comment">// Required parameters</span></span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> servingSize;</span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> servings;</span><br><span class="line">        <span class="comment">// Optional parameters - initialized to default values</span></span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">int</span> calories = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">int</span> fat = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">int</span> sodium = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">int</span> carbohydrate = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="title">Builder</span><span class="params">(<span class="keyword">int</span> servingSize, <span class="keyword">int</span> servings)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.servingSize = servingSize;</span><br><span class="line">            <span class="keyword">this</span>.servings = servings;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> Builder <span class="title">calories</span><span class="params">(<span class="keyword">int</span> val)</span> </span>&#123;</span><br><span class="line">            calories = val;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">this</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> Builder <span class="title">fat</span><span class="params">(<span class="keyword">int</span> val)</span> </span>&#123;</span><br><span class="line">            fat = val;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">this</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> Builder <span class="title">sodium</span><span class="params">(<span class="keyword">int</span> val)</span> </span>&#123;</span><br><span class="line">            sodium = val;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">this</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> Builder <span class="title">carbohydrate</span><span class="params">(<span class="keyword">int</span> val)</span> </span>&#123;</span><br><span class="line">            carbohydrate = val;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">this</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> NutritionFacts <span class="title">build</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> NutritionFacts(<span class="keyword">this</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">NutritionFacts</span><span class="params">(Builder builder)</span> </span>&#123;</span><br><span class="line">        servingSize = builder.servingSize;</span><br><span class="line">        servings = builder.servings;</span><br><span class="line">        calories = builder.calories;</span><br><span class="line">        fat = builder.fat;</span><br><span class="line">        sodium = builder.sodium;</span><br><span class="line">        carbohydrate = builder.carbohydrate;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这样我们在生成代码的时候就可以通过链式调用来生成我们的对象实例。构造器模式很灵活，一个构造器可以构造多个对象。但是构造器的缺点就是为了创建一个对象，必须首先创建它的构造器。</p></li><li><p>使用私有构造函数或枚举类型实施单例模式：实现单例模式的第一种方法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Singleton with public final field</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Elvis</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> Elvis INSTANCE = <span class="keyword">new</span> Elvis();</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">Elvis</span><span class="params">()</span> </span>&#123; ... &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">leaveTheBuilding</span><span class="params">()</span> </span>&#123; ... &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上述代码可以防止用户来自己创建Elvis实例。但是拥有特殊权限的客户端可以借助AccessibleObject.setAccessible 方法利用反射调用私有构造函数，如果需要防范这种问题，需要修改构造器，使其在请求创建第二个实例的时候抛出异常即可。另外一种方法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Singleton with static factory</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Elvis</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Elvis INSTANCE = <span class="keyword">new</span> Elvis();</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">Elvis</span><span class="params">()</span> </span>&#123; ... &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Elvis <span class="title">getInstance</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> INSTANCE; &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">leaveTheBuilding</span><span class="params">()</span> </span>&#123; ... &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>静态工厂方法的一个优点是，它可以在不更改 API 的情况下决定类是否是单例，如为每个线程返回一个单例；第二个优点是，如果应用程序需要的话，可以编写泛型的单例工厂。实现单例的第三种方法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Enum singleton - the preferred approach</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">enum</span> Elvis &#123;</span><br><span class="line">    INSTANCE;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">leaveTheBuilding</span><span class="params">()</span> </span>&#123; ... &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这种方法类似于 public 字段方法，但是它更简洁，默认提供了序列化机制，提供了对多个实例化的严格保证，即使面对复杂的序列化或反射攻击也是如此。</p></li><li><p>用私有构造函数实现不可实例化：对于一个工具类库，如Arrays，实例化这些类是没有意义的。试图通过使类抽象来实施不可实例化是行不通的。因为可以对类进行子类化，并实例化子类。有一个简单的习惯用法来确保不可实例化。只有当类不包含显式构造函数时，才会生成默认构造函数，因此可以通过包含私有构造函数使类不可实例化：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Noninstantiable utility class</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UtilityClass</span> </span>&#123;</span><br><span class="line">    <span class="comment">// Suppress default constructor for noninstantiability</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">UtilityClass</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> AssertionError();</span><br><span class="line">    &#125; ... <span class="comment">// Remainder omitted</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>因为显式构造函数是私有的，所以在类之外是不可访问的。AssertionError 不是严格要求的，但是它提供了保障，以防构造函数意外地被调用。</p></li><li><p>依赖注入优于硬连接资源：尽量将类依赖的资源在创建新实例时将资源传递给构造函数，从而实现依赖注入。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Dependency injection provides flexibility and testability</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SpellChecker</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Lexicon dictionary;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">SpellChecker</span><span class="params">(Lexicon dictionary)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.dictionary = Objects.requireNonNull(dictionary);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isValid</span><span class="params">(String word)</span> </span>&#123; ... &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> List&lt;String&gt; <span class="title">suggestions</span><span class="params">(String typo)</span> </span>&#123; ... &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>另外，这种模式的一个有用变体是将资源工厂传递给构造函数。Java 8 中引入的 <code>Supplier&lt;T&gt;</code> 非常适合表示工厂。尽管依赖注入极大地提高了灵活性和可测试性，但它可能会使大型项目变得混乱，这些项目通常包含数千个依赖项。</p></li><li><p>避免创建不必要的对象：作为一个不该做的极端例子，请考虑下面的语句：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">String s = <span class="keyword">new</span> String(<span class="string">&quot;bikini&quot;</span>); <span class="comment">// DON&#x27;T DO THIS!</span></span><br></pre></td></tr></table></figure><p>该语句每次执行时都会创建一个新的 String 实例，而这些对象创建都不是必需的。String 构造函数的参数 <code>(&quot;bikini&quot;)</code> 本身就是一个 String 实例，在功能上与构造函数创建的所有对象相同。另外，有些对象的创建代价很高，如果你需要重复地使用这样一个「昂贵的对象」，那么最好将其缓存以供复用：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Reusing expensive object for improved performance</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RomanNumerals</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Pattern ROMAN = Pattern.compile(<span class="string">&quot;^(?=.)M*(C[MD]|D?C&#123;0,3&#125;)&quot;</span> + <span class="string">&quot;(X[CL]|L?X&#123;0,3&#125;)(I[XV]|V?I&#123;0,3&#125;)$&quot;</span>);</span><br><span class="line">    <span class="function"><span class="keyword">static</span> <span class="keyword">boolean</span> <span class="title">isRomanNumeral</span><span class="params">(String s)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> ROMAN.matcher(s).matches();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>另外，还需要注意基本类型优于包装类，需要提防意外的自动自动装箱。</p></li><li><p>排除过时的对象引用：考虑一个栈的pop操作：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Object <span class="title">pop</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (size == <span class="number">0</span>)</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> EmptyStackException();</span><br><span class="line">    <span class="keyword">return</span> elements[--size];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上述代码没有明显的问题，但是存在内存泄露的隐患：如果堆栈增长，然后收缩，那么从堆栈中弹出的对象将不会被垃圾收集，即使使用堆栈的程序不再引用它们。改进方式：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Object <span class="title">pop</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (size == <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> EmptyStackException();</span><br><span class="line">    Object result = elements[--size];</span><br><span class="line">    elements[size] = <span class="keyword">null</span>; <span class="comment">// Eliminate obsolete reference</span></span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>一般来说，一个类管理它自己的内存时，程序员应该警惕内存泄漏。当释放一个元素时，该元素中包含的任何对象引用都应该被置为 null。</p><p>另一个常见的内存泄漏源是缓存。一旦将对象引用放入缓存中，就很容易忘记它就在那里，并且在它变得无关紧要之后很久仍将它留在缓存中。如果你非常幸运地实现了一个缓存，只要缓存外有对其键的引用，那么就将缓存表示为 WeakHashMap，当条目过时后，条目将被自动删除。</p><p>内存泄漏的第三个常见来源是侦听器和其他回调。 如果你实现了一个 API，其中客户端注册回调，但不显式取消它们，除非你采取一些行动，否则它们将累积。</p></li><li><p>避免使用终结器和清除器：终结器是不可预测的，通常是危险的，也是不必要的。清除器的危险比终结器小，但仍然不可预测、缓慢，而且通常是不必要的。终结器和清除器的一个缺点是不能保证它们会被立即执行，另外一个缺点是它们可能会使的即将要被清理的对象死而复生。终结器和清除器可以充当一个安全网，以防资源的所有者忽略调用它的 close 方法。</p></li><li><p>使用try-with-resources优于try-finally：从历史上看，try-finally 语句是确保正确关闭资源的最佳方法，即使在出现异常或返回时也是如此。但是当存在两个资源的时候，可能就需要嵌套的调用了，这会导致代码不易阅读。最好的方法就是使用try-with-resources：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// try-with-resources on multiple resources - short and sweet</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">copy</span><span class="params">(String src, String dst)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> (InputStream in = <span class="keyword">new</span> FileInputStream(src);OutputStream out = <span class="keyword">new</span> FileOutputStream(dst)) &#123;</span><br><span class="line">        <span class="keyword">byte</span>[] buf = <span class="keyword">new</span> <span class="keyword">byte</span>[BUFFER_SIZE];</span><br><span class="line">        <span class="keyword">int</span> n;</span><br><span class="line">        <span class="keyword">while</span> ((n = in.read(buf)) &gt;= <span class="number">0</span>)</span><br><span class="line">            out.write(buf, <span class="number">0</span>, n);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><h2 id="第三章-对象的通用方法"><a href="#第三章-对象的通用方法" class="headerlink" title="第三章 对象的通用方法"></a>第三章 对象的通用方法</h2><ol start="10"><li><p>覆盖 equals 方法时应该遵守的约定：当满足下面的条件的时候，不应该覆盖equals方法：</p><ul><li>类的每个实例本质上是唯一的</li><li>该类不需要提供逻辑相等测试</li><li>超类已经覆盖了equals，超类行为适合于这个类</li><li>类是私有的或者包私有的，并且你确信它的 equals 方法永远不会被调用</li></ul><p>equals方法实现了等价关系：反身性，对称性，传递性，一致性，最后还需要满足非无效性：即<code>o.equals(null)</code>返回false。为了搞笑实现equals方法，需要：</p><ul><li>使用 == 运算符检查参数是否是对该对象的引用</li><li>使用 instanceof 运算符检查参数是否具有正确的类型</li><li>将参数转换为正确的类型</li><li>对于类中的每个「重要」字段，检查参数的字段是否与该对象的相应字段匹配</li><li>是否满足等价关系</li></ul></li><li><p>当覆盖 equals 方法的时候，总要覆盖 hashCode 方法：由于相等的对象必须具有相等的散列码，如果PhoneNumber没有实现hashCode方法的话：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Map&lt;PhoneNumber, String&gt; m = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">m.put(<span class="keyword">new</span> PhoneNumber(<span class="number">707</span>, <span class="number">867</span>, <span class="number">5309</span>), <span class="string">&quot;Jenny&quot;</span>);</span><br><span class="line"><span class="comment">// m.get(new PhoneNumber(707, 867,5309)) == null</span></span><br></pre></td></tr></table></figure><p>第三行的结果将是null，而不是<code>&quot;Jenny&quot;</code>。实现hashCode方法的一个简单方法步骤：</p><ul><li>声明一个名为 result 的 int 变量，并将其初始化为对象中第一个重要字段的散列码 c</li><li>对象中剩余的重要字段 f，执行以下操作：<ul><li>为字段计算一个整数散列码 c：如果字段是基本数据类型，计算 <code>Type.hashCode(f)</code>，其中 type 是与 f 类型对应的包装类。如果字段是对象引用，并且该类的 equals 方法通过递归调用 equals 方法来比较字段，则递归调用字段上的 hashCode 方法。如果字段是一个数组，则将其每个重要元素都视为一个单独的字段。也就是说，通过递归地应用这些规则计算每个重要元素的散列码，并将每个步骤 2.b 的值组合起来。如果数组中没有重要元素，则使用常量，最好不是 0。如果所有元素都很重要，那么使用 <code>Arrays.hashCode</code>。</li><li>将步骤 2.a 中计算的散列码 c 合并到 result 变量</li></ul></li><li>返回result</li></ul><p>一个简单的demo：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Typical hashCode method</span></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">hashCode</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> result = Short.hashCode(areaCode);</span><br><span class="line">    result = <span class="number">31</span> * result + Short.hashCode(prefix);</span><br><span class="line">    result = <span class="number">31</span> * result + Short.hashCode(lineNum);</span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>始终覆盖 toString 方法：虽然Object提供了默认的toString方法，但是它返回的字符串通常不是用户希望看到的。提供一个好的 toString 实现（能）使类更易于使用，使用该类的系统（也）更易于调试。当实际使用时，toString 方法应该返回对象中包含的所有有用信息。</p></li><li><p>明智地覆盖 clone 方法：Cloneable 接口的目的是作为 mixin 接口，用于让类来宣称它们允许克隆。不幸的是，它没有达到这个目的。它的主要缺点是缺少 clone 方法，并且 Object 类的 clone 方法是受保护的。它决定了 Object 类受保护的 clone 实现的行为：如果一个类实现了 Cloneable 接口，Object 类的 clone 方法则返回该类实例的逐字段拷贝；否则它会抛出 CloneNotSupportedException。默认提供的clone方法执行的是浅拷贝，如果需要深拷贝，就需要自己覆盖clone方法，实现该功能。</p></li><li><p>考虑实现 Comparable 接口：与本章讨论的其他方法不同，compareTo 方法不是在 Object 中声明的。相反，它是 Comparable 接口中的唯一方法。通过让类实现 Comparable，就可与依赖于此接口的所有通用算法和集合实现进行互操作。如果一个类有多个重要的字段，此时就需要用户来指定对应的比较顺序。在 Java 8 中，Comparator 接口配备了一组比较器构造方法，可以流畅地构造比较器。然后可以使用这些比较器来实现 Comparator 接口所要求的 compareTo 方法。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Comparable with comparator construction methods</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Comparator&lt;PhoneNumber&gt; COMPARATOR = comparingInt((PhoneNumber pn) -&gt; pn.areaCode)</span><br><span class="line">    .thenComparingInt(pn -&gt; pn.prefix)</span><br><span class="line">    .thenComparingInt(pn -&gt; pn.lineNum);</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compareTo</span><span class="params">(PhoneNumber pn)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> COMPARATOR.compare(<span class="keyword">this</span>, pn);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><h2 id="第四章-类和接口"><a href="#第四章-类和接口" class="headerlink" title="第四章 类和接口"></a>第四章 类和接口</h2><ol start="15"><li><p>尽量减少类和成员的可访问性：隐藏内部数据和其他实现细节用于实现信息封装，可以解耦组成系统的组件。通用方法是让每个类或者成员尽可能不可访问。对于顶级（非嵌套）类和接口，只有两个可能的访问级别：包私有和公共。如果一个方法覆盖了超类方法，那么它在子类中的访问级别就不能比超类更严格。公共类的实例字段很少采用 public 修饰，因为带有公共可变字段的类通常不是线程安全的。请注意，非零长度的数组总是可变的，因此对于类来说，拥有一个公共静态 final 数组字段或返回该字段的访问器是错误的。如果一个类具有这样的字段或访问器，客户端将能够修改数组的内容。对于 Java 9，作为模块系统的一部分，还引入了另外两个隐式访问级别。模块是包的分组单位，就像包是类的分组单位一样。模块可以通过模块声明中的导出声明显式地导出它的一些包。</p></li><li><p>在公共类中，使用访问器方法，而不是公共字段：如果类可以在包之外访问，那么提供访问器方法来保持更改类内部表示的灵活性。但是，如果一个类是包级私有的或者是私有嵌套类，那么公开它的数据字段并没有什么本质上的错误。无论是在类定义还是在使用它的客户端代码中，这种方法产生的视觉混乱都比访问方法少。虽然公共类直接公开字段从来都不是一个好主意，但是如果字段是不可变的，那么危害就会小一些。</p></li><li><p>减少可变性：不可变类就是一个实例不能被修改的类。要使类不可变，请遵循以下 5 条规则：</p><ol><li>不要提供修改对象状态的方法</li><li>确保类不能被扩展</li><li>所有字段用 final 修饰</li><li>所有字段设为私有</li><li>确保对任何可变组件的独占访问</li></ol><p>不可变对象提供的好处：</p><ol><li>不可变对象本质上是线程安全的</li><li>不可变对象可以很好的作为其他对象的构建模块</li><li>不可变对象自带提供故障原子性。他们的状态从未改变，所以不可能出现暂时的不一致。</li></ol><p>不可变类的主要缺点是每个不同的值都需要一个单独的对象。</p></li><li><p>优先选择复合而不是继承：在包中使用继承是安全的，其中子类和超类实现由相同的程序员控制。在对专为扩展而设计和文档化的类时使用继承也是安全的。然而，对普通的具体类进行跨包边界的继承是危险的。与方法调用不同，继承破坏了封装。换句话说，子类的功能正确与否依赖于它的超类的实现细节。子类脆弱的一个原因是他们的超类可以在后续版本中获得新的方法。有一种方法可以避免上述所有问题。与其扩展现有类，不如为新类提供一个引用现有类实例的私有字段。这种设计称为复合，因为现有的类是新类的一个组件。只有在子类确实是超类的子类型的情况下，继承才合适。换句话说，只有当两个类之间存在「is-a」关系时，类 B 才应该扩展类 A。</p></li><li><p>继承要设计良好并且具有文档，否则禁止使用：首先，类必须精确地在文档中记录覆盖任何方法的效果。换句话说，类必须在文档中记录它对可覆盖方法的自用性。对于每个公共或受保护的方法，文档必须指出方法调用的可覆盖方法、调用顺序以及每次调用的结果如何影响后续处理过程。但是，这是否违背了一个格言：好的 API 文档应该描述一个给定的方法做什么，而不是如何做？是的，它确实违背了！这是继承违反封装这一事实的不幸结果。要为一个类编制文档，使其能够安全地子类化，你必须描述实现细节，否则这些细节应该是未指定的。为了允许继承，类必须遵守更多的限制。构造函数不能直接或间接调用可重写的方法。 如果你违反了这个规则，程序就会失败。超类构造函数在子类构造函数之前运行，因此在子类构造函数运行之前将调用子类中的覆盖方法。如果重写方法依赖于子类构造函数执行的任何初始化，则该方法的行为将不像预期的那样。</p></li><li><p>接口优于抽象类：Java 有两种机制来定义允许多种实现的类型：接口和抽象类。由于 Java 8 中引入了接口的默认方法，这两种机制都允许你为一些实例方法提供实现。一个主要区别是，一个类要实现抽象类定义的类型，该类必须是抽象类的子类。因为 Java 只允许单一继承，这种限制对抽象类而言严重制约了它们作为类型定义的使用。使用接口的优点：</p><ol><li>可以很容易地对现有类进行改造，以实现新的接口</li><li>接口是定义 mixin（混合类型）的理想工具</li><li>接口允许构造非层次化类型框架</li></ol></li><li><p>为后代设计接口：在 Java 8 之前，在不破坏现有实现的情况下向接口添加方法是不可能的。如果在接口中添加新方法，通常导致现有的实现出现编译时错误，提示缺少该方法。在 Java 8 中，添加了默认的方法构造，目的是允许向现有接口添加方法。除非必要，否则应该避免使用默认方法向现有接口添加新方法，在这种情况下，你应该仔细考虑现有接口实现是否可能被默认方法破坏。尽管默认方法现在已经是 Java 平台的一部分，但是谨慎地设计接口仍然是非常重要的。虽然默认方法使向现有接口添加方法成为可能，但这样做存在很大风险。 如果一个接口包含一个小缺陷，它可能会永远影响它的使用者；如果接口有严重缺陷，它可能会毁掉包含它的 API。</p></li><li><p>接口只用于定义类型：当一个类实现了一个接口时，这个接口作为一种类型，可以用来引用类的实例。不满足上述条件的一种接口是所谓的常量接口。如果你想导出常量，有几个合理的选择。如果这些常量与现有的类或接口紧密绑定，则应该将它们添加到类或接口。例如，所有数值包装类，比如 Integer 和 Double，都导出 MIN_VALUE 和 MAX_VALUE 常量。如果将这些常量看作枚举类型的成员，那么应该使用 enum 类型导出它们。否则，你应该使用不可实例化的工具类导出常量。</p></li><li><p>类层次结构优于带标签的类：有时候，你可能会遇到这样一个类，它的实例有两种或两种以上的样式，并且包含一个标签字段来表示实例的样式。这样的标签类有许多缺点。它们充斥着样板代码，包括 enum 声明、标签字段和 switch 语句。标签类冗长、容易出错和低效。面向对象的语言提供了一个更好的选择来定义能够表示多种类型对象的单一数据类型：子类型。标签类只是类层次结构的简易模仿。</p></li><li><p>静态成员类优于非静态成员类：有四种嵌套类：静态成员类、非静态成员类、匿名类和局部类。除了第一种，所有的类都被称为内部类。静态成员类是最简单的嵌套类。最好把它看做是一个普通的类，只是碰巧在另一个类中声明而已，并且可以访问外部类的所有成员，甚至那些声明为 private 的成员。静态成员类的一个常见用法是作为公有的辅助类。从语法上讲，静态成员类和非静态成员类之间的唯一区别是静态成员类在其声明中具有修饰符 static。如果声明的成员类不需要访问外部的实例，那么应始终在声明中添加 static 修饰符，使其成为静态的而不是非静态的成员类。匿名类的适用性有很多限制。你不能实例化它们，除非在声明它们的时候。在 lambda 表达式被添加到 Java 之前，匿名类是动态创建小型函数对象和进程对象的首选方法，但 lambda 表达式现在是首选方法。局部类是四种嵌套类中最不常用的。局部类几乎可以在任何能够声明局部变量的地方使用，并且遵守相同的作用域规则。局部类具有与其他嵌套类相同的属性。</p></li><li><p>源文件仅限有单个顶层类：虽然 Java 编译器允许你在单个源文件中定义多个顶层类，但这样做没有任何好处，而且存在重大风险。这种风险源于这样一个事实：在源文件中定义多个顶层类使得为一个类提供多个定义成为可能。</p></li></ol><h2 id="第五章-泛型"><a href="#第五章-泛型" class="headerlink" title="第五章 泛型"></a>第五章 泛型</h2><ol start="26"><li><p>不要使用原始类型：声明中具有一个或多个类型参数的类或接口就是泛型类或泛型接口，每个泛型都定义了一个原始类型，它是没有任何相关类型参数的泛型的名称。例如，<code>List&lt;E&gt;</code> 对应的原始类型是 List。原始类型的行为就好像所有泛型信息都从类型声明中删除了一样。它们的存在主要是为了与之前的泛型代码兼容。当从集合中检索元素时，编译器会为你执行不可见的强制类型转换，并确保它们不会失败。使用原始类型（没有类型参数的泛型）是合法的，但是你永远不应该这样做。如果使用原始类型，就会失去泛型的安全性和表现力。考虑如下程序：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Fails at runtime - unsafeAdd method uses a raw type (List)!</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    List&lt;String&gt; strings = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">    unsafeAdd(strings, Integer.valueOf(<span class="number">42</span>));</span><br><span class="line">    String s = strings.get(<span class="number">0</span>); <span class="comment">// Has compiler-generated cast</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">unsafeAdd</span><span class="params">(List list, Object o)</span> </span>&#123;</span><br><span class="line">    list.add(o);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>该程序可以编译，但因为它使用原始类型 List，所以你会得到一个警告：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Test.java:10: warning: [unchecked] unchecked call to add(E) as a</span><br><span class="line">member of the raw type List</span><br><span class="line">list.add(o);</span><br><span class="line">^</span><br></pre></td></tr></table></figure><p>实际上，如果你运行程序，当程序试图将调用 <code>strings.get(0)</code> 的结果强制转换为字符串时，你会得到一个 ClassCastException。这是一个由编译器生成的强制类型转换，它通常都能成功，但在本例中，我们忽略了编译器的警告，并为此付出了代价。</p><p>如果将 unsafeAdd 声明中的原始类型 List 替换为参数化类型 <code>List</code>，并尝试重新编译程序，你会发现它不再编译，而是发出错误消息：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Test.java:5: error: incompatible types: List&lt;String&gt; cannot be</span><br><span class="line">converted to List&lt;Object&gt;</span><br><span class="line">unsafeAdd(strings, Integer.valueOf(42));</span><br><span class="line">^</span><br></pre></td></tr></table></figure><p>对于元素类型未知且无关紧要的集合，你可能会尝试使用原始类型。这种方法是可行的，但是它使用的是原始类型，这是很危险的。安全的替代方法是使用无界通配符类型。如果你想使用泛型，但不知道或不关心实际的类型参数是什么，那么可以使用问号代替。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; Uses unbounded wildcard type - typesafe and flexible</span><br><span class="line">static int numElementsInCommon(Set&lt;?&gt; s1, Set&lt;?&gt; s2) &#123; ... &#125;</span><br></pre></td></tr></table></figure><p>对于不应该使用原始类型的规则，有一些小的例外。必须在类字面量中使用原始类型。换句话说，<code>List.class</code>，<code>String[].class</code> 和 <code>int.class</code> 都是合法的，但是 <code>List.class</code> 和 <code>List.class</code> 不是。第二个例外是 instanceof 运算符。由于泛型信息在运行时被删除，因此在不是无界通配符类型之外的参数化类型上使用 instanceof 操作符是非法的。使用无界通配符类型代替原始类型不会以任何方式影响 instanceof 运算符的行为。在这种情况下，尖括号和问号只是多余的。下面的例子是使用通用类型 instanceof 运算符的首选方法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Legitimate use of raw type - instanceof operator</span></span><br><span class="line"><span class="keyword">if</span> (o <span class="keyword">instanceof</span> Set) &#123; <span class="comment">// Raw type</span></span><br><span class="line">    Set&lt;?&gt; s = (Set&lt;?&gt;) o; <span class="comment">// Wildcard type</span></span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>总之，使用原始类型可能会在运行时导致异常，所以不要轻易使用它们。它们仅用于与引入泛型之前的遗留代码进行兼容和互操作。快速回顾一下，<code>Set</code> 是一个参数化类型，表示可以包含任何类型的对象的集合，<code>Set</code> 是一个通配符类型，表示只能包含某种未知类型的对象的集合，Set 是一个原始类型，它选择了泛型系统。前两个是安全的，后一个就不安全了。</p></li><li><p>消除 unchecked 警告：使用泛型获得的经验越多，得到的警告就越少，但是不要期望新编写的代码能够完全正确地编译。力求消除所有 unchecked 警告。 如果你消除了所有警告，你就可以确信你的代码是类型安全的，这是一件非常好的事情。如果不能消除警告，但是可以证明引发警告的代码是类型安全的，那么（并且只有在那时）使用 SuppressWarnings(“unchecked”) 注解来抑制警告。SuppressWarnings 注解可以用于任何声明中，从单个局部变量声明到整个类。总是在尽可能小的范围上使用 SuppressWarnings 注解。 每次使用SuppressWarnings(“unchecked”) 注解时，要添加一条注释，说明这样做是安全的。</p></li><li><p>list 优于数组：数组与泛型有两个重要区别。首先，数组是协变的。这个听起来很吓人的单词的意思很简单，如果 Sub 是 Super 的一个子类型，那么数组类型 Sub[] 就是数组类型 Super[] 的一个子类型。数组和泛型之间的第二个主要区别：数组是具体化的。这意味着数组在运行时知道并强制执行他们的元素类型。相比之下，泛型是通过擦除来实现的。</p><p>由于这些基本差异，数组和泛型不能很好地混合。例如，创建泛型、参数化类型或类型参数的数组是非法的。因此，这些数组创建表达式都不是合法的：<code>new List[]</code>、<code>new List[]</code>、<code>new E[]</code>。所有这些都会在编译时导致泛型数组创建错误。为了更具体，请考虑以下代码片段：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Why generic array creation is illegal - won&#x27;t compile!</span></span><br><span class="line">List&lt;String&gt;[] stringLists = <span class="keyword">new</span> List&lt;String&gt;[<span class="number">1</span>]; <span class="comment">// (1)</span></span><br><span class="line">List&lt;Integer&gt; intList = List.of(<span class="number">42</span>); <span class="comment">// (2)</span></span><br><span class="line">Object[] objects = stringLists; <span class="comment">// (3)</span></span><br><span class="line">objects[<span class="number">0</span>] = intList; <span class="comment">// (4)</span></span><br><span class="line">String s = stringLists[<span class="number">0</span>].get(<span class="number">0</span>); <span class="comment">// (5)</span></span><br></pre></td></tr></table></figure><p>假设创建泛型数组的第 1 行是合法的。第 2 行创建并初始化一个包含单个元素的 <code>List</code>。第 3 行将 <code>List</code> 数组存储到 Object 类型的数组变量中，这是合法的，因为数组是协变的。第 4 行将 <code>List</code> 存储到 Object 类型的数组的唯一元素中，这是成功的，因为泛型是由擦除实现的：<code>List</code> 实例的运行时类型是 List，<code>List</code>[] 实例的运行时类型是 List[]，因此这个赋值不会生成 ArrayStoreException。现在我们有麻烦了。我们将一个 <code>List</code> 实例存储到一个数组中，该数组声明只保存 <code>List</code> 实例。在第 5 行，我们从这个数组的唯一列表中检索唯一元素。编译器自动将检索到的元素转换为 String 类型，但它是一个 Integer 类型的元素，因此我们在运行时得到一个 ClassCastException。为了防止这种情况发生，第 1 行（创建泛型数组）必须生成编译时错误。</p><p>当你在转换为数组类型时遇到泛型数组创建错误或 unchecked 强制转换警告时，通常最好的解决方案是使用集合类型 <code>List</code>，而不是数组类型 E[]。</p><p>总之，数组和泛型有非常不同的类型规则。数组是协变的、具体化的；泛型是不变的和可被擦除的。因此，数组提供了运行时类型安全，而不是编译时类型安全，对于泛型反之亦然。一般来说，数组和泛型不能很好地混合。如果你发现将它们混合在一起并得到编译时错误或警告，那么你的第一个反应该是将数组替换为 list。</p></li><li><p>优先使用泛型：考虑一个泛型栈结构：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">Stack</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    elements = <span class="keyword">new</span> E[DEFAULT_INITIAL_CAPACITY];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>通常至少会得到一个错误或警告，这个类也不例外。幸运的是，这个类只生成一个错误：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Stack.java:8: generic array creation</span><br><span class="line">elements &#x3D; new E[DEFAULT_INITIAL_CAPACITY];</span><br><span class="line">^</span><br></pre></td></tr></table></figure><p>每当你编写由数组支持的泛型时，就会出现这个问题。有两种合理的方法来解决它。第一个解决方案直接绕过了创建泛型数组的禁令：创建对象数组并将其强制转换为泛型数组类型。现在，编译器将发出一个警告来代替错误。这种用法是合法的，但（一般而言）它不是类型安全的：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Stack.java:8: warning: [unchecked] unchecked cast</span><br><span class="line">found: Object[], required: E[]</span><br><span class="line">elements &#x3D; (E[]) new Object[DEFAULT_INITIAL_CAPACITY];</span><br><span class="line">^</span><br></pre></td></tr></table></figure><p>消除 Stack 中泛型数组创建错误的第二种方法是将字段元素的类型从 E[] 更改为 Object[]。如果你这样做，你会得到一个不同的错误：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Stack.java:19: incompatible types</span><br><span class="line">found: Object, required: E</span><br><span class="line">E result &#x3D; elements[--size];</span><br><span class="line">^</span><br></pre></td></tr></table></figure><p>通过将从数组中检索到的元素转换为 E，可以将此错误转换为警告，但你将得到警告：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Stack.java:19: warning: [unchecked] unchecked cast</span><br><span class="line">found: Object, required: E</span><br><span class="line">E result &#x3D; (E) elements[--size];</span><br><span class="line">^</span><br></pre></td></tr></table></figure><p>消除泛型数组创建的两种技术都有其追随者。第一个更容易读：数组声明为 E[] 类型，这清楚地表明它只包含 E 的实例。它也更简洁：在一个典型的泛型类中，从数组中读取代码中的许多点；第一种技术只需要一次转换（在创建数组的地方），而第二种技术在每次读取数组元素时都需要单独的转换。因此，第一种技术是可取的，在实践中更常用。</p><p>泛型比需要在客户端代码中转换的类型更安全、更容易使用。</p></li><li><p>优先使用泛型方法：允许类型参数被包含该类型参数本身的表达式限制，尽管这种情况比较少见。这就是所谓的递归类型限定。递归类型边界的一个常见用法是与 Comparable 接口相关联，后者定义了类型的自然顺序：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Comparable</span>&lt;<span class="title">T</span>&gt; </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">compareTo</span><span class="params">(T o)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>许多方法采用实现 Comparable 的元素集合，在其中进行搜索，计算其最小值或最大值，等等。要做到这些，需要集合中的每个元素与集合中的每个其他元素相比较，换句话说，就是列表中的元素相互比较。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Using a recursive type bound to express mutual comparability</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> &lt;E extends Comparable&lt;E&gt;&gt; <span class="function">E <span class="title">max</span><span class="params">(Collection&lt;E&gt; c)</span></span>;</span><br></pre></td></tr></table></figure><p>类型限定 <code>&lt;E extends Comparable&lt;E&gt;&gt;</code> 可以被理解为「可以与自身进行比较的任何类型 E」，这或多或少与相互可比性的概念相对应。</p></li><li><p>使用有界通配符增加 API 的灵活性：假设我们想添加一个方法，该方法接受一系列元素并将它们全部推入堆栈。这是第一次尝试：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// pushAll method without wildcard type - deficient!</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">pushAll</span><span class="params">(Iterable&lt;E&gt; src)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (E e : src)</span><br><span class="line">        push(e);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>该方法能够正确编译，但并不完全令人满意。下面的代码将会产生错误：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Stack&lt;Number&gt; numberStack = <span class="keyword">new</span> Stack&lt;&gt;();</span><br><span class="line">Iterable&lt;Integer&gt; integers = ... ;</span><br><span class="line">numberStack.pushAll(integers);</span><br></pre></td></tr></table></figure><p>错误信息：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">StackTest.java:<span class="number">7</span>: error: incompatible types: Iterable&lt;Integer&gt;</span><br><span class="line">cannot be converted to Iterable&lt;Number&gt;</span><br><span class="line">        numberStack.pushAll(integers);</span><br><span class="line">                    ^</span><br></pre></td></tr></table></figure><p>Java 提供了一种特殊的参数化类型，有界通配符类型来处理这种情况。pushAll 的输入参数的类型不应该是「E 的 Iterable 接口」，而应该是「E 的某个子类型的 Iterable 接口」，并且有一个通配符类型，它的确切含义是：<code>Iterable&lt;? extends E&gt;</code>：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Wildcard type for a parameter that serves as an E producer</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">pushAll</span><span class="params">(Iterable&lt;? extends E&gt; src)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (E e : src)</span><br><span class="line">        push(e);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>popAll方法的代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// popAll method without wildcard type - deficient!</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">popAll</span><span class="params">(Collection&lt;E&gt; dst)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (!isEmpty())</span><br><span class="line">        dst.add(pop());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>同样，如果目标集合的元素类型与堆栈的元素类型完全匹配，那么这种方法可以很好地编译。但这也不是完全令人满意：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Stack&lt;Number&gt; numberStack = <span class="keyword">new</span> Stack&lt;Number&gt;();</span><br><span class="line">Collection&lt;Object&gt; objects = ... ;</span><br><span class="line">numberStack.popAll(objects);</span><br></pre></td></tr></table></figure><p>同样，有一个通配符类型，它的确切含义是：<code>Collection&lt;? super E&gt;</code>。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Wildcard type for parameter that serves as an E consumer</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">popAll</span><span class="params">(Collection&lt;? <span class="keyword">super</span> E&gt; dst)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">while</span> (!isEmpty())</span><br><span class="line">    dst.add(pop());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>总而言之，PECS 表示生产者应使用 extends，消费者应使用 super。</p></li><li><p>明智地合用泛型和可变参数：泛型和可变参数不能很好的结合起来。考虑如下代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Mixing generics and varargs can violate type safety!</span></span><br><span class="line"><span class="comment">// 泛型和可变参数混合使用可能违反类型安全原则！</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">dangerous</span><span class="params">(List&lt;String&gt;... stringLists)</span> </span>&#123;</span><br><span class="line">    List&lt;Integer&gt; intList = List.of(<span class="number">42</span>);</span><br><span class="line">    Object[] objects = stringLists;</span><br><span class="line">    objects[<span class="number">0</span>] = intList; <span class="comment">// Heap pollution</span></span><br><span class="line">    String s = stringLists[<span class="number">0</span>].get(<span class="number">0</span>); <span class="comment">// ClassCastException</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>此方法没有显式的强制类型转换，但在使用一个或多个参数调用时抛出 ClassCastException。它的最后一行有一个由编译器生成的隐式强制转换。此转换失败，表明类型安全性受到了影响，并且在泛型可变参数数组中存储值是不安全的。为什么使用泛型可变参数声明方法是合法的，而显式创建泛型数组是非法的？答案是，带有泛型或参数化类型的可变参数的方法在实际开发中非常有用，因此语言设计人员选择忍受这种不一致性。事实上，Java 库导出了几个这样的方法，包括 Arrays.asList(T… a)、Collections.addAll(Collection&lt;? super T&gt; c, T… elements) 以及 EnumSet.of(E first, E… rest)。</p><p>在 Java 7 中添加了 SafeVarargs 注释，以允许使用泛型可变参数的方法的作者自动抑制客户端警告。本质上，SafeVarargs 注释构成了方法作者的一个承诺，即该方法是类型安全的。 </p><p>可变参数方法和泛型不能很好地交互，因为可变参数工具是构建在数组之上的漏洞抽象，并且数组具有与泛型不同的类型规则。虽然泛型可变参数不是类型安全的，但它们是合法的。如果选择使用泛型（或参数化）可变参数编写方法，首先要确保该方法是类型安全的，然后使用 @SafeVarargs 对其进行注释。</p></li><li><p>考虑类型安全的异构容器：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Typesafe heterogeneous container pattern - implementation</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Favorites</span> </span>&#123;</span><br><span class="line">  <span class="keyword">private</span> Map&lt;Class&lt;?&gt;, Object&gt; favorites = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line"></span><br><span class="line">  <span class="keyword">public</span> &lt;T&gt; <span class="function"><span class="keyword">void</span> <span class="title">putFavorite</span><span class="params">(Class&lt;T&gt; type, T instance)</span> </span>&#123;</span><br><span class="line">    favorites.put(Objects.requireNonNull(type), instance);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">public</span> &lt;T&gt; <span class="function">T <span class="title">getFavorite</span><span class="params">(Class&lt;T&gt; type)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> type.cast(favorites.get(type));</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里发生了一些微妙的事情。每个 Favorites 实例都由一个名为 favorites 的私有 <code>Map&lt;Class&lt;?&gt;, Object&gt;</code> 支持。你可能认为由于通配符类型是无界的，所以无法将任何内容放入此映射中，但事实恰恰相反。需要注意的是，通配符类型是嵌套的：通配符类型不是 Map 的类型，而是键的类型。这意味着每个键都可以有不同的参数化类型：一个可以是 <code>Class&lt;String&gt;</code>，下一个是 <code>Class&lt;Integer&gt;</code>，等等。这就是异构的原理。</p><p>接下来要注意的是 favorites 的值类型仅仅是 Object。换句话说，Map 不保证键和值之间的类型关系，即每个值都是其键所表示的类型。实际上，Java 的类型系统还没有强大到足以表达这一点。但是我们知道这是事实，当需要检索一个 favorite 时，我们会利用它。</p><p>putFavorite 的实现很简单：它只是将从给定 Class 对象到给定 Favorites 实例的放入 favorites 中。如前所述，这将丢弃键和值之间的「类型关联」；将无法确定值是键的实例。但这没关系，因为 getFavorites 方法可以重新建立这个关联。</p><p>getFavorite 的实现比 putFavorite 的实现更复杂。首先，它从 favorites 中获取与给定 Class 对象对应的值。这是正确的对象引用返回，但它有错误的编译时类型：它是 Object（favorites 的值类型），我们需要返回一个 T。因此，getFavorite 的实现通过使用 Class 的 cast 方法，将对象引用类型动态转化为所代表的 Class 对象。</p><p>总之，以集合的 API 为例的泛型在正常使用时将每个容器的类型参数限制为固定数量。你可以通过将类型参数放置在键上而不是容器上来绕过这个限制。你可以使用 Class 对象作为此类类型安全异构容器的键。以这种方式使用的 Class 对象称为类型标记。还可以使用自定义键类型。例如，可以使用 DatabaseRow 类型表示数据库行（容器），并使用泛型类型 <code>Column&lt;T&gt;</code> 作为它的键。</p></li></ol><h2 id="第六章-枚举和注解"><a href="#第六章-枚举和注解" class="headerlink" title="第六章 枚举和注解"></a>第六章 枚举和注解</h2><ol start="34"><li><p>用枚举类型代替 int 常量：在枚举类型被添加到 JAVA 之前，表示枚举类型的一种常见模式是声明一组 int 的常量，这种技术称为 int 枚举模式，它有许多缺点。它没有提供任何类型安全性，并且几乎不具备表现力。如果你传递一个苹果给方法，希望得到一个橘子，使用 == 操作符比较苹果和橘子时编译器并不会提示错误，或更糟的情况：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Tasty citrus flavored applesauce!</span></span><br><span class="line"><span class="keyword">int</span> i = (APPLE_FUJI - ORANGE_TEMPLE) / APPLE_PIPPIN;</span><br></pre></td></tr></table></figure><p>使用 String 常量代替 int 常量。这种称为 String 枚举模式的变体甚至更不可取。虽然它确实为常量提供了可打印的字符串，但是它可能会导致不知情的用户将字符串常量硬编码到客户端代码中，而不是使用字段名。使用枚举可以解决上述问题。</p><p>从表面上看，Java 枚举类型可能与其他语言（如 C、c++ 和 c#）的枚举类型类似，但不能只看表象。Java 的枚举类型是成熟的类，比其他语言中的枚举类型功能强大得多，在其他语言中的枚举本质上是 int 值。除了纠正 int 枚举的不足之外，枚举类型还允许添加任意方法和字段并实现任意接口。</p><p>编写一个富枚举类型很容易，如上述的 Planet。要将数据与枚举常量关联，可声明实例字段并编写一个构造函数，该构造函数接受数据并将其存储在字段中。 枚举本质上是不可变的，因此所有字段都应该是 final。字段可以是公共的，但是最好将它们设置为私有并提供公共访问器。</p><p>有一种更好的方法可以将不同的行为与每个枚举常量关联起来，这些方法称为特定常量方法实现：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Enum type with constant-specific method implementations</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">enum</span> Operation &#123;</span><br><span class="line">    PLUS &#123;<span class="function"><span class="keyword">public</span> <span class="keyword">double</span> <span class="title">apply</span><span class="params">(<span class="keyword">double</span> x, <span class="keyword">double</span> y)</span></span>&#123;<span class="keyword">return</span> x + y;&#125;&#125;,</span><br><span class="line">    MINUS &#123;<span class="function"><span class="keyword">public</span> <span class="keyword">double</span> <span class="title">apply</span><span class="params">(<span class="keyword">double</span> x, <span class="keyword">double</span> y)</span></span>&#123;<span class="keyword">return</span> x - y;&#125;&#125;,</span><br><span class="line">    TIMES &#123;<span class="function"><span class="keyword">public</span> <span class="keyword">double</span> <span class="title">apply</span><span class="params">(<span class="keyword">double</span> x, <span class="keyword">double</span> y)</span></span>&#123;<span class="keyword">return</span> x * y;&#125;&#125;,</span><br><span class="line">    DIVIDE&#123;<span class="function"><span class="keyword">public</span> <span class="keyword">double</span> <span class="title">apply</span><span class="params">(<span class="keyword">double</span> x, <span class="keyword">double</span> y)</span></span>&#123;<span class="keyword">return</span> x / y;&#125;&#125;;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">double</span> <span class="title">apply</span><span class="params">(<span class="keyword">double</span> x, <span class="keyword">double</span> y)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>使用实例字段替代序数：所有枚举都有一个 ordinal 方法，该方法返回枚举类型中每个枚举常数的数值位置。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Abuse of ordinal to derive an associated value - DON&#x27;T DO THIS</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">enum</span> Ensemble &#123;</span><br><span class="line">    SOLO, DUET, TRIO, QUARTET, QUINTET,SEXTET, SEPTET, OCTET, NONET, DECTET;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">numberOfMusicians</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> ordinal() + <span class="number">1</span>; &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>虽然这个枚举可以工作，但维护却是噩梦。如果常量被重新排序，numberOfMusicians 方法将被破坏。有一个简单的解决方案：不要从枚举的序数派生与枚举关联的值；而是将其存储在实例字段中：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">enum</span> Ensemble &#123;</span><br><span class="line">    SOLO(<span class="number">1</span>), DUET(<span class="number">2</span>), TRIO(<span class="number">3</span>), QUARTET(<span class="number">4</span>), QUINTET(<span class="number">5</span>),SEXTET(<span class="number">6</span>), SEPTET(<span class="number">7</span>), OCTET(<span class="number">8</span>), DOUBLE_QUARTET(<span class="number">8</span>),NONET(<span class="number">9</span>), DECTET(<span class="number">10</span>),TRIPLE_QUARTET(<span class="number">12</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> numberOfMusicians;</span><br><span class="line"></span><br><span class="line">    Ensemble(<span class="keyword">int</span> size) &#123; <span class="keyword">this</span>.numberOfMusicians = size; &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">numberOfMusicians</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> numberOfMusicians; &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>枚举规范对 ordinal 方法的评价是这样的：「大多数程序员都不会去使用这个方法。它是为基于枚举的通用数据结构（如 EnumSet 和 EnumMap）而设计的」。除非你使用这个数据结构编写代码，否则最好完全避免使用这个方法。</p></li><li><p>用 EnumSet 替代位字段：位字段模式如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Bit field enumeration constants - OBSOLETE!</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Text</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> STYLE_BOLD = <span class="number">1</span> &lt;&lt; <span class="number">0</span>; <span class="comment">// 1</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> STYLE_ITALIC = <span class="number">1</span> &lt;&lt; <span class="number">1</span>; <span class="comment">// 2</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> STYLE_UNDERLINE = <span class="number">1</span> &lt;&lt; <span class="number">2</span>; <span class="comment">// 4</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> STYLE_STRIKETHROUGH = <span class="number">1</span> &lt;&lt; <span class="number">3</span>; <span class="comment">// 8</span></span><br><span class="line">    <span class="comment">// Parameter is bitwise OR of zero or more STYLE_ constants</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">applyStyles</span><span class="params">(<span class="keyword">int</span> styles)</span> </span>&#123; ... &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>允许你使用位运算的 OR 操作将几个常量组合成一个 Set：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">text.applyStyles(STYLE_BOLD | STYLE_ITALIC);</span><br></pre></td></tr></table></figure><p>位字段表示方式允许使用位运算高效地执行 Set 操作，如并集和交集。但是位字段具有 int 枚举常量所有缺点，甚至更多。当位字段被打印为数字时，它比简单的 int 枚举常量更难理解。没有一种简单的方法可以遍历由位字段表示的所有元素。</p><p>当之前的示例修改为使用枚举和 EnumSet 而不是位字段时。它更短，更清晰，更安全：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// EnumSet - a modern replacement for bit fields</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Text</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">enum</span> Style &#123; BOLD, ITALIC, UNDERLINE, STRIKETHROUGH &#125;</span><br><span class="line">    <span class="comment">// Any Set could be passed in, but EnumSet is clearly best</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">applyStyles</span><span class="params">(Set&lt;Style&gt; styles)</span> </span>&#123; ... &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>下面是将 EnumSet 实例传递给 applyStyles 方法的客户端代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">text.applyStyles(EnumSet.of(Style.BOLD, Style.ITALIC));</span><br></pre></td></tr></table></figure><p>EnumSet 类结合了位字段的简洁性和性能。EnumSet 的一个真正的缺点是，从 Java 9 开始，它不能创建不可变的 EnumSet。但是，可以用 <code>Collections.unmodifiableSet</code> 包装 EnumSet，实现不可变性，但简洁性和性能将受到影响。</p></li><li><p>使用 EnumMap 替换序数索引：如果想要使用 Enum 里面的美居元素来对一组对象进行分组的话，请不要使用序数索引：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Using ordinal() to index into an array - DON&#x27;T DO THIS!</span></span><br><span class="line">Set&lt;Plant&gt;[] plantsByLifeCycle =(Set&lt;Plant&gt;[]) <span class="keyword">new</span> Set[Plant.LifeCycle.values().length];</span><br></pre></td></tr></table></figure><p>这样带来的问题是不便于维护。Java 提供了一种简单的方式实现该目的，EnumMap：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Using an EnumMap to associate data with an enum</span></span><br><span class="line">Map&lt;Plant.LifeCycle, Set&lt;Plant&gt;&gt; plantsByLifeCycle =<span class="keyword">new</span> EnumMap&lt;&gt;(Plant.LifeCycle.class);</span><br></pre></td></tr></table></figure><p>这个程序比原来的版本更短，更清晰，更安全，速度也差不多。没有不安全的转换；不需要手动标记输出，因为 Map 的键是能转换为可打印字符串的枚举；在计算数组索引时不可能出错。</p></li><li><p>使用接口模拟可扩展枚举：利用枚举类型可以实现任意接口这一事实，为 opcode 类型定义一个接口，并为接口的标准实现定义一个枚举：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Emulated extensible enum using an interface</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Operation</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">double</span> <span class="title">apply</span><span class="params">(<span class="keyword">double</span> x, <span class="keyword">double</span> y)</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">enum</span> BasicOperation implements Operation &#123;</span><br><span class="line">    PLUS(<span class="string">&quot;+&quot;</span>) &#123;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">double</span> <span class="title">apply</span><span class="params">(<span class="keyword">double</span> x, <span class="keyword">double</span> y)</span> </span>&#123; <span class="keyword">return</span> x + y; &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    MINUS(<span class="string">&quot;-&quot;</span>) &#123;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">double</span> <span class="title">apply</span><span class="params">(<span class="keyword">double</span> x, <span class="keyword">double</span> y)</span> </span>&#123; <span class="keyword">return</span> x - y; &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    TIMES(<span class="string">&quot;*&quot;</span>) &#123;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">double</span> <span class="title">apply</span><span class="params">(<span class="keyword">double</span> x, <span class="keyword">double</span> y)</span> </span>&#123; <span class="keyword">return</span> x * y; &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    DIVIDE(<span class="string">&quot;/&quot;</span>) &#123;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">double</span> <span class="title">apply</span><span class="params">(<span class="keyword">double</span> x, <span class="keyword">double</span> y)</span> </span>&#123; <span class="keyword">return</span> x / y; &#125;</span><br><span class="line">    &#125;;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> String symbol;</span><br><span class="line"></span><br><span class="line">    BasicOperation(String symbol) &#123;</span><br><span class="line">        <span class="keyword">this</span>.symbol = symbol;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> symbol;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>注解优于命名模式：使用命名模式来标明某些程序元素需要工具或框架特殊处理的方式是很常见的，例如，在版本 4 之前，JUnit 测试框架要求其用户通过以字符 test 开头的名称来指定测试方法。命名模式有几个问题：</p><ol><li>首先，排版错误会导致没有提示的失败</li><li>无法确保只在相应的程序元素上使用它们</li><li>它们没有提供将参数值与程序元素关联的好方法</li></ol><p>假设我们声明了一个 Test 注解，那么我们需要相应的工具来解析这些注解：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Program to process marker annotations</span></span><br><span class="line"><span class="keyword">import</span> java.lang.reflect.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RunTests</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> tests = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> passed = <span class="number">0</span>;</span><br><span class="line">        Class&lt;?&gt; testClass = Class.forName(args[<span class="number">0</span>]);</span><br><span class="line">        <span class="keyword">for</span> (Method m : testClass.getDeclaredMethods()) &#123;</span><br><span class="line">            <span class="keyword">if</span> (m.isAnnotationPresent(Test.class)) &#123;</span><br><span class="line">                tests++;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    m.invoke(<span class="keyword">null</span>);</span><br><span class="line">                    passed++;</span><br><span class="line">                &#125; <span class="keyword">catch</span> (InvocationTargetException wrappedExc) &#123;</span><br><span class="line">                    Throwable exc = wrappedExc.getCause();</span><br><span class="line">                    System.out.println(m + <span class="string">&quot; failed: &quot;</span> + exc);</span><br><span class="line">                &#125; <span class="keyword">catch</span> (Exception exc) &#123;</span><br><span class="line">                    System.out.println(<span class="string">&quot;Invalid @Test: &quot;</span> + m);</span><br><span class="line">                &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    System.out.printf(<span class="string">&quot;Passed: %d, Failed: %d%n&quot;</span>,passed, tests - passed);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>使用注解很简洁，同时也防止了使用命名模式所带来的一系列的问题。</p></li><li><p>坚持使用 @Override 注解：在每个方法声明上都使用 <code>@Override</code> 注解来覆盖超类型声明，那么编译器可以帮助你减少受到有害错误的影响，如错误将重写实现为重载。在具体类中，可以不对覆盖抽象方法声明的方法使用该注解。</p></li><li><p>使用标记接口定义类型：标记接口是一种不包含任何方法声明的接口，它只是指定一个类，该类实现了具有某些属性的接口。例如 Serializable 接口。与标记注解相比，标记接口有两个优点。首先，标记接口定义的类型由标记类的实例实现；标记注解不会。标记接口相对于标记注解的另一个优点是可以更精确地定位它们。相对于标记接口，标记注解的主要优势是它们可以是其他注解功能的一部分。</p></li></ol><h2 id="第七章-Lambda表达式和流"><a href="#第七章-Lambda表达式和流" class="headerlink" title="第七章 Lambda表达式和流"></a>第七章 Lambda表达式和流</h2><ol start="42"><li><p>lambda 表达式优于匿名类：在历史上，带有单个抽象方法的接口被用作函数类型。它们的实例（称为函数对象）表示函数或操作。自从 JDK 1.1 在 1997 年发布以来，创建函数对象的主要方法就是匿名类：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Anonymous class instance as a function object - obsolete!</span></span><br><span class="line">Collections.sort(words, <span class="keyword">new</span> Comparator&lt;String&gt;() &#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compare</span><span class="params">(String s1, String s2)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> Integer.compare(s1.length(), s2.length());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><p>在 Java 8 中官方化了一个概念，即具有单个抽象方法的接口是特殊的，应该得到特殊处理。这些接口现在被称为函数式接口，允许使用 lambda 表达式创建这些接口的实例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Lambda expression as function object (replaces anonymous class)</span></span><br><span class="line">Collections.sort(words,(s1, s2) -&gt; Integer.compare(s1.length(), s2.length()));</span><br></pre></td></tr></table></figure><p>一般来说，省略lambda中参数的类型，除非编译器不能自动推断出来。另外，在lambda表达式中this关键字指向的是外部的类的实例，但是匿名类指的是匿名类自己。</p></li><li><p>方法引用优于 lambda 表达式：lambda 表达式与匿名类相比，主要优势是更简洁。Java 提供了一种方法来生成比 lambda 表达式更简洁的函数对象：方法引用。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">map.merge(key, <span class="number">1</span>, Integer::sum);</span><br></pre></td></tr></table></figure><p>而是用lambda代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">map.merge(key, <span class="number">1</span>, (count, incr) -&gt; count + incr);</span><br></pre></td></tr></table></figure><p>方法引用通常为 lambda 表达式提供了一种更简洁的选择。如果方法引用更短、更清晰，则使用它们；如果没有，仍然使用 lambda 表达式。</p></li><li><p>优先使用标准函数式接口：现在 Java 已经有了 lambda 表达式，编写 API 的最佳实践已经发生了很大的变化。java.util.function 包提供了大量的标准函数接口供你使用。如果一个标准的函数式接口可以完成这项工作，那么你通常应该优先使用它，而不是使用专门构建的函数式接口。六个基本的函数式接口总结如下：</p><table><thead><tr><th>Interface</th><th>Function Signature</th><th>Example</th></tr></thead><tbody><tr><td><code>UnaryOperator</code></td><td><code>T apply(T t)</code></td><td><code>String::toLowerCase</code></td></tr><tr><td><code>BinaryOperator</code></td><td><code>T apply(T t1, T t2)</code></td><td><code>BigInteger::add</code></td></tr><tr><td><code>Predicate</code></td><td><code>boolean test(T t)</code></td><td><code>Collection::isEmpty</code></td></tr><tr><td><code>Function</code></td><td><code>R apply(T t)</code></td><td><code>Arrays::asList</code></td></tr><tr><td><code>Supplier</code></td><td><code>T get()</code></td><td><code>Instant::now</code></td></tr><tr><td><code>Consumer</code></td><td><code>void accept(T t)</code></td><td><code>System.out::println</code></td></tr></tbody></table><p>还有 6 个基本接口的 3 个变体，用于操作基本类型 int、long 和 double。Function 接口还有 9 个额外的变体，在结果类型为基本数据类型时使用。</p></li><li><p>明智地使用流：在 Java 8 中添加了流 API，以简化序列或并行执行批量操作的任务。这个 API 提供了两个关键的抽象：流（表示有限或无限的数据元素序列）和流管道（表示对这些元素的多阶段计算）。流管道的计算是惰性的：直到调用 Terminal 操作时才开始计算，并且对完成 Terminal 操作不需要的数据元素永远不会计算。这种惰性的求值机制使得处理无限流成为可能。流 API 非常通用，实际上任何计算都可以使用流来执行，但这并不意味着你就应该这样做。如果使用得当，流可以使程序更短、更清晰；如果使用不当，它们会使程序难以读取和维护。由于 Java 不支持基本字符流：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;Hello world!&quot;</span>.chars().forEach(System.out::print);</span><br></pre></td></tr></table></figure><p>你可能希望它打印 Hello world!，但如果运行它，你会发现它打印 721011081081113211911111410810033。这是因为 “Hello world!”.chars() 返回的流元素不是 char 值，而是 int 值，因此调用了 print 的 int 重载。强制转换可以解决这个问题：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;Hello world!&quot;</span>.chars().forEach(x -&gt; System.out.print((<span class="keyword">char</span>) x));</span><br></pre></td></tr></table></figure><p>有些事情你可以对代码块做，而你不能对函数对象（通常是 lambda 表达式或方法引用）做</p><ul><li>从代码块中，可以读取或修改作用域中的任何局部变量；在 lambda 表达式中，只能读取 final 或有效的 final 变量，不能修改任何局部变量。</li><li>从代码块中，可以从封闭方法返回、中断或继续封闭循环，或抛出声明要抛出的任何已检查异常；在 lambda 表达式中，你不能做这些事情。</li></ul><p>相反，流使做一些事情变得非常容易：</p><ul><li>元素序列的一致变换</li><li>过滤元素序列</li><li>使用单个操作组合元素序列</li><li>将元素序列累积到一个集合中，可能是按某个公共属性对它们进行分组</li><li>在元素序列中搜索满足某些条件的元素</li></ul></li><li><p>在流中使用无副作用的函数：你可能会看到如下使用流的代码片段，它用于构建文本文件中单词的频率表：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Uses the streams API but not the paradigm--Don&#x27;t do this!</span></span><br><span class="line">Map&lt;String, Long&gt; freq = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line"><span class="keyword">try</span> (Stream&lt;String&gt; words = <span class="keyword">new</span> Scanner(file).tokens()) &#123;</span><br><span class="line">    words.forEach(word -&gt; &#123;</span><br><span class="line">        freq.merge(word.toLowerCase(), <span class="number">1L</span>, Long::sum);</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>简单地说，它根本不是流代码，而是伪装成流代码的迭代代码。它没有从流 API 中获得任何好处，而且它（稍微）比相应的迭代代码更长、更难于阅读和更难以维护。这个问题源于这样一个事实：这段代码在一个 Terminal 操作中（forEach）执行它的所有工作，使用一个会改变外部状态的 lambda 表达式（频率表）。改进后的代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Proper use of streams to initialize a frequency table</span></span><br><span class="line">Map&lt;String, Long&gt; freq;</span><br><span class="line"><span class="keyword">try</span> (Stream&lt;String&gt; words = <span class="keyword">new</span> Scanner(file).tokens()) &#123;</span><br><span class="line">    freq = words.collect(groupingBy(String::toLowerCase, counting()));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个代码片段与前面的代码片段做了相同的事情，但是正确地使用了流 API。它更短更清晰。</p><p>将流的元素收集到一个真正的 Collection 中的 collector 非常简单。这样的 collector 有三种：<code>toList()</code>、<code>toSet()</code> 和 <code>toCollection(collectionFactory)</code>。它们分别返回 List、Set 和程序员指定的集合类型。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Pipeline to get a top-ten list of words from a frequency table</span></span><br><span class="line">List&lt;String&gt; topTen = freq.keySet().stream()</span><br><span class="line">    .sorted(comparing(freq::get).reversed())</span><br><span class="line">    .limit(<span class="number">10</span>)</span><br><span class="line">    .collect(toList());</span><br></pre></td></tr></table></figure><p>另外还有 groupingBy 和 join。</p></li><li><p>优先选择 Collection 而不是流作为返回类型：在编写返回元素序列的方法时，有些用户可能希望将它们作为流处理，而有些用户可能希望对它们进行迭代。如果可以返回集合，那么就这样做。如果你已经在一个集合中拥有了元素，或者序列中的元素数量足够小，可以创建一个新的元素，那么返回一个标准集合，例如 ArrayList 。否则，请考虑像对 power 集那样实现自定义集合。如果返回集合不可行，则返回流或 iterable，以看起来更自然的方式返回。</p></li><li><p>谨慎使用并行流：在主流语言中，Java 一直走在提供简化并发编程任务工具的前列。当 Java 在 1996 年发布时，它内置了对线程的支持，支持同步和 wait/notify。Java 5 引入了 java.util.concurrent。具有并发集合和执行器框架的并发库。Java 7 引入了 fork-join 包，这是一个用于并行分解的高性能框架。Java 8 引入了流，它可以通过对 parallel 方法的一次调用来并行化。</p><p>并行性带来的性能提升在 ArrayList、HashMap、HashSet 和 ConcurrentHashMap 实例上的流效果最好；int 数组和 long 数组也在其中。 这些数据结构的共同之处在于，它们都可以被精确且廉价地分割成任意大小的子程序，这使得在并行线程之间划分工作变得很容易。</p><p>并行化流不仅会导致糟糕的性能，包括活动失败；它会导致不正确的结果和不可预知的行为（安全故障）。 如果管道使用映射器、过滤器和其他程序员提供的函数对象，而这些对象没有遵守其规范，则并行化管道可能导致安全故障。流规范对这些功能对象提出了严格的要求。例如，传递给流的 reduce 操作的累加器和组合器函数必须是关联的、不干扰的和无状态的。</p></li></ol><h2 id="第八章-方法"><a href="#第八章-方法" class="headerlink" title="第八章 方法"></a>第八章 方法</h2><ol start="49"><li><p>检查参数的有效性：大多数方法和构造函数都对传递给它们的参数值有一些限制。例如，索引值必须是非负的，对象引用必须是非空的。如果一个无效的参数值被传递给一个方法，如果该方法在执行之前会检查它的参数，那么这个过程将迅速失败，并引发适当的异常。如果方法未能检查其参数，可能会发生以下几件事。该方法可能会在处理过程中出现令人困惑的异常而失败。更糟的是，该方法可以正常返回，但会静默计算错误的结果。在 Java 7 中添加的 Objects.requireNonNull 方法非常灵活和方便，因此不再需要手动执行空检查。在 Java 9 中，范围检查功能被添加到 java.util.Objects 中。这个功能由三个方法组成：checkFromIndexSize、checkFromToIndex 和 checkIndex。非公共方法可以使用断言检查它们的参数。</p><p>在执行方法的计算任务之前，应该显式地检查方法的参数，这条规则也有例外。一个重要的例外是有效性检查成本较高或不切实际，或者检查是在计算过程中隐式执行了。例如，考虑一个为对象 List 排序的方法，比如 Collections.sort(List)。List 中的所有对象必须相互比较。在对 List 排序的过程中，List 中的每个对象都会与列表中的其他对象进行比较。如果对象不能相互比较，将抛出 ClassCastException，这正是 sort 方法应该做的。因此，没有必要预先检查列表中的元素是否具有可比性。</p></li><li><p>在需要时制作防御性副本：即使使用一种安全的语言，如果你不付出一些努力，也无法与其他类隔离。你必须进行防御性的设计，并假定你的类的客户端会尽最大努力破坏它的不变量。 随着人们越来越多地尝试破坏系统的安全性，这个观点越来越正确。考虑这样的一个类：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Broken &quot;immutable&quot; time period class</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">Period</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Date start;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Date end;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Period</span><span class="params">(Date start, Date end)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (start.compareTo(end) &gt; <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(start + <span class="string">&quot; after &quot;</span> + end);</span><br><span class="line">        <span class="keyword">this</span>.start = start;</span><br><span class="line">        <span class="keyword">this</span>.end = end;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Date <span class="title">start</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> start;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Date <span class="title">end</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> end;</span><br><span class="line">    &#125;</span><br><span class="line">    ... <span class="comment">// Remainder omitted</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>乍一看，这个类似乎是不可变的，并且要求一个时间段的开始时间不能在结束时间之后。然而，利用 Date 是可变的这一事实很容易绕过这个约束：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Attack the internals of a Period instance</span></span><br><span class="line">Date start = <span class="keyword">new</span> Date();</span><br><span class="line">Date end = <span class="keyword">new</span> Date();</span><br><span class="line">Period p = <span class="keyword">new</span> Period(start, end);</span><br><span class="line">end.setYear(<span class="number">78</span>); <span class="comment">// Modifies internals of p!</span></span><br></pre></td></tr></table></figure><p>为了防止这样的攻击，可以选择制作防御性副本：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Repaired constructor - makes defensive copies of parameters</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">Period</span><span class="params">(Date start, Date end)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.start = <span class="keyword">new</span> Date(start.getTime());</span><br><span class="line">    <span class="keyword">this</span>.end = <span class="keyword">new</span> Date(end.getTime());</span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">this</span>.start.compareTo(<span class="keyword">this</span>.end) &gt; <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="keyword">this</span>.start + <span class="string">&quot; after &quot;</span> + <span class="keyword">this</span>.end);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Repaired accessors - make defensive copies of internal fields</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Date <span class="title">start</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> Date(start.getTime());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> Date <span class="title">end</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> Date(end.getTime());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>防御性复制可能会带来性能损失，最好的方法是使用不可变类，比如Instant（或 Local-DateTime 或 ZonedDateTime）来代替 Date，Date 已过时，不应在新代码中使用。</p></li><li><p>仔细设计方法签名：</p><ul><li>仔细选择方法名称。</li><li>不要提供过于便利的方法</li><li>避免长参数列表</li><li>对于参数类型，优先选择接口而不是类</li><li>双元素枚举类型优于 boolean 参数</li></ul></li><li><p>明智地使用重载：考虑下面的代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Broken! - What does this program print?</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CollectionClassifier</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">classify</span><span class="params">(Set&lt;?&gt; s)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;Set&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">classify</span><span class="params">(List&lt;?&gt; lst)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;List&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">classify</span><span class="params">(Collection&lt;?&gt; c)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;Unknown Collection&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Collection&lt;?&gt;[] collections = &#123;</span><br><span class="line">            <span class="keyword">new</span> HashSet&lt;String&gt;(),<span class="keyword">new</span> ArrayList&lt;BigInteger&gt;(),<span class="keyword">new</span> HashMap&lt;String, String&gt;().values()</span><br><span class="line">        &#125;;</span><br><span class="line">        <span class="keyword">for</span> (Collection&lt;?&gt; c : collections)</span><br><span class="line">            System.out.println(classify(c));</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>你可能期望这个程序打印 Set，然后是 List 和 Unknown Collection，但是它没有这样做。它打印 Unknown Collection 三次。为什么会这样？因为 classify 方法被重载，并且 在编译时就决定了要调用哪个重载。</p><p>这个程序的行为违反常规，因为重载方法的选择是静态的，而覆盖方法的选择是动态的。 在运行时根据调用方法的对象的运行时类型选择覆盖方法的正确版本。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Wine</span> </span>&#123;</span><br><span class="line">    <span class="function">String <span class="title">name</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> <span class="string">&quot;wine&quot;</span>; &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SparklingWine</span> <span class="keyword">extends</span> <span class="title">Wine</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function">String <span class="title">name</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> <span class="string">&quot;sparkling wine&quot;</span>; &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Champagne</span> <span class="keyword">extends</span> <span class="title">SparklingWine</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function">String <span class="title">name</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> <span class="string">&quot;champagne&quot;</span>; &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Overriding</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        List&lt;Wine&gt; wineList = List.of(<span class="keyword">new</span> Wine(), <span class="keyword">new</span> SparklingWine(), <span class="keyword">new</span> Champagne());</span><br><span class="line">    <span class="keyword">for</span> (Wine wine : wineList)</span><br><span class="line">        System.out.println(wine.name());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>正如你所期望的，这个程序打印出 wine、sparkling 和 champagne，即使实例的编译时类型是循环每次迭代中的 wine。</p><p>应该避免混淆重载的用法。安全、保守的策略是永远不导出具有相同数量参数的两个重载。这些限制并不十分繁琐，因为你总是可以为方法提供不同的名称，而不是重载它们。</p></li><li><p>明智地使用可变参数：可变参数方法接受指定类型的零个或多个参数。可变参数方法首先创建一个数组，其大小是在调用点上传递的参数数量，然后将参数值放入数组，最后将数组传递给方法。在性能关键的情况下使用可变参数时要小心。每次调用可变参数方法都会导致数组分配和初始化。如果你已经从经验上确定你负担不起这个成本，但是你仍需要可变参数的灵活性，那么有一种模式可以让你鱼与熊掌兼得。假设你已经确定对方法 95% 的调用只需要三个或更少的参数。可以声明该方法的 5 个重载，每个重载 0 到 3 个普通参数，当参数数量超过 3 个时引入可变参数：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">foo</span><span class="params">()</span> </span>&#123; &#125;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">foo</span><span class="params">(<span class="keyword">int</span> a1)</span> </span>&#123; &#125;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">foo</span><span class="params">(<span class="keyword">int</span> a1, <span class="keyword">int</span> a2)</span> </span>&#123; &#125;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">foo</span><span class="params">(<span class="keyword">int</span> a1, <span class="keyword">int</span> a2, <span class="keyword">int</span> a3)</span> </span>&#123; &#125;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">foo</span><span class="params">(<span class="keyword">int</span> a1, <span class="keyword">int</span> a2, <span class="keyword">int</span> a3, <span class="keyword">int</span>... rest)</span> </span>&#123; &#125;</span><br></pre></td></tr></table></figure></li><li><p>返回空集合或数组，而不是 null：在几乎每次使用返回 null 来代替空集合或数组的方法时，都需要使用这种权宜之计。它很容易出错，因为编写客户端的程序员可能忘记编写特殊情况的代码来处理 null 返回。这样的错误可能会被忽略多年，因为这样的方法通常返回一个或多个对象。此外，在空容器中返回 null 会使返回容器的方法的实现复杂化。数组的情况与集合的情况相同。永远不要返回 null，而应该返回零长度的数组。永远不要用 null 来代替空数组或集合。它使你的 API 更难以使用，更容易出错，并且没有性能优势。</p></li><li><p>明智地返回 Optional：在 Java 8 之前，在编写在某些情况下无法返回值的方法时，可以采用两种方法。要么抛出异常，要么返回 null（假设返回类型是对象引用类型）。这两种方法都不完美。应该为异常条件保留异常，并且抛出异常代价高昂，因为在创建异常时捕获整个堆栈跟踪。返回 null 没有这些缺点，但是它有自己的缺点。如果方法返回 null，客户端必须包含特殊情况代码来处理 null 返回的可能性，除非程序员能够证明 null 返回是不可能的。如果客户端忽略检查 null 返回并将 null 返回值存储在某个数据结构中，那么 NullPointerException 可能会在将来的某个时间，在代码中的某个与该问题无关的位置产生。</p><p>在 Java 8 中，还有第三种方法来编写可能无法返回值的方法。<code>Optional&lt;T&gt;</code> 类表示一个不可变的容器，它可以包含一个非空的 T 引用，也可以什么都不包含。不包含任何内容的 Optional 被称为空。一个值被认为存在于一个非空的 Optional 中。Optional 的本质上是一个不可变的集合，它最多可以容纳一个元素。具备 Optional 返回值的方法比抛出异常的方法更灵活、更容易使用，并且比返回 null 的方法更不容易出错。</p><p>如果你发现自己编写的方法不能总是返回确定值，并且你认为该方法的用户在每次调用时应该考虑这种可能性，那么你可能应该让方法返回一个 Optional。但是，你应该意识到，返回 Optional 会带来实际的性能后果；对于性能关键的方法，最好返回 null 或抛出异常。最后，除了作为返回值之外，你几乎不应该以任何其他方式使用 Optional。</p></li><li><p>为所有公开的 API 元素编写文档注释：如果 API 要可用，就必须对其进行文档化。传统上，API 文档是手工生成的，保持与代码的同步是一件苦差事。Java 编程环境使用 Javadoc 实用程序简化了这一任务。Javadoc 使用特殊格式的文档注释（通常称为文档注释）从源代码自动生成 API 文档。</p><p>要正确地编写 API 文档，必须在每个公开的类、接口、构造函数、方法和字段声明之前加上文档注释。 如果一个类是可序列化的，还应该记录它的序列化形式。方法的文档注释应该简洁地描述方法与其客户端之间的约定。</p></li></ol><h2 id="第九章-通用程序设计"><a href="#第九章-通用程序设计" class="headerlink" title="第九章 通用程序设计"></a>第九章 通用程序设计</h2><ol start="57"><li><p>将局部变量的作用域最小化：通过最小化局部变量的范围，可以提高代码的可读性和可维护性，并降低出错的可能性。在做循环操作的时候，尽量使用for而不是while。下面是使用局部变量的方法技巧：</p><ul><li>将局部变量的作用域最小化，最具说服力的方式就是在第一次使用它的地方声明。</li><li>每个局部变量声明都应该包含一个初始化表达式。</li><li>最小化局部变量范围的最后一种技术是保持方法小而集中。</li></ul></li><li><p>for-each 循环优于传统的 for 循环：通常我们使用迭代器来遍历集合，使用数组索引遍历数组，但是他们的缺点就是需要自己维护迭代器和索引变量，最好的方法是使用for-each循环。但是，下列情况不适合for-each循环：</p><ul><li>破坏性过滤，如果需要遍历一个集合并删除选定元素，则需要使用显式的迭代器，以便调用其 remove 方法。</li><li>转换，如果需要遍历一个 List 或数组并替换其中部分或全部元素的值，那么需要 List 迭代器或数组索引来替换元素的值。</li><li>并行迭代，如果需要并行遍历多个集合，那么需要显式地控制迭代器或索引变量，以便所有迭代器或索引变量都可以同步执行。</li></ul></li><li><p>了解并使用库：假设你想要生成 0 到某个上界之间的随机整数：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Common but deeply flawed!</span></span><br><span class="line"><span class="keyword">static</span> Random rnd = <span class="keyword">new</span> Random();</span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">int</span> <span class="title">random</span><span class="params">(<span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> Math.abs(rnd.nextInt()) % n;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>有三个缺点：首先，如果 n 是小的平方数，随机数序列会在相当短的时间内重复。第二个缺陷是，如果 n 不是 2 的幂，那么平均而言，一些数字将比其他数字更频繁地返回。第三个缺陷是，在极少数情况下会返回超出指定范围的数字，这是灾难性的结果。</p><p>从 Java 7 开始，就不应该再使用 Random。在大多数情况下，选择的随机数生成器现在是 ThreadLocalRandom。使用这些库能生成更高的随机数，同时，你不必浪费时间为那些与你的工作无关的问题编写专门的解决方案。</p></li><li><p>若需要精确答案就应避免使用 float 和 double 类型：float 和 double 类型特别不适合进行货币计算，因为不可能将 0.1（或 10 的任意负次幂）精确地表示为 float 或 double。为了得到准确值，应该使用BigDecimal或者是long，int类型进行计算操作。</p></li><li><p>基本数据类型优于包装类：将 == 操作符应用于包装类型几乎都是错误的，而在使用基本类型的时候则是正确的。在操作中混合使用基本类型和包装类型时，包装类型就会自动拆箱，如果包装类是null，可能就会导致NullPointerException。</p><p>什么时候该使用包装类型？第一个是作为集合中的元素、键和值。在参数化类型和方法中，必须使用包装类型作为类型参数，因为 Java 不允许使用基本类型。最后，在进行反射方法调用时，必须使用包装类型。</p><p>总之，只要有选择，就应该优先使用基本类型，而不是包装类型。基本类型更简单、更快。当你的程序使用 == 操作符比较两个包装类型时，它会执行标识比较，这几乎肯定不是你想要的。</p></li><li><p>其他类型更合适时应避免使用字符串：字符串被设计用来表示文本，它们在这方面做得很好。下面是一些字符串不推荐使用的方式：</p><ul><li>字符串是枚举类型的糟糕替代品</li><li>字符串是聚合类型的糟糕替代品</li></ul><p>总之，当存在或可以编写更好的数据类型时，应避免将字符串用来表示对象。如果使用不当，字符串比其他类型更麻烦、灵活性更差、速度更慢、更容易出错。字符串经常被误用的类型包括基本类型、枚举和聚合类型。</p></li><li><p>当心字符串连接引起的性能问题：使用字符串串联运算符重复串联 n 个字符串需要 n 的平方级时间。这是字符串不可变这一事实导致的结果。当连接两个字符串时，将复制这两个字符串的内容。要获得能接受的性能，请使用 StringBuilder 代替 String。</p></li><li><p>通过接口引用对象：应该优先使用接口而不是类来引用对象。如果存在合适的接口类型，那么应该使用接口类型声明参数、返回值、变量和字段。惟一真正需要引用对象的类的时候是使用构造函数创建它的时候。如果你养成了使用接口作为类型的习惯，那么你的程序将更加灵活。如果没有合适的接口存在，那么用类引用对象是完全合适的。</p></li><li><p>接口优于反射：核心反射机制 java.lang.reflect 提供对任意类的编程访问。给定一个 Class 对象，你可以获得 Constructor、Method 和 Field 实例，分别代表了该 Class 实例所表示的类的构造器、方法和字段。使用反射是有代价的：</p><ul><li>你失去了编译时类型检查的所有好处，包括异常检查</li><li>执行反射访问所需的代码既笨拙又冗长</li><li>性能降低，反射方法调用比普通方法调用慢得多</li></ul><p>反射是一种功能强大的工具，对于某些复杂的系统编程任务是必需的，但是它有很多缺点。如果编写的程序必须在编译时处理未知的类，则应该尽可能只使用反射实例化对象，并使用在编译时已知的接口或超类访问对象。</p></li><li><p>明智地使用本地方法：Java 本地接口（JNI）允许 Java 程序调用本地方法，这些方法是用 C 或 C++ 等本地编程语言编写的。为了提高性能，很少建议使用本地方法。使用本地方法有严重的缺点。由于本地语言不安全，使用本地方法的应用程序不再能免受内存毁坏错误的影响同时很难进行调试。</p></li><li><p>明智地进行优化：不要过早地进行优化。为了获得良好的性能而改变 API 是一个非常糟糕的想法。同时，在每次尝试优化之前和之后测量性能。</p></li><li><p>遵守被广泛认可的命名约定：</p><table><thead><tr><th>Identifier Type</th><th>Example</th></tr></thead><tbody><tr><td>Package or module</td><td><code>org.junit.jupiter.api</code>, <code>com.google.common.collect</code></td></tr><tr><td>Class or Interface</td><td>Stream, FutureTask, LinkedHashMap, HttpClient</td></tr><tr><td>Method or Field</td><td>remove, groupingBy, getCrc</td></tr><tr><td>Constant Field</td><td>MIN_VALUE, NEGATIVE_INFINITY</td></tr><tr><td>Local Variable</td><td>i, denom, houseNum</td></tr><tr><td>Type Parameter</td><td>T, E, K, V, X, R, U, V, T1, T2</td></tr></tbody></table></li></ol><h2 id="第十章-异常"><a href="#第十章-异常" class="headerlink" title="第十章 异常"></a>第十章 异常</h2><ol start="69"><li><p>仅在确有异常条件下使用异常：异常只适用于确有异常的情况；它们不应该用于一般的控制流程。下列代码不应该使用：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Horrible abuse of exceptions. Don&#x27;t ever do this!</span></span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">int</span> i = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span>(<span class="keyword">true</span>)</span><br><span class="line">        range[i++].climb();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">catch</span> (ArrayIndexOutOfBoundsException e) &#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们完全可以使用for-each循环实现。</p></li><li><p>对可恢复情况使用 checked 异常，对编程错误使用运行时异常：Java 提供了三种可抛出项：checked 异常、运行时异常和错误。决定是使用 checked 异常还是 unchecked 异常的基本规则是：使用 checked 异常的情况是为了合理地期望调用者能够从中恢复。有两种 unchecked 的可抛出项：运行时异常和错误。它们在行为上是一样的：都是可抛出的，通常不需要也不应该被捕获。使用运行时异常来指示编程错误。 绝大多数运行时异常都表示操作违反了先决条件。</p></li><li><p>避免不必要地使用 checked 异常：在 API 中过度使用 checked 异常会变得不那么令人愉快。如果一个方法抛出 checked 异常，调用它的代码必须在一个或多个 catch 块中处理它们；或者通过声明抛出，让它们向外传播。无论哪种方式，它都给 API 的用户带来了负担。消除 checked 异常的最简单方法是返回所需结果类型的 Optional 对象（Item-55）。该方法只返回一个空的 Optional 对象，而不是抛出一个 checked 异常。</p><p>总之，如果谨慎使用，checked 异常可以提高程序的可靠性；当过度使用时，它们会使 API 难以使用。如果调用者不应从失败中恢复，则抛出 unchecked 异常。如果恢复是可能的，并且你希望强制调用者处理异常条件，那么首先考虑返回一个 Optional 对象。只有当在失败的情况下，提供的信息不充分时，你才应该抛出一个 checked 异常。</p></li><li><p>鼓励复用标准异常：使你的 API 更容易学习和使用，因为它符合程序员已经熟悉的既定约定。最常见的可复用异常：</p><table><thead><tr><th>Exception</th><th>Occasion for Use</th></tr></thead><tbody><tr><td>IllegalArgumentException</td><td>Non-null parameter value is inappropriate（非空参数值不合适）</td></tr><tr><td>IllegalStateException</td><td>Object state is inappropriate for method invocation（对象状态不适用于方法调用）</td></tr><tr><td>NullPointerException</td><td>Parameter value is null where prohibited（禁止参数为空时仍传入 null）</td></tr><tr><td>IndexOutOfBoundsException</td><td>Index parameter value is out of range（索引参数值超出范围）</td></tr><tr><td>ConcurrentModificationException</td><td>Concurrent modification of an object has been detected where it is prohibited（在禁止并发修改对象的地方检测到该动作）</td></tr><tr><td>UnsupportedOperationException</td><td>Object does not support method（对象不支持该方法调用）</td></tr></tbody></table><p>另外，不要直接复用 Exception、RuntimeException、Throwable 或 Error。应当将这些类视为抽象类。你不能对这些异常进行可靠的测试，因为它们是方法可能抛出的异常的超类。</p></li><li><p>抛出能用抽象解释的异常：当一个方法抛出一个与它所执行的任务没有明显关联的异常时，这是令人不安的。这种情况经常发生在由方法传播自低层抽象抛出的异常。为了避免这个问题，高层应该捕获低层异常，并确保抛出的异常可以用高层抽象解释。 这个习惯用法称为异常转换：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Exception Translation</span></span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">    ... <span class="comment">// Use lower-level abstraction to do our bidding</span></span><br><span class="line">&#125; <span class="keyword">catch</span> (LowerLevelException e) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> HigherLevelException(...);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>虽然异常转换优于底层异常的盲目传播，但它不应该被过度使用。在可能的情况下，处理低层异常的最佳方法是确保低层方法避免异常。</p></li><li><p>为每个方法记录会抛出的所有异常：始终单独声明 checked 异常，并使用 Javadoc 的 @throw 标记精确记录每次抛出异常的条件。使用 Javadoc 的 @throw 标记记录方法会抛出的每个异常，但是不要对 unchecked 异常使用 throws 关键字。如果一个类中的许多方法都因为相同的原因抛出异常，你可以在类的文档注释中记录异常， 而不是为每个方法单独记录异常。</p></li><li><p>异常详细消息中应包含捕获失败的信息：当程序由于未捕获异常而失败时，系统可以自动打印出异常的堆栈跟踪。堆栈跟踪包含异常的字符串表示，这是调用其 toString 方法的结果。这通常包括异常的类名及其详细信息。要捕获失败，异常的详细消息应该包含导致异常的所有参数和字段的值。因为许多人在诊断和修复软件问题的过程中可能会看到堆栈跟踪，所以不应包含密码、加密密钥等详细信息。</p></li><li><p>尽力保证故障原子性：在对象抛出异常之后，通常希望对象仍然处于定义良好的可用状态，即使在执行操作时发生了故障。对于 checked 异常尤其如此，调用者希望从异常中恢复。一般来说，失败的方法调用应该使对象处于调用之前的状态。 具有此属性的方法称为具备故障原子性。有几种方式可以达到这种效果：</p><ul><li>最简单的方法是设计不可变对象</li><li>对计算进行排序，以便可能发生故障的部分都先于修改对象的部分发生</li><li>以对象的临时副本执行操作，并在操作完成后用临时副本替换对象的内容</li><li>编写恢复代码，拦截在操作过程中发生的故障，并使对象回滚到操作开始之前的状态</li></ul></li><li><p>不要忽略异常：如果在方法调用的周围加上一条 try 语句，其 catch 块为空，可以很容易忽略异常，空 catch 块违背了异常的目的，它的存在是为了强制你处理异常情况。如果你选择忽略异常，catch 块应该包含一条注释，解释为什么这样做是合适的，并且应该将变量命名为 ignored。</p></li></ol><h2 id="第十一章-并发"><a href="#第十一章-并发" class="headerlink" title="第十一章 并发"></a>第十一章 并发</h2><ol start="78"><li><p>对共享可变数据的同步访问：synchronized 关键字确保一次只有一个线程可以执行一个方法或块。没有同步，一个线程所做的的更改可能对其他线程不可见。同步不仅阻止线程察觉到处于不一致状态的对象，而且确保每个进入同步方法或块的线程都能察觉由同一把锁保护的所有已修改的效果。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Broken! - How long would you expect this program to run?</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">StopThread</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">boolean</span> stopRequested;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        Thread backgroundThread = <span class="keyword">new</span> Thread(() -&gt; &#123;</span><br><span class="line">        <span class="keyword">int</span> i = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span> (!stopRequested)</span><br><span class="line">            i++;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">    backgroundThread.start();</span><br><span class="line">    TimeUnit.SECONDS.sleep(<span class="number">1</span>);</span><br><span class="line">    stopRequested = <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在缺乏同步的情况下，无法保证后台线程何时（如果有的话）看到主线程所做的 stopRequested 值的更改。在缺乏同步的情况下，虚拟机可以很好地转换这段代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> (!stopRequested)</span><br><span class="line">    i++;</span><br><span class="line">into <span class="keyword">this</span> code:</span><br><span class="line"><span class="keyword">if</span> (!stopRequested)</span><br><span class="line">    <span class="keyword">while</span> (<span class="keyword">true</span>)</span><br><span class="line">        i++;</span><br></pre></td></tr></table></figure><p>这种优化称为提升，这正是 OpenJDK 服务器 VM 所做的。结果是活性失败：程序无法取得进展。</p><p>注意，写方法（requestStop）和读方法（stopRequested）都是同步的。仅同步写方法是不够的！除非读和写操作都同步，否则不能保证同步工作。虽然 volatile 修饰符不执行互斥，但它保证任何读取字段的线程都会看到最近写入的值。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Broken - requires synchronization!</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">volatile</span> <span class="keyword">int</span> nextSerialNumber = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">generateSerialNumber</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> nextSerialNumber++;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>问题在于增量运算符 (++) 不是原子性的。它对 nextSerialNumber 字段执行两个操作：首先读取值，然后返回一个新值，旧值再加 1。如果第二个线程在读取旧值和写入新值之间读取字段，则第二个线程将看到与第一个线程相同的值，并返回相同的序列号。可以将 synchronized 添加到方法声明中，另外，也使用 AtomicLong 类，它是 <code>java.util.concurrent.atomic</code> 的一部分。</p><p>总之，当多个线程共享可变数据时，每个读取或写入数据的线程都必须执行同步。 在缺乏同步的情况下，不能保证一个线程的更改对另一个线程可见。</p></li><li><p>避免过度同步：过度的同步可能导致性能下降、死锁甚至不确定行为。作为规则，你应该在同步区域内做尽可能少的工作。获取锁，检查共享数据，根据需要进行转换，然后删除锁。如果你必须执行一些耗时的活动，请设法将其移出同步区域。</p></li><li><p>Executor、task、流优于直接使用线程：java.util.concurrent 已经添加到 Java 中。这个包有一个 Executor 框架，它是一个灵活的基于接口的任务执行工具。对于小程序或负载较轻的服务器，Executors.newCachedThreadPool 通常是一个不错的选择，因为它不需要配置，而且通常「做正确的事情」。但是对于负载沉重的生产服务器来说，缓存的线程池不是一个好的选择！在缓存的线程池中，提交的任务不会排队，而是立即传递给线程执行。如果没有可用的线程，则创建一个新的线程。如果服务器负载过重，所有 CPU 都被充分利用，并且有更多的任务到达，就会创建更多的线程，这只会使情况变得更糟。因此，在负载沉重的生产服务器中，最好使用 Executors.newFixedThreadPool，它为你提供一个线程数量固定的池，或者直接使用 ThreadPoolExecutor 类来实现最大限度的控制。</p></li><li><p>并发实用工具优于 wait 和 notify：考虑到正确使用 wait 和 notify 的困难，你应该使用更高级别的并发实用工具。java.util.concurrent 中级别较高的实用工具可分为三类：Executor 框架，Item-80 简要介绍了该框架；并发集合；同步器。本条目简要介绍并发集合和同步器。</p><p>并发集合是标准集合接口，如 List、Queue 和 Map 的高性能并发实现。为了提供高并发性，这些实现在内部管理它们自己的同步。一些集合接口使用阻塞操作进行了扩展，这些操作将等待（或阻塞）成功执行。例如，BlockingQueue 扩展了 Queue 并添加了几个方法，包括 take，它从队列中删除并返回首个元素，如果队列为空，则等待。</p><p>同步器是允许线程彼此等待的对象，允许它们协调各自的活动。最常用的同步器是 CountDownLatch 和 Semaphore。较不常用的是 CyclicBarrier 和 Exchanger。最强大的同步器是 Phaser。</p><p>始终使用 wait 习惯用法，即循环来调用 wait 方法；永远不要在循环之外调用它。 循环用于在等待之前和之后测试条件。</p></li><li><p>文档应包含线程安全属性：类的线程安全的描述通常属于该类的文档注释，但是具有特殊线程安全属性的方法应该在它们自己的文档注释中描述这些属性。没有必要记录枚举类型的不变性。</p></li><li><p>明智地使用延迟初始化：延迟初始化是延迟字段的初始化，直到需要它的值。与大多数优化一样，延迟初始化的最佳建议是「除非需要，否则不要这样做」。在大多数情况下，常规初始化优于延迟初始化。</p></li><li><p>不要依赖线程调度器：任何依赖线程调度器来保证正确性或性能的程序都可能是不可移植的。如果线程没有做有用的工作，它们就不应该运行。线程优先级可以少量地用于提高已经工作的程序的服务质量，但绝不应该用于「修复」几乎不能工作的程序。</p></li></ol><h2 id="第十二章-序列化"><a href="#第十二章-序列化" class="headerlink" title="第十二章 序列化"></a>第十二章 序列化</h2><ol start="85"><li><p>Java 序列化的替代方案：序列化的一个根本问题是它的可攻击范围太大，且难以保护，而且问题还在不断增多：通过调用 ObjectInputStream 上的 readObject 方法反序列化对象图。这个方法本质上是一个神奇的构造函数，可以用来实例化类路径上几乎任何类型的对象，只要该类型实现 Serializable 接口。避免序列化利用的最好方法是永远不要反序列化任何东西。永远不要反序列化不可信的数据。</p><p>序列化是危险的，应该避免。如果你从头开始设计一个系统，可以使用跨平台的结构化数据，如 JSON 或 protobuf。不要反序列化不可信的数据。如果必须这样做，请使用对象反序列化过滤，但要注意，它不能保证阻止所有攻击。避免编写可序列化的类。</p></li><li><p>非常谨慎地实现 Serializable：使类的实例可序列化非常简单，只需实现 Serializable 接口即可。因为这很容易做到，所以有一个普遍的误解，认为序列化只需要程序员付出很少的努力。而事实上要复杂得多。虽然使类可序列化的即时代价可以忽略不计，但长期代价通常是巨大的：</p><ul><li>一旦类的实现被发布，它就会降低更改该类实现的灵活性</li><li>增加了出现 bug 和安全漏洞的可能性</li><li>增加了与发布类的新版本相关的测试负担</li></ul><p>为继承而设计的类（Item-19）很少情况适合实现 Serializable 接口，接口也很少情况适合扩展它。另外，内部类不应该实现 Serializable。</p></li><li><p>考虑使用自定义序列化形式：当对象的物理表示与其逻辑数据内容有很大差异时，使用默认的序列化形式有四个缺点：</p><ul><li>它将导出的 API 永久地绑定到当前的内部实现</li><li>它会占用过多的空间</li><li>它会消耗过多的时间</li><li>它可能导致堆栈溢出</li></ul><p>无论你是否使用默认的序列化形式，必须对对象序列化强制执行任何同步操作，就像对读取对象的整个状态的任何其他方法强制执行的那样。无论选择哪种序列化形式，都要在编写的每个可序列化类中声明显式的序列版本 UID。 这消除了序列版本 UID 成为不兼容性的潜在来源。这么做还能获得一个小的性能优势。如果没有提供序列版本 UID，则需要执行高开销的计算在运行时生成一个 UID。不要更改序列版本 UID，除非你想破坏与现有序列化所有实例的兼容性。</p></li><li><p>防御性地编写 readObject 方法：当对象被反序列化时，对任何客户端不能拥有的对象引用的字段进行防御性地复制至关重要。 因此，对于每个可序列化的不可变类，如果它包含了私有的可变组件，那么在它的 readObjec 方法中，必须要对这些组件进行防御性地复制：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// readObject method with defensive copying and validity checking</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">readObject</span><span class="params">(ObjectInputStream s)</span> <span class="keyword">throws</span> IOException, ClassNotFoundException </span>&#123;</span><br><span class="line">    s.defaultReadObject();</span><br><span class="line">    <span class="comment">// Defensively copy our mutable components</span></span><br><span class="line">    start = <span class="keyword">new</span> Date(start.getTime());</span><br><span class="line">    end = <span class="keyword">new</span> Date(end.getTime());</span><br><span class="line">    <span class="comment">// Check that our invariants are satisfied</span></span><br><span class="line">    <span class="keyword">if</span> (start.compareTo(end) &gt; <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> InvalidObjectException(start +<span class="string">&quot; after &quot;</span>+ end);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>下面是编写 readObject 方法的指导原则：</p><ul><li>对象引用字段必须保持私有的的类，应防御性地复制该字段中的每个对象</li><li>检查任何不变量，如果检查失败，则抛出 InvalidObjectException</li><li>如果必须在反序列化后验证整个对象图，那么使用 ObjectInputValidation 接口</li><li>不要直接或间接地调用类中任何可被覆盖的方法</li></ul></li><li><p>对于实例控制，枚举类型优于 readResolve：在可能的情况下，使用枚举类型强制实例控制不变量。如果这是不可能的，并且你需要一个既可序列化又实例控制的类，那么你必须提供一个 readResolve 方法，并确保该类的所有实例字段都是基本类型，或使用 transient 修饰。</p></li><li><p>考虑以序列化代理代替序列化实例：实现 Serializable 接口的决定增加了出现 bug 和安全问题的可能性，因为它允许使用一种超语言机制来创建实例，而不是使用普通的构造函数。然而，有一种技术可以大大降低这些风险。这种技术称为序列化代理模式。序列化代理模式相当简单。首先，设计一个私有静态嵌套类，它简洁地表示外围类实例的逻辑状态。这个嵌套类称为外围类的序列化代理。它应该有一个构造函数，其参数类型是外围类。这个构造函数只是从它的参数复制数据：它不需要做任何一致性检查或防御性复制。</p><p>序列化代理模式有两个限制。它与客户端可扩展的类不兼容；序列化代理模式所增强的功能和安全性并不是没有代价的。</p><p>当你发现必须在客户端不可扩展的类上编写 readObject 或 writeObject 方法时，请考虑序列化代理模式。要想稳健地将带有重要约束条件的对象序列化时，这种模式可能是最容易的方法。</p></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>一致性算法</title>
      <link href="2020/11/25/%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95/"/>
      <url>2020/11/25/%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<p>本文主要介绍分布式系统中的一致性算法，包括 Panxos，Raft 和 ZAB 算法。</p><a id="more"></a><h2 id="一致性概念"><a href="#一致性概念" class="headerlink" title="一致性概念"></a>一致性概念</h2><p>CAP 理论：对于一个分布式系统，不能同时满足以下三点：</p><ul><li>一致性（Consistency）：在分布式系统中的所有数据备份，在同一时刻是否同样的值。</li><li>可用性（Availability）：在集群中一部分节点故障后，集群整体是否还能响应客户端的读写请求。</li><li>分区容错性（Partition Tolerance）：一个分布式系统里面，节点组成的网络本来应该是连通的。然而可能因为一些故障，使得有些节点之间不连通了，整个网络就分成了几块区域。数据就散布在了这些不连通的区域中。这就叫分区。当你一个数据项只在一个节点中保存，那么分区出现后，和这个节点不连通的部分就访问不到这个数据了。这时分区就是无法容忍的。提高分区容忍性的办法就是一个数据项复制到多个节点上，那么出现分区之后，这一数据项就可能分布到各个区里。容忍性就提高了。</li></ul><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201125163500285.png" class="lazyload" data-srcset="image-20201125163500285.png" srcset="data:image/png;base64,666" alt="image-20201125163500285"/></div><span class="image-caption">image-20201125163500285</span></div><p>一致性模型：</p><ul><li>弱一致性：如果能容忍后续的部分或者全部访问不到，则是弱一致性。<ul><li>最终一致性：如果经过一段时间后要求能访问到更新后的数据，则是最终一致性。如 DNS，Gossip（Cassandra 通信协议）。</li></ul></li><li>强一致性：对于关系型数据库，要求更新过的数据能被后续的访问都能看到，这是强一致性。如 Raft，ZAB，Paxos。</li></ul><p>问题：数据不能存在单点上，分布式系统对 fault tolerence 的一般解决方案是 state machine replication。其实我们今天讨论的准确的说，应该是 state machine replication的共识( consensus)算法。paxos其实是一个共识算法。系统的最终一致性，不仅需要达成共识，还会取决于 clientl的行为。</p><p>强一致性算法：</p><ul><li><p>主从同步复制：</p><ol><li>Master 接受写请求</li><li>Master 复制日志到 slave</li><li>Master 等待，直到<strong>所有</strong> slave 返回成功信息</li></ol><p>问题：一个节点失败，Master阻塞，导致整个集群不可用，保证了一致性，可用性却大大降低。</p></li><li><p>多数派：每次写都保证写入大于N/2个节点，每次读保证从大于N/2个节点中读。</p><p>问题：并发环境下，无法保证系统正确性，顺序很重要</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201125165428310.png" class="lazyload" data-srcset="image-20201125165428310.png" srcset="data:image/png;base64,666" alt="image-20201125165428310"/></div><span class="image-caption">image-20201125165428310</span></div></li><li><p>Paxos：分为 Basic Paxos，Multi Paxos 和 Fast Paxos。</p></li></ul><p>Basic Paxos：</p><ul><li><p>角色分配：</p><ul><li>Client：请求发起者。像是民众</li><li>Proposer：接受 Client 请求，向集群提出提议，像是议员</li><li>Acceptor（Voter）：提议投票和接受者，只有形成法定人数（Quorum，一般为多数派）时，提议才会最终被接受。像是国会。</li><li>Learner：提议接受者，backup。像是记录员</li></ul></li><li><p>阶段：</p><ol><li>Phase 1a：Prepare：proposer 提出一个提案，编号为 N，这个 N 大于之前提出提案的编号。</li><li>Phase 1b：Promise：如果 N 大于此 acceptor 之前接受的提案编号，则接受，否则拒绝。</li><li>Phase 2a：Accept：如果达到多数派，此时 proposer 发出accept 请求，请求包含编号N，以及提案内容。</li><li>Phase 2b：Accepted：如果 N 大于此 acceptor 之前接受的提案编号，则接受，否则拒绝。</li></ol><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201125182135831.png" class="lazyload" data-srcset="image-20201125182135831.png" srcset="data:image/png;base64,666" alt="image-20201125182135831"/></div><span class="image-caption">image-20201125182135831</span></div></li><li><p>问题：部分节点失败，但是达到了 Quoroms</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201125182308674.png" class="lazyload" data-srcset="image-20201125182308674.png" srcset="data:image/png;base64,666" alt="image-20201125182308674"/></div><span class="image-caption">image-20201125182308674</span></div></li><li><p>问题：Proposer 失败</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201125182517810.png" class="lazyload" data-srcset="image-20201125182517810.png" srcset="data:image/png;base64,666" alt="image-20201125182517810"/></div><span class="image-caption">image-20201125182517810</span></div></li><li><p>问题：活锁，指的是两个 Proposer 互相间隔发出提案，要求进行投票</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201125182646023.png" class="lazyload" data-srcset="image-20201125182646023.png" srcset="data:image/png;base64,666" alt="image-20201125182646023"/></div><span class="image-caption">image-20201125182646023</span></div><blockquote><p>上图中的提案编号应该依次是 1,2,3,4…</p></blockquote><p>使用 Random Timeout 来解决上述问题。</p></li><li><p>其他问题：难以实现，效率低（2 轮 RPC）</p></li></ul><p>Multi Paxos：</p><ul><li><p>新概念：</p><ul><li>Leader：唯一的 Proposer，所有请求都需要经过此 Leader</li></ul></li><li><p>流程：首先执行 Leader 竞选（Basic Paxos 阶段1），选择之后直接执行 Basic Paxos 阶段2即可</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201125183931856.png" class="lazyload" data-srcset="image-20201125183931856.png" srcset="data:image/png;base64,666" alt="image-20201125183931856"/></div><span class="image-caption">image-20201125183931856</span></div></li><li><p>简化：减少角色，Server 之一同时充当 Proposer 和 Acceptor</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201125184130384.png" class="lazyload" data-srcset="image-20201125184130384.png" srcset="data:image/png;base64,666" alt="image-20201125184130384"/></div><span class="image-caption">image-20201125184130384</span></div><p>第一阶段也是进行 Leader 选举，然后再 Propose 提案。</p></li></ul><h2 id="强一致性算法"><a href="#强一致性算法" class="headerlink" title="强一致性算法"></a>强一致性算法</h2><p>Raft 算法：</p><ul><li><p>三个问题：</p><ul><li><p>Leader Election：通过 Election Timeout 来转变为 Candidate，进行选举，选举成功后，Leader 会发送 heartbeat timeout，来表示自己存在与网络当中</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201125185427865.png" class="lazyload" data-srcset="image-20201125185427865.png" srcset="data:image/png;base64,666" alt="image-20201125185427865"/></div><span class="image-caption">image-20201125185427865</span></div><ul><li>问题：Leader 宕机了，剩余节点继续执行 Leader Election</li><li>问题：如果两个节点同时成为 Candidate，则通过 Random Timeout 来恢复</li></ul></li><li><p>Log Replication：首先将 log entry 发送给 follower，之后如果获取到大多数投票后，就进行数据持久化，同时发送消息给客户端，最后发送信号给 follower，进行持久化</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201125190201928.png" class="lazyload" data-srcset="image-20201125190201928.png" srcset="data:image/png;base64,666" alt="image-20201125190201928"/></div><span class="image-caption">image-20201125190201928</span></div></li></ul></li></ul><ul><li><p>Safety：发生故障时或者网络发生分区后，如何进行数据恢复。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201125190443066.png" class="lazyload" data-srcset="image-20201125190443066.png" srcset="data:image/png;base64,666" alt="image-20201125190443066"/></div><span class="image-caption">image-20201125190443066</span></div><p>在下面的网络分区由于没有达到多数派，数据不会被持久化，但是上面的分区却可以进行数据持久化，这也是为什么一般集群中节点的数量是奇数的原因。当网络被修复之后，由于上面一部分的 Term 大于下面一部分，下面一部分就会更改 Leader，同事新的 Leader 会发送数据包进行数据持久化操作。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201125190848884.png" class="lazyload" data-srcset="image-20201125190848884.png" srcset="data:image/png;base64,666" alt="image-20201125190848884"/></div><span class="image-caption">image-20201125190848884</span></div></li></ul><ul><li><p>重新定义角色：</p><ul><li>Leader：整个集群只有一个 Leader</li><li>Follower：只会接受来自 Leader 的请求</li><li>Candidate：准备竞选 Leader 的节点</li></ul></li><li><p>原理动画解释：<a href="http://thesecretlivesofdata.com/raft/">http://thesecretlivesofdata.com/raft/</a></p></li><li><p>场景测试：<a href="https://raft.github.io/">https://raft.github.io</a></p></li></ul><p>ZAB：基本上和 Raft 相同，在一些名词的法上有些区别：如 ZAB 将某一个 leader 的周期称为 epoch,而 raft 则称之为term。实现上也有些许不同：如 raft 保证日志连续性，心跳方向为 leader 至 follower，而 ZAB 则相反。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 分布式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深入理解JAVA虚拟机笔记</title>
      <link href="2020/11/12/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JAVA%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%AC%94%E8%AE%B0/"/>
      <url>2020/11/12/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JAVA%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<p>本文主要整理由周志明编写的《深入理解Java虚拟机》第三版书籍的整理笔记。</p><a id="more"></a><h2 id="第二章-Java内存区域与内存溢出异常"><a href="#第二章-Java内存区域与内存溢出异常" class="headerlink" title="第二章 Java内存区域与内存溢出异常"></a>第二章 Java内存区域与内存溢出异常</h2><p>运行时数据区域：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201112190800951.png" class="lazyload" data-srcset="image-20201112190800951.png" srcset="data:image/png;base64,666" alt="image-20201112190800951"/></div><span class="image-caption">image-20201112190800951</span></div><ul><li>程序计数器：通过改变其值来获取下一条需要执行的字节码指令。</li><li>虚拟机栈：每个方法执行的时候会创建一个栈帧，用于存储局部变量，方法出口等信息。</li><li>本地方法栈：同虚拟机栈，只不过本地方法栈是为本地方法服务的。</li><li>堆：几乎所有的对象实例都会在这里面分配。</li><li>方法区：用于存储已被虚拟机加载的类型信息、常量、静态变量、即时编译器编译后的代码缓存等数据。<ul><li>运行时常量池：是方法区的一部分，常量池表，Class文件中描述信息会放在此处。</li></ul></li></ul><p>直接内存：在JDK 1.4中新加入了NIO（New Input/Output）类，引入了一种基于通道（Channel）与缓冲区（Buffer）的I/O方式，它可以使用Native函数库直接分配堆外内存，然后通过一个存储在Java堆里面的DirectByteBuffer对象作为这块内存的引用进行操作。</p><p>对象的创建：当Java虚拟机遇到一条字节码new指令时，首先将去检查这个指令的参数是否能在常量池中定位到一个类的符号引用，并且检查这个符号引用代表的类是否已被加载、解析和初始化过。如果没有，那必须先执行相应的类加载过程。在类加载检查通过后，接下来虚拟机将为新生对象分配内存。分配方式有指针碰撞和空闲列表两种方式。接下来，就需要执行构造函数了，也就是Class文件中的<code>&lt;init&gt;()</code>方法。</p><p>对象的内存布局：对象在堆里面的内存布局分为三部分：对象头，实例数据，对齐填充</p><ul><li>对象头：第一类用于存储对象自身的运行时数据，如哈希码，GC分代年龄等，第二部分是类型指针，用于确定该对象是那个类的实例。</li><li>实例数据：从父类继承和该类中定义的数据。</li><li>对齐填充：用于保证对象是8字节对齐的。</li></ul><p>对象的访问定位：主流的方式有两种，使用句柄或者使用直接指针，HotSpot虚拟机使用直接指针方式。</p><ul><li><p>句柄：好处就是reference中存储的是稳定句柄地址，在对象被移动（垃圾收集时移动对象是非常普遍的行为）时只会改变句柄中的实例数据指针，而referrence不用修改</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201112195734391.png" class="lazyload" data-srcset="image-20201112195734391.png" srcset="data:image/png;base64,666" alt="image-20201112195734391"/></div><span class="image-caption">image-20201112195734391</span></div></li><li><p>直接指针：好处就是速度更快，它节省了一次指针定位的时间开销</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201112195807566.png" class="lazyload" data-srcset="image-20201112195807566.png" srcset="data:image/png;base64,666" alt="image-20201112195807566"/></div><span class="image-caption">image-20201112195807566</span></div></li></ul><h2 id="第三章-垃圾收集器与内存分配策略"><a href="#第三章-垃圾收集器与内存分配策略" class="headerlink" title="第三章 垃圾收集器与内存分配策略"></a>第三章 垃圾收集器与内存分配策略</h2><p>引用计数算法：在对象中添加一个引用计数器，每当有一个地方引用它时，计数器值就加一；当引用失效时，计数器值就减一；任何时刻计数器为零的对象就是不可能再被使用的。该方法不能检测循环引用。</p><p>可达性分析算法：基本思路就是通过一系列称为“GC Roots”的根对象作为起始节点集，从这些节点开始，根据引用关系向下搜索，搜索过程所走过的路径称为“引用链”（Reference Chain），如果某个对象到GC Roots间没有任何引用链相连，或者用图论的话来说就是从GC Roots到这个对象不可达时，则证明此对象是不可能再被使用的。在Java技术体系中，GC Roots对象有：</p><ul><li>虚拟机栈中引用的对象</li><li>在方法区中类静态属性引用的对象，常量引用的对象</li><li>同步锁持有的对象</li></ul><p>引用类型：在JDK 1.2版之后，Java对引用的概念进行了扩充，有以下几类</p><ul><li>强引用：最传统的“引用”的定义，是指在程序代码之中普遍存在的引用赋值</li><li>软引用：来描述一些还有用，但非必须的对象。只被软引用关联着的对象，在系统将要发生内存溢出异常前，会把这些对象列进回收范围之中进行第二次回收</li><li>弱引用：也是用来描述那些非必须对象，但是它的强度比软引用更弱一些，被弱引用关联的对象只能生存到下一次垃圾收集发生为止</li><li>虚引用：最弱的一种引用关系，一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用来取得一个对象实例，为一个对象设置虚引用关联的唯一目的只是为了能在这个对象被收集器回收时收到一个系统通知</li></ul><p>对象自我拯救：即使在可达性分析算法中判定为不可达的对象，这时候它们暂时还处于“缓刑”阶段，要真正宣告一个对象死亡，至少要经历两次标记过程：如果对象在进行可达性分析后发现没有与GC Roots相连接的引用链，那它将会被第一次标记，随后进行一次筛选，筛选的条件是此对象是否有必要执行finalize()方法。假如对象没有覆盖finalize()方法，或者finalize()方法已经被虚拟机调用过，那么虚拟机将这两种情况都视为“没有必要执行”。如果这个对象被判定为确有必要执行finalize()方法，那么该对象将会被放置在一个名为F-Queue的队列之中，并在稍后由一条由虚拟机自动建立的、低调度优先级的Finalizer线程去执行它们的finalize()方法。finalize()方法是对象逃脱死亡命运的最后一次机会，稍后收集器将对F-Queue中的对象进行第二次小规模的标记，如果对象要在finalize()中成功拯救自己，即只要重新与引用链上的任何一个对象建立关联即可，譬如把自己（this关键字）赋值给某个类变量或者对象的成员变量，那在第二次标记时它将被移出“即将回收”的集合。</p><p>回收方法区：在Java堆中，尤其是在新生代中，对常规应用进行一次垃圾收集通常可以回收70%至99%的内存空间，相比之下，方法区回收囿于苛刻的判定条件，其区域垃圾收集的回收成果往往远低于此。方法区的垃圾收集主要回收两部分内容：废弃的常量和不再使用的类型。</p><p>分代收集理论：建立在三个假说之上：</p><ol><li>弱分代假说：绝大多数对象都是朝生夕灭的。</li><li>强分代假说：熬过越多次垃圾收集过程的对象就越难以消亡。</li><li>跨代引用假说：跨代引用相对于同代引用来说仅占极少数。</li></ol><p>前两个假说表明如果一个区域中大多数对象都是朝生夕灭，难以熬过垃圾收集过程的话，那么把它们集中放在一起，每次回收时只关注如何保留少量存活而不是去标记那些大量将要被回收的对象，就能以较低代价回收到大量的空间；如果剩下的都是难以消亡的对象，那把它们集中放在一块，虚拟机便可以使用较低的频率来回收这个区域，这就同时兼顾了垃圾收集的时间开销和内存的空间有效利用；第三点表明我们就不应再为了少量的跨代引用去扫描整个老年代，也不必浪费空间专门记录每一个对象是否存在及存在哪些跨代引用。</p><p>标记-清除算法：首先标记出所有需要回收的对象，在标记完成后，统一回收掉所有被标记的对象。缺点：第一个是执行效率不稳定，如果Java堆中包含大量对象，而且其中大部分是需要被回收的，这时必须进行大量标记和清除的动作，导致标记和清除两个过程的执行效率都随对象数量增长而降低；第二个是内存空间的碎片化问题，标记、清除之后会产生大量不连续的内存碎片，空间碎片太多可能会导致当以后在程序运行过程中需要分配较大对象时无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201127191857885.png" class="lazyload" data-srcset="image-20201127191857885.png" srcset="data:image/png;base64,666" alt="image-20201127191857885"/></div><span class="image-caption">image-20201127191857885</span></div><p>标记-复制算法：将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉。如果内存中多数对象都是存活的，这种算法将会产生大量的内存间复制的开销，但对于多数对象都是可回收的情况，算法需要复制的就是占少数的存活对象，而且每次都是针对整个半区进行内存回收，分配内存时也就不用考虑有空间碎片的复杂情况，只要移动堆顶指针，按顺序分配即可。这样实现简单，运行高效，不过其缺陷也显而易见，这种复制回收算法的代价是将可用内存缩小为了原来的一半，空间浪费未免太多了一点。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201127191840578.png" class="lazyload" data-srcset="image-20201127191840578.png" srcset="data:image/png;base64,666" alt="image-20201127191840578"/></div><span class="image-caption">image-20201127191840578</span></div><blockquote><p>新生代存在朝生夕灭现象，存活者大概只有 10% 左右，内存空间比可以分为 8 ：1</p></blockquote><p>标记-整理算法：其中的标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向内存空间一端移动，然后直接清理掉边界以外的内存。标记-清除算法与标记-整理算法的本质差异在于前者是一种非移动式的回收算法，而后者是移动式的。是否移动回收后的存活对象是一项优缺点并存的风险决策：在老年代这种每次回收都有大量对象存活区域，移动存活对象并更新所有引用这些对象的地方将会是一种极为负重的操作，而且这种对象移动操作必须全程暂停用户应用程序才能进行；而不移动对象的时候又存在空间碎片化问题。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201127192619303.png" class="lazyload" data-srcset="image-20201127192619303.png" srcset="data:image/png;base64,666" alt="image-20201127192619303"/></div><span class="image-caption">image-20201127192619303</span></div><p>经典垃圾收集器：</p><ul><li><p>Serial 收集器：是一个单线程工作的收集器，但它的“单线程”的意义并不仅仅是说明它只会使用一个处理器或一条收集线程去完成垃圾收集工作，更重要的是强调在它进行垃圾收集时，必须暂停其他所有工作线程，直到它收集结束。优点是简单，内存消耗低；缺点是需要暂停其他工作线程。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201127193322965.png" class="lazyload" data-srcset="image-20201127193322965.png" srcset="data:image/png;base64,666" alt="image-20201127193322965"/></div><span class="image-caption">image-20201127193322965</span></div></li><li><p>ParNew 收集器：实质上是Serial收集器的多线程并行版本。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201127193714941.png" class="lazyload" data-srcset="image-20201127193714941.png" srcset="data:image/png;base64,666" alt="image-20201127193714941"/></div><span class="image-caption">image-20201127193714941</span></div></li><li><p>Parallel Scavenge收集器：也是一款新生代收集器，它同样是基于标记-复制算法实现的收集器，也是能够并行收集的多线程收集器，它的特点在于它的关注点与其他收集器不同，CMS等收集器的关注点是尽可能地缩短垃圾收集时用户线程的停顿时间，而Parallel Scavenge收集器的目标则是达到一个可控制的吞吐量。</p></li><li><p>Serial Old收集器：Serial收集器的老年代版本，它同样是一个单线程收集器，使用标记-整理算法。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201127194020758.png" class="lazyload" data-srcset="image-20201127194020758.png" srcset="data:image/png;base64,666" alt="image-20201127194020758"/></div><span class="image-caption">image-20201127194020758</span></div></li><li><p>Parallel Old收集器：是Parallel Scavenge收集器的老年代版本，支持多线程并发收集，基于标记-整理算法实现。吞吐量优先收集器。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201127194122503.png" class="lazyload" data-srcset="image-20201127194122503.png" srcset="data:image/png;base64,666" alt="image-20201127194122503"/></div><span class="image-caption">image-20201127194122503</span></div></li><li><p>CMS（Concurrent Mark Sweep）收集器：是一种以获取最短回收停顿时间为目标的收集器。很大一部分Java应用基于 B/S 实现，这类应用通常都会较为关注服务的响应速度，希望系统停顿时间尽可能短，以给用户带来良好的交互体验。CMS收集器就非常符合这类应用的需求。收集过程如下：</p><ol><li>初始标记：记仅仅只是标记一下GC Roots能直接关联到的对象，速度很快；Stop the World</li><li>并发标记：是从GC Roots的直接关联对象开始遍历整个对象图的过程，这个过程耗时较长但是不需要停顿用户线程，可以与垃圾收集线程一起并发运行；</li><li>重新标记：则是为了修正并发标记期间，因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录；Stop the World</li><li>并发清除：清理删除掉标记阶段判断的已经死亡的对象，由于不需要移动存活对象，所以这个阶段也是可以与用户线程同时并发的。</li></ol><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201127194644675.png" class="lazyload" data-srcset="image-20201127194644675.png" srcset="data:image/png;base64,666" alt="image-20201127194644675"/></div><span class="image-caption">image-20201127194644675</span></div><p>优点：并发收集，低停顿；缺点：对处理器资源敏感（并发阶段会导致应用程序变慢，降低总吞吐量），无法处理“浮动垃圾”（并发清理阶段，用户线程是还在继续运行的，程序在运行自然就还会伴随有新的垃圾对象不断产生），基于标记清除，空间碎片化问题严重。</p></li><li><p>Garbage First收集器：简称 G1 收集器，在G1收集器出现之前的所有其他收集器，包括CMS在内，垃圾收集的目标范围要么是整个新生代（Minor GC），要么就是整个老年代（Major GC），再要么就是整个Java堆（Full GC）。而G1跳出了这个樊笼，它可以面向堆内存任何部分来组成回收集（Collection Set，一般简称CSet）进行回收，衡量标准不再是它属于哪个分代，而是哪块内存中存放的垃圾数量最多，回收收益最大，这就是G1收集器的Mixed GC模式。G1不再坚持固定大小以及固定数量的分代区域划分，而是把连续的Java堆划分为多个大小相等的独立区域（Region），每一个Region都可以根据需要，扮演新生代的Eden空间、Survivor空间，或者老年代空间。收集器能够对扮演不同角色的Region采用不同的策略去处理，从而获取更好的收集效果。G1收集器过程：</p><ol><li>初始标记：仅仅只是标记一下GC Roots能直接关联到的对象，需要短暂停顿</li><li>并发标记：从GC Root开始对堆中对象进行可达性分析，递归扫描整个堆里的对象图，找出要回收的对象，这阶段耗时较长，但可与用户程序并发执行。</li><li>最终标记：对用户线程做另一个短暂的暂停，用于处理并发阶段结束后仍遗留下来的最后那少量的SATB记录。</li><li>筛选回收：负责更新Region的统计数据，对各个Region的回收价值和成本进行排序，根据用户所期望的停顿时间来制定回收计划，可以自由选择任意多个Region构成回收集，然后把决定回收的那一部分Region的存活对象复制到空的Region中，再清理掉整个旧Region的全部空间。这里的操作涉及存活对象的移动，是必须暂停用户线程，由多条收集器线程并行完成的。</li></ol><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201127201915199.png" class="lazyload" data-srcset="image-20201127201915199.png" srcset="data:image/png;base64,666" alt="image-20201127201915199"/></div><span class="image-caption">image-20201127201915199</span></div></li></ul><p>低延迟垃圾收集器：HotSpot的垃圾收集器从Serial发展到CMS再到G1，经历了逾二十年时间，经过了数百上千万台服务器上的应用实践，已经被淬炼得相当成熟了，不过它们距离“完美”还是很遥远。衡量垃圾收集器的三项最重要的指标是：内存占用（Footprint）、吞吐量（Throughput）和延迟（Latency），三者共同构成了一个“不可能三角”。图3-14中浅色阶段表示必须挂起用户线程，深色表示收集器线程与用户线程是并发工作的。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201127202152302.png" class="lazyload" data-srcset="image-20201127202152302.png" srcset="data:image/png;base64,666" alt="image-20201127202152302"/></div><span class="image-caption">image-20201127202152302</span></div><ul><li><p>Shenandoah收集器：Shenandoah作为第一款不由Oracle（包括以前的Sun）公司的虚拟机团队所领导开发的HotSpot垃圾收集器，不可避免地会受到一些来自“官方”的排挤。Shenandoah反而更像是G1的下一代继承者，它们两者有着相似的堆内存布局，在初始标记、并发标记等许多阶段的处理思路上都高度一致，甚至还直接共享了一部分实现代码。虽然Shenandoah也是使用基于Region的堆内存布局，同样有着用于存放大对象的Humongous Region，默认的回收策略也同样是优先处理回收价值最大的Region……但在管理堆内存方面，它与G1至少有三个明显的不同之处，最重要的当然是支持并发的整理算法，G1的回收阶段是可以多线程并行的，但却不能与用户线程并发；其次，Shenandoah（目前）是默认不使用分代收集的；Shenandoah摒弃了在G1中耗费大量内存和计算资源去维护的记忆集，改用名为“连接矩阵”（Connection Matrix）的全局数据结构来记录跨Region的引用关系，降低了处理跨代指针时的记忆集维护消耗。大致上可以分为九个阶段：初始标记，并发标记，最终标记，并发清理，并发回收，初始引用更新，最终引用更新，并发清理。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201127203047510.png" class="lazyload" data-srcset="image-20201127203047510.png" srcset="data:image/png;base64,666" alt="image-20201127203047510"/></div><span class="image-caption">image-20201127203047510</span></div><p>最重要三个阶段是并发标记、并发回收、并发引用更新。</p></li><li><p>ZCG收集器：Z Garbage Collector，是由Oracle公司研发的。ZGC和Shenandoah的目标是高度相似的，都希望在尽可能对吞吐量影响不太大的前提下[2]，实现在任意堆内存大小下都可以把垃圾收集的停顿时间限制在十毫秒以内的低延迟。ZGC也采用基于Region的堆内存布局，但与它们不同的是，ZGC的Region（在一些官方资料中将它称为Page或者ZPage，本章为行文一致继续称为Region）具有动态性——动态创建和销毁，以及动态的区域容量大小。Shenandoah使用转发指针和读屏障来实现并发整理，ZGC虽然同样用到了读屏障，但用的却是一条与Shenandoah完全不同，更加复杂精巧的解题思路：染色指针技术。分为四个阶段：并发标记，并发预备重分配，并发重分配，并发重映射。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201127203846223.png" class="lazyload" data-srcset="image-20201127203846223.png" srcset="data:image/png;base64,666" alt="image-20201127203846223"/></div><span class="image-caption">image-20201127203846223</span></div></li></ul><p>Epsilon收集器：这是一款以不能够进行垃圾收集为“卖点”的垃圾收集器，要负责堆的管理与布局、对象的分配、与解释器的协作、与编译器的协作、与监控子系统协作等职责，其中至少堆的管理和对象的分配这部分功能是Java虚拟机能够正常运作的必要支持，是一个最小化功能的垃圾收集器也必须实现的内容。对弈比较小的应用有用武之地。</p><h2 id="第四章-虚拟机性能监控、故障处理工具"><a href="#第四章-虚拟机性能监控、故障处理工具" class="headerlink" title="第四章 虚拟机性能监控、故障处理工具"></a>第四章 虚拟机性能监控、故障处理工具</h2><p>基础故障处理工具：</p><ul><li>jps：虚拟机进程状况工具，可以列出正在运行的虚拟机进程，并显示虚拟机执行主类（Main Class，main()函数所在的类）名称以及这些进程的本地虚拟机唯一ID（LVMID，Local Virtual Machine Identifier）。</li><li>jstat（JVM Statistics Monitoring Tool）：用于监视虚拟机各种运行状态信息的命令行工具，可以显示本地或者远程[1]虚拟机进程中的类加载、内存、垃圾收集、即时编译等运行时数据。</li><li>jinfo（Configuration Info for Java）：实时查看和调整虚拟机各项参数。</li><li>jmap（Memory Map for Java）：用于生成堆转储快照（一般称为heapdump或dump文件）。</li><li>jhat（JVM Heap Analysis Tool）：与jmap搭配使用，来分析jmap生成的堆转储快照。</li><li>jstack（Stack Trace for Java）：用于生成虚拟机当前时刻的线程快照（一般称为threaddump或者 javacore文件），线程快照就是当前虚拟机内每一条线程正在执行的方法堆栈的集合，生成线程快照的目的通常是定位线程出现长时间停顿的原因，如线程间死锁、死循环。</li></ul><p>可视化故障处理工具：</p><ul><li>JHSDB：基于服务性代理的调试工具</li><li>JConsole：Java监视与管理控制台</li><li>VisualVM：多合-故障处理工具，是功能最强大的运行监视和故障处理程序之一</li><li>JMC（Java Mission Control）：可持续在线的监控工具</li></ul><h2 id="第六章-类文件结构"><a href="#第六章-类文件结构" class="headerlink" title="第六章 类文件结构"></a>第六章 类文件结构</h2><p>平台无关性：字节码(Byte Code)文件是构成平台无关性的基石，Java 虚拟机只接受字节码文件，而不管这些文件是怎么的得到的，这就为其他语言可以运行在 Java 虚拟机上提供了基础。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201128225527804.png" class="lazyload" data-srcset="image-20201128225527804.png" srcset="data:image/png;base64,666" alt="image-20201128225527804"/></div><span class="image-caption">image-20201128225527804</span></div><p>Class类文件的结构：</p><ul><li><p>Class文件是一组以8个字节为基础单位的二进制流，并且按照 Big-Endian 来排列位数较大的数。</p></li><li><p>Class文件采用一种类似C语言的言结构体的伪结构来存储数据，这种伪结构中只有两种数据类型：“无符号数”和“表”。</p><ul><li><p>无符号数属于基本的数据类型，以u1、u2、u4、u8来分别代表1个字节、2个字节、4个字节和8个<br>字节的无符号数，无符号数可以用来描述数字、索引引用、数量值或者按照UTF-8编码构成字符串<br>值。</p></li><li><p>表是由多个无符号数或者其他表作为数据项构成的复合数据类型，为了便于区分，所有表的命名<br>都习惯性地以“_info”结尾。整个Class文件本质上也可以视作是一张表：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201128230232765.png" class="lazyload" data-srcset="image-20201128230232765.png" srcset="data:image/png;base64,666" alt="image-20201128230232765"/></div><span class="image-caption">image-20201128230232765</span></div><p>无论是无符号数还是表，当需要描述同一类型但数量不定的多个数据时，经常会使用一个前置的容量计数器加若干个连续的数据项的形式，这时候称这一系列连续的某一类型的数据为某一类型的“集合”。</p></li></ul></li><li><p>魔数：每个Class文件的头4个字节被称为魔数（Magic Number），它的唯一作用是确定这个文件是否为一个能被虚拟机接受的Class文件。文件格式的制定者可以自由地选择魔数值，只要这个魔数值还没有被广泛采用过而且不会引起混淆。Class文件的魔数取得很有“浪漫气息”，值为0xCAFEBABE（咖啡宝贝？）。</p></li><li><p>Class 文件的版本：第5和第6个字节是次版本号（Minor Version），第7和第8个字节是主版本号（Major Version）。</p></li><li><p>常量池：常量池可以比喻为Class文件里的资源仓库，它是Class文件结构中与其他项目关联最多的数据，通常也是占用Class文件空间最大的数据项目之一。由于常量池中常量的数量是不固定的，所以在常量池的入口需要放置一项u2类型的数据，代表常量池容量计数值（constant_pool_count）。与Java中语言习惯不同，这个容量计数是从1而不是0开始的。这样做的目的在于，如果后面某些指向常量池的索引值的数据在特定情况下需要表达“不引用任何一个常量池项目”的含义，可以把索引值设置为0来表示。常量池中主要存放两大类常量：字面量（Literal）和符号引用（Symbolic References）。常量池中每一项常量都是一个表，截至JDK13，常量表中分别有17种不同类型的常量。这17类表都有一个共同的特点，表结构起始的第一位是个u1类型的标志位（tag，取值见表6-3中标志列），代表着当前常量属于哪种常量类型。17种常量类型：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201128235404018.png" class="lazyload" data-srcset="image-20201128235404018.png" srcset="data:image/png;base64,666" alt="image-20201128235404018"/></div><span class="image-caption">image-20201128235404018</span></div></li><li><p>访问标志：用于识别一些类或者接口层次的访问信息，包括：这个Class是类还是接口；是否定义为public类型；是否定义为abstract类型；如果是类的话，是否被声明为final；</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201129000121788.png" class="lazyload" data-srcset="image-20201129000121788.png" srcset="data:image/png;base64,666" alt="image-20201129000121788"/></div><span class="image-caption">image-20201129000121788</span></div></li><li><p>类索引、父类索引与接口索引集合：类索引（this_class）和父类索引（super_class）都是一个u2类型的数据，而接口索引集合（interfaces）是一组u2类型的数据的集合，Class文件中由这三项数据来确定该类型的继承关系。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201129091647440.png" class="lazyload" data-srcset="image-20201129091647440.png" srcset="data:image/png;base64,666" alt="image-20201129091647440"/></div><span class="image-caption">image-20201129091647440</span></div></li><li><p>字段表集合：字段表（field_info）用于描述接口或者类中声明的变量。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201129091933843.png" class="lazyload" data-srcset="image-20201129091933843.png" srcset="data:image/png;base64,666" alt="image-20201129091933843"/></div><span class="image-caption">image-20201129091933843</span></div><p>字段修饰符放在access_flags项目中，跟随access_flags标志的是两项索引值：name_index descriptor_index。它们都是对常量池项的引用，分别代表着字段的简单名称以及字段和方法的描述符。</p></li><li><p>方法表集合：Class文件存储格式中对方法的描述与对字段的描述采用了几乎完全一致的方式，方法表的结构如同字段表一样，依次包括访问标志（access_flags）、名称索引（name_index）、描述符索引（descriptor_index）、属性表集合（attributes）几项，如表6-11所示。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201129092210757.png" class="lazyload" data-srcset="image-20201129092210757.png" srcset="data:image/png;base64,666" alt="image-20201129092210757"/></div><span class="image-caption">image-20201129092210757</span></div></li><li><p>属性表集合：属性表（attribute_info）在前面的讲解之中已经出现过数次，Class文件、字段表、方法表都可以携带自己的属性表集合，以描述某些场景专有的信息。部分属性表如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201129092437699.png" class="lazyload" data-srcset="image-20201129092437699.png" srcset="data:image/png;base64,666" alt="image-20201129092437699"/></div><span class="image-caption">image-20201129092437699</span></div><p>对于每一个属性，它的名称都要从常量池中引用一个CONSTANT_Utf8_info类型的常量来表示，而属性值的结构则是完全自定义的，只需要通过一个u4的长度属性去说明属性值所占用的位数即可。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201129092513520.png" class="lazyload" data-srcset="image-20201129092513520.png" srcset="data:image/png;base64,666" alt="image-20201129092513520"/></div><span class="image-caption">image-20201129092513520</span></div></li></ul><p>字节码指令简介：由于Java虚拟机采用面向操作数栈而不是面向寄存器的架构，所以大多数指令都不包含操作数，只有一个操作码（一个字节），指令参数都存放在操作数栈中。由于Class文件格式放弃了编译后代码的操作数长度对齐，这就意味着虚拟机在处理那些超过一个字节的数据时，不得不在运行时从字节中重建出具体数据的结构；放弃了操作数长度对齐，就意味着可以省略掉大量的填充和间隔符号；用一个字节来代表操作码，也是为了尽可能获得短小精干的编译代码。</p><ul><li>字节码和数据类型：大多数指令都包含其操作所对应的数据类型信息，如iload，fload。大部分指令都没有支持整数类型byte、char和short，甚至没有任何指令支持boolean类型。编译器会在编译期或运行期将byte和short类型的数据带符号扩展（Sign-Extend）为相应的int类型数据，将boolean和char类型数据零位扩展（Zero-Extend）为相应的int类型数据。</li><li>加载和存储指令：<code>iload、iload_&lt;n&gt;、，istore、istore_&lt;n&gt;</code>等</li><li>运算指令：算术指令用于对两个操作数栈上的值进行某种特定运算，并把结果重新存入到操作栈顶。分为两种：对整型数据进行运算的指令与对浮点型数据进行运算的指令。换句话说是不存在直接支持byte、short、char和boolean类型的算术指令，对于上述几种数据的运算，应使用操作int类型的指令代替。指令有：<code>iadd、ladd、fadd、dadd</code>等。Java虚拟机在进行浮点数运算时，所有的运算结果都必须舍入到适当的精度，非精确的结果必须舍入为可被表示的最接近的精确值；如果有两种可表示的形式与该值一样接近，那将优先选择最低有效位为零的；而在把浮点数转换为整数时，Java虚拟机使用IEEE 754标准中的向零舍入模式，这种模式的舍入结果会导致数字被截断，所有小数部分的有效字节都会被丢弃掉。</li><li>类型转换指令：Java虚拟机直接支持（即转换时无须显式的转换指令）宽化类型转换（即小范围类型向大范围类型的安全转换），处理窄化类型转换（Narrowing Numeric Conversion）时，就必须显式地使用转换指令来完成，这些转换指令包括i2b、i2c、i2s、l2i、f2i、f2l、d2i、d2l和d2f。在将int或long类型窄化转换为整数类型T的时候，转换过程仅仅是简单丢弃除最低位N字节以外的内容，N是类型T的数据类型长度，这将可能导致转换结果与输入值有不同的正负号。</li><li>对象创建和访问指令：对象创建后，就可以通过对象访问指令获取对象实例或者数组实例中的字段或者数组元素，这些指令包括：<ul><li>创建类实例的指令：new</li><li>创建数组的指令：newarray、anewarray、multianewarray</li><li>访问类字段（static字段，或者称为类变量）和实例字段（非static字段，或者称为实例变量）的指令：getfield、putfield、getstatic、putstatic</li><li>把一个数组元素加载到操作数栈的指令：baload、caload、saload、iaload、laload、faload、daload、aaload</li><li>将一个操作数栈的值储存到数组元素中的指令：bastore、castore、sastore、iastore、fastore、dastore、aastore</li><li>取数组长度的指令：arraylength</li><li>检查类实例类型的指令：instanceof、checkcast</li></ul></li><li>操作数栈管理指令：<code>pop，dup，swap</code>等</li><li>控制转移指令：<code>ifeq，ret，if_icmpeq</code>等</li><li>方法调用和返回指令：<ul><li>invokevirtual指令：用于调用对象的实例方法，根据对象的实际类型进行分派（虚方法分派），这也是Java语言中最常见的方法分派方式。</li><li>invokeinterface指令：用于调用接口方法，它会在运行时搜索一个实现了这个接口方法的对象，找出适合的方法进行调用。</li><li>invokespecial指令：用于调用一些需要特殊处理的实例方法，包括实例初始化方法、私有方法和父类方法。</li><li>invokestatic指令：用于调用类静态方法（static方法）。</li><li>invokedynamic指令：用于在运行时动态解析出调用点限定符所引用的方法。并执行该方法。前面四条调用指令的分派逻辑都固化在Java虚拟机内部，用户无法改变，而invokedynamic指令的分派逻辑是由用户所设定的引导方法决定的。</li></ul></li><li>异常处理指令：在Java程序中显式抛出异常的操作（throw语句）都由athrow指令来实现。</li><li>同步指令：Java虚拟机可以支持方法级的同步和方法内部一段指令序列的同步，这两种同步结构都是使用管程（Monitor，更常见的是直接将它称为“锁”）来实现的。当方法调用时，调用指令将会检查方法的ACC_SYNCHRONIZED访问标志是否被设置，如果设置了，执行线程就要求先成功持有管程，然后才能执行方法，最后当方法完成（无论是正常完成还是非正常完成）时释放管程。同步一段指令集序列通常是由Java语言中的synchronized语句块来表示的，Java虚拟机的指令集中有monitorenter和monitorexit两条指令来支持synchronized关键字的语义。</li></ul><p>公有设计，私有实现：《Java虚拟机规范》描绘了Java虚拟机应有的共同程序存储格式：Class文件格式以及字节码指令集。但一个优秀的虚拟机实现，在满足《Java虚拟机规范》的约束下对具体实现做出修改和优化也是完全可行的。虚拟机实现的方式主要有以下两种：</p><ul><li>将输入的Java虚拟机代码在加载时或执行时翻译成另一种虚拟机的指令集；</li><li>将输入的Java虚拟机代码在加载时或执行时翻译成宿主机处理程序的本地指令集（即即时编译器代码生成技术）</li></ul><p>Class文件结构的发展：相对于语言、API以及Java技术体系中其他方面的变化，Class文件结构一直处于一个相对比较稳定的状态，Class文件的主体结构、字节码指令的语义和数量几乎没有出现过变动，所有对Class文件格式的改进，都集中在访问标志、属性表这些设计上原本就是可扩展的数据结构中添加新内容。</p><h2 id="第七章-虚拟机类加载机制"><a href="#第七章-虚拟机类加载机制" class="headerlink" title="第七章 虚拟机类加载机制"></a>第七章 虚拟机类加载机制</h2><p>概述：Java虚拟机把描述类的数据从Class文件加载到内存，并对数据进行校验、转换解析和初始化，最终形成可以被虚拟机直接使用的Java类型，这个过程被称作虚拟机的类加载机制。与那些在编译时需要进行连接的语言不同，在Java语言里面，类型的加载、连接和初始化过程都是在程序运行期间完成的，这种策略让Java语言进行提前编译会面临额外的困难，也会让类加载时稍微增加一些性能开销，但是却为Java应用提供了极高的扩展性和灵活性。</p><p>类加载的时机：一个类的整个生命周期如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201129102422665.png" class="lazyload" data-srcset="image-20201129102422665.png" srcset="data:image/png;base64,666" alt="image-20201129102422665"/></div><span class="image-caption">image-20201129102422665</span></div><p>加载、验证、准备、初始化和卸载这五个阶段的顺序是确定的，而解析阶段则不一定：它在某些情况下可以在初始化阶段之后再开始，这是为了支持Java语言的运行时绑定特性（也称为动态绑定或晚期绑定）。但是对于初始化阶段，《Java虚拟机规范》则是严格规定了有且只有六种情况必须立即对类进行“初始化”（而加载、验证、准备自然需要在此之前开始）：</p><ol><li>遇到new、getstatic、putstatic或invokestatic这四条字节码指令时，如果类型没有进行过初始化，则需要先触发其初始化阶段。如使用new关键字，读取或设置一个类的静态字段，调用一个类的静态方法。</li><li>使用java.lang.reflect包的方法对类型进行反射调用的时候，如果类型没有进行过初始化，则需要先触发其初始化。</li><li>当初始化类的时候，如果发现其父类还没有进行过初始化，则需要先触发其父类的初始化。</li><li>当虚拟机启动时，用户需要指定一个要执行的主类（包含main()方法的那个类），虚拟机会先初始化这个主类。</li><li>如果一个java.lang.invoke.MethodHandle实例最后的解析结果为REF_getStatic、REF_putStatic、REF_invokeStatic、REF_newInvokeSpecial四种类型的方法句柄，并且这个方法句柄对应的类没有进行过初始化，则需要先触发其初始化。</li><li>当一个接口中定义了JDK 8新加入的默认方法（被default关键字修饰的接口方法）时，如果有这个接口的实现类发生了初始化，那该接口要在其之前被初始化。</li></ol><p>类加载过程：加载、验证、准备、解析和初始化这五个阶段所执行的具体动作。</p><ul><li>加载：<ul><li>通过一个类的全限定名来获取定义此类的二进制字节流。</li><li>将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构。</li><li>在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口。</li></ul></li><li>验证：这一阶段的目的是确保Class文件的字节流中包含的信息符合《Java虚拟机规范》的全部约束要求，保证这些信息被当作代码运行后不会危害虚拟机自身的安全。<ul><li>文件格式验证</li><li>元数据验证：这个类的父类是否继承了不允许被继承的类；如果这个类不是抽象类，是否实现了其父类或接口之中要求实现的所有方法</li><li>字节码验证：这阶段就要对类的方法体（Class文件中的Code属性）进行校验分析，如保证任何跳转指令都不会跳转到方法体以外的字节码指令上，保证方法体中的类型转换总是有效的等。</li><li>符号引用验证：验证该类是否缺少或者被禁止访问它依赖的某些外部类、方法、字段等资源。如符号引用中的类、字段、方法的可访问性（<code>private、protected、public、&lt;package&gt;</code>）是否可被当前类访问等。</li></ul></li><li>准备：是正式为<strong>类中定义的变量</strong>（即静态变量，被static修饰的变量）分配内存并设置类变量初始值的阶段。需要注意的是如果是<code>static int value = 123</code>，准备阶段的初始值是0而不是123，因为这时尚未开始执行任何Java方法，而把value赋值为123的putstatic指令是程序被编译后，存放于类构造器<code>&lt;clinit&gt;()</code>方法之中的；但是如果是<code>public static final int value = 123</code>，那么准备阶段的值就是123。</li><li>解析：是Java虚拟机将常量池内的符号引用替换为直接引用的过程。<ul><li>类或接口的解析：如果C不是一个数组类型，那虚拟机将会把代表N的全限定名传递给D的类加载器去加载这个类C。在加载过程中，由于元数据验证、字节码验证的需要，又可能触发其他相关类的加载动作，例如加载这个类的父类或实现的接口。一旦这个加载过程出现了任何异常，解析过程就将宣告失败。成功的话，那么C在虚拟机中实际上已经成为一个有效的类或接口了，但在解析完成前还要进行符号引用验证，确认D是否具备对C的访问权限。</li><li>字段解析</li><li>方法解析</li><li>接口方法解析</li></ul></li><li>初始化：直到初始化阶段，Java虚拟机才真正开始执行类中编写的Java程序代码，将主导权移交给应用程序。初始化阶段就是执行类构造器<code>&lt;clinit&gt;()</code>方法的过程。<code>&lt;clinit&gt;()</code>并不是程序员在Java代码中直接编写的方法，它是Javac编译器的自动生成物。<code>&lt;clinit&gt;()</code>方法是由编译器自动收集类中的所有类变量的赋值动作和静态语句块（static{}块）中的语句合并产生的，编译器收集的顺序是由语句在源文件中出现的顺序决定的，静态语句块中只能访问到定义在静态语句块之前的变量。Java虚拟机会保证在子类的<code>&lt;clinit&gt;()</code>方法执行前，父类的<code>&lt;clinit&gt;()</code>方法已经执行完毕。</li></ul><p>类加载器：Java虚拟机设计团队有意把类加载阶段中的“通过一个类的全限定名来获取描述该类的二进制字节流”这个动作放到Java虚拟机外部去实现，以便让应用程序自己决定如何去获取所需的类。实现这个动作的代码被称为“类加载器”（Class Loader）。</p><ul><li><p>类与类加载器：比较两个类是否“相等”，只有在这两个类是由同一个类加载器加载的前提下才有意义，否则，即使这两个类来源于同一个Class文件，被同一个Java虚拟机加载，只要加载它们的类加载器不同，那这两个类就必定不相等。</p></li><li><p>双亲委派模型：</p><ul><li><p>三层类加载器：</p><ul><li>启动类加载器：这个类加载器负责加载存放在<code>&lt;JAVA_HOME&gt;\lib</code>目录，是Java虚拟机能够识别的（按照文件名识别，如rt.jar、tools.jar，名字不符合的类库即使放在lib目录中也不会被加载）类库加载到虚拟机的内存中。</li><li>扩展类加载器：负责加载<JAVA_HOME>\lib\ext目录中，或者被java.ext.dirs系统变量所指定的路径中所有的类库。</li><li>应用程序类加载器：由于应用程序类加载器是ClassLoader类中的getSystemClassLoader()方法的返回值，所以有些场合中也称它为“系统类加载器”。它负责加载用户类路径（ClassPath）上所有的类库，开发者同样可以直接在代码中使用这个类加载器。</li></ul><p>JDK 9之前的Java应用都是由这三种类加载器互相配合来完成加载的，如果用户认为有必要，还可<br>以加入自定义的类加载器来进行拓展：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201129130856054.png" class="lazyload" data-srcset="image-20201129130856054.png" srcset="data:image/png;base64,666" alt="image-20201129130856054"/></div><span class="image-caption">image-20201129130856054</span></div></li><li><p>双亲委派模型：如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器去完成，每一个层次的类加载器都是如此，因此所有的加载请求最终都应该传送到最顶层的启动类加载器中，只有当父加载器反馈自己无法完成这个加载请求（它的搜索范围中没有找到所需的类）时，子加载器才会尝试自己去完成加载。好处是Java中的类随着它的类加载器一起具备了一种带有优先级的层次关系。</p></li></ul></li></ul><p>Java模块化系统：</p><ul><li><p>模块的兼容性：JDK 9提出了与“类路径”（ClassPath）相对应的“模块路径”（ModulePath）的概念。简单来说，就是某个类库到底是模块还是传统的JAR包，只取决于它存放在哪种路径上。有如下访问规则：</p><ul><li>JAR文件在类路径的访问规则：所有类路径下的JAR文件及其他资源文件，都被视为自动打包在一个匿名模块（Unnamed Module）里，这个匿名模块几乎是没有任何隔离的，它可以看到和使用类路径上所有的包、JDK系统模块中所有的导出包，以及模块路径上所有模块中导出的包。</li><li>模块在模块路径的访问规则：模块路径下的具名模块（Named Module）只能访问到它依赖定义中列明依赖的模块和包，匿名模块里所有的内容对具名模块来说都是不可见的，即具名模块看不见传统JAR包的内容。</li><li>JAR文件在模块路径的访问规则：如果把一个传统的、不包含模块定义的JAR文件放置到模块路径中，它就会变成一个自动模块（Automatic Module）。尽管不包含module-info.class，但自动模块将默认依赖于整个模块路径中的所有模块，因此可以访问到所有模块导出的包，自动模块也默认导出自己所有的包。</li></ul></li><li><p>模块下的类加载器：JDK 9并没有从根本上动摇从JDK 1.2以来运行了二十年之久的三层类加载器架构以及双亲委派模型。但是为了模块化系统的顺利施行，模块化下的类加载器仍然发生了一些应该被注意到变动，主要包括以下几个方面：</p><ul><li>扩展类加载器被平台类加载器取代</li><li>平台类加载器和应用程序类加载器都不再派生自java.net.URLClassLoader，现在启动类加载器、平台类加载器、应用程序类加载器全都继承于jdk.internal.loader.BuiltinClassLoader，在BuiltinClassLoader中实现了新的模块化架构下类如从模块中加载的逻辑，以及模块中资源可访问性的处理</li><li>JDK 9中虽然仍然维持着三层类加载器和双亲委派的架构，但类加载的委派关系也发生了变动。当平台及应用程序类加载器收到类加载请求，在委派给父加载器加载前，要先判断该类是否能够归属到某一个系统模块中，如果可以找到这样的归属关系，就要优先委派给负责那个模块的加载器完成加载</li></ul><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201129132525034.png" class="lazyload" data-srcset="image-20201129132525034.png" srcset="data:image/png;base64,666" alt="image-20201129132525034"/></div><span class="image-caption">image-20201129132525034</span></div></li></ul><h2 id="第八章-虚拟机字节码执行引擎"><a href="#第八章-虚拟机字节码执行引擎" class="headerlink" title="第八章 虚拟机字节码执行引擎"></a>第八章 虚拟机字节码执行引擎</h2><p>运行时栈帧结构：下图是 JVM 的栈和栈帧的总体结构：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201201211749470.png" class="lazyload" data-srcset="image-20201201211749470.png" srcset="data:image/png;base64,666" alt="image-20201201211749470"/></div><span class="image-caption">image-20201201211749470</span></div><p>每个栈帧里面包含有局部变量表、操作数栈、动态连接、方法返回地址和一些额外的附加信息。</p><ul><li><p>局部变量表：是一组变量值的存储空间，用于存放方法参数和方法内部定义的局部变量。变量槽空间一般是 32 位，对于long类型的变量，需要两个槽来保存。当方法被调用的时候，首先存储相关的实参，然后再存储方法内部的局部变量。比如，对于实例方法，局部变量表第0位代表的就是方法所属对象的引用，方法中通过 this 隐式访问到。另外，局部变量表中的变量槽可以被重用，这可能会带来副作用，如 gc 过程。最后，局部变量没有所谓的“准备阶段”，因此，对局部变量引用前需要先赋值。</p></li><li><p>操作数栈：用于保存相应的操作数。在进行运算的时候需要检查指令和对应的数据类型是否匹配。在概念模型上，两个不同的栈帧是完全相互独立的，但是在实际过程中，可能存在重合，这样做的好处是节约空间，同时无需进行额外的实参-形参转换。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201201213604264.png" class="lazyload" data-srcset="image-20201201213604264.png" srcset="data:image/png;base64,666" alt="image-20201201213604264"/></div><span class="image-caption">image-20201201213604264</span></div></li><li><p>动态链接：每个栈帧都包含一个指向运行时常量池[1]中该栈帧所属方法的引用，持有这个引用是为了支持方法调用过程中的动态连接（Dynamic Linking）。</p></li><li><p>方法返回地址：正常返回上层方法调用者，可能会提供返回值，异常返回的话，不带任何返回值。推出的过程实际上等同于将当前栈帧出栈。</p></li></ul><p>方法调用：</p><ul><li><p>解析：在类加载的过程中，如果方法的调用版本在运行期不可变，就可以将方法的符号引用转化为直接引用，该类方法的调用称为解析。在 Java 中，这样的方法有静态方法，私有方法，实例构造器，父类方法，final 方法。这些方法称为“非虚方法”，其他的就成为“虚方法”。</p></li><li><p>分派（dispatch）：</p><ul><li><p>静态分派：假设 <code>Human man = new Man()</code>，那么Human成为变量的静态类型，或者是外观类型，后面的Man则称为变量的实际类型或者运行时类型。所有依赖静态类型来决定方法执行版本的分派动作，都称为静态分派。静态分派的最典型应用表现就是方法重载。静态分派发生在编译阶段。虽然编译器能够在确定方法重载版本，但是实际上只是选择一个相对更合适的版本。假设有一个类实现了sayHello方法，重载了所有类型的参数。那么对应<code>sayHello(&#39;a&#39;)</code>中的a的类型被解析为char，如果注释掉char类型的重载，那么a会被解析成int类型，依次往后是：Character，Serializable(Character的一个接口)，Object（父类），变长参数。</p></li><li><p>动态分派：与重写有关。<code>Human man = new Man()</code>，man执行重写方法的时候，会执行<code>Man</code>类里面的对应的方法，而不是<code>Woman</code>里面的重载方法，这与变量的实际类型有关。调用重写方法的时候，执行指令是<code>invokevirtual</code>，其运行过程如下：</p><ol><li>找到变量指向对象的实际类型，记做C</li><li>如果在C中找到与方法签名一直的方法，进行访问权限校验，通过直接返回这个方法的直接调用，否则返回<code>java.lang.IllegalAccessError</code></li><li>否则，按照继承关系从下往上依次对C的各个父类进行2操作</li><li>如果始终没有找到合适方法，抛出<code>java.lang.AbstractMethodError</code>异常</li></ol><p>注意，方法存在多态，但是字段不存在多态。</p></li></ul></li><li><p>虚拟机动态分派的实现：通常虚拟机会创建一个虚方法表（vtable，对应的还有接口方法表itable），使用虚方法表索引来代替元数据查找以提高性能。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201201230836050.png" class="lazyload" data-srcset="image-20201201230836050.png" srcset="data:image/png;base64,666" alt="image-20201201230836050"/></div><span class="image-caption">image-20201201230836050</span></div></li></ul><p>动态类型语言支持：</p><ul><li><p>动态类型语言：动态类型语言的关键特征是它的类型检查的主体过程是在运行期而不是编译期进行的，如Javascript等。那相对地，在编译期就进行类型检查过程的语言，譬如C++和Java等就是最常用的静态类型语言。</p></li><li><p>Java与动态类型：在 Java7 之前的4条方法调用指令（<code>invoke*</code>）的第一个参数都是被调用方法的符号引用。前面已经提到过，方法的符号引用在编译时产生，而动态类型语言只有在运行期才能确定方法的接收者。这样，在Java虚拟机上实现的动态类型语言就不得不使用“曲线救国”的方式（如编译时留个占位符类型，运行时动态生成字节码实现具体类型到占位符类型的适配）来实现，但这样势必会让动态类型语言实现的复杂度增加，也会带来额外的性能和内存开销。</p></li><li><p><code>java.lang.invoke</code>：该包提供了一种新的动态确定方法的机制，称为方法句柄。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> java.lang.invoke.MethodHandles.lookup;</span><br><span class="line"><span class="keyword">import</span> java.lang.invoke.MethodHandle;</span><br><span class="line"><span class="keyword">import</span> java.lang.invoke.MethodType;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MethodHandleTest</span> </span>&#123;</span><br><span class="line">    <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">ClassA</span> </span>&#123;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">println</span><span class="params">(String s)</span> </span>&#123;</span><br><span class="line">        System.out.println(s);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Throwable </span>&#123;</span><br><span class="line">        Object obj = System.currentTimeMillis() % <span class="number">2</span> == <span class="number">0</span> ? System.out : <span class="keyword">new</span> ClassA();</span><br><span class="line">        <span class="comment">// 无论obj最终是哪个实现类，下面这句都能正确调用到println方法。</span></span><br><span class="line">        getPrintlnMH(obj).invokeExact(<span class="string">&quot;icyfenix&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> MethodHandle <span class="title">getPrintlnMH</span><span class="params">(Object reveiver)</span> <span class="keyword">throws</span> Throwable </span>&#123;</span><br><span class="line">        <span class="comment">// MethodType：代表“方法类型”，包含了方法的返回值（methodType()的第一个参数）和具体参数（methodType()第二个及以后的参数）。</span></span><br><span class="line">        MethodType mt = MethodType.methodType(<span class="keyword">void</span>.class, String.class);</span><br><span class="line">        <span class="comment">// lookup()方法来自于MethodHandles.lookup，这句的作用是在指定类中查找符合给定的方法名称、方法类型，并且符合调用权限的方法句柄。</span></span><br><span class="line">        <span class="comment">// 因为这里调用的是一个虚方法，按照Java语言的规则，方法第一个参数是隐式的，代表该方法的接收者，也即this指向的对象，这个参数以前是放在参数列表中进行传递，现在提供了bindTo()方法来完成这件事情。</span></span><br><span class="line">        <span class="keyword">return</span> lookup().findVirtual(reveiver.getClass(), <span class="string">&quot;println&quot;</span>, mt).bindTo(reveiver);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>MethodHandle在使用方法和效果上与Reflection有众多相似之处。不过，它们也有以下这些区别：</p><ul><li>Reflection和MethodHandle机制本质上都是在模拟方法调用，但是Reflection是在模拟Java代码层次的方法调用，而MethodHandle是在模拟字节码层次的方法调用。</li><li>Reflection中的java.lang.reflect.Method对象远比MethodHandle机制中的java.lang.invoke.MethodHandle对象所包含的信息来得多。</li><li>Reflection API的设计目标是只为Java语言服务的，而MethodHandle则设计为可服务于所有Java虚拟机之上的语言。</li></ul></li><li><p>invokedynamic指令：作为Java诞生以来唯一一条新加入的字节码指令，都是为了解决原有4条“invoke*”指令方法分派规则完全固化在虚拟机之中的问题，把如何查找目标方法的决定权从虚拟机转嫁到具体用户代码之中。invokedynamic指令的第一个参数不再是代表方法符号引用的CONSTANT_Methodref_info常量，而是变为JDK 7<br>时新加入的CONSTANT_InvokeDynamic_info常量，从这个新常量中可以得到3项信息：引导方法<br>（Bootstrap Method，该方法存放在新增的BootstrapMethods属性中）、方法类型（MethodType）和<br>名称。</p></li><li><p>掌控方法分派规则：子类方法不能直接调用祖父类方法，可以通过MethodHandle来进行访问，如遇到权限问题，可以使用<code>lookupImpl.setAccessible(true)</code>来解决。</p></li></ul><p>基于栈的字节码解释执行引擎：</p><ul><li><p>解释执行：Java语言被定为解释执行的语言，这在JDK1.0时代算是准确的，但是之后Java也发展出了可以生成本地代码的编译器，这个时候说Java是解释执行的语言就不再准确了。下图中间分支指代解释执行过程，最下面分支指代编译执行过程：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201202095616929.png" class="lazyload" data-srcset="image-20201202095616929.png" srcset="data:image/png;base64,666" alt="image-20201202095616929"/></div><span class="image-caption">image-20201202095616929</span></div></li><li><p>基于栈的指令集与基于寄存器的指令集：Java指令基于栈结构，x86指令基于寄存器，使用栈结构带来的好处是可移植性更强，缺点是运行速度慢。</p></li></ul><h2 id="第九章-类加载案例"><a href="#第九章-类加载案例" class="headerlink" title="第九章 类加载案例"></a>第九章 类加载案例</h2><p>案例分析：</p><ul><li><p>Tomcat：在Tomcat中一种有四种目录存放Java类库：</p><ol><li>放置在/common目录中。类库可被Tomcat和所有的Web应用程序共同使用。</li><li>放置在/server目录中。类库可被Tomcat使用，对所有的Web应用程序都不可见。</li><li>放置在/shared目录中。类库可被所有的Web应用程序共同使用，但对Tomcat自己不可见。</li><li>放置在/WebApp/WEB-INF目录中。类库仅仅可以被该Web应用程序使用，对Tomcat和其他Web应用程序都不可见。</li></ol><p>为了支持这套目录，并且对目录里面的类库进行加载和隔离，Tomcat实现了自定义的类加载器，按照双亲委派模型：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201203105110135.png" class="lazyload" data-srcset="image-20201203105110135.png" srcset="data:image/png;base64,666" alt="image-20201203105110135"/></div><span class="image-caption">image-20201203105110135</span></div><p>在Tomcat6之后，只有指定了tomcat/conf/catalina.properties配置文件的server.loader和share.loader项后才会真正建立Catalina类加载器和Shared类加载器的实例，否则会用到这两个类加载器的地方都会用Common类加载器的实例代替。同时前文提到的前三个目录也会被改为一个/lib目录。</p></li><li><p>OSGi：是OSGi联盟（OSGi Alliance）制订的一个基于Java语言的动态模块化规范。OSGi中的每个模块（Bundle）可以声明它所依赖的Package（通过Import-Package描述），也可以声明它允许导出发布的Package（通过Export-Package描述）。这和后来出现的Java模块化功能重合了。由于模块之间相依依赖的原因，加载器之间的关系不再是双亲委派模型的树形结构，而是已经进一步发展成一种更为复杂的、运行时才能确定的网状结构。在模块中相互依赖会造成死锁。</p></li><li><p>Backport工具：将高级的Java语法转化为低版本Java也能运行的语句代码的工具。</p></li></ul><h2 id="第十章-前端编译和优化"><a href="#第十章-前端编译和优化" class="headerlink" title="第十章 前端编译和优化"></a>第十章 前端编译和优化</h2><p>Java中前端编译一般指将<code>*.java</code>编译为<code>*.class</code>字节码文件的过程，主要有下列过程：</p><ol><li>准备过程：初始化插入式注解处理器</li><li>解析与填充符号表过程：词法，语法分析，填充符号表</li><li>插入式注解处理器的注解处理过程：插入式注解处理器的执行阶段</li><li>分析与字节码生成过程：标注检查，解语法糖，字节码生成</li></ol><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201205124231612.png" class="lazyload" data-srcset="image-20201205124231612.png" srcset="data:image/png;base64,666" alt="image-20201205124231612"/></div><span class="image-caption">image-20201205124231612</span></div><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201205124301591.png" class="lazyload" data-srcset="image-20201205124301591.png" srcset="data:image/png;base64,666" alt="image-20201205124301591"/></div><span class="image-caption">image-20201205124301591</span></div><p>解析与填充符号表：</p><ol><li>词法语法分析：词法分析用于生成标记（token）集合的过程，语法分析则是根据标记序列构造抽象语法树的过程。</li><li>填充符号表：符号表（Symbol Table）是由一组符号地址和符号信息构成的数据结构，符号表中所登记的信息在编译的不同阶段都要被用到，如类型检查等。</li></ol><p>注解处理器：可以把插入式注解处理器看作是一组编译器的插件，当这些插件工作时，允许读取、修改、添加抽象语法树中的任意元素。如果这些插件在处理注解期间对语法树进行过修改，编译器将回到解析及填充符号表的过程重新处理，直到所有插入式注解处理器都没有再对语法树进行修改为止，每一次循环过程称为一个轮次（Round）。</p><p>语义分析和字节码生成：</p><ol><li>标注检查：变量使用前是否已被声明、变量与赋值之间的数据类型是否能够匹配，等等，在该过程中顺便执行常量折叠优化。</li><li>数据及控制流分析：是对程序上下文逻辑更进一步的验证，它可以检查出诸如程序局部变量在使用前是否有赋值、方法的每条路径是否都有返回值、是否所有的受查异常都被正确处理了等问题。final修饰的变量不可变就是在这一阶段完成的。</li><li>解语法糖：将一些语法糖进行还原，Java中常见语法糖有泛型，变长参数，自动装箱拆箱等。</li><li>字节码生成：把前面各个步骤所生成的信息（语法树、符号表）转化成字节码指令写到磁盘中，编译器还进行了少量的代码添加和转换工作。例如前文多次登场的实例构造器<code>&lt;init&gt;()</code>方法和类构造器<code>&lt;clinit&gt;()</code>方法就是在这个阶段被添加到语法树之中的。实例构造器并不等同于默认构造函数。<code>&lt;init&gt;()</code>和<code>&lt;clinit&gt;()</code>这两个构造器的产生实际上是一种代码收敛的过程，编译器会把语句块（对于实例构造器而言是“{}”块，对于类构造器是“static{}”块）、变量初始化（实例变量和类变量）、调用父类的实例构造器（仅仅是实例构造器，<code>&lt;clinit&gt;()</code>方法中无须调用父类的<code>&lt;clinit&gt;()</code>方法，Java虚拟机会自动保证父类构造器的正确执行，但在<code>&lt;clinit&gt;()</code>方法中经常会生成调用java.lang.Object的<code>&lt;init&gt;()</code>方法的代码）等操作收敛到<code>&lt;init&gt;()</code>和<code>&lt;clinit&gt;()</code>方法之中。</li></ol><p>Java语法糖：</p><ol><li><p>泛型：Java选择的泛型实现方式是类型擦除式泛型，而C#选择的泛型实现方式是具现化式泛型。由于采用的是类型擦出式泛型，以下操作不合法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TypeErasureGenerics</span>&lt;<span class="title">E</span>&gt; </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">doSomething</span><span class="params">(Object item)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (item <span class="keyword">instanceof</span> E) &#123; <span class="comment">// 不合法，无法对泛型进行实例判断</span></span><br><span class="line">        ...</span><br><span class="line">        &#125;</span><br><span class="line">        E newItem = <span class="keyword">new</span> E(); <span class="comment">// 不合法，无法使用泛型创建对象</span></span><br><span class="line">        E[] itemArray = <span class="keyword">new</span> E[<span class="number">10</span>]; <span class="comment">// 不合法，无法使用泛型创建数组</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>java中的泛型只在程序源码中存在，在编译后的字节码文件中，全部泛型都被替换为原来的裸类型（Raw Type）了，并且在相应的地方插入了强制转型代码，因此对于运行期的Java语言来说，<code>ArrayList&lt;int&gt;</code>与<code>ArrayList&lt;String&gt;</code>其实是同一个类型。当初Java选择这种方式实现泛型的历史原因在于Java语言的向后兼容性。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201205130631950.png" class="lazyload" data-srcset="image-20201205130631950.png" srcset="data:image/png;base64,666" alt="image-20201205130631950"/></div><span class="image-caption">image-20201205130631950</span></div><p>将这段Java代码编译成Class文件，然后再使用反编译工具：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201205130714474.png" class="lazyload" data-srcset="image-20201205130714474.png" srcset="data:image/png;base64,666" alt="image-20201205130714474"/></div><span class="image-caption">image-20201205130714474</span></div><p>由于类型擦除，导致的问题有：不支持原始类型的泛型，运行期无法取到泛型类型信息。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201205131020421.png" class="lazyload" data-srcset="image-20201205131020421.png" srcset="data:image/png;base64,666" alt="image-20201205131020421"/></div><span class="image-caption">image-20201205131020421</span></div><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201205131111259.png" class="lazyload" data-srcset="image-20201205131111259.png" srcset="data:image/png;base64,666" alt="image-20201205131111259"/></div><span class="image-caption">image-20201205131111259</span></div><p>上述代码不能被编译，相反下列代码可以被编译，因为方法签名不同：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201205131152443.png" class="lazyload" data-srcset="image-20201205131152443.png" srcset="data:image/png;base64,666" alt="image-20201205131152443"/></div><span class="image-caption">image-20201205131152443</span></div></li><li><p>自动装箱，拆箱与遍历循环：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201205131228596.png" class="lazyload" data-srcset="image-20201205131228596.png" srcset="data:image/png;base64,666" alt="image-20201205131228596"/></div><span class="image-caption">image-20201205131228596</span></div><p>遍历循环的类需要实现Iterable接口的原因从上图可以看出。</p></li><li><p>条件编译：java语言没有预处理器，但是可以实现条件编译，使用<code>if(true)</code>等。</p></li></ol><h2 id="第十一章-后端编译和优化"><a href="#第十一章-后端编译和优化" class="headerlink" title="第十一章 后端编译和优化"></a>第十一章 后端编译和优化</h2><p>即时（JIT）编译器：在运行时，虚拟机将会把热点代码编译成本地机器码，并以各种手段尽可能地进行代码优化，运行时完成这个任务的后端编译器被称为即时编译器。</p><ul><li><p>解释器和编译器：解释器与编译器两者各有优势：当程序需要迅速启动和执行的时候，解释器可以首先发挥作用，省去编译的时间，立即运行。当程序启动后，随着时间的推移，编译器逐渐发挥作用，把越来越多的代码编译成本地代码，这样可以减少解释器的中间损耗，获得更高的执行效率。在Java中，解释器和编译器是相互协作的：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201205155102424.png" class="lazyload" data-srcset="image-20201205155102424.png" srcset="data:image/png;base64,666" alt="image-20201205155102424"/></div><span class="image-caption">image-20201205155102424</span></div><p>为了使程序启动响应速度与运行效率之间达到最佳平衡，HotSpot虚拟机在编译子系统中加入了分层编译的功能。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201205155331944.png" class="lazyload" data-srcset="image-20201205155331944.png" srcset="data:image/png;base64,666" alt="image-20201205155331944"/></div><span class="image-caption">image-20201205155331944</span></div></li><li><p>编译对象与触发条件：热点代码指的是被多次调用的方法，或者是多次执行的循环体。发现对应的热点代码后，编译的目标对象都是整个方法体。为了判断某段代码是不是热点代码，可以使用基于采样的热点探测和基于计数器的热点探测。HotSpot使用的是后者，为了实现热点计数，需要两类计数器：方法调用计数器和回边计数器。一旦超过阈值，就会触发即时编译。</p></li><li><p>编译过程：在编译请求产生时，虚拟机在编译器还未完成编译之前，都仍然将按照解释方式继续执行代码，而编译动作则在后台的编译线程中进行。下图是编译器的全过程示意图：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201205155947036.png" class="lazyload" data-srcset="image-20201205155947036.png" srcset="data:image/png;base64,666" alt="image-20201205155947036"/></div><span class="image-caption">image-20201205155947036</span></div></li></ul><p>提前编译器：目前提前编译有两条路径：一条分支是做与传统C、C++编译器类似的，在程序运行之前把程序代码编译成机器码的静态翻译工作；另外一条分支是把原本即时编译器在运行时要做的编译工作提前做好并保存下来，下次运行到这些代码（譬如公共库代码在被同一台机器其他Java进程使用）时直接把它加载进来使用。第一条路径直指Java中的即时编译的最大弱点：即时编译需要占用程序的运行时间和运算资源。第二条路径本质上是给即时编译器做缓存加速，可以成为动态提前编译（Dynamic AOT）。即时编译器的优点在：性能分析制导优化，激进预测性优化和链接时优化。Java中的提前编译器有Jaotc。</p><p>编译器优化技术：</p><ul><li>方法内联：是其他优化的基础，减少方法分派的开销</li><li>逃逸分析：分析对象动态作用域，当一个对象在方法里面被定义后，它可能被外部方法所引用，例如作为调用参数传递到其他方法中，这种称为方法逃逸；甚至还有可能被外部线程访问到，譬如赋值给可以在其他线程中访问的实例变量，这种称为线程逃逸；从不逃逸、方法逃逸到线程逃逸，称为对象由低到高的不同逃逸程度。根据不同逃逸程度：可以执行栈上分配，标量替换，同步消除。</li><li>公共子表达式消除</li><li>数组边界检查消除</li></ul><h2 id="第十二章-Java内存模型与线程"><a href="#第十二章-Java内存模型与线程" class="headerlink" title="第十二章 Java内存模型与线程"></a>第十二章 Java内存模型与线程</h2><p>硬件的效率与一致性：由于处理器的运行速度远高于IO的速度，为此引入了高速缓存，但是引入高速缓存又造成了缓存一致性的问题。由此产生一致性协议：MSI，MESI，MOSI等。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201205185105826.png" class="lazyload" data-srcset="image-20201205185105826.png" srcset="data:image/png;base64,666" alt="image-20201205185105826"/></div><span class="image-caption">image-20201205185105826</span></div><p>Java内存模型：</p><ul><li><p>主内存与工作内存：规定了所有的变量都存储在主内存（Main Memory）中，每条线程还有自己的工作内存（Working Memory，可与前面讲的处理器高速缓存类比），线程的工作内存中保存了被该线程使用的变量的主内存副本，线程对变量的所有操作（读取、赋值等）都必须在工作内存中进行，而不能直接读写主内存中的数据。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201205185323393.png" class="lazyload" data-srcset="image-20201205185323393.png" srcset="data:image/png;base64,666" alt="image-20201205185323393"/></div><span class="image-caption">image-20201205185323393</span></div></li><li><p>内存间交互操作：lock，unlock，read，load，store，write，use，assign。伤处操作都是原子的，不可再分的。</p></li><li><p>对于volatile型变量的特殊规则：当一个变量被volatile定义的时候，将具有：</p><ul><li>保证此变量对所有线程的可见性，这里的“可见性”是指当一条线程修改了这个变量的值，新值对于其他线程来说是可以立即得知的。</li><li>禁止指令重排序优化，普通的变量仅会保证在该方法的执行过程中所有依赖赋值结果的地方都能获取到正确的结果，而不能保证变量赋值操作的顺序与程序代码中的执行顺序一致。</li></ul></li><li><p>针对long和double型变量的特殊规则：允许虚拟机将没有被volatile修饰的64位数据的读写操作划分为两次32位的操作来进行，即允许虚拟机实现自行选择是否要保证64位数据类型的load、store、read和write这四个操作的原子性。</p></li><li><p>原子性，可见性与有序性：由Java内存模型来直接保证的原子性变量操作包括read、load、assign、use、store和write这六个；可见性就是指当一个线程修改了共享变量的值时，其他线程能够立即得知这个修改；如果在本线程内观察，所有的操作都是有序的；如果在一个线程中观察另一个线程，所有的操作都是无序的。</p></li><li><p>先行发生原则：</p><ul><li>程序次序规则：在一个线程内，按照控制流顺序，书写在前面的操作先行发生于书写在后面的操作，是控制流顺序。</li><li>管程锁定规则：一个unlock操作先行发生于后面对同一个锁的lock操作。</li><li>volatile变量规则：对一个volatile变量的写操作先行发生于后面对这个变量的读操作。</li><li>线程启动规则：Thread对象的start()方法先行发生于此线程的每一个动作。</li><li>线程终止规则：线程中的所有操作都先行发生于对此线程的终止检测，我们可以通过Thread::join()方法是否结束、Thread::isAlive()的返回值等手段检测线程是否已经终止执行。</li><li>线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生，可以通过Thread::interrupted()方法检测到是否有中断发生。</li><li>对象终结规则：一个对象的初始化完成（构造函数执行结束）先行发生于它的finalize()方法的开始。</li><li>传递性：如果操作A先行发生于操作B，操作B先行发生于操作C，那就可以得出操作A先行发生于操作C的结论。</li></ul></li></ul><p>Java与线程：</p><ul><li><p>线程的实现：内核线程实现，用户线程实现，混合实现。</p></li><li><p>Java线程调度：</p><ul><li>协同式线程调度：线程的执行时间由线程本身来控制，线程把自己的工作执行完了之后，要主动通知系统切换到另外一个线程上去。</li><li>抢占式线程：每个线程将由系统来分配执行时间，线程的切换不由线程本身来决定。</li></ul><p>Java线程调度是由系统自动完成的，但是可以为不同的线程分配不同的优先级，来建议操作系统多分配一些时间在优先级高的线程上。</p></li><li><p>状态转换：Java中定义了6种线程状态：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201205194306856.png" class="lazyload" data-srcset="image-20201205194306856.png" srcset="data:image/png;base64,666" alt="image-20201205194306856"/></div><span class="image-caption">image-20201205194306856</span></div></li></ul><p>Java与协程：</p><ul><li>内核线程的局限：天然的缺陷是切换、调度成本高昂，系统能容纳的线程数量也很有限。</li><li>协程的复苏：由于最初多数的用户线程是被设计成协同式调度的，所以它有了一个别名——“协程”（Coroutine）。又由于这时候的协程会完整地做调用栈的保护、恢复工作，所以今天也被称为“有栈协程”。协程的主要优势是轻量，缺点是需要在应用层面实现的内容（调用栈、调度器这些）特别多。</li><li>Java的解决方案：纤程（fiber），一种轻量的线程，使用JVM调度，而不是操作系统。</li></ul><h2 id="第十三章-线程安全与锁优化"><a href="#第十三章-线程安全与锁优化" class="headerlink" title="第十三章 线程安全与锁优化"></a>第十三章 线程安全与锁优化</h2><p>线程安全：当多个线程同时访问一个对象时，如果不用考虑这些线程在运行时环境下的调度和交替执行，也不需要进行额外的同步，或者在调用方进行任何其他的协调操作，调用这个对象的行为都可以获得正确的结果，那就称这个对象是线程安全的。</p><ul><li>Java语言中的线程安全：<ol><li>不可变：不可变的对象一定是线程安全，无论是对象的方法实现还是方法的调用者，都不需要再进行任何线程安全保障措施。基本类型数据使用final关键字修饰可以保证不可变，如果想要保证对象不可变，需要将对象的字段设置为final才可以。</li><li>绝对线程安全：不管运行时环境如何，调用者都不需要任何额外的同步措施。</li><li>相对线程安全：通常意义上所讲的线程安全，它需要保证对这个对象单次的操作是线程安全的，我们在调用的时候不需要进行额外的保障措施，但是对于一些特定顺序的连续调用，就可能需要在调用端使用额外的同步手段来保证调用的正确性。在Java语言中，大部分声称线程安全的类都属于这种类型，例如Vector。</li><li>线程兼容：指对象本身并不是线程安全的，但是可以通过在调用端正确地使用同步手段来保证对象在并发环境中可以安全地使用。我们平常说一个类不是线程安全的，通常就是指这种情况。Java中的ArrayList就是这种情况。</li><li>线程对立：是指不管调用端是否采取了同步措施，都无法在多线程环境中并发使用代码。</li></ol></li><li>线程安全的方法实现：<ol><li>互斥同步：临界区（Critical Section）、互斥量（Mutex）和信号量（Semaphore）都是常见的互斥实现方式。在Java里面，互斥同步手段是synchronized关键字，这是一种块结构的同步语法。该关键字经过编译之后，会产生monitorenter和monitorexit这两个字节码指令。这两个字节码指令都需要一个reference类型的参数来指明要锁定和解锁的对象。如果Java源码中的synchronized明确指定了对象参数，那就以这个对象的引用作为reference；如果没有明确指定，那将根据synchronized修饰的方法类型（如实例方法或类方法），来决定是取代码所在的对象实例还是取类型对应的Class对象来作为线程要持有的锁。另外的话也有重入锁（ReentrantLock），相较于synchronized，重入锁提供：等待可中断，公平锁，锁绑定多个条件。</li><li>非阻塞同步：互斥同步面临的主要问题是进行线程阻塞和唤醒所带来的性能开销，因此这种同步也被称为阻塞同步。基于冲突检测的乐观并发策略，通俗地说就是不管风险，先进行操作，如果没有其他线程争用共享数据，那操作就直接成功了；如果共享的数据的确被争用，产生了冲突，那再进行其他的补偿措施，最常用的补偿措施是不断地重试，直到出现没有竞争的共享数据为止。这种乐观并发策略的实现不再需要把线程阻塞挂起，因此这种同步操作被称为非阻塞同步。这种方法需要硬件支持，因为我们必须要求操作和冲突检测这两个步骤具备原子性。如测试并设置（Test-and-Set）；获取并增加（Fetch-and-Increment）；交换（Swap）；比较并交换（Compare-and-Swap，下文称CAS）。</li><li>无同步方案：如果能让一个方法本来就不涉及共享数据，那它自然就不需要任何同步措施去保证其正确性，因此会有一些代码天生就是线程安全的。</li></ol></li></ul><p>锁优化：</p><ul><li><p>自旋锁与自适应自旋：互斥同步对性能最大的影响是阻塞的实现，挂起线程和恢复线程的操作都需要转入内核态中完成，这些操作给Java虚拟机的并发性能带来了很大的压力。如果物理机器有一个以上的处理器或者处理器核心，能让两个或以上的线程同时并行执行，我们就可以让后面请求锁的那个线程“稍等一会”，但不放弃处理器的执行时间，看看持有锁的线程是否很快就会释放锁。为了让线程等待，我们只须让线程执行一个忙循环（自旋），这项技术就是所谓的自旋锁。自适应意味着自旋的时间不再是固定的了，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定的。</p></li><li><p>锁消除：锁消除是指虚拟机即时编译器在运行时，对一些代码要求同步，但是对被检测到不可能存在共享数据竞争的锁进行消除。锁消除的主要判定依据来源于逃逸分析的数据支持，如果判断到一段代码中，在堆上的所有数据都不会逃逸出去被其他线程访问到，那就可以把它们当作栈上数据对待，认为它们是线程私有的，同步加锁自然就无须再进行。</p></li><li><p>锁粗化：原则上，总是推荐将同步块的作用范围限制得尽量小，这样是为了使得需要同步的操作数量尽可能变少，即使存在锁竞争，等待锁的线程也能尽可能快地拿到锁。但是如果一系列的连续操作都对同一个对象反复加锁和解锁，甚至加锁操作是出现在循环体之中的，那即使没有线程竞争，频繁地进行互斥同步操作也会导致不必要的性能损耗。因此可以进行锁粗化操作。</p></li><li><p>轻量级锁：HotSpot虚拟机对象头布局：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201206125352406.png" class="lazyload" data-srcset="image-20201206125352406.png" srcset="data:image/png;base64,666" alt="image-20201206125352406"/></div><span class="image-caption">image-20201206125352406</span></div><p>在代码即将进入同步块的时候，如果此同步对象没有被锁定（锁标志位为“01”状态），虚拟机首先将在当前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，用于存储锁对象目前的Mark Word的拷贝：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201206125505870.png" class="lazyload" data-srcset="image-20201206125505870.png" srcset="data:image/png;base64,666" alt="image-20201206125505870"/></div><span class="image-caption">image-20201206125505870</span></div><p>然后，虚拟机将使用CAS操作尝试把对象的Mark Word更新为指向Lock Record的指针。如果这个更新动作成功了，即代表该线程拥有了这个对象的锁，并且对象Mark Word的锁标志位将转变为“00”，表示此对象处于轻量级锁定状态。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201206125621073.png" class="lazyload" data-srcset="image-20201206125621073.png" srcset="data:image/png;base64,666" alt="image-20201206125621073"/></div><span class="image-caption">image-20201206125621073</span></div></li><li><p>偏向锁：它的目的是消除数据在无竞争情况下的同步原语，进一步提高程序的运行性能。如果说轻量级锁是在无竞争的情况下使用CAS操作去消除同步使用的互斥量，那偏向锁就是在无竞争的情况下把整个同步都消除掉，连CAS操作都不去做了。偏向锁会偏向于第一个获得它的线程，如果在接下来的执行过程中，该锁一直没有被其他的线程获取，则持有偏向锁的线程将永远不需要再进行同步。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201206125818939.png" class="lazyload" data-srcset="image-20201206125818939.png" srcset="data:image/png;base64,666" alt="image-20201206125818939"/></div><span class="image-caption">image-20201206125818939</span></div><p>在Java语言里面一个对象如果计算过哈希码，就应该一直保持该值不变，否则很多依赖对象哈希码的API都可能存<br>在出错风险。因此，当一个对象已经计算过一致性哈希码后，它就再也无法进入偏向锁状态了；而当一个对象当前正处于偏向锁状态，又收到需要计算其一致性哈希码请求时，它的偏向状态会被立即撤销，并且锁会膨胀为重量级锁。</p></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>设计模式</title>
      <link href="2020/11/07/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
      <url>2020/11/07/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<p>设计模式是软件开发人员在软件开发过程中面临的一般问题的解决方案。这些解决方案是众多软件开发人员经过相当长的一段时间的试验和错误总结出来的。本文介绍设计模式。</p><a id="more"></a><h2 id="设计模式简介"><a href="#设计模式简介" class="headerlink" title="设计模式简介"></a>设计模式简介</h2><p>设计模式是一套被反复使用的、多数人知晓的、经过分类编目的、代码设计经验的总结。使用设计模式是为了重用代码、让代码更容易被他人理解、保证代码可靠性。</p><p>GoF：四位作者合称，他们提出的设计模式主要基于以下面向对象设计原则：</p><ul><li>对接口编程而不是对实现编程。</li><li>优先使用对象组合而不是继承。</li></ul><p>设计模式的用途：是开发人员的共同平台，代表着最佳的实践。</p><p>设计模式的类型：创建型模式，结构型模式，行为型模式。另外将介绍 J2EE 模式。</p><table><thead><tr><th align="left">序号</th><th align="left">模式 &amp; 描述</th><th align="left">包括</th></tr></thead><tbody><tr><td align="left">1</td><td align="left"><strong>创建型模式</strong> <br />这些设计模式提供了一种在创建对象的同时隐藏创建逻辑的方式，而不是使用 new 运算符直接实例化对象。这使得程序在判断针对某个给定实例需要创建哪些对象时更加灵活。</td><td align="left">工厂模式（Factory Pattern）<br />抽象工厂模式（Abstract Factory Pattern）<br />单例模式（Singleton Pattern）<br />建造者模式（Builder Pattern）<br />原型模式（Prototype Pattern）</td></tr><tr><td align="left">2</td><td align="left"><strong>结构型模式</strong> <br />这些设计模式关注类和对象的组合。继承的概念被用来组合接口和定义组合对象获得新功能的方式。</td><td align="left">适配器模式（Adapter Pattern）<br />桥接模式（Bridge Pattern）<br />过滤器模式（Filter、Criteria Pattern）<br />组合模式（Composite Pattern）<br />装饰器模式（Decorator Pattern）<br />外观模式（Facade Pattern）<br />享元模式（Flyweight Pattern）<br />代理模式（Proxy Pattern）</td></tr><tr><td align="left">3</td><td align="left"><strong>行为型模式</strong> <br />这些设计模式特别关注对象之间的通信。</td><td align="left">责任链模式（Chain of Responsibility Pattern）<br />命令模式（Command Pattern）<br />解释器模式（Interpreter Pattern）<br />迭代器模式（Iterator Pattern）<br />中介者模式（Mediator Pattern）<br />备忘录模式（Memento Pattern）<br />观察者模式（Observer Pattern）<br />状态模式（State Pattern）<br />空对象模式（Null Object Pattern）<br />策略模式（Strategy Pattern）<br />模板模式（Template Pattern）<br />访问者模式（Visitor Pattern）</td></tr><tr><td align="left">4</td><td align="left"><strong>J2EE 模式</strong> <br />这些设计模式特别关注表示层。这些模式是由 Sun Java Center 鉴定的。</td><td align="left">MVC 模式（MVC Pattern）         <br />业务代表模式（Business Delegate Pattern）                                                                                                                                                                                 <br />组合实体模式（Composite Entity Pattern）<br />数据访问对象模式（Data Access Object Pattern）<br />前端控制器模式（Front Controller Pattern）<br />拦截过滤器模式（Intercepting Filter Pattern）<br />服务定位器模式（Service Locator Pattern）<br />传输对象模式（Transfer Object Pattern）</td></tr></tbody></table><p>设计模式六大原则：</p><ul><li>开闭原则：对扩展开放，对修改关闭，实现热插拔，提高扩展性</li><li>里氏代换原则：任何基类可以出现的地方，子类一定可以出现，实现抽象的规范，实现子父类互相替换</li><li>依赖倒转原则：针对接口编程，依赖于抽象而不依赖于具体</li><li>接口隔离原则：使用多个隔离的接口，比使用单个接口要好，降低类之间的耦合度</li><li>迪米特法则：一个实体应当尽量少地与其他实体之间发生相互作用，使得系统功能模块相对独立</li><li>合成复用原则：尽量使用合成/聚合的方式，而不是使用继承</li></ul><h2 id="工厂模式"><a href="#工厂模式" class="headerlink" title="工厂模式"></a>工厂模式</h2><p>介绍：工厂模式（Factory Pattern）是 Java 中最常用的设计模式之一。这种类型的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。在工厂模式中，我们在创建对象时不会对客户端暴露创建逻辑，并且是通过使用一个共同的接口来指向新创建的对象。</p><p>优点：1、一个调用者想创建一个对象，只要知道其名称就可以了。 2、扩展性高，如果想增加一个产品，只要扩展一个工厂类就可以。 3、屏蔽产品的具体实现，调用者只关心产品的接口。</p><p>缺点：每次增加一个产品时，都需要增加一个具体类和对象实现工厂，使得系统中类的个数成倍增加，在一定程度上增加了系统的复杂度，同时也增加了系统具体类的依赖。</p><p>使用场景： 1、日志记录器：记录可能记录到本地硬盘、系统事件、远程服务器等，用户可以选择记录日志到什么地方。 2、数据库访问，当用户不知道最后系统采用哪一类数据库，以及数据库可能有变化时。 3、设计一个连接服务器的框架，需要三个协议，”POP3”、”IMAP”、”HTTP”，可以把这三个作为产品类，共同实现一个接口。</p><p>实现：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="AB6B814A-0B09-4863-93D6-1E22D6B07FF8.jpg" class="lazyload" data-srcset="AB6B814A-0B09-4863-93D6-1E22D6B07FF8.jpg" srcset="data:image/png;base64,666" alt="工厂模式的 UML 图"/></div><span class="image-caption">工厂模式的 UML 图</span></div><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ShapeFactory</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">   <span class="comment">//使用 getShape 方法获取形状类型的对象</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> Shape <span class="title">getShape</span><span class="params">(String shapeType)</span></span>&#123;</span><br><span class="line">      <span class="keyword">if</span>(shapeType == <span class="keyword">null</span>)&#123;</span><br><span class="line">         <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">      &#125;        </span><br><span class="line">      <span class="keyword">if</span>(shapeType.equalsIgnoreCase(<span class="string">&quot;CIRCLE&quot;</span>))&#123;</span><br><span class="line">         <span class="keyword">return</span> <span class="keyword">new</span> Circle();</span><br><span class="line">      &#125; <span class="keyword">else</span> <span class="keyword">if</span>(shapeType.equalsIgnoreCase(<span class="string">&quot;RECTANGLE&quot;</span>))&#123;</span><br><span class="line">         <span class="keyword">return</span> <span class="keyword">new</span> Rectangle();</span><br><span class="line">      &#125; <span class="keyword">else</span> <span class="keyword">if</span>(shapeType.equalsIgnoreCase(<span class="string">&quot;SQUARE&quot;</span>))&#123;</span><br><span class="line">         <span class="keyword">return</span> <span class="keyword">new</span> Square();</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="抽象工厂模式"><a href="#抽象工厂模式" class="headerlink" title="抽象工厂模式"></a>抽象工厂模式</h2><p>介绍：抽象工厂模式（Abstract Factory Pattern）是围绕一个超级工厂创建其他工厂。该超级工厂又称为其他工厂的工厂。在抽象工厂模式中，接口是负责创建一个相关对象的工厂，不需要显式指定它们的类。每个生成的工厂都能按照工厂模式提供对象。</p><p>优点：当一个产品族中的多个对象被设计成一起工作时，它能保证客户端始终只使用同一个产品族中的对象。</p><p>缺点：产品族扩展非常困难，要增加一个系列的某一产品，既要在抽象的 Creator 里加代码，又要在具体的里面加代码。</p><p>使用场景： 1、QQ 换皮肤，一整套一起换。 2、生成不同操作系统的程序。</p><p>实现：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="3E13CDD1-2CD2-4C66-BD33-DECBF172AE03.jpg" class="lazyload" data-srcset="3E13CDD1-2CD2-4C66-BD33-DECBF172AE03.jpg" srcset="data:image/png;base64,666" alt="抽象工厂模式的 UML 图"/></div><span class="image-caption">抽象工厂模式的 UML 图</span></div><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FactoryProducer</span> </span>&#123;</span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> AbstractFactory <span class="title">getFactory</span><span class="params">(String choice)</span></span>&#123;</span><br><span class="line">      <span class="keyword">if</span>(choice.equalsIgnoreCase(<span class="string">&quot;SHAPE&quot;</span>))&#123;</span><br><span class="line">         <span class="keyword">return</span> <span class="keyword">new</span> ShapeFactory();</span><br><span class="line">      &#125; <span class="keyword">else</span> <span class="keyword">if</span>(choice.equalsIgnoreCase(<span class="string">&quot;COLOR&quot;</span>))&#123;</span><br><span class="line">         <span class="keyword">return</span> <span class="keyword">new</span> ColorFactory();</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="单例模式"><a href="#单例模式" class="headerlink" title="单例模式"></a>单例模式</h2><p>介绍：单例模式（Singleton Pattern）是 Java 中最简单的设计模式之一。这种模式涉及到一个单一的类，该类负责创建自己的对象，同时确保只有单个对象被创建。这个类提供了一种访问其唯一的对象的方式，可以直接访问，不需要实例化该类的对象。</p><p>优点：1、在内存里只有一个实例，减少了内存的开销，尤其是频繁的创建和销毁实例（比如管理学院首页页面缓存）。2、避免对资源的多重占用（比如写文件操作）。</p><p>缺点：没有接口，不能继承，与单一职责原则冲突，一个类应该只关心内部逻辑，而不关心外面怎么样来实例化。</p><p>使用场景：1、要求生产唯一序列号。2、WEB 中的计数器，不用每次刷新都在数据库里加一次，用单例先缓存起来。3、创建的一个对象需要消耗的资源过多，比如 I/O 与数据库的连接等。</p><p>实现：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="62576915-36E0-4B67-B078-704699CA980A.jpg" class="lazyload" data-srcset="62576915-36E0-4B67-B078-704699CA980A.jpg" srcset="data:image/png;base64,666" alt="单例模式的 UML 图"/></div><span class="image-caption">单例模式的 UML 图</span></div><ul><li><p>懒汉式，线程不安全</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Singleton</span> </span>&#123;  </span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> Singleton instance;  </span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">Singleton</span> <span class="params">()</span></span>&#123;&#125;  </span><br><span class="line">  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Singleton <span class="title">getInstance</span><span class="params">()</span> </span>&#123;  </span><br><span class="line">        <span class="keyword">if</span> (instance == <span class="keyword">null</span>) &#123;  </span><br><span class="line">            instance = <span class="keyword">new</span> Singleton();  </span><br><span class="line">        &#125;  </span><br><span class="line">    <span class="keyword">return</span> instance;  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>懒汉式，线程安全</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Singleton</span> </span>&#123;  </span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> Singleton instance;  </span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">Singleton</span> <span class="params">()</span></span>&#123;&#125;  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">synchronized</span> Singleton <span class="title">getInstance</span><span class="params">()</span> </span>&#123;  </span><br><span class="line">        <span class="keyword">if</span> (instance == <span class="keyword">null</span>) &#123;  </span><br><span class="line">            instance = <span class="keyword">new</span> Singleton();  </span><br><span class="line">        &#125;  </span><br><span class="line">    <span class="keyword">return</span> instance;  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>饿汉式</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Singleton</span> </span>&#123;  </span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> Singleton instance = <span class="keyword">new</span> Singleton();  </span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">Singleton</span> <span class="params">()</span></span>&#123;&#125;  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Singleton <span class="title">getInstance</span><span class="params">()</span> </span>&#123;  </span><br><span class="line">    <span class="keyword">return</span> instance;  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>双重校验锁（DCL，即 double-checked locking）：采用双锁机制，安全且在多线程情况下能保持高性能。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Singleton</span> </span>&#123;  </span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">volatile</span> <span class="keyword">static</span> Singleton singleton;  </span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">Singleton</span> <span class="params">()</span></span>&#123;&#125;  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Singleton <span class="title">getSingleton</span><span class="params">()</span> </span>&#123;  </span><br><span class="line">        <span class="keyword">if</span> (singleton == <span class="keyword">null</span>) &#123;  </span><br><span class="line">            <span class="keyword">synchronized</span> (Singleton.class) &#123;  </span><br><span class="line">                <span class="keyword">if</span> (singleton == <span class="keyword">null</span>) &#123;  </span><br><span class="line">                    singleton = <span class="keyword">new</span> Singleton();  </span><br><span class="line">                &#125;  </span><br><span class="line">            &#125;  </span><br><span class="line">        &#125;  </span><br><span class="line">    <span class="keyword">return</span> singleton;  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>静态内部类：能达到和双重校验锁一样的效果，但是实现更加简单</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Singleton</span> </span>&#123;  </span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">SingletonHolder</span> </span>&#123;  </span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Singleton INSTANCE = <span class="keyword">new</span> Singleton();  </span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">Singleton</span> <span class="params">()</span></span>&#123;&#125;  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> Singleton <span class="title">getInstance</span><span class="params">()</span> </span>&#123;  </span><br><span class="line">    <span class="keyword">return</span> SingletonHolder.INSTANCE;  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>枚举：这种实现方式还没有被广泛采用，但这是实现单例模式的最佳方法。它更简洁，自动支持序列化机制，绝对防止多次实例化。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">enum</span> Singleton &#123;  </span><br><span class="line">    INSTANCE;  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">whateverMethod</span><span class="params">()</span> </span>&#123;  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h2 id="建造者模式"><a href="#建造者模式" class="headerlink" title="建造者模式"></a>建造者模式</h2><p>介绍：建造者模式（Builder Pattern）使用多个简单的对象一步一步构建成一个复杂的对象。一个 Builder 类会一步一步构造最终的对象。该 Builder 类是独立于其他对象的。</p><p>优点： 1、建造者独立，易扩展。 2、便于控制细节风险。</p><p>缺点： 1、产品必须有共同点，范围有限制。 2、如内部变化复杂，会有很多的建造类。</p><p>使用场景： 1、需要生成的对象具有复杂的内部结构。 2、需要生成的对象内部属性本身相互依赖。</p><p>实现：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="20201015-builder-pattern.svg" class="lazyload" data-srcset="20201015-builder-pattern.svg" srcset="data:image/png;base64,666" alt="建造者模式的 UML 图"/></div><span class="image-caption">建造者模式的 UML 图</span></div><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MealBuilder</span> </span>&#123;</span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">public</span> Meal <span class="title">prepareVegMeal</span> <span class="params">()</span></span>&#123;</span><br><span class="line">      Meal meal = <span class="keyword">new</span> Meal();</span><br><span class="line">      meal.addItem(<span class="keyword">new</span> VegBurger());</span><br><span class="line">      meal.addItem(<span class="keyword">new</span> Coke());</span><br><span class="line">      <span class="keyword">return</span> meal;</span><br><span class="line">   &#125;   </span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">public</span> Meal <span class="title">prepareNonVegMeal</span> <span class="params">()</span></span>&#123;</span><br><span class="line">      Meal meal = <span class="keyword">new</span> Meal();</span><br><span class="line">      meal.addItem(<span class="keyword">new</span> ChickenBurger());</span><br><span class="line">      meal.addItem(<span class="keyword">new</span> Pepsi());</span><br><span class="line">      <span class="keyword">return</span> meal;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="原型模式"><a href="#原型模式" class="headerlink" title="原型模式"></a>原型模式</h2><p>介绍：原型模式（Prototype Pattern）是用于创建重复的对象，同时又能保证性能。这种模式是实现了一个原型接口，该接口用于创建当前对象的克隆。当直接创建对象的代价比较大时，则采用这种模式。</p><p>优点： 1、性能提高。 2、逃避构造函数的约束。</p><p>缺点： 1、配备克隆方法需要对类的功能进行通盘考虑，这对于全新的类不是很难，但对于已有的类不一定很容易，特别当一个类引用不支持串行化的间接对象，或者引用含有循环结构的时候。 2、必须实现 Cloneable 接口。</p><p>使用场景： 1、资源优化场景。 2、类初始化需要消化非常多的资源，这个资源包括数据、硬件资源等。 3、性能和安全要求的场景。 4、通过 new 产生一个对象需要非常繁琐的数据准备或访问权限，则可以使用原型模式。 5、一个对象多个修改者的场景。 6、一个对象需要提供给其他对象访问，而且各个调用者可能都需要修改其值时，可以考虑使用原型模式拷贝多个对象供调用者使用。 7、在实际项目中，原型模式很少单独出现，一般是和工厂方法模式一起出现，通过 clone 的方法创建一个对象，然后由工厂方法提供给调用者。原型模式已经与 Java 融为浑然一体，大家可以随手拿来使用。</p><p>实现：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="20201015-prototype-pattern.svg" class="lazyload" data-srcset="20201015-prototype-pattern.svg" srcset="data:image/png;base64,666" alt="原型模式的 UML 图"/></div><span class="image-caption">原型模式的 UML 图</span></div><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.Hashtable;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ShapeCache</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">   <span class="keyword">private</span> <span class="keyword">static</span> Hashtable&lt;String, Shape&gt; shapeMap </span><br><span class="line">      = <span class="keyword">new</span> Hashtable&lt;String, Shape&gt;();</span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Shape <span class="title">getShape</span><span class="params">(String shapeId)</span> </span>&#123;</span><br><span class="line">      Shape cachedShape = shapeMap.get(shapeId);</span><br><span class="line">      <span class="keyword">return</span> (Shape) cachedShape.clone();</span><br><span class="line">   &#125;</span><br><span class="line"> </span><br><span class="line">   <span class="comment">// 对每种形状都运行数据库查询，并创建该形状</span></span><br><span class="line">   <span class="comment">// shapeMap.put(shapeKey, shape);</span></span><br><span class="line">   <span class="comment">// 例如，我们要添加三种形状</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">loadCache</span><span class="params">()</span> </span>&#123;</span><br><span class="line">      Circle circle = <span class="keyword">new</span> Circle();</span><br><span class="line">      circle.setId(<span class="string">&quot;1&quot;</span>);</span><br><span class="line">      shapeMap.put(circle.getId(),circle);</span><br><span class="line"> </span><br><span class="line">      Square square = <span class="keyword">new</span> Square();</span><br><span class="line">      square.setId(<span class="string">&quot;2&quot;</span>);</span><br><span class="line">      shapeMap.put(square.getId(),square);</span><br><span class="line"> </span><br><span class="line">      Rectangle rectangle = <span class="keyword">new</span> Rectangle();</span><br><span class="line">      rectangle.setId(<span class="string">&quot;3&quot;</span>);</span><br><span class="line">      shapeMap.put(rectangle.getId(),rectangle);</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">Shape</span> <span class="keyword">implements</span> <span class="title">Cloneable</span> </span>&#123;</span><br><span class="line">   </span><br><span class="line">   <span class="keyword">private</span> String id;</span><br><span class="line">   <span class="keyword">protected</span> String type;</span><br><span class="line">   </span><br><span class="line">   <span class="function"><span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">draw</span><span class="params">()</span></span>;</span><br><span class="line">   </span><br><span class="line">   <span class="function"><span class="keyword">public</span> String <span class="title">getType</span><span class="params">()</span></span>&#123;</span><br><span class="line">      <span class="keyword">return</span> type;</span><br><span class="line">   &#125;</span><br><span class="line">   </span><br><span class="line">   <span class="function"><span class="keyword">public</span> String <span class="title">getId</span><span class="params">()</span> </span>&#123;</span><br><span class="line">      <span class="keyword">return</span> id;</span><br><span class="line">   &#125;</span><br><span class="line">   </span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setId</span><span class="params">(String id)</span> </span>&#123;</span><br><span class="line">      <span class="keyword">this</span>.id = id;</span><br><span class="line">   &#125;</span><br><span class="line">   </span><br><span class="line">   <span class="function"><span class="keyword">public</span> Object <span class="title">clone</span><span class="params">()</span> </span>&#123;<span class="comment">// clone 方法实现</span></span><br><span class="line">      Object clone = <span class="keyword">null</span>;</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">         clone = <span class="keyword">super</span>.clone();</span><br><span class="line">      &#125; <span class="keyword">catch</span> (CloneNotSupportedException e) &#123;</span><br><span class="line">         e.printStackTrace();</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">return</span> clone;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="适配器模式"><a href="#适配器模式" class="headerlink" title="适配器模式"></a>适配器模式</h2><p>介绍：适配器模式（Adapter Pattern）是作为两个不兼容的接口之间的桥梁。这种模式涉及到一个单一的类，该类负责加入独立的或不兼容的接口功能。举个真实的例子，读卡器是作为内存卡和笔记本之间的适配器。您将内存卡插入读卡器，再将读卡器插入笔记本，这样就可以通过笔记本来读取内存卡。</p><p>优点： 1、可以让任何两个没有关联的类一起运行。 2、提高了类的复用。 3、增加了类的透明度。 4、灵活性好。</p><p>缺点： 1、过多地使用适配器，会让系统非常零乱，不易整体进行把握。比如，明明看到调用的是 A 接口，其实内部被适配成了 B 接口的实现，一个系统如果太多出现这种情况，无异于一场灾难。因此如果不是很有必要，可以不使用适配器，而是直接对系统进行重构。 2.由于 JAVA 至多继承一个类，所以至多只能适配一个适配者类，而且目标类必须是抽象类。</p><p>使用场景：有动机地修改一个正常运行的系统的接口，这时应该考虑使用适配器模式。</p><p>实现：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="20201015-adapter.svg" class="lazyload" data-srcset="20201015-adapter.svg" srcset="data:image/png;base64,666" alt="适配器模式的 UML 图"/></div><span class="image-caption">适配器模式的 UML 图</span></div><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MediaAdapter</span> <span class="keyword">implements</span> <span class="title">MediaPlayer</span> </span>&#123;</span><br><span class="line"> </span><br><span class="line">   AdvancedMediaPlayer advancedMusicPlayer;</span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="title">MediaAdapter</span><span class="params">(String audioType)</span></span>&#123;</span><br><span class="line">      <span class="keyword">if</span>(audioType.equalsIgnoreCase(<span class="string">&quot;vlc&quot;</span>) )&#123;</span><br><span class="line">         advancedMusicPlayer = <span class="keyword">new</span> VlcPlayer();       </span><br><span class="line">      &#125; <span class="keyword">else</span> <span class="keyword">if</span> (audioType.equalsIgnoreCase(<span class="string">&quot;mp4&quot;</span>))&#123;</span><br><span class="line">         advancedMusicPlayer = <span class="keyword">new</span> Mp4Player();</span><br><span class="line">      &#125;  </span><br><span class="line">   &#125;</span><br><span class="line"> </span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">play</span><span class="params">(String audioType, String fileName)</span> </span>&#123;</span><br><span class="line">      <span class="keyword">if</span>(audioType.equalsIgnoreCase(<span class="string">&quot;vlc&quot;</span>))&#123;</span><br><span class="line">         advancedMusicPlayer.playVlc(fileName);</span><br><span class="line">      &#125;<span class="keyword">else</span> <span class="keyword">if</span>(audioType.equalsIgnoreCase(<span class="string">&quot;mp4&quot;</span>))&#123;</span><br><span class="line">         advancedMusicPlayer.playMp4(fileName);</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AudioPlayer</span> <span class="keyword">implements</span> <span class="title">MediaPlayer</span> </span>&#123;</span><br><span class="line">   MediaAdapter mediaAdapter; </span><br><span class="line"> </span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">play</span><span class="params">(String audioType, String fileName)</span> </span>&#123;    </span><br><span class="line"> </span><br><span class="line">      <span class="comment">//播放 mp3 音乐文件的内置支持</span></span><br><span class="line">      <span class="keyword">if</span>(audioType.equalsIgnoreCase(<span class="string">&quot;mp3&quot;</span>))&#123;</span><br><span class="line">         System.out.println(<span class="string">&quot;Playing mp3 file. Name: &quot;</span>+ fileName);         </span><br><span class="line">      &#125; </span><br><span class="line">      <span class="comment">//mediaAdapter 提供了播放其他文件格式的支持</span></span><br><span class="line">      <span class="keyword">else</span> <span class="keyword">if</span>(audioType.equalsIgnoreCase(<span class="string">&quot;vlc&quot;</span>) </span><br><span class="line">         || audioType.equalsIgnoreCase(<span class="string">&quot;mp4&quot;</span>))&#123;</span><br><span class="line">         mediaAdapter = <span class="keyword">new</span> MediaAdapter(audioType);</span><br><span class="line">         mediaAdapter.play(audioType, fileName);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">else</span>&#123;</span><br><span class="line">         System.out.println(<span class="string">&quot;Invalid media. &quot;</span>+</span><br><span class="line">            audioType + <span class="string">&quot; format not supported&quot;</span>);</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;   </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="桥接模式"><a href="#桥接模式" class="headerlink" title="桥接模式"></a>桥接模式</h2><p>介绍：桥接（Bridge）是用于把抽象化与实现化解耦，使得二者可以独立变化。这种模式涉及到一个作为桥接的接口，使得实体类的功能独立于接口实现类。这两种类型的类可被结构化改变而互不影响。</p><p>优点： 1、抽象和实现的分离。 2、优秀的扩展能力。 3、实现细节对客户透明。</p><p>缺点：桥接模式的引入会增加系统的理解与设计难度，由于聚合关联关系建立在抽象层，要求开发者针对抽象进行设计与编程。</p><p>使用场景： 1、如果一个系统需要在构件的抽象化角色和具体化角色之间增加更多的灵活性，避免在两个层次之间建立静态的继承联系，通过桥接模式可以使它们在抽象层建立一个关联关系。 2、对于那些不希望使用继承或因为多层次继承导致系统类的个数急剧增加的系统，桥接模式尤为适用。 3、一个类存在两个独立变化的维度，且这两个维度都需要进行扩展。</p><p>实现：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="20201015-bridge.svg" class="lazyload" data-srcset="20201015-bridge.svg" srcset="data:image/png;base64,666" alt="桥接模式的 UML 图"/></div><span class="image-caption">桥接模式的 UML 图</span></div><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">Shape</span> </span>&#123;</span><br><span class="line">   <span class="keyword">protected</span> DrawAPI drawAPI;</span><br><span class="line">   <span class="function"><span class="keyword">protected</span> <span class="title">Shape</span><span class="params">(DrawAPI drawAPI)</span></span>&#123;</span><br><span class="line">      <span class="keyword">this</span>.drawAPI = drawAPI;</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">draw</span><span class="params">()</span></span>;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="过滤器模式"><a href="#过滤器模式" class="headerlink" title="过滤器模式"></a>过滤器模式</h2><p>介绍：过滤器模式（Filter Pattern）或标准模式（Criteria Pattern）是一种设计模式，这种模式允许开发人员使用不同的标准来过滤一组对象，通过逻辑运算以解耦的方式把它们连接起来。</p><p>实现：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="20201015-filter.svg" class="lazyload" data-srcset="20201015-filter.svg" srcset="data:image/png;base64,666" alt="过滤器模式的 UML 图"/></div><span class="image-caption">过滤器模式的 UML 图</span></div><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Criteria</span> </span>&#123;</span><br><span class="line">   <span class="function"><span class="keyword">public</span> List&lt;Person&gt; <span class="title">meetCriteria</span><span class="params">(List&lt;Person&gt; persons)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="组合模式"><a href="#组合模式" class="headerlink" title="组合模式"></a>组合模式</h2><p>介绍：组合模式（Composite Pattern），又叫部分整体模式，是用于把一组相似的对象当作一个单一的对象。组合模式依据树形结构来组合对象，用来表示部分以及整体层次。这种模式创建了一个包含自己对象组的类。该类提供了修改相同对象组的方式。所谓组合模式，其实说的是对象包含对象的问题，通过组合的方式（在对象内部引用对象）来进行布局。</p><p>优点： 1、高层模块调用简单。 2、节点自由增加。</p><p>缺点：在使用组合模式时，其叶子和树枝的声明都是实现类，而不是接口，违反了依赖倒置原则。</p><p>使用场景：部分、整体场景，如树形菜单，文件、文件夹的管理。</p><p>实现：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="20201015-composite.svg" class="lazyload" data-srcset="20201015-composite.svg" srcset="data:image/png;base64,666" alt="组合模式的 UML 图"/></div><span class="image-caption">组合模式的 UML 图</span></div><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Employee</span> </span>&#123;</span><br><span class="line">   <span class="keyword">private</span> String name;</span><br><span class="line">   <span class="keyword">private</span> String dept;</span><br><span class="line">   <span class="keyword">private</span> <span class="keyword">int</span> salary;</span><br><span class="line">   <span class="keyword">private</span> List&lt;Employee&gt; subordinates;</span><br><span class="line"> </span><br><span class="line">   <span class="comment">//构造函数</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="title">Employee</span><span class="params">(String name,String dept, <span class="keyword">int</span> sal)</span> </span>&#123;</span><br><span class="line">      <span class="keyword">this</span>.name = name;</span><br><span class="line">      <span class="keyword">this</span>.dept = dept;</span><br><span class="line">      <span class="keyword">this</span>.salary = sal;</span><br><span class="line">      subordinates = <span class="keyword">new</span> ArrayList&lt;Employee&gt;();</span><br><span class="line">   &#125;</span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">add</span><span class="params">(Employee e)</span> </span>&#123;</span><br><span class="line">      subordinates.add(e);</span><br><span class="line">   &#125;</span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">remove</span><span class="params">(Employee e)</span> </span>&#123;</span><br><span class="line">      subordinates.remove(e);</span><br><span class="line">   &#125;</span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">public</span> List&lt;Employee&gt; <span class="title">getSubordinates</span><span class="params">()</span></span>&#123;</span><br><span class="line">     <span class="keyword">return</span> subordinates;</span><br><span class="line">   &#125;</span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span></span>&#123;</span><br><span class="line">      <span class="keyword">return</span> (<span class="string">&quot;Employee :[ Name : &quot;</span>+ name </span><br><span class="line">      +<span class="string">&quot;, dept : &quot;</span>+ dept + <span class="string">&quot;, salary :&quot;</span></span><br><span class="line">      + salary+<span class="string">&quot; ]&quot;</span>);</span><br><span class="line">   &#125;   </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="装饰器模式"><a href="#装饰器模式" class="headerlink" title="装饰器模式"></a>装饰器模式</h2><p>介绍：装饰器模式（Decorator Pattern）允许向一个现有的对象添加新的功能，同时又不改变其结构。这种模式创建了一个装饰类，用来包装原有的类，并在保持类方法签名完整性的前提下，提供了额外的功能。</p><p>优点：装饰类和被装饰类可以独立发展，不会相互耦合，装饰模式是继承的一个替代模式，装饰模式可以动态扩展一个实现类的功能。</p><p>缺点：多层装饰比较复杂。</p><p>使用场景： 1、扩展一个类的功能。 2、动态增加功能，动态撤销。</p><p>实现：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="20201015-decorator.svg" class="lazyload" data-srcset="20201015-decorator.svg" srcset="data:image/png;base64,666" alt="装饰器模式的 UML 图"/></div><span class="image-caption">装饰器模式的 UML 图</span></div><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">ShapeDecorator</span> <span class="keyword">implements</span> <span class="title">Shape</span> </span>&#123;</span><br><span class="line">   <span class="keyword">protected</span> Shape decoratedShape;</span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="title">ShapeDecorator</span><span class="params">(Shape decoratedShape)</span></span>&#123;</span><br><span class="line">      <span class="keyword">this</span>.decoratedShape = decoratedShape;</span><br><span class="line">   &#125;</span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">draw</span><span class="params">()</span></span>&#123;</span><br><span class="line">      decoratedShape.draw();</span><br><span class="line">   &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RedShapeDecorator</span> <span class="keyword">extends</span> <span class="title">ShapeDecorator</span> </span>&#123;</span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="title">RedShapeDecorator</span><span class="params">(Shape decoratedShape)</span> </span>&#123;</span><br><span class="line">      <span class="keyword">super</span>(decoratedShape);     </span><br><span class="line">   &#125;</span><br><span class="line"> </span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">draw</span><span class="params">()</span> </span>&#123;</span><br><span class="line">      decoratedShape.draw();         </span><br><span class="line">      setRedBorder(decoratedShape);</span><br><span class="line">   &#125;</span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">setRedBorder</span><span class="params">(Shape decoratedShape)</span></span>&#123;</span><br><span class="line">      System.out.println(<span class="string">&quot;Border Color: Red&quot;</span>);</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="外观模式"><a href="#外观模式" class="headerlink" title="外观模式"></a>外观模式</h2><p>介绍：外观模式（Facade Pattern）隐藏系统的复杂性，并向客户端提供了一个客户端可以访问系统的接口。这种模式涉及到一个单一的类，该类提供了客户端请求的简化方法和对现有系统类方法的委托调用。</p><p>优点： 1、减少系统相互依赖。 2、提高灵活性。 3、提高了安全性。</p><p>缺点：不符合开闭原则，如果要改东西很麻烦，继承重写都不合适。</p><p>使用场景： 1、为复杂的模块或子系统提供外界访问的模块。 2、子系统相对独立。 3、预防低水平人员带来的风险。</p><p>实现：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="20201015-facade.svg" class="lazyload" data-srcset="20201015-facade.svg" srcset="data:image/png;base64,666" alt="外观模式的 UML 图"/></div><span class="image-caption">外观模式的 UML 图</span></div><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ShapeMaker</span> </span>&#123;</span><br><span class="line">   <span class="keyword">private</span> Shape circle;</span><br><span class="line">   <span class="keyword">private</span> Shape rectangle;</span><br><span class="line">   <span class="keyword">private</span> Shape square;</span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="title">ShapeMaker</span><span class="params">()</span> </span>&#123;</span><br><span class="line">      circle = <span class="keyword">new</span> Circle();</span><br><span class="line">      rectangle = <span class="keyword">new</span> Rectangle();</span><br><span class="line">      square = <span class="keyword">new</span> Square();</span><br><span class="line">   &#125;</span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">drawCircle</span><span class="params">()</span></span>&#123;</span><br><span class="line">      circle.draw();</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">drawRectangle</span><span class="params">()</span></span>&#123;</span><br><span class="line">      rectangle.draw();</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">drawSquare</span><span class="params">()</span></span>&#123;</span><br><span class="line">      square.draw();</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="享元模式"><a href="#享元模式" class="headerlink" title="享元模式"></a>享元模式</h2><p>介绍：享元模式（Flyweight Pattern）主要用于减少创建对象的数量，以减少内存占用和提高性能。享元模式尝试重用现有的同类对象，如果未找到匹配的对象，则创建新对象。</p><p>优点：大大减少对象的创建，降低系统的内存，使效率提高。</p><p>缺点：提高了系统的复杂度，需要分离出外部状态和内部状态，而且外部状态具有固有化的性质，不应该随着内部状态的变化而变化，否则会造成系统的混乱。</p><p>使用场景： 1、系统有大量相似对象。 2、需要缓冲池的场景。</p><p>实现：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="20201015-fiyweight.svg" class="lazyload" data-srcset="20201015-fiyweight.svg" srcset="data:image/png;base64,666" alt="享元模式的 UML 图"/></div><span class="image-caption">享元模式的 UML 图</span></div><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.HashMap;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ShapeFactory</span> </span>&#123;</span><br><span class="line">   <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> HashMap&lt;String, Shape&gt; circleMap = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Shape <span class="title">getCircle</span><span class="params">(String color)</span> </span>&#123;</span><br><span class="line">      Circle circle = (Circle)circleMap.get(color);</span><br><span class="line"> </span><br><span class="line">      <span class="keyword">if</span>(circle == <span class="keyword">null</span>) &#123;</span><br><span class="line">         circle = <span class="keyword">new</span> Circle(color);</span><br><span class="line">         circleMap.put(color, circle);</span><br><span class="line">         System.out.println(<span class="string">&quot;Creating circle of color : &quot;</span> + color);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">return</span> circle;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="代理模式"><a href="#代理模式" class="headerlink" title="代理模式"></a>代理模式</h2><p>介绍：在代理模式（Proxy Pattern）中，一个类代表另一个类的功能。这种类型的设计模式属于结构型模式。在代理模式中，我们创建具有现有对象的对象，以便向外界提供功能接口。</p><p>优点： 1、职责清晰。 2、高扩展性。 3、智能化。</p><p>缺点： 1、由于在客户端和真实主题之间增加了代理对象，因此有些类型的代理模式可能会造成请求的处理速度变慢。 2、实现代理模式需要额外的工作，有些代理模式的实现非常复杂。</p><p>使用场景：按职责来划分，通常有以下使用场景： 1、远程代理。 2、虚拟代理。 3、Copy-on-Write 代理。 4、保护（Protect or Access）代理。 5、Cache代理。 6、防火墙（Firewall）代理。 7、同步化（Synchronization）代理。 8、智能引用（Smart Reference）代理。</p><p>实现：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="20201015-proxy.svg" class="lazyload" data-srcset="20201015-proxy.svg" srcset="data:image/png;base64,666" alt="代理模式的 UML 图"/></div><span class="image-caption">代理模式的 UML 图</span></div><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ProxyImage</span> <span class="keyword">implements</span> <span class="title">Image</span></span>&#123;</span><br><span class="line"> </span><br><span class="line">   <span class="keyword">private</span> RealImage realImage;</span><br><span class="line">   <span class="keyword">private</span> String fileName;</span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="title">ProxyImage</span><span class="params">(String fileName)</span></span>&#123;</span><br><span class="line">      <span class="keyword">this</span>.fileName = fileName;</span><br><span class="line">   &#125;</span><br><span class="line"> </span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">display</span><span class="params">()</span> </span>&#123;</span><br><span class="line">      <span class="keyword">if</span>(realImage == <span class="keyword">null</span>)&#123;</span><br><span class="line">         realImage = <span class="keyword">new</span> RealImage(fileName);</span><br><span class="line">      &#125;</span><br><span class="line">      realImage.display();</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="责任链模式"><a href="#责任链模式" class="headerlink" title="责任链模式"></a>责任链模式</h2><p>介绍：责任链模式（Chain of Responsibility Pattern）为请求创建了一个接收者对象的链。这种模式给予请求的类型，对请求的发送者和接收者进行解耦。在这种模式中，通常每个接收者都包含对另一个接收者的引用。如果一个对象不能处理该请求，那么它会把相同的请求传给下一个接收者，依此类推。</p><p>优点： 1、降低耦合度。它将请求的发送者和接收者解耦。 2、简化了对象。使得对象不需要知道链的结构。 3、增强给对象指派职责的灵活性。通过改变链内的成员或者调动它们的次序，允许动态地新增或者删除责任。 4、增加新的请求处理类很方便。</p><p>缺点： 1、不能保证请求一定被接收。 2、系统性能将受到一定影响，而且在进行代码调试时不太方便，可能会造成循环调用。 3、可能不容易观察运行时的特征，有碍于除错。</p><p>使用场景： 1、有多个对象可以处理同一个请求，具体哪个对象处理该请求由运行时刻自动确定。 2、在不明确指定接收者的情况下，向多个对象中的一个提交一个请求。 3、可动态指定一组对象处理请求。</p><p>实现：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="20201015-chain-of-responsibility.svg" class="lazyload" data-srcset="20201015-chain-of-responsibility.svg" srcset="data:image/png;base64,666" alt="责任链模式的 UML 图"/></div><span class="image-caption">责任链模式的 UML 图</span></div><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">AbstractLogger</span> </span>&#123;</span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> INFO = <span class="number">1</span>;</span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> DEBUG = <span class="number">2</span>;</span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> ERROR = <span class="number">3</span>;</span><br><span class="line"> </span><br><span class="line">   <span class="keyword">protected</span> <span class="keyword">int</span> level;</span><br><span class="line"> </span><br><span class="line">   <span class="comment">//责任链中的下一个元素</span></span><br><span class="line">   <span class="keyword">protected</span> AbstractLogger nextLogger;</span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setNextLogger</span><span class="params">(AbstractLogger nextLogger)</span></span>&#123;</span><br><span class="line">      <span class="keyword">this</span>.nextLogger = nextLogger;</span><br><span class="line">   &#125;</span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">logMessage</span><span class="params">(<span class="keyword">int</span> level, String message)</span></span>&#123;</span><br><span class="line">      <span class="keyword">if</span>(<span class="keyword">this</span>.level &lt;= level)&#123;</span><br><span class="line">         write(message);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span>(nextLogger !=<span class="keyword">null</span>)&#123;</span><br><span class="line">         nextLogger.logMessage(level, message);<span class="comment">// 向下层传播</span></span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">abstract</span> <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">write</span><span class="params">(String message)</span></span>;</span><br><span class="line">   </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="命令模式"><a href="#命令模式" class="headerlink" title="命令模式"></a>命令模式</h2><p>介绍：命令模式（Command Pattern）是一种数据驱动的设计模式，它属于行为型模式。请求以命令的形式包裹在对象中，并传给调用对象。调用对象寻找可以处理该命令的合适的对象，并把该命令传给相应的对象，该对象执行命令。</p><p>优点： 1、降低了系统耦合度。 2、新的命令可以很容易添加到系统中去。</p><p>缺点：使用命令模式可能会导致某些系统有过多的具体命令类。</p><p>使用场景：认为是命令的地方都可以使用命令模式，比如： 1、GUI 中每一个按钮都是一条命令。 2、模拟 CMD。</p><p>实现：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="20201015-command-1.svg" class="lazyload" data-srcset="20201015-command-1.svg" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Broker</span> </span>&#123;</span><br><span class="line">   <span class="keyword">private</span> List&lt;Order&gt; orderList = <span class="keyword">new</span> ArrayList&lt;Order&gt;(); </span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">takeOrder</span><span class="params">(Order order)</span></span>&#123;</span><br><span class="line">      orderList.add(order);      </span><br><span class="line">   &#125;</span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">placeOrders</span><span class="params">()</span></span>&#123;</span><br><span class="line">      <span class="keyword">for</span> (Order order : orderList) &#123;</span><br><span class="line">         order.execute();</span><br><span class="line">      &#125;</span><br><span class="line">      orderList.clear();</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="解释器模式"><a href="#解释器模式" class="headerlink" title="解释器模式"></a>解释器模式</h2><p>介绍：解释器模式（Interpreter Pattern）提供了评估语言的语法或表达式的方式，它属于行为型模式。这种模式实现了一个表达式接口，该接口解释一个特定的上下文。这种模式被用在 SQL 解析、符号处理引擎等。</p><p>优点： 1、可扩展性比较好，灵活。 2、增加了新的解释表达式的方式。 3、易于实现简单文法。</p><p>缺点： 1、可利用场景比较少。 2、对于复杂的文法比较难维护。 3、解释器模式会引起类膨胀。 4、解释器模式采用递归调用方法。</p><p>使用场景： 1、可以将一个需要解释执行的语言中的句子表示为一个抽象语法树。 2、一些重复出现的问题可以用一种简单的语言来进行表达。 3、一个简单语法需要解释的场景。</p><p>实现：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="interpreter_pattern_uml_diagram.jpg" class="lazyload" data-srcset="interpreter_pattern_uml_diagram.jpg" srcset="data:image/png;base64,666" alt="解释器模式的 UML 图"/></div><span class="image-caption">解释器模式的 UML 图</span></div><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">OrExpression</span> <span class="keyword">implements</span> <span class="title">Expression</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">   <span class="keyword">private</span> Expression expr1 = <span class="keyword">null</span>;</span><br><span class="line">   <span class="keyword">private</span> Expression expr2 = <span class="keyword">null</span>;</span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="title">OrExpression</span><span class="params">(Expression expr1, Expression expr2)</span> </span>&#123; </span><br><span class="line">      <span class="keyword">this</span>.expr1 = expr1;</span><br><span class="line">      <span class="keyword">this</span>.expr2 = expr2;</span><br><span class="line">   &#125;</span><br><span class="line"> </span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">interpret</span><span class="params">(String context)</span> </span>&#123;      </span><br><span class="line">      <span class="keyword">return</span> expr1.interpret(context) || expr2.interpret(context);</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="迭代器模式"><a href="#迭代器模式" class="headerlink" title="迭代器模式"></a>迭代器模式</h2><p>介绍：迭代器模式（Iterator Pattern）是 Java 和 .Net 编程环境中非常常用的设计模式。这种模式用于顺序访问集合对象的元素，不需要知道集合对象的底层表示。</p><p>优点： 1、它支持以不同的方式遍历一个聚合对象。 2、迭代器简化了聚合类。 3、在同一个聚合上可以有多个遍历。 4、在迭代器模式中，增加新的聚合类和迭代器类都很方便，无须修改原有代码。</p><p>缺点：由于迭代器模式将存储数据和遍历数据的职责分离，增加新的聚合类需要对应增加新的迭代器类，类的个数成对增加，这在一定程度上增加了系统的复杂性。</p><p>使用场景： 1、访问一个聚合对象的内容而无须暴露它的内部表示。 2、需要为聚合对象提供多种遍历方式。 3、为遍历不同的聚合结构提供一个统一的接口。</p><p>实现：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="iterator_pattern_uml_diagram.jpg" class="lazyload" data-srcset="iterator_pattern_uml_diagram.jpg" srcset="data:image/png;base64,666" alt="迭代器模式的 UML 图"/></div><span class="image-caption">迭代器模式的 UML 图</span></div><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">NameRepository</span> <span class="keyword">implements</span> <span class="title">Container</span> </span>&#123;</span><br><span class="line">   <span class="keyword">public</span> String names[] = &#123;<span class="string">&quot;Robert&quot;</span> , <span class="string">&quot;John&quot;</span> ,<span class="string">&quot;Julie&quot;</span> , <span class="string">&quot;Lora&quot;</span>&#125;;</span><br><span class="line"> </span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> Iterator <span class="title">getIterator</span><span class="params">()</span> </span>&#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">new</span> NameIterator();</span><br><span class="line">   &#125;</span><br><span class="line"> </span><br><span class="line">   <span class="keyword">private</span> <span class="class"><span class="keyword">class</span> <span class="title">NameIterator</span> <span class="keyword">implements</span> <span class="title">Iterator</span> </span>&#123;</span><br><span class="line"> </span><br><span class="line">      <span class="keyword">int</span> index;</span><br><span class="line"> </span><br><span class="line">      <span class="meta">@Override</span></span><br><span class="line">      <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">hasNext</span><span class="params">()</span> </span>&#123;</span><br><span class="line">         <span class="keyword">if</span>(index &lt; names.length)&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">         &#125;</span><br><span class="line">         <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">      &#125;</span><br><span class="line"> </span><br><span class="line">      <span class="meta">@Override</span></span><br><span class="line">      <span class="function"><span class="keyword">public</span> Object <span class="title">next</span><span class="params">()</span> </span>&#123;</span><br><span class="line">         <span class="keyword">if</span>(<span class="keyword">this</span>.hasNext())&#123;</span><br><span class="line">            <span class="keyword">return</span> names[index++];</span><br><span class="line">         &#125;</span><br><span class="line">         <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">      &#125;     </span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="中介者模式"><a href="#中介者模式" class="headerlink" title="中介者模式"></a>中介者模式</h2><p>介绍：中介者模式（Mediator Pattern）是用来降低多个对象和类之间的通信复杂性。这种模式提供了一个中介类，该类通常处理不同类之间的通信，并支持松耦合，使代码易于维护。</p><p>优点： 1、降低了类的复杂度，将一对多转化成了一对一。 2、各个类之间的解耦。 3、符合迪米特原则。</p><p>缺点：中介者会庞大，变得复杂难以维护。</p><p>使用场景： 1、系统中对象之间存在比较复杂的引用关系，导致它们之间的依赖关系结构混乱而且难以复用该对象。 2、想通过一个中间类来封装多个类中的行为，而又不想生成太多的子类。</p><p>实现：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="mediator_pattern_uml_diagram.jpg" class="lazyload" data-srcset="mediator_pattern_uml_diagram.jpg" srcset="data:image/png;base64,666" alt="中介者模式的 UML 图"/></div><span class="image-caption">中介者模式的 UML 图</span></div><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.Date;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ChatRoom</span> </span>&#123;</span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">showMessage</span><span class="params">(User user, String message)</span></span>&#123;</span><br><span class="line">      System.out.println(<span class="keyword">new</span> Date().toString()</span><br><span class="line">         + <span class="string">&quot; [&quot;</span> + user.getName() +<span class="string">&quot;] : &quot;</span> + message);</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="备忘录模式"><a href="#备忘录模式" class="headerlink" title="备忘录模式"></a>备忘录模式</h2><p>介绍：备忘录模式（Memento Pattern）保存一个对象的某个状态，以便在适当的时候恢复对象。</p><p>优点： 1、给用户提供了一种可以恢复状态的机制，可以使用户能够比较方便地回到某个历史的状态。 2、实现了信息的封装，使得用户不需要关心状态的保存细节。</p><p>缺点：消耗资源。如果类的成员变量过多，势必会占用比较大的资源，而且每一次保存都会消耗一定的内存。</p><p>使用场景： 1、需要保存/恢复数据的相关状态场景。 2、提供一个可回滚的操作。</p><p>实现：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="memento_pattern_uml_diagram.jpg" class="lazyload" data-srcset="memento_pattern_uml_diagram.jpg" srcset="data:image/png;base64,666" alt="备忘录模式的 UML 图"/></div><span class="image-caption">备忘录模式的 UML 图</span></div><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CareTaker</span> </span>&#123;</span><br><span class="line">   <span class="keyword">private</span> List&lt;Memento&gt; mementoList = <span class="keyword">new</span> ArrayList&lt;Memento&gt;();</span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">add</span><span class="params">(Memento state)</span></span>&#123;</span><br><span class="line">      mementoList.add(state);</span><br><span class="line">   &#125;</span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">public</span> Memento <span class="title">get</span><span class="params">(<span class="keyword">int</span> index)</span></span>&#123;</span><br><span class="line">      <span class="keyword">return</span> mementoList.get(index);</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="观察者模式"><a href="#观察者模式" class="headerlink" title="观察者模式"></a>观察者模式</h2><p>介绍：当对象间存在一对多关系时，则使用观察者模式（Observer Pattern）。比如，当一个对象被修改时，则会自动通知依赖它的对象。</p><p>优点： 1、观察者和被观察者是抽象耦合的。 2、建立一套触发机制。</p><p>缺点： 1、如果一个被观察者对象有很多的直接和间接的观察者的话，将所有的观察者都通知到会花费很多时间。 2、如果在观察者和观察目标之间有循环依赖的话，观察目标会触发它们之间进行循环调用，可能导致系统崩溃。 3、观察者模式没有相应的机制让观察者知道所观察的目标对象是怎么发生变化的，而仅仅只是知道观察目标发生了变化。</p><p>使用场景：</p><ul><li>一个抽象模型有两个方面，其中一个方面依赖于另一个方面。将这些方面封装在独立的对象中使它们可以各自独立地改变和复用。</li><li>一个对象的改变将导致其他一个或多个对象也发生改变，而不知道具体有多少对象将发生改变，可以降低对象之间的耦合度。</li><li>一个对象必须通知其他对象，而并不知道这些对象是谁。</li><li>需要在系统中创建一个触发链，A对象的行为将影响B对象，B对象的行为将影响C对象……，可以使用观察者模式创建一种链式触发机制。</li></ul><p>实现：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="observer_pattern_uml_diagram.jpg" class="lazyload" data-srcset="observer_pattern_uml_diagram.jpg" srcset="data:image/png;base64,666" alt="观察者模式的 UML 图"/></div><span class="image-caption">观察者模式的 UML 图</span></div><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Subject</span> </span>&#123;</span><br><span class="line">   </span><br><span class="line">   <span class="keyword">private</span> List&lt;Observer&gt; observers </span><br><span class="line">      = <span class="keyword">new</span> ArrayList&lt;Observer&gt;();</span><br><span class="line">   <span class="keyword">private</span> <span class="keyword">int</span> state;</span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getState</span><span class="params">()</span> </span>&#123;</span><br><span class="line">      <span class="keyword">return</span> state;</span><br><span class="line">   &#125;</span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setState</span><span class="params">(<span class="keyword">int</span> state)</span> </span>&#123;</span><br><span class="line">      <span class="keyword">this</span>.state = state;</span><br><span class="line">      notifyAllObservers();</span><br><span class="line">   &#125;</span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">attach</span><span class="params">(Observer observer)</span></span>&#123;</span><br><span class="line">      observers.add(observer);      </span><br><span class="line">   &#125;</span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">notifyAllObservers</span><span class="params">()</span></span>&#123;</span><br><span class="line">      <span class="keyword">for</span> (Observer observer : observers) &#123;</span><br><span class="line">         observer.update();</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="状态模式"><a href="#状态模式" class="headerlink" title="状态模式"></a>状态模式</h2><p>介绍：在状态模式（State Pattern）中，类的行为是基于它的状态改变的。在状态模式中，我们创建表示各种状态的对象和一个行为随着状态对象改变而改变的 context 对象。</p><p>优点： 1、封装了转换规则。 2、枚举可能的状态，在枚举状态之前需要确定状态种类。 3、将所有与某个状态有关的行为放到一个类中，并且可以方便地增加新的状态，只需要改变对象状态即可改变对象的行为。 4、允许状态转换逻辑与状态对象合成一体，而不是某一个巨大的条件语句块。 5、可以让多个环境对象共享一个状态对象，从而减少系统中对象的个数。</p><p>缺点： 1、状态模式的使用必然会增加系统类和对象的个数。 2、状态模式的结构与实现都较为复杂，如果使用不当将导致程序结构和代码的混乱。 3、状态模式对”开闭原则”的支持并不太好，对于可以切换状态的状态模式，增加新的状态类需要修改那些负责状态转换的源代码，否则无法切换到新增状态，而且修改某个状态类的行为也需修改对应类的源代码。</p><p>使用场景： 1、行为随状态改变而改变的场景。 2、条件、分支语句的代替者。</p><p>实现：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="state_pattern_uml_diagram.png" class="lazyload" data-srcset="state_pattern_uml_diagram.png" srcset="data:image/png;base64,666" alt="状态模式的 UML 图"/></div><span class="image-caption">状态模式的 UML 图</span></div><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">StopState</span> <span class="keyword">implements</span> <span class="title">State</span> </span>&#123;</span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">doAction</span><span class="params">(Context context)</span> </span>&#123;</span><br><span class="line">      System.out.println(<span class="string">&quot;Player is in stop state&quot;</span>);</span><br><span class="line">      context.setState(<span class="keyword">this</span>); </span><br><span class="line">   &#125;</span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span></span>&#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="string">&quot;Stop State&quot;</span>;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="空对象模式"><a href="#空对象模式" class="headerlink" title="空对象模式"></a>空对象模式</h2><p>介绍：在空对象模式（Null Object Pattern）中，一个空对象取代 NULL 对象实例的检查。Null 对象不是检查空值，而是反应一个不做任何动作的关系。这样的 Null 对象也可以在数据不可用的时候提供默认的行为。在空对象模式中，我们创建一个指定各种要执行的操作的抽象类和扩展该类的实体类，还创建一个未对该类做任何实现的空对象类，该空对象类将无缝地使用在需要检查空值的地方。</p><p>实现：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="null_pattern_uml_diagram.jpg" class="lazyload" data-srcset="null_pattern_uml_diagram.jpg" srcset="data:image/png;base64,666" alt="空对象模式的 UML 图"/></div><span class="image-caption">空对象模式的 UML 图</span></div><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">NullCustomer</span> <span class="keyword">extends</span> <span class="title">AbstractCustomer</span> </span>&#123;</span><br><span class="line"> </span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> String <span class="title">getName</span><span class="params">()</span> </span>&#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="string">&quot;Not Available in Customer Database&quot;</span>;</span><br><span class="line">   &#125;</span><br><span class="line"> </span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isNil</span><span class="params">()</span> </span>&#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="策略模式"><a href="#策略模式" class="headerlink" title="策略模式"></a>策略模式</h2><p>介绍：在策略模式（Strategy Pattern）中，一个类的行为或其算法可以在运行时更改。在策略模式中，我们创建表示各种策略的对象和一个行为随着策略对象改变而改变的 context 对象。策略对象改变 context 对象的执行算法。</p><p>优点： 1、算法可以自由切换。 2、避免使用多重条件判断。 3、扩展性良好。</p><p>缺点： 1、策略类会增多。 2、所有策略类都需要对外暴露。</p><p>使用场景： 1、如果在一个系统里面有许多类，它们之间的区别仅在于它们的行为，那么使用策略模式可以动态地让一个对象在许多行为中选择一种行为。 2、一个系统需要动态地在几种算法中选择一种。 3、如果一个对象有很多的行为，如果不用恰当的模式，这些行为就只好使用多重的条件选择语句来实现。</p><p>实现：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="strategy_pattern_uml_diagram.jpg" class="lazyload" data-srcset="strategy_pattern_uml_diagram.jpg" srcset="data:image/png;base64,666" alt="策略模式的 UML 图"/></div><span class="image-caption">策略模式的 UML 图</span></div><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Context</span> </span>&#123;</span><br><span class="line">   <span class="keyword">private</span> Strategy strategy;</span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="title">Context</span><span class="params">(Strategy strategy)</span></span>&#123;</span><br><span class="line">      <span class="keyword">this</span>.strategy = strategy;</span><br><span class="line">   &#125;</span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">executeStrategy</span><span class="params">(<span class="keyword">int</span> num1, <span class="keyword">int</span> num2)</span></span>&#123;</span><br><span class="line">      <span class="keyword">return</span> strategy.doOperation(num1, num2);</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="模板模式"><a href="#模板模式" class="headerlink" title="模板模式"></a>模板模式</h2><p>介绍：在模板模式（Template Pattern）中，一个抽象类公开定义了执行它的方法的方式/模板。它的子类可以按需要重写方法实现，但调用将以抽象类中定义的方式进行。</p><p>优点： 1、封装不变部分，扩展可变部分。 2、提取公共代码，便于维护。 3、行为由父类控制，子类实现。</p><p>缺点：每一个不同的实现都需要一个子类来实现，导致类的个数增加，使得系统更加庞大。</p><p>使用场景： 1、有多个子类共有的方法，且逻辑相同。 2、重要的、复杂的方法，可以考虑作为模板方法。</p><p>实现：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="template_pattern_uml_diagram.jpg" class="lazyload" data-srcset="template_pattern_uml_diagram.jpg" srcset="data:image/png;base64,666" alt="模板模式的 UML 图"/></div><span class="image-caption">模板模式的 UML 图</span></div><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">Game</span> </span>&#123;</span><br><span class="line">   <span class="function"><span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">initialize</span><span class="params">()</span></span>;</span><br><span class="line">   <span class="function"><span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">startPlay</span><span class="params">()</span></span>;</span><br><span class="line">   <span class="function"><span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">endPlay</span><span class="params">()</span></span>;</span><br><span class="line"> </span><br><span class="line">   <span class="comment">//模板</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">void</span> <span class="title">play</span><span class="params">()</span></span>&#123;</span><br><span class="line"> </span><br><span class="line">      <span class="comment">//初始化游戏</span></span><br><span class="line">      initialize();</span><br><span class="line"> </span><br><span class="line">      <span class="comment">//开始游戏</span></span><br><span class="line">      startPlay();</span><br><span class="line"> </span><br><span class="line">      <span class="comment">//结束游戏</span></span><br><span class="line">      endPlay();</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="访问者模式"><a href="#访问者模式" class="headerlink" title="访问者模式"></a>访问者模式</h2><p>介绍：在访问者模式（Visitor Pattern）中，我们使用了一个访问者类，它改变了元素类的执行算法。通过这种方式，元素的执行算法可以随着访问者改变而改变。这种类型的设计模式属于行为型模式。根据模式，元素对象已接受访问者对象，这样访问者对象就可以处理元素对象上的操作。</p><p>优点： 1、符合单一职责原则。 2、优秀的扩展性。 3、灵活性。</p><p>缺点： 1、具体元素对访问者公布细节，违反了迪米特原则。 2、具体元素变更比较困难。 3、违反了依赖倒置原则，依赖了具体类，没有依赖抽象。</p><p>使用场景： 1、对象结构中对象对应的类很少改变，但经常需要在此对象结构上定义新的操作。 2、需要对一个对象结构中的对象进行很多不同的并且不相关的操作，而需要避免让这些操作”污染”这些对象的类，也不希望在增加新操作时修改这些类。</p><p>实现：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="visitor_pattern_uml_diagram.jpg" class="lazyload" data-srcset="visitor_pattern_uml_diagram.jpg" srcset="data:image/png;base64,666" alt="访问者模式的 UML 图"/></div><span class="image-caption">访问者模式的 UML 图</span></div><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Mouse</span>  <span class="keyword">implements</span> <span class="title">ComputerPart</span> </span>&#123;</span><br><span class="line"> </span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">accept</span><span class="params">(ComputerPartVisitor computerPartVisitor)</span> </span>&#123;</span><br><span class="line">      computerPartVisitor.visit(<span class="keyword">this</span>);</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="MVC模式"><a href="#MVC模式" class="headerlink" title="MVC模式"></a>MVC模式</h2><p>介绍：MVC 模式代表 Model-View-Controller（模型-视图-控制器） 模式。这种模式用于应用程序的分层开发。</p><ul><li>Model（模型） - 模型代表一个存取数据的对象或 JAVA POJO。它也可以带有逻辑，在数据变化时更新控制器。</li><li>View（视图） - 视图代表模型包含的数据的可视化。</li><li>Controller（控制器） - 控制器作用于模型和视图上。它控制数据流向模型对象，并在数据变化时更新视图。它使视图与模型分离开。</li></ul><p>实现：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="mvc-2.svg" class="lazyload" data-srcset="mvc-2.svg" srcset="data:image/png;base64,666" alt="MVC 模式的 UML 图"/></div><span class="image-caption">MVC 模式的 UML 图</span></div><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">StudentController</span> </span>&#123;</span><br><span class="line">   <span class="keyword">private</span> Student model;</span><br><span class="line">   <span class="keyword">private</span> StudentView view;</span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="title">StudentController</span><span class="params">(Student model, StudentView view)</span></span>&#123;</span><br><span class="line">      <span class="keyword">this</span>.model = model;</span><br><span class="line">      <span class="keyword">this</span>.view = view;</span><br><span class="line">   &#125;</span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setStudentName</span><span class="params">(String name)</span></span>&#123;</span><br><span class="line">      model.setName(name);    </span><br><span class="line">   &#125;</span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">public</span> String <span class="title">getStudentName</span><span class="params">()</span></span>&#123;</span><br><span class="line">      <span class="keyword">return</span> model.getName();    </span><br><span class="line">   &#125;</span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setStudentRollNo</span><span class="params">(String rollNo)</span></span>&#123;</span><br><span class="line">      model.setRollNo(rollNo);      </span><br><span class="line">   &#125;</span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">public</span> String <span class="title">getStudentRollNo</span><span class="params">()</span></span>&#123;</span><br><span class="line">      <span class="keyword">return</span> model.getRollNo();     </span><br><span class="line">   &#125;</span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">updateView</span><span class="params">()</span></span>&#123;           </span><br><span class="line">      view.printStudentDetails(model.getName(), model.getRollNo());</span><br><span class="line">   &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="业务代表模式"><a href="#业务代表模式" class="headerlink" title="业务代表模式"></a>业务代表模式</h2><p>介绍：业务代表模式（Business Delegate Pattern）用于对表示层和业务层解耦。它基本上是用来减少通信或对表示层代码中的业务层代码的远程查询功能。在业务层中我们有以下实体。</p><ul><li>客户端（Client） - 表示层代码可以是 JSP、servlet 或 UI java 代码。</li><li>业务代表（Business Delegate） - 一个为客户端实体提供的入口类，它提供了对业务服务方法的访问。</li><li>查询服务（LookUp Service） - 查找服务对象负责获取相关的业务实现，并提供业务对象对业务代表对象的访问。</li><li>业务服务（Business Service） - 业务服务接口。实现了该业务服务的实体类，提供了实际的业务实现逻辑。</li></ul><p>实现：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="business.svg" class="lazyload" data-srcset="business.svg" srcset="data:image/png;base64,666" alt="业务代表模式的 UML 图"/></div><span class="image-caption">业务代表模式的 UML 图</span></div><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BusinessDelegate</span> </span>&#123;</span><br><span class="line">   <span class="keyword">private</span> BusinessLookUp lookupService = <span class="keyword">new</span> BusinessLookUp();</span><br><span class="line">   <span class="keyword">private</span> BusinessService businessService;</span><br><span class="line">   <span class="keyword">private</span> String serviceType;</span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setServiceType</span><span class="params">(String serviceType)</span></span>&#123;</span><br><span class="line">      <span class="keyword">this</span>.serviceType = serviceType;</span><br><span class="line">   &#125;</span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">doTask</span><span class="params">()</span></span>&#123;</span><br><span class="line">      businessService = lookupService.getBusinessService(serviceType);</span><br><span class="line">      businessService.doProcessing();     </span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="组合实体模式"><a href="#组合实体模式" class="headerlink" title="组合实体模式"></a>组合实体模式</h2><p>介绍：组合实体模式（Composite Entity Pattern）用在 EJB 持久化机制中。一个组合实体是一个 EJB 实体 bean，代表了对象的图解。当更新一个组合实体时，内部依赖对象 beans 会自动更新，因为它们是由 EJB 实体 bean 管理的。以下是组合实体 bean 的参与者。</p><ul><li>组合实体（Composite Entity） - 它是主要的实体 bean。它可以是粗粒的，或者可以包含一个粗粒度对象，用于持续生命周期。</li><li>粗粒度对象（Coarse-Grained Object） - 该对象包含依赖对象。它有自己的生命周期，也能管理依赖对象的生命周期。</li><li>依赖对象（Dependent Object） - 依赖对象是一个持续生命周期依赖于粗粒度对象的对象。</li><li>策略（Strategies） - 策略表示如何实现组合实体。</li></ul><p>实现：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="compositeentity_pattern_uml_diagram.jpg" class="lazyload" data-srcset="compositeentity_pattern_uml_diagram.jpg" srcset="data:image/png;base64,666" alt="组合实体模式的 UML 图"/></div><span class="image-caption">组合实体模式的 UML 图</span></div><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CompositeEntity</span> </span>&#123;</span><br><span class="line">   <span class="keyword">private</span> CoarseGrainedObject cgo = <span class="keyword">new</span> CoarseGrainedObject();</span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setData</span><span class="params">(String data1, String data2)</span></span>&#123;</span><br><span class="line">      cgo.setData(data1, data2);</span><br><span class="line">   &#125;</span><br><span class="line"> </span><br><span class="line">   <span class="keyword">public</span> String[] getData()&#123;</span><br><span class="line">      <span class="keyword">return</span> cgo.getData();</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="数据访问对象模式"><a href="#数据访问对象模式" class="headerlink" title="数据访问对象模式"></a>数据访问对象模式</h2><p>介绍：数据访问对象模式（Data Access Object Pattern）或 DAO 模式用于把低级的数据访问 API 或操作从高级的业务服务中分离出来。以下是数据访问对象模式的参与者。</p><ul><li>数据访问对象接口（Data Access Object Interface） - 该接口定义了在一个模型对象上要执行的标准操作。</li><li>数据访问对象实体类（Data Access Object concrete class） - 该类实现了上述的接口。该类负责从数据源获取数据，数据源可以是数据库，也可以是 xml，或者是其他的存储机制。</li><li>模型对象/数值对象（Model Object/Value Object） - 该对象是简单的 POJO，包含了 get/set 方法来存储通过使用 DAO 类检索到的数据。</li></ul><p>实现：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="dao_pattern_uml_diagram.jpg" class="lazyload" data-srcset="dao_pattern_uml_diagram.jpg" srcset="data:image/png;base64,666" alt="数据访问对象模式的 UML 图"/></div><span class="image-caption">数据访问对象模式的 UML 图</span></div><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">StudentDaoImpl</span> <span class="keyword">implements</span> <span class="title">StudentDao</span> </span>&#123;</span><br><span class="line">   </span><br><span class="line">   <span class="comment">//列表是当作一个数据库</span></span><br><span class="line">   List&lt;Student&gt; students;</span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="title">StudentDaoImpl</span><span class="params">()</span></span>&#123;</span><br><span class="line">      students = <span class="keyword">new</span> ArrayList&lt;Student&gt;();</span><br><span class="line">      Student student1 = <span class="keyword">new</span> Student(<span class="string">&quot;Robert&quot;</span>,<span class="number">0</span>);</span><br><span class="line">      Student student2 = <span class="keyword">new</span> Student(<span class="string">&quot;John&quot;</span>,<span class="number">1</span>);</span><br><span class="line">      students.add(student1);</span><br><span class="line">      students.add(student2);    </span><br><span class="line">   &#125;</span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">deleteStudent</span><span class="params">(Student student)</span> </span>&#123;</span><br><span class="line">      students.remove(student.getRollNo());</span><br><span class="line">      System.out.println(<span class="string">&quot;Student: Roll No &quot;</span> + student.getRollNo() </span><br><span class="line">         +<span class="string">&quot;, deleted from database&quot;</span>);</span><br><span class="line">   &#125;</span><br><span class="line"> </span><br><span class="line">   <span class="comment">//从数据库中检索学生名单</span></span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> List&lt;Student&gt; <span class="title">getAllStudents</span><span class="params">()</span> </span>&#123;</span><br><span class="line">      <span class="keyword">return</span> students;</span><br><span class="line">   &#125;</span><br><span class="line"> </span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> Student <span class="title">getStudent</span><span class="params">(<span class="keyword">int</span> rollNo)</span> </span>&#123;</span><br><span class="line">      <span class="keyword">return</span> students.get(rollNo);</span><br><span class="line">   &#125;</span><br><span class="line"> </span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">updateStudent</span><span class="params">(Student student)</span> </span>&#123;</span><br><span class="line">      students.get(student.getRollNo()).setName(student.getName());</span><br><span class="line">      System.out.println(<span class="string">&quot;Student: Roll No &quot;</span> + student.getRollNo() </span><br><span class="line">         +<span class="string">&quot;, updated in the database&quot;</span>);</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="前端控制器模式"><a href="#前端控制器模式" class="headerlink" title="前端控制器模式"></a>前端控制器模式</h2><p>介绍：前端控制器模式（Front Controller Pattern）是用来提供一个集中的请求处理机制，所有的请求都将由一个单一的处理程序处理。该处理程序可以做认证/授权/记录日志，或者跟踪请求，然后把请求传给相应的处理程序。以下是这种设计模式的实体。</p><ul><li>前端控制器（Front Controller） - 处理应用程序所有类型请求的单个处理程序，应用程序可以是基于 web 的应用程序，也可以是基于桌面的应用程序。</li><li>调度器（Dispatcher） - 前端控制器可能使用一个调度器对象来调度请求到相应的具体处理程序。</li><li>视图（View） - 视图是为请求而创建的对象。</li></ul><p>实现：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="frontcontroller_pattern_uml_diagram.jpg" class="lazyload" data-srcset="frontcontroller_pattern_uml_diagram.jpg" srcset="data:image/png;base64,666" alt="前端控制器模式的 UML 图"/></div><span class="image-caption">前端控制器模式的 UML 图</span></div><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FrontController</span> </span>&#123;</span><br><span class="line">   </span><br><span class="line">   <span class="keyword">private</span> Dispatcher dispatcher;</span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="title">FrontController</span><span class="params">()</span></span>&#123;</span><br><span class="line">      dispatcher = <span class="keyword">new</span> Dispatcher();</span><br><span class="line">   &#125;</span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">isAuthenticUser</span><span class="params">()</span></span>&#123;</span><br><span class="line">      System.out.println(<span class="string">&quot;User is authenticated successfully.&quot;</span>);</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">   &#125;</span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">trackRequest</span><span class="params">(String request)</span></span>&#123;</span><br><span class="line">      System.out.println(<span class="string">&quot;Page requested: &quot;</span> + request);</span><br><span class="line">   &#125;</span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">dispatchRequest</span><span class="params">(String request)</span></span>&#123;</span><br><span class="line">      <span class="comment">//记录每一个请求</span></span><br><span class="line">      trackRequest(request);</span><br><span class="line">      <span class="comment">//对用户进行身份验证</span></span><br><span class="line">      <span class="keyword">if</span>(isAuthenticUser())&#123;</span><br><span class="line">         dispatcher.dispatch(request);</span><br><span class="line">      &#125;  </span><br><span class="line">   &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="拦截过滤器模式"><a href="#拦截过滤器模式" class="headerlink" title="拦截过滤器模式"></a>拦截过滤器模式</h2><p>介绍：拦截过滤器模式（Intercepting Filter Pattern）用于对应用程序的请求或响应做一些预处理/后处理。定义过滤器，并在把请求传给实际目标应用程序之前应用在请求上。过滤器可以做认证/授权/记录日志，或者跟踪请求，然后把请求传给相应的处理程序。以下是这种设计模式的实体。</p><ul><li>过滤器（Filter） - 过滤器在请求处理程序执行请求之前或之后，执行某些任务。</li><li>过滤器链（Filter Chain） - 过滤器链带有多个过滤器，并在 Target 上按照定义的顺序执行这些过滤器。</li><li>Target - Target 对象是请求处理程序。</li><li>过滤管理器（Filter Manager） - 过滤管理器管理过滤器和过滤器链。</li><li>客户端（Client） - Client 是向 Target 对象发送请求的对象。</li></ul><p>实现：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="20201015-intercepting.svg" class="lazyload" data-srcset="20201015-intercepting.svg" srcset="data:image/png;base64,666" alt="拦截过滤器模式的 UML 图"/></div><span class="image-caption">拦截过滤器模式的 UML 图</span></div><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FilterManager</span> </span>&#123;</span><br><span class="line">   FilterChain filterChain;</span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="title">FilterManager</span><span class="params">(Target target)</span></span>&#123;</span><br><span class="line">      filterChain = <span class="keyword">new</span> FilterChain();</span><br><span class="line">      filterChain.setTarget(target);</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setFilter</span><span class="params">(Filter filter)</span></span>&#123;</span><br><span class="line">      filterChain.addFilter(filter);</span><br><span class="line">   &#125;</span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">filterRequest</span><span class="params">(String request)</span></span>&#123;</span><br><span class="line">      filterChain.execute(request);</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="服务定位器模式"><a href="#服务定位器模式" class="headerlink" title="服务定位器模式"></a>服务定位器模式</h2><p>介绍：服务定位器模式（Service Locator Pattern）用在我们想使用 JNDI 查询定位各种服务的时候。考虑到为某个服务查找 JNDI 的代价很高，服务定位器模式充分利用了缓存技术。在首次请求某个服务时，服务定位器在 JNDI 中查找服务，并缓存该服务对象。当再次请求相同的服务时，服务定位器会在它的缓存中查找，这样可以在很大程度上提高应用程序的性能。以下是这种设计模式的实体。</p><ul><li>服务（Service） - 实际处理请求的服务。对这种服务的引用可以在 JNDI 服务器中查找到。</li><li>Context / 初始的 Context - JNDI Context 带有对要查找的服务的引用。</li><li>服务定位器（Service Locator） - 服务定位器是通过 JNDI 查找和缓存服务来获取服务的单点接触。</li><li>缓存（Cache） - 缓存存储服务的引用，以便复用它们。</li><li>客户端（Client） - Client 是通过 ServiceLocator 调用服务的对象。</li></ul><p>实现：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="20201015-service-locator.svg" class="lazyload" data-srcset="20201015-service-locator.svg" srcset="data:image/png;base64,666" alt="服务定位器模式的 UML 图"/></div><span class="image-caption">服务定位器模式的 UML 图</span></div><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Cache</span> </span>&#123;</span><br><span class="line"> </span><br><span class="line">   <span class="keyword">private</span> List&lt;Service&gt; services;</span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="title">Cache</span><span class="params">()</span></span>&#123;</span><br><span class="line">      services = <span class="keyword">new</span> ArrayList&lt;Service&gt;();</span><br><span class="line">   &#125;</span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">public</span> Service <span class="title">getService</span><span class="params">(String serviceName)</span></span>&#123;</span><br><span class="line">      <span class="keyword">for</span> (Service service : services) &#123;</span><br><span class="line">         <span class="keyword">if</span>(service.getName().equalsIgnoreCase(serviceName))&#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;Returning cached  &quot;</span>+serviceName+<span class="string">&quot; object&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span> service;</span><br><span class="line">         &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">   &#125;</span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">addService</span><span class="params">(Service newService)</span></span>&#123;</span><br><span class="line">      <span class="keyword">boolean</span> exists = <span class="keyword">false</span>;</span><br><span class="line">      <span class="keyword">for</span> (Service service : services) &#123;</span><br><span class="line">         <span class="keyword">if</span>(service.getName().equalsIgnoreCase(newService.getName()))&#123;</span><br><span class="line">            exists = <span class="keyword">true</span>;</span><br><span class="line">         &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span>(!exists)&#123;</span><br><span class="line">         services.add(newService);</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ServiceLocator</span> </span>&#123;</span><br><span class="line">   <span class="keyword">private</span> <span class="keyword">static</span> Cache cache;</span><br><span class="line"> </span><br><span class="line">   <span class="keyword">static</span> &#123;</span><br><span class="line">      cache = <span class="keyword">new</span> Cache();    </span><br><span class="line">   &#125;</span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Service <span class="title">getService</span><span class="params">(String jndiName)</span></span>&#123;</span><br><span class="line"> </span><br><span class="line">      Service service = cache.getService(jndiName);</span><br><span class="line"> </span><br><span class="line">      <span class="keyword">if</span>(service != <span class="keyword">null</span>)&#123;</span><br><span class="line">         <span class="keyword">return</span> service;</span><br><span class="line">      &#125;</span><br><span class="line"> </span><br><span class="line">      InitialContext context = <span class="keyword">new</span> InitialContext();</span><br><span class="line">      Service service1 = (Service)context.lookup(jndiName);</span><br><span class="line">      cache.addService(service1);</span><br><span class="line">      <span class="keyword">return</span> service1;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="传输对象模式"><a href="#传输对象模式" class="headerlink" title="传输对象模式"></a>传输对象模式</h2><p>介绍：传输对象模式（Transfer Object Pattern）用于从客户端向服务器一次性传递带有多个属性的数据。传输对象也被称为数值对象。传输对象是一个具有 getter/setter 方法的简单的 POJO 类，它是可序列化的，所以它可以通过网络传输。它没有任何的行为。服务器端的业务类通常从数据库读取数据，然后填充 POJO，并把它发送到客户端或按值传递它。对于客户端，传输对象是只读的。客户端可以创建自己的传输对象，并把它传递给服务器，以便一次性更新数据库中的数值。以下是这种设计模式的实体。</p><ul><li>业务对象（Business Object） - 为传输对象填充数据的业务服务。</li><li>传输对象（Transfer Object） - 简单的 POJO，只有设置/获取属性的方法。</li><li>客户端（Client） - 客户端可以发送请求或者发送传输对象到业务对象。</li></ul><p>实现：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="20201015-transfer.svg" class="lazyload" data-srcset="20201015-transfer.svg" srcset="data:image/png;base64,666" alt="传输对象模式的 UML 图"/></div><span class="image-caption">传输对象模式的 UML 图</span></div><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">StudentBO</span> </span>&#123;</span><br><span class="line">   </span><br><span class="line">   <span class="comment">//列表是当作一个数据库</span></span><br><span class="line">   List&lt;StudentVO&gt; students;</span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="title">StudentBO</span><span class="params">()</span></span>&#123;</span><br><span class="line">      students = <span class="keyword">new</span> ArrayList&lt;StudentVO&gt;();</span><br><span class="line">      StudentVO student1 = <span class="keyword">new</span> StudentVO(<span class="string">&quot;Robert&quot;</span>,<span class="number">0</span>);</span><br><span class="line">      StudentVO student2 = <span class="keyword">new</span> StudentVO(<span class="string">&quot;John&quot;</span>,<span class="number">1</span>);</span><br><span class="line">      students.add(student1);</span><br><span class="line">      students.add(student2);    </span><br><span class="line">   &#125;</span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">deleteStudent</span><span class="params">(StudentVO student)</span> </span>&#123;</span><br><span class="line">      students.remove(student.getRollNo());</span><br><span class="line">      System.out.println(<span class="string">&quot;Student: Roll No &quot;</span> </span><br><span class="line">      + student.getRollNo() +<span class="string">&quot;, deleted from database&quot;</span>);</span><br><span class="line">   &#125;</span><br><span class="line"> </span><br><span class="line">   <span class="comment">//从数据库中检索学生名单</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> List&lt;StudentVO&gt; <span class="title">getAllStudents</span><span class="params">()</span> </span>&#123;</span><br><span class="line">      <span class="keyword">return</span> students;</span><br><span class="line">   &#125;</span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">public</span> StudentVO <span class="title">getStudent</span><span class="params">(<span class="keyword">int</span> rollNo)</span> </span>&#123;</span><br><span class="line">      <span class="keyword">return</span> students.get(rollNo);</span><br><span class="line">   &#125;</span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">updateStudent</span><span class="params">(StudentVO student)</span> </span>&#123;</span><br><span class="line">      students.get(student.getRollNo()).setName(student.getName());</span><br><span class="line">      System.out.println(<span class="string">&quot;Student: Roll No &quot;</span> </span><br><span class="line">      + student.getRollNo() +<span class="string">&quot;, updated in the database&quot;</span>);</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> 设计模式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OnJava8笔记</title>
      <link href="2020/10/25/OnJava8%E7%AC%94%E8%AE%B0/"/>
      <url>2020/10/25/OnJava8%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<p>本文主要整理了 OnJava8 的阅读笔记。</p><a id="more"></a><h2 id="第三章-万物皆对象"><a href="#第三章-万物皆对象" class="headerlink" title="第三章 万物皆对象"></a>第三章 万物皆对象</h2><p>对象操纵：在 Java 中程序员实际操作的是对象的引用，方法参数中传递的也只是对象的引用。</p><p>对象创建：new。</p><ul><li><p>数据存储：</p><ul><li>寄存器：Java 中不存在该方式。</li><li>栈内存：存放一些 Java 数据，比如对象的引用。</li><li>堆内存：Java 对象都存于其中。</li><li>常量内存：程序代码中，不会改变。</li><li>非 RAM 存储：序列化对象（用于传送）和持久化对象（用于恢复）。</li></ul></li><li><p>基本类型的存储：不是通过 new 创建，变量直接存储值。有 boolean，byte，short，char，int，float，long，double，void。boolean 类型的大小没有明确规定。</p></li><li><p>高精度数值：BigInteger 和 BigDecimal。</p></li><li><p>数组的存储：当创建对象数组的时候，实际上是对象引用的数组，初始化为 null。</p></li></ul><p>代码注释：<code>/* ... */</code> 和 <code>//</code>。</p><p>对象清理：</p><ul><li>作用域：<code>&#123;&#125;</code> 决定，不允许父作用域和子作用域声明相同的变量。</li><li>对象作用域：使用 new 关键字创建的 Java 对象生命周期超出作用域。</li></ul><p>类的创建：</p><ul><li>类型：class</li><li>字段：类里面声明的变量</li><li>方法：类里面定义的函数</li><li>基本类型的默认值：全 0，但是不适用与局部变量。</li><li>方法签名：方法名和参数列表统称为方法签名。</li></ul><p>程序编写：</p><ul><li>命名可见性：反向使用自己的网络域名，但是存在空文件夹</li><li>使用其他组件：import</li><li>static 关键字：类变量和类方法声明，在没有对象时候也可以进行调用，另外类变量在所有的对象中共享</li></ul><h2 id="第四章-运算符"><a href="#第四章-运算符" class="headerlink" title="第四章 运算符"></a>第四章 运算符</h2><p>赋值：<code>=</code>，基本类型的赋值都是直接的，而不像对象，赋予的只是其内存的引用。在方法的参数中传递一个对象，在方法体里面对其进行修改，那么在该对象在外部也会被修改。</p><p>算术运算符：<code>+，-，*，/，%</code>，其中<code>+, -</code>可以作为一元运算符。</p><p>递增和递减：<code>++,--</code>。前缀递增和递减立即修改变量的值，后缀则是使用变量的值，然后再修改。</p><p>关系运算符：<code>&gt;, &gt;=, &lt;, &lt;=, ==, !=</code>。判断基本对象的时候使用<code>==</code>，判断对象的使用 equals 方法，判断对象时使用 <code>==</code> 比较的只是引用。</p><p>逻辑运算符：<code>&amp;&amp;, OR, !</code>。Java 支持短路。</p><p>字面量常量：<code>0x, 0, 0b, L, F, L</code>, F 可以默认不写。</p><p>下划线：用于分割数字字面量。</p><p>指数计数法：<code>e</code>。</p><p>位运算符：<code>&amp;, |, ^, ~</code>。</p><p>移位运算符：<code>&lt;&lt;, &gt;&gt;, &gt;&gt;&gt;</code>。注意 <code>&gt;&gt;</code> 是算术右移，<code>&gt;&gt;&gt;</code> 是逻辑右移（首位添0）。</p><p>三目运算符：<code>&lt;boolean condition&gt; ? &lt;value1&gt; : &lt;value2&gt;</code>。</p><p>字符串运算符：<code>+</code>。</p><p>类型转换：向上转换是安全的，向下转换需要显式说明<code>(type)</code>。对于浮点数向整数转换，小数总是被截断。</p><p>Java 没有 sizeof 运算符，因为每种类型的值都是固定的。</p><h2 id="第五章-控制流"><a href="#第五章-控制流" class="headerlink" title="第五章 控制流"></a>第五章 控制流</h2><p>true 和 false：所有关系运算符都能产生条件语句，注意在 Java 中使用数值作为布尔值是非法的。</p><p>条件控制：<code>if-else</code>。</p><p>迭代语句：<code>while</code>，<code>do-while</code>，<code>for</code>，<code>for-in</code>。</p><p>return：退出当前的方法，放回一个方法值。</p><p>break 和 continue：break 用于中止内层循环，continue 用于跳过此次迭代。</p><p>goto：Java 不支持 <code>goto</code> 语句，但是支持标签语法，可以和 break 和 continue 一起使用。</p><p>switch-case：每个 case 后面跟上 break，同时在 Java7 的时候开始支持字符串匹配。</p><h2 id="第六章-初始化和清理"><a href="#第六章-初始化和清理" class="headerlink" title="第六章 初始化和清理"></a>第六章 初始化和清理</h2><p>使用构造器保证初始化：构造器名称和类名相同，每次创建一个对象的时候，自动调用构造器进行初始化。构造器并没有返回值。</p><p>方法重载：每个被重载的方法需要具有一个独一无二的参数列表。返回值并不能用来区分重载的方法。</p><p>无参构造器：一个无参构造器就是不接受参数的构造器，如果没有显式提供任何构造器，那么编译器会自动提供一个无参构造器。</p><p>this：this 关键字只能在非静态的方法内部使用，等同于当前方法所属的对象引用。</p><p>在构造器中调用构造器：通过 <code>this(param list)</code> 实现。注意只能通过 this 调用一次构造器，不可重复多次调用构造器。并且，只能在构造器首行进行调用。</p><p>static 的含义：static 修饰的方法中不存在 this。静态方法和静态变量是为了类而创建的。</p><p>垃圾回收器：在 Java 中，对象并非总是被垃圾回收：</p><ol><li>对象可能不被垃圾回收。</li><li>垃圾回收不等同于析构。</li><li>垃圾回收只和内存有关。</li></ol><p>在 Java 中，虽然提供了一个 <code>finialize()</code> 的方法用于清理对象，但是事实上我们并不需要过多使用该方法。记住，无论是”垃圾回收”还是”终结”，都不保证一定会发生。如果 Java 虚拟机（JVM）并未面临内存耗尽的情形，它可能不会浪费时间执行垃圾回收以恢复内存。</p><p>垃圾回收器如何工作：</p><ul><li>引用计数：每个对象有一个引用计数器，每次有引用指向该对象的时候，引用计数加 1.当引用离开作用域或者被置为 null 的时候，引用计数减一。垃圾回收器会遍历含有全部对象的列表，当发现某个对象的引用计数为 0 时，就释放其占用的空间（但是，引用计数模式经常会在计数为 0 时立即释放对象）。这个机制存在一个缺点：如果对象之间存在<strong>循环引用</strong>，那么它们的引用计数都不为 0，就会出现应该被回收但无法被回收的情况。</li><li>自适应的垃圾回收技术：对于任意“活”的对象，总是可以追溯到其存活在栈或者静态区的引用，从栈或者静态存储区出发，将会发现所有的活的对象。至于如何处理找到的存活对象，取决于不同的 Java 虚拟机实现。其中有一种做法叫做停止-复制（stop-and-copy）。顾名思义，这需要先暂停程序的运行（不属于后台回收模式），然后将所有存活的对象从当前堆复制到另一个堆，没有复制的就是需要被垃圾回收的。另外，当对象被复制到新堆时，它们是一个挨着一个紧凑排列，然后就可以按照前面描述的那样简单、直接地分配新空间了。上述方法存在缺点：需要两个堆，然后再两个堆之间折腾，得维护比实际空间多一倍的空间；另外在于复制本身，一旦程序进入稳定状态之后，可能只会产生少量垃圾，甚至没有垃圾。尽管如此，复制回收器仍然会将所有内存从一处复制到另一处，这很浪费。为了避免这种状况，一些 Java 虚拟机会进行检查：要是没有新垃圾产生，就会转换到另一种模式（即”自适应”）。这种模式称为标记-清扫（mark-and-sweep）。对一般用途而言，”标记-清扫”方式速度相当慢，但是当你知道程序只会产生少量垃圾甚至不产生垃圾时，它的速度就很快了。”标记-清扫”所依据的思路仍然是从栈和静态存储区出发，遍历所有的引用，找出所有存活的对象。但是，每当找到一个存活对象，就给对象设一个标记，并不回收它。只有当标记过程完成后，清理动作才开始。在清理过程中，没有标记的对象将被释放，不会发生任何复制动作。”标记-清扫”后剩下的堆空间是不连续的，垃圾回收器要是希望得到连续空间的话，就需要重新整理剩下的对象。</li></ul><p>成员初始化：在方法中的变量没有默认值，需要手动指定一个值之后才能使用；在类中的变量则会赋予默认值。</p><p>初始化的顺序：假设有个名为 <strong>Dog</strong> 的类：</p><ol><li>即使没有显式地使用 <strong>static</strong> 关键字，构造器实际上也是静态方法。所以，当首次创建 <strong>Dog</strong> 类型的对象或是首次访问 <strong>Dog</strong> 类的静态方法或属性时，Java 解释器必须在类路径中查找，以定位 <strong>Dog.class</strong>。</li><li>当加载完 <strong>Dog.class</strong> 后（后面会学到，这将创建一个 <strong>Class</strong> 对象），有关静态初始化的所有动作都会执行。因此，静态初始化只会在首次加载 <strong>Class</strong> 对象时初始化一次。</li><li>当用 <code>new Dog()</code> 创建对象时，首先会在堆上为 <strong>Dog</strong> 对象分配足够的存储空间。</li><li>分配的存储空间首先会被清零，即会将 <strong>Dog</strong> 对象中的所有基本类型数据设置为默认值（数字会被置为 0，布尔型和字符型也相同），引用被置为 <strong>null</strong>。</li><li>执行所有出现在字段定义处的初始化动作。</li><li>执行构造器。你将会在”复用”这一章看到，这可能会牵涉到很多动作，尤其当涉及继承的时候。</li></ol><p>显式的静态初始化：<code>static &#123; statements； &#125;</code>，与其他静态初始化动作一样，这段代码仅执行一次：当首次创建这个类的对象或首次访问这个类的静态成员（甚至不需要创建该类的对象）时。</p><p>实例初始化：<code>&#123; statements; &#125;</code>，实例初始化子句是在两个构造器之前执行的。</p><p>数组初始化：<code>Type[] arg = new Type[length]</code>，<code>Type[] arg = &#123;value1, value2,,,&#125;</code></p><p>可变参数列表：<code>void method(int t, char... args)</code></p><p>枚举类型：<code>enum Type &#123;&#125;</code></p><h2 id="第七章-封装"><a href="#第七章-封装" class="headerlink" title="第七章 封装"></a>第七章 封装</h2><p>包的概念：包内包含有一组类，它们被组织在一个单独的命名空间下。对于单文件的程序，该文件在默认包（default package）下。另外，每个 Java 源文件只能有一个 public 类。</p><p>代码组织：为了将功能相近的 Java 源文件组织到一起，可以使用关键字 package。该关键字必须是文件中除了注释的第一行代码。当需要使用到某个包中的类时，可以使用 import 关键字。</p><p>独一无二的包名：通常选择反转的域名。</p><p>冲突：当两个包下面含有相同的类时，就会出现名称冲突的问题，可以将特定的类写全名称，比如<code>java.util.ArrayList</code>。</p><p>使用包的注意事项：当创建一个包的时候，包名实际上就隐含了目录结构。</p><p>访问权限修饰符：Java 访问权限控制符 public，protected，private 位于定义的类名，属性名和方法名前。</p><p>public：当使用 public 关键字的时候，意味着 public 后声明的成员对于每个人都是可用的。</p><p>默认包：指不加修饰符定义的成员，可以被相同包下的文件访问。</p><p>private：除了包含成员的类，其他任何类都无法访问这个成员。</p><p>protected：继承的类可以访问父类中对应的成员，同时也提供了包访问权限。</p><p>类访问权限：类既不能是 private，也不能是 protected 的，只能使用 public 或者 是包访问权限。</p><h2 id="第八章-复用"><a href="#第八章-复用" class="headerlink" title="第八章 复用"></a>第八章 复用</h2><p>复用方式：</p><ul><li>组合：在新类里面创建现有类的对象</li><li>继承：创建现有类型的子类</li><li>委托：介于继承和组合之间，将一个成员对象放在正在构建的类中，但同时又在新的类中公开来自成员对象的所有方法（Java 中不直接支持）</li></ul><p>组合语法：将对象的引用放在一个新的类里面，就算是使用了组合。</p><p>继承语法：使用 extends 关键字。继承后，可以在方法里面使用 super 关键字来使用父类的方法。</p><p>子类的初始化：当某个派生类被实例化的时候，会递归向上调用父类的构造器，最高层级的父类的构造器首先被执行，然后是最高层级下的子类，，，一直到该派生类构造器。</p><p>带参数的构造器：当没有有参数的基类构造器，只含有有参数的基类构造器，此时就需要通过 super 手动调用基类的构造器。</p><p>组合和继承的选择：当想要在新类中包含一个已有类的功能时，使用组合，而非继承；当使用继承时，使用一个现有类并开发出它的新版本，通常这意味着使用一个通用类，并为了某个特殊需求将其特殊化。组合用来表达“有一个”的关系，而继承则是“是一个”关系。</p><p>向上转型：派生类到基类的转型称之为向上转型，向上转型是安全的，因为子类必定包含了所有父类的方法。</p><p>final 关键字：final 修饰的数据通常指该数据不能被改变：</p><ul><li>final 数据：对于基本类型，final 使得数值恒定不变，对于对象引用，final 则是使得引用恒定不变。空白 final 是指没有初始化值的 final 属性，编译器保证在使用空白 final 之前必须被初始化，此时必须在构造器中对 final 变量进行赋值。</li><li>final 参数：在参数列表中，将参数声明为 final 意味着在方法中不能改变参数指向的对象或基本变量。</li><li>final 方法：给方法上锁，防止子类通过覆写改变方法的行为。类中所有的 private 方法都隐式地指定为 final。</li><li>final 类：当说一个类是 final ，就意味着它不能被继承。</li></ul><p>类初始化和加载：在 Java 中，每个类的编译代码都存在于它自己独立的文件中，该文件只有在使用程序代码时才会被加载。一般可以说“类的代码在首次使用时加载”。这通常是指创建类的第一个对象，或者是访问了类的 static 属性或方法。构造器也是一个 static 方法尽管它的 static 关键字是隐式的。因此，准确地说，一个类当它任意一个 static 成员被访问时，就会被加载。</p><h2 id="第九章-多态"><a href="#第九章-多态" class="headerlink" title="第九章 多态"></a>第九章 多态</h2><p>向上转型：当使用向上转型的时候，我们可以讲所有派生类当做是基类来看待，提高了程序的可拓展性。</p><p>方法调用绑定：当派生类重写了基类的方法时，我们使用向上转型后，调用这些被重写的方法时，编译器会动态绑定到派生类中被重写的方法，执行方法调用。Java 中除了 <strong>static</strong> 和 <strong>final</strong> 方法（<strong>private</strong> 方法也是隐式的 <strong>final</strong>）外，其他所有方法都是后期绑定。</p><p>陷阱：</p><ul><li>试图重写私有方法</li><li>只有普通的方法调用是多态的，属性并不能多态</li></ul><p>构造器和多态：</p><ul><li>构造器调用顺序：首先是基类构造器被调用，然后按照顺序初始化成员，接着调用派生类构造器的方法体</li><li>继承和清理：在清理工作的时候，应该先释放派生类的对象，然后释放基类的对象</li><li>构造器内部多态方法的行为：如果在构造器中调用了正在构造的对象的动态绑定方法，就会用到那个方法的重写定义</li></ul><p>协变返回类型：派生类的被重写方法可以返回基类方法返回类型的派生类型。</p><p>向下转型：重新将基类类型改为派生类类型，是不安全的。</p><h2 id="第十章-接口"><a href="#第十章-接口" class="headerlink" title="第十章 接口"></a>第十章 接口</h2><p>接口和抽象类提供了一种将接口与实现分离的更加结构化的方法，抽象类是一种介于普通类和接口之间的折中手段。</p><p>抽象类和方法：抽象方法只有声明没有方法体，并且使用 abstract 关键字，包含有抽象方法的类称为抽象类，并且类本身也必须限定为抽象。抽象类不能被实例化，如果某个类继承自抽象类，就必须实现该抽象类中所有的抽象方法，如果不这么做的话，新的类也是一个抽象类。</p><p>接口创建：使用 interface 关键字创接口。一个接口表示，所有实现了该接口的类看起来都这样。在 Java8 之前，接口里面只允许抽象方法（不用加 abstract 关键字），在 Java8 里面又新增了默认方法。另外，接口同样可以包含属性，这些属性被隐式指明为 static 和 final。使用 implements 关键字使一个类遵循某个特定接口（或一组接口），它表示：接口只是外形，现在我要说明它是如何工作的。最后，接口中的方法是 public 权限的。</p><ul><li>默认方法：当实现了某个接口的类没有实现某个方法的时候，此时可以使用接口的默认方法，使用 default 关键字，可以带有方法体。增加默认方法的极具说服力的理由是它允许在不破坏已使用接口的代码的情况下，在接口中增加新的方法。</li><li>多继承：Java 中只支持单继承，当时 Java 通过默认方法具有某种多继承的特性，结合带有默认方法的接口意味着结合了多个基类中的行为。因为接口中仍然不允许存在属性（只有静态属性，不适用），所以属性仍然只会来自单个基类或抽象类，也就是说，不会存在状态的多继承。</li><li>接口中的静态方法：Java8 中允许在接口中添加静态方法，这么做能恰当地把工具功能置于接口中，从而操作接口，或者成为通用的工具。</li></ul><p>抽象类和接口：</p><table><thead><tr><th>特性</th><th align="left">接口</th><th>抽象类</th></tr></thead><tbody><tr><td>组合</td><td align="left">新类可以组合多个接口</td><td>只能继承单一抽象类</td></tr><tr><td>状态</td><td align="left">不能包含属性（除了静态属性，不支持对象状态）</td><td>可以包含属性，非抽象方法可能引用这些属性</td></tr><tr><td>默认方法和抽象方法</td><td align="left">不需要在子类中实现默认方法。默认方法可以引用其他接口的方法</td><td>必须在子类中实现抽象方法</td></tr><tr><td>构造器</td><td align="left">没有构造器</td><td>可以有构造器</td></tr><tr><td>可见性</td><td align="left">隐式 <strong>public</strong></td><td>可以是 <strong>protected</strong> 或友元</td></tr></tbody></table><p>完全解耦：使用接口更有利于实现完全解耦，使得代码更具有可复用性。</p><p>多接口实现：一个类只能继承自一个父类，同时可以实现多个接口，提高类的灵活度。</p><p>使用继承扩展接口：通过继承，可以很容易在接口中增加方法声明，还可以在新的接口中实现多个接口。注意，通常来说，extends 只能用于单一类，但是在构建接口时可以引用多个基类接口。</p><p>实现接口时的命名冲突：覆写、实现和重载令人不快地搅和在一起带来了困难，当打算组合接口时，在不同的接口中使用相同的方法名通常会造成代码可读性的混乱，尽量避免这种情况。</p><p>接口适配：接口最吸引人的原因之一是相同的接口可以有多个实现。在简单情况下体现在一个方法接受接口作为参数，该接口的实现和传递对象则取决于方法的使用者。</p><p>接口字段：因为接口中的字段都自动是 static 和 final 的，所以接口就成为了创建一组常量的方便的工具。但是在 Java8 中，应尽量使用 enum 关键字来定义枚举变量。</p><p>接口嵌套：接口可以嵌套在类或者是其他接口中。</p><h2 id="第十一章-内部类"><a href="#第十一章-内部类" class="headerlink" title="第十一章 内部类"></a>第十一章 内部类</h2><p>内部类创建：将类的定义放在外部类的里面。如果想从外部类的非静态方法之外的任意位置创建某个内部类的对象，那么必须具体地指明这个对象的类型：<em>OuterClassName.InnerClassName</em>。</p><p>链接外部类：当生成一个内部类的对象的时候，该对象能够访问到外部对象的所有成员，而不需要其他任何特殊权限。当某个外部类的对象创建了一个内部类对象时，此内部类对象必定会秘密地捕获一个指向那个外部类对象的引用。然后，在你访问此外部类的成员时，就是用那个引用来选择外部类的成员。但是这些都是编译器的细节了。</p><p>使用 <code>.this</code> 和 <code>.new</code>：如果你需要生成对外部类对象的引用，可以使用外部类的名字后面紧跟圆点和 <strong>this</strong>。有时你可能想要告知某些其他对象，去创建其某个内部类的对象。要实现此目的，你必须在 <strong>new</strong> 表达式中提供对其他外部类对象的引用，这是需要使用 <strong>.new</strong> 语法。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// innerclasses/DotNew.java</span></span><br><span class="line"><span class="comment">// Creating an inner class directly using .new syntax</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DotNew</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Inner</span> </span>&#123;&#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        DotNew dn = <span class="keyword">new</span> DotNew();</span><br><span class="line">        DotNew.Inner dni = dn.<span class="function">new <span class="title">Inner</span><span class="params">()</span></span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>内部类和向上转型：当将内部类向上转型为其基类，尤其是转型为一个接口的时候，内部类就有了用武之地。这是因为此内部类-某个接口的实现-能够完全不可见，并且不可用。所得到的只是指向基类或接口的引用，所以能够很方便地隐藏实现细节。</p><p>在方法和作用域中声明内部类：可以在一个方法里面或者在任意的作用域内定义内部类。</p><p>匿名内部类：通常使用 <code>new ClassName(params) &#123; ... &#125;;</code>，params 用于构造器传参，后面的分号指代语句结束。另外，如果匿名类内部希望使用一个定义在其外部的对象，那么编译器要求其参数引用必须是 final 的。注意在实例化匿名类的时候，可以使用非 final 修饰的变量。匿名内部类与正规的继承相比有些受限，因为匿名内部类既可以扩展类，也可以实现接口，但是不能两者兼备。而且如果是实现接口，也只能实现一个接口。</p><p>嵌套类：如果不需要内部类对象与其外部类对象之间有联系，那么可以将内部类声明为 static，这通常称为嵌套类。想要理解 static 应用于内部类时的含义，就必须记住，普通的内部类对象隐式地保存了一个引用，指向创建它的外部类对象。然而，当内部类是 static 的时，就不是这样了。嵌套类意味着：</p><ol><li>要创建嵌套类的对象，并不需要其外部类的对象。</li><li>不能从嵌套类的对象中访问非静态的外部类对象。</li></ol><p>嵌套类与普通的内部类还有一个区别。普通内部类的字段与方法，只能放在类的外部层次上，所以普通的内部类不能有 static 数据和 static 字段，也不能包含嵌套类。但是嵌套类可以包含所有这些东西。</p><ul><li>接口内部的类：嵌套类可以作为接口的一部分。你放到接口中的任何类都自动地是 public 和 static 的。</li><li>从多层嵌套类中访问外部类的成员：一个内部类被嵌套多少层并不重要——它能透明地访问所有它所嵌入的外部类的所有成员。</li></ul><p>为什么需要内部类：</p><ul><li>闭包和回调：在 Java8 之前，内部类是实现闭包的唯一方式，在 Java8 中，我们可以使用 lambda 表达式来实现闭包行为，并且更加优雅。</li></ul><p>继承内部类：因为内部类的构造器必须连接到指向其外部类对象的引用，所以在继承内部类的时候，事情会变得有点复杂。问题在于，那个指向外部类对象的“秘密的”引用必须被初始化，而在派生类中不再存在可连接的默认对象。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// innerclasses/InheritInner.java</span></span><br><span class="line"><span class="comment">// Inheriting an inner class</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">WithInner</span> </span>&#123;</span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">Inner</span> </span>&#123;&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">InheritInner</span> <span class="keyword">extends</span> <span class="title">WithInner</span>.<span class="title">Inner</span> </span>&#123;</span><br><span class="line">    <span class="comment">//- InheritInner() &#123;&#125; // Won&#x27;t compile</span></span><br><span class="line">    InheritInner(WithInner wi) &#123;</span><br><span class="line">        wi.<span class="keyword">super</span>();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        WithInner wi = <span class="keyword">new</span> WithInner();</span><br><span class="line">        InheritInner ii = <span class="keyword">new</span> InheritInner(wi);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>内部类标示符：由于编译后每个类都会产生一个 .class 文件，其中包含了如何创建该类型的对象的全部信息。内部类也必须生成一个 .class 文件以包含它们的 Class 对象信息。这些类文件的命名有严格的规则：外部类的名字，加上 “$” ，再加上内部类的名字。如果内部类是匿名的，编译器会简单地产生一个数字作为其标识符。</p><h2 id="第十二章-集合"><a href="#第十二章-集合" class="headerlink" title="第十二章 集合"></a>第十二章 集合</h2><p>泛型和类型安全的集合：通过使用泛型，规定了向某个集合中可以添加的变量类型，方便进行处理，同时不会引发类型转型错误等问题。</p><p>Java 集合类库的两个概念：集合（Collection）和映射（Map）。</p><p>添加元素组：通过 Arrays.asList 和 Collections.addAll 方法来添加元素组。注意 Arrays.asList 的返回值是一个 List，但是这个 List 不能调整大小。</p><p>集合的打印：必须使用 Arrays.toString 来生成数组的可打印形式，但是打印集合无需任何操作。</p><p>列表 List：有 ArrayList 和 LinkedList，前者擅长随机访问，后者擅长插入删除操作。当确定元素是否是属于某个 <strong>List</strong> ，寻找某个元素的索引，以及通过引用从 <strong>List</strong> 中删除元素时，都会用到 <code>equals()</code> 方法。<code>toArray()</code> 方法将任意的 Collection 转换为数组。</p><p>迭代器 Iterators：在任何集合中，都必须有某种方式可以插入元素并再次获取它们。毕竟，保存事物是集合最基本的工作。对于 <strong>List</strong> ， <code>add()</code> 是插入元素的一种方式， <code>get()</code> 是获取元素的一种方式。如果从更高层次的角度考虑，会发现这里有个缺点：要使用集合，必须对集合的确切类型编程。为此引入迭代器，迭代器相关方法有<code>iterator，next，hasNext，remove</code>。迭代器统一了对集合的访问方式。</p><p>ListIterator：ListIterator 是一个更强大的 Iterator 子类型，它只能由各种 List 类生成。 Iterator 只能向前移动，而 ListIterator 可以双向移动。它可以生成迭代器在列表中指向位置的后一个和前一个元素的索引，并且可以使用 <code>set()</code> 方法替换它访问过的最近一个元素。</p><p>LinkedList：LinkedList 还添加了一些方法，使其可以被用作栈、队列或双端队列（deque） 。在这些方法中，有些彼此之间可能只是名称有些差异，或者只存在些许差异，以使得这些名字在特定用法的上下文环境中更加适用（特别是在 Queue 中）。如 element，peek，poll，offer 等。</p><p>栈 Stack：后进先出规则，Java 1.0 中附带了一个 Stack 类，结果设计得很糟糕（为了向后兼容，我们永远坚持 Java 中的旧设计错误）。Java 6 添加了 ArrayDeque ，其中包含直接实现堆栈功能的方法。</p><p>集合 Set：Set 不保存重复的元素，Set 具有与 Collection 相同的接口，因此没有任何额外的功能。HashSet 产生的输出没有可辨别的顺序，这是因为出于对速度的追求， HashSet 使用了散列。由 HashSet 维护的顺序与 TreeSet 或 LinkedHashSet 不同，因为它们的实现具有不同的元素存储方式。TreeSet 将元素存储在红-黑树数据结构中，而 HashSet 使用散列函数。LinkedHashSet 因为查询速度的原因也使用了散列，但是看起来使用了链表来维护元素的插入顺序。</p><p>映射 Map：根据键快速查找值的结构。Map 可以返回由其键组成的 Set ，由其值组成的 Collection ，或者其键值对的 Set 。keySet() 方法生成由在 petPeople 中的所有键组成的 Set ，它在 for-in 语句中被用来遍历该 Map 。</p><p>队列 Queue：先进先出的集合，LinkedList 实现了 Queue 接口，并且提供了一些方法以支持队列行为，因此 LinkedList 可以用作 Queue 的一种实现。offer() 是与 Queue 相关的方法之一，它在允许的情况下，在队列的尾部插入一个元素，或者返回 false 。 peek() 和 element() 都返回队头元素而不删除它，但是如果队列为空，则 element() 抛出 NoSuchElementException ，而 peek() 返回 null 。 poll() 和 remove() 都删除并返回队头元素，但如果队列为空，poll() 返回 null ，而 remove() 抛出 NoSuchElementException 。</p><p>优先级队列 PriorityQueue：先进先出（FIFO）描述了最典型的队列规则（queuing discipline）。优先级队列声明下一个弹出的元素是最需要的元素（具有最高的优先级）。当在 PriorityQueue 上调用 offer() 方法来插入一个对象时，该对象会在队列中被排序。默认的排序使用队列中对象的自然顺序（natural order），但是可以通过提供自己的 Comparator 来修改这个顺序。 PriorityQueue 确保在调用 peek()， poll() 或 remove() 方法时，获得的元素将是队列中优先级最高的元素。</p><p>集合和迭代器：Collection 是所有序列集合共有的根接口，使用接口描述的一个理由是它可以使我们创建更通用的代码。通过针对接口而非具体实现来编写代码，我们的代码可以应用于更多类型的对象。为了对集合进行遍历操作，我们可以使用迭代器来进行操作。</p><p>for-in 迭代器：到目前为止，for-in 语法主要用于数组，但它也适用于任何 Collection 对象。这样做的原因是 Java 5 引入了一个名为 Iterable 的接口，该接口包含一个能够生成 Iterator 的 iterator() 方法。for-in 使用此 Iterable 接口来遍历序列。</p><p>适配器惯用法：如果已经有一个接口并且需要另一个接口时，则编写适配器就可以解决这个问题。在这里，若希望在默认的正向迭代器的基础上，添加产生反向迭代器的能力，因此不能使用覆盖，相反，而是添加了一个能够生成 Iterable 对象的方法，该对象可以用于 for-in 语句。</p><p>注意：不要在新代码中使用遗留类 Vector ，Hashtable 和 Stack 。</p><p>Java 集合框架简图：黄色为接口，绿色为抽象类，蓝色为具体类。虚线箭头表示实现关系，实线箭头表示继承关系。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="collection.png" class="lazyload" data-srcset="collection.png" srcset="data:image/png;base64,666" alt="collection"/></div><span class="image-caption">collection</span></div><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="map.png" class="lazyload" data-srcset="map.png" srcset="data:image/png;base64,666" alt="map"/></div><span class="image-caption">map</span></div><h2 id="第十三章-函数式编程"><a href="#第十三章-函数式编程" class="headerlink" title="第十三章 函数式编程"></a>第十三章 函数式编程</h2><p>Lambda 表达式：<code>(params) -&gt; &#123; statements; &#125;</code>，只有一个参数的时候，可以省略括号，如果只有一行的话，花括号应该省略。</p><p>方法引用：<code>ClassName::MethodName</code>。</p><ul><li>未绑定的方法引用：未绑定的方法引用是指没有关联对象的普通（非静态）方法。 使用未绑定的引用时，我们必须先提供对象。</li><li>构造函数的引用：<code>ClassName::new</code></li></ul><p>函数式接口：Lambda 表达式包含类型推导，但是如果存在<code>(x, y) -&gt; x + y</code>这样的 lambda 表达式，编译器就不能自动进行类型推导了。因为 x, y 既可以是 String 类型，也可以是 int 类型。此时引入<code>java.util.function</code>包，包含了一组接口，每个接口只有一个抽象方法，称为函数式方法。Java 8 允许我们将函数赋值给接口，这样的语法更加简单漂亮。</p><ul><li><p>多参数函数式接口：在 function 包中，只有很少的接口，我们可以自己定义一个函数接口，如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// functional/TriFunction.java</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@FunctionalInterface</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">TriFunction</span>&lt;<span class="title">T</span>, <span class="title">U</span>, <span class="title">V</span>, <span class="title">R</span>&gt; </span>&#123;</span><br><span class="line">    <span class="function">R <span class="title">apply</span><span class="params">(T t, U u, V v)</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></li></ul><p>高阶函数：消费或产生函数的函数。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// functional/ProduceFunction.java</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.function.*;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">FuncSS</span> <span class="keyword">extends</span> <span class="title">Function</span>&lt;<span class="title">String</span>, <span class="title">String</span>&gt; </span>&#123;&#125; <span class="comment">// [1]</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ProduceFunction</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">static</span> FuncSS <span class="title">produce</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> s -&gt; s.toLowerCase(); <span class="comment">// [2]</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    FuncSS f = produce();</span><br><span class="line">    System.out.println(f.apply(<span class="string">&quot;YELLING&quot;</span>));</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>闭包：对外部变量引用的函数。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// functional/Closure1.java</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.function.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Closure1</span> </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> i;</span><br><span class="line">  <span class="function">IntSupplier <span class="title">makeFun</span><span class="params">(<span class="keyword">int</span> x)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> () -&gt; x + i++;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>柯里化和部分求值：柯里化意为：将一个多参数的函数，转换为一系列单参数函数。</p><h2 id="第十四章-流式编程"><a href="#第十四章-流式编程" class="headerlink" title="第十四章 流式编程"></a>第十四章 流式编程</h2><p>流式编程的特点：代码可读性更高；懒加载，意味着它只在绝对必要时才计算，由于计算延迟，流使我们能够表示非常大（甚至无限）的序列，而不需要考虑内存问题。</p><p>流支持：Java 8 通过在接口中添加<code>default</code>修饰的方法实现流的平滑嵌入。流操作有三种类型：创建流，修改流元素（中间操作），消费流元素（终端操作）。</p><p>流创建：通过 Stream.of 将一组元素转化为流，除此之外，每个集合都可以通过调用 stream 方法来产生一个流。除此以外，还有：</p><ul><li>随机数流：<code>new Random().ints()</code></li><li>int 类型流：<code>IntStream.range(start, end, step)</code></li><li>generate：<code>Stream.generate(obj)</code></li><li>iterate：<code>Stream.iterate(initValue, cb)</code></li><li>流的构造着模式：首先创建一个 builder 对象，然后将创建流所需的多个信息传递给它，最后builder 对象执行“创建”流的操作。</li><li>Arrays: <code>Arrays.stream()</code></li></ul><p>中间操作：用于从一个流中获取对象，并将对象作为另一个流从后端输出，以连接到其他操作。</p><ul><li>peek：无修改地查看流中的元素</li><li>sorted：排序，可以使用 lambda 参数</li><li>distinct：消除重复元素</li><li>filter：通过过滤条件的被保存下来，否则删除</li><li>map：将函数操作应用在输入流的元素中，并将返回值传递到输出流中。还有 mapToInt, mapToLong 等</li><li>flatMap：将产生流的函数应用在每个元素上（与 <code>map()</code> 所做的相同），然后将每个流都扁平化为元素，因而最终产生的仅仅是元素。对应还有 flatMapToInt 等</li></ul><p>Optimal 类：一些标准流操作返回 Optional 对象，因为它们并不能保证预期结果一定存在。当流为空的时候你会获得一个 Optional.empty 对象，而不是抛出异常。</p><ul><li>解包 Optimal 的函数：<code>ifPresent(Consumer)</code>, <code>orElse(otherObject)</code></li><li>创建 Optimal：静态方法有<code>empty(), of(value), ofNullable(value)</code></li><li>Optimal 流：假设你的生成器可能产生 null 值，那么当用它来创建流时，你会自然地想到用 Optional 来包装元素。可以使用 filter() 来保留那些非空 Optional</li></ul><p>终端操作：以下操作将会获取流的最终结果，终端操作（Terminal Operations）总是我们在流管道中所做的最后一件事。</p><ul><li>数组：toArray</li><li>循环：forEach，forEachOrdered</li><li>集合：collect</li><li>组合：reduce</li><li>匹配：allMatch，anyMatch，noneMatch</li><li>查找：findFirst，findAny</li><li>信息：count，max，min</li><li>数字流信息：average，max，min</li></ul><h2 id="第十五章-异常"><a href="#第十五章-异常" class="headerlink" title="第十五章 异常"></a>第十五章 异常</h2><p>异常概念：C 以及其他早期语言常常具有多种错误处理模式，这些模式往往建立在约定俗成的基础之上，而并不属于语言的一部分。通常会返回某个特殊值或者设置某个标志，并且假定接收者将对这个返回值或标志进行检查，以判定是否发生了错误。“异常”这个词有“我对此感到意外”的意思。问题出现了，你也许不清楚该如何处理，但你的确知道不应该置之不理，你要停下来，看看是不是有别人或在别的地方，能够处理这个问题。</p><p>异常捕获：</p><ul><li>try 语句块：对可能产生异常的语句进行捕获</li><li>catch 语句块：对每种可能出现的异常准备相应的处理语句</li><li>终止和恢复：Java 支持终止模型，这种模型假设错误非常严重，以至于程序无法返回到异常发生的地方继续执行。另外一种是恢复模型，如果 Java 想要实现类似恢复的行为，可以把 try 块放在循环里面，直到得到满意的结果</li></ul><p>自定义异常：想要自定义异常类，必须从已有的异常类继承。</p><p>异常声明：在方法后面加上<code>throws ExceptionType1，ExceptionType2,,,</code></p><p>捕获所有异常：直接捕获基类 Exception</p><ul><li><p>多重捕获：Java7 中支持，使用 <code>|</code> 连接不同类型的异常，如<code>catch(Except1 | Except2 | Except3 | Except4 e) &#123;&#125;</code></p></li><li><p>栈轨迹：printStackTrace</p></li><li><p>重新抛出异常：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">catch</span>(Exception e) &#123;</span><br><span class="line">    System.out.println(<span class="string">&quot;An exception was thrown&quot;</span>);</span><br><span class="line">    <span class="keyword">throw</span> e;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><p>使用 finally 进行清理：不管是否发生异常，都会执行 finally 块里面的语句。</p><ul><li>finally 作用：用于将资源恢复到初始状态</li><li>在 return 中使用 finally：从何处返回无关紧要，finally 子句永远会执行</li><li>异常丢失：finally 里面使用 return 将会导致不会抛出任何异常</li></ul><p>Try-With-Resources 用法：<code>try()&#123;  &#125;catch(Exception e)&#123;  &#125;</code>，在 try 小括号里面的声明的对象需要实现<code>java.lang.AutoCloseable</code>接口，接口只有一个方法<code>close()</code>。退出 try 块会调用每个对象的 close() 方法，并以与创建顺序相反的顺序关闭它们。</p><p>异常匹配：异常处理系统会按照代码的书写顺序找出“最近”的处理程序。找到匹配的处理程序之后，它就认为异常将得到处理，然后就不再继续查找。</p><h2 id="第十七章-文件"><a href="#第十七章-文件" class="headerlink" title="第十七章 文件"></a>第十七章 文件</h2><p>文件和目录路径：一个 <strong>Path</strong> 对象表示一个文件或者目录的路径，是一个跨操作系统（OS）和文件系统的抽象，通过 <code>Paths.get(URL)</code> 来获得一个对应的 Path 对象。</p><ul><li>选取路径部分片段：getName</li><li>路径分析：<strong>Files</strong> 工具类包含一系列完整的方法用于获得 <strong>Path</strong> 相关的信息，如<code>exists，size，isDirectory</code></li><li>Paths 的增删修改：relative，resolve</li></ul><p>遍历目录：Files.walkFileTree，具体操作实现由参数二 FileVisitor 里面的四个抽象方法决定：</p><ol><li>preVisitDirectory()：在访问目录中条目之前在目录上运行。 </li><li>visitFile()：运行目录中的每一个文件。  </li><li>visitFileFailed()：调用无法访问的文件。   </li><li>postVisitDirectory()：在访问目录中条目之后在目录上运行，包括所有的子目录。</li></ol><p>文件系统：可以使用静态的 FileSystems 工具类获取默认的文件系统</p><p>路径监听：通过文件系统的 WatchService 可以设置一个进程对目录中的更改做出响应</p><p>文件查找：通过在 FileSystem 对象上调用 getPathMatcher 可以获得一个 PathMatcher，传入对应的两种模式：glob 或者 regex。</p><p>文件读写：如果文件比较小，使用 Files.readAllLines 可以一次性读取整个文件，返回一个 <code>List&lt;String&gt;</code>；使用 Files.write 写入 byte 数组或者任何可迭代对象。对于文件比较大的时候，可以使用 Files.lines 将文件转换为输入流。</p><h2 id="第十八章-字符串"><a href="#第十八章-字符串" class="headerlink" title="第十八章 字符串"></a>第十八章 字符串</h2><p>字符串的不可变性：String 对象是不可变的，String 类中的每个看起来会修改 String 值的方法，实际上都是创建了一个全新的 String 对象。</p><p><code>+</code> 的重载与 StringBuilder：在 String 中，<code>+</code> 代表了字符串之间的 append 操作，每次 <code>+</code> 都会创建一个 String 对象，代价高昂。StringBuilder 提供了丰富全面的方法，包括<code>insert，replace，append，delete</code>。另外还有 StringBuffer，和 StringBuilder 不同点在于后者是线程不安全的，前者是线程安全的。</p><p>意外递归：如<code>&quot;som string&quot; + this </code>，我们想要打印出某个字符串的地址，但是编译器首先辨别出左边是 String 对象，<code>+</code> 要求右边的变量也是 String 对象（先进行转换），这就涉及到了意外递归。可以使用<code>Object.toString()</code>打印地址。</p><p>字符串操作：当需要改变字符串的内容时，<code>String</code> 类的方法都会返回一个新的 <code>String</code> 对象。同时，如果内容不改变，<code>String</code> 方法只是返回原始对象的一个引用而已。这可以节约存储空间以及避免额外的开销。</p><p>格式化输出：</p><ul><li><p>System.out.printf, System.out.format</p></li><li><p>格式化修饰符：<code>%[argument_index$][flags][width][.precision]conversion </code></p></li><li><p>Formatter 转换：</p><table><thead><tr><th>类型</th><th>含义</th></tr></thead><tbody><tr><td><code>d</code></td><td>整型（十进制）</td></tr><tr><td><code>c</code></td><td>Unicode字符</td></tr><tr><td><code>b</code></td><td>Boolean值</td></tr><tr><td><code>s</code></td><td>String</td></tr><tr><td><code>f</code></td><td>浮点数（十进制）</td></tr><tr><td><code>e</code></td><td>浮点数（科学计数）</td></tr><tr><td><code>x</code></td><td>整型（十六进制）</td></tr><tr><td><code>h</code></td><td>散列码（十六进制）</td></tr><tr><td><code>%</code></td><td>字面值“%”</td></tr></tbody></table></li><li><p>String.format</p></li></ul><p>正则化表达式：</p><ul><li><p>在正则表达式中，用 <code>\d</code> 表示一位数字。如果在其他语言中使用过正则表达式，那你可能就能发现 Java 对反斜线 \ 的不同处理方式。在其他语言中，<code>\\</code> 表示“我想要在正则表达式中插入一个普通的（字面上的）反斜线，请不要给它任何特殊的意义。”而在Java中，<code>\\</code> 的意思是“我要插入一个正则表达式的反斜线，所以其后的字符具有特殊的意义。”例如，如果你想表示一位数字，那么正则表达式应该是 <code>\\d</code>。如果你想插入一个普通的反斜线，应该这样写 <code>\\\</code>。不过换行符和制表符之类的东西只需要使用单反斜线：<code>\n\t</code>。如果要表示“可能有一个负号，后面跟着一位或多位数字”，可以这样：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-?\\d+</span><br></pre></td></tr></table></figure></li><li><p>表达式：</p><table><thead><tr><th>表达式</th><th>含义</th></tr></thead><tbody><tr><td><code>.</code></td><td>任意字符</td></tr><tr><td><code>[abc]</code></td><td>包含<code>a</code>、<code>b</code>或<code>c</code>的任何字符（和`a</td></tr><tr><td><code>[^abc]</code></td><td>除<code>a</code>、<code>b</code>和<code>c</code>之外的任何字符（否定）</td></tr><tr><td><code>[a-zA-Z]</code></td><td>从<code>a</code>到<code>z</code>或从<code>A</code>到<code>Z</code>的任何字符（范围）</td></tr><tr><td><code>[abc[hij]]</code></td><td><code>a</code>、<code>b</code>、<code>c</code>、<code>h</code>、<code>i</code>、<code>j</code>中的任意字符（与`a</td></tr><tr><td><code>[a-z&amp;&amp;[hij]]</code></td><td>任意<code>h</code>、<code>i</code>或<code>j</code>（交）</td></tr><tr><td><code>\s</code></td><td>空白符（空格、tab、换行、换页、回车）</td></tr><tr><td><code>\S</code></td><td>非空白符（<code>[^\s]</code>）</td></tr><tr><td><code>\d</code></td><td>数字（<code>[0-9]</code>）</td></tr><tr><td><code>\D</code></td><td>非数字（<code>[^0-9]</code>）</td></tr><tr><td><code>\w</code></td><td>词字符（<code>[a-zA-Z_0-9]</code>）</td></tr><tr><td><code>\W</code></td><td>非词字符（<code>[^\w]</code>）</td></tr></tbody></table></li><li><p>CharSequence：接口从 CharBuffer，String，StringBuffer，StringBuilder 抽象出了一般化定义</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">CharSequence</span> </span>&#123;   </span><br><span class="line">    <span class="function"><span class="keyword">char</span> <span class="title">charAt</span><span class="params">(<span class="keyword">int</span> i)</span></span>;   </span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">length</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function">CharSequence <span class="title">subSequence</span><span class="params">(<span class="keyword">int</span> start, <span class="keyword">int</span> end)</span></span>;</span><br><span class="line">    <span class="function">String <span class="title">toString</span><span class="params">()</span></span>; </span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li><p>Pattern 和 Matcher：更具一个 String 对象生成一个 Pattern 对象，通过 Pattern 对象的 match 方法产生一个 Matcher 对象。</p></li><li><p>组（group）：<code>A(B(C))D</code> 中有三个组：组 0 是 <code>ABCD</code>，组 1 是 <code>BC</code>，组 2 是 <code>C</code>。通过 Matcher 对象的 group 方法可以获取到每个组。</p></li></ul><h2 id="第十九章-类型信息"><a href="#第十九章-类型信息" class="headerlink" title="第十九章 类型信息"></a>第十九章 类型信息</h2><p>Java 在运行时识别对象和类的信息的方式：传统的 RTTI(RunTime Type Information，运行时类型信息)，反射机制。</p><p>RTTI 必要性：下面这个代码展示了 Shape 基类下的派生类的相关操作，使用 RTTI，我们可以在运行时进行类型确认，同时，编码的时候只需要注意对基类的处理就行，不会影响代码的可扩展性。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Shapes</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Stream.of(</span><br><span class="line">            <span class="keyword">new</span> Circle(), <span class="keyword">new</span> Square(), <span class="keyword">new</span> Triangle())</span><br><span class="line">            .forEach(Shape::draw);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>实际上，上述代码编译时候，Stream 和 Java 泛型系统确保放入的都是 Shape 对象或者其派生类，运行时，自动类型转换确保从 Stream 中取出的对象都是 Shape 类型。</p><p>Class 对象：Class 对象包含了与类有关的信息，每个类都会产生一个 Class 对象，每当编译一个新类，就会产生一个 Class 对象（保存在同名的 .class 文件中），为了生成该类的对象，JVM 首先会调用类加载器子系统将这个类加载到内存中。Java 是动态加载的，即只有在类需要的时候才会进行类的加载。所有的 Class 对象都属于 Class 类，可以通过<code>Class.forName()</code>来得到类的 Class 对象，或者通过<code>someInstance.getClass()</code>得到。</p><ul><li>类字面常量：对于一个 FancyToy.class 的文件，我们可以直接使用<code>FancyToy.class</code>得到对应的类对象，相较于<code>Class.forName</code>的方式，该种方式更加简单和安全，并且效率更高。另外，使用类字面常量的时候，不会自动初始化该 Class 对象。为了使用类的三个步骤：<ul><li>加载：查找字节码，并且创建一个 Class 对象</li><li>链接：验证字节码，为 static 字段分配存储空间，如果需要，将解析这个类对其他类的引用</li><li>初始化：先初始化基类，然后执行 static 初始化器和 static 初始化块</li></ul></li><li>泛化的 Class 引用：Class 引用总是指向某个 Class 对象，而 Class 对象可以用于产生类的实例，并且包含可作用于这些实例的所有方法代码。使用 <code>Class&lt;?&gt;</code> 表示通配所有类型，<code>Class&lt;? extends Sup&gt;</code>表示通配所有 Sup 的派生类型，<code>Class&lt;? super Sub&gt;</code>表示通配 Sub 的基类。</li><li>cast 方法：接受参数对象，并将其类型转换为 <code>Class</code> 引用的类型。</li></ul><p>类型转换检测：Java 中支持自动向上转型，但是向下转型是强制的，需要用户指代向下转换的类型，如果没有通过向下类型转换，就会报错，否则转型成功。另外，可以使用 instanceof 判断某个实例是否是某个对象的实例。Class.isInstance 可以动态测试对象类型。</p><p>类的等价比较：当查询类型信息的时候，使用 instanceof 或者 isInstance，这两种方式产生的结果相同，但是 Class 对象直接比较与上述方式不同。instanceof 说的是“你是这个类，还是从这个类派生的类？”。而如果使用 == 比较实际的Class 对象，则与继承无关 —— 它要么是确切的类型，要么不是。</p><p>反射：运行时类信息。<code>java.lang.reflect</code>库中包含了相关的类来实现反射这一机制。RTTI 和反射的真正区别在于，使用 RTTI 时，编译器在编译时会打开并检查 .class 文件。换句话说，你可以用“正常”的方式调用一个对象的所有方法；而通过反射，.class 文件在编译时不可用，它由运行时环境打开并检查。</p><ul><li>类方法提取器：getMethods 和 getConstructors 获取对应的类方法</li></ul><p>动态代理：代理是基本的设计模式之一。一个对象封装真实对象，代替其提供其他或不同的操作—这些操作通常涉及到与“真实”对象的通信，因此代理通常充当中间对象。通过调用静态方法<code>Proxy.newProxyInstance</code>来创建动态代理。</p><p>接口和类型：interface 关键字的一个重要目标就是允许程序员隔离组件，进而降低耦合度。</p><h2 id="第二十章-泛型"><a href="#第二十章-泛型" class="headerlink" title="第二十章 泛型"></a>第二十章 泛型</h2><p>简单泛型：直接使用类型暂代符表示某种类型即可，下图是一个二元组：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// onjava/Tuple2.java</span></span><br><span class="line"><span class="keyword">package</span> onjava;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Tuple2</span>&lt;<span class="title">A</span>, <span class="title">B</span>&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">final</span> A a1;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">final</span> B a2;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Tuple2</span><span class="params">(A a, B b)</span> </span>&#123; a1 = a; a2 = b; &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>泛型接口：泛型可以应用于接口，例如生成器，这是一种专门负责创建对象的类。注意，Java 中支持基本类型作为泛型类型。</p><p>泛型方法：泛型方法独立于类而改变方法。作为准则，请“尽可能”使用泛型方法。通常将单个方法泛型化要比将整个类泛型化更清晰易懂。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// generics/GenericMethods.java</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">GenericMethods</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> &lt;T&gt; <span class="function"><span class="keyword">void</span> <span class="title">f</span><span class="params">(T x)</span> </span>&#123;</span><br><span class="line">        System.out.println(x.getClass().getName());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>泛型擦除：Java 泛型是使用擦除实现的。这意味着当你在使用泛型时，任何具体的类型信息都被擦除了，你唯一知道的就是你在使用一个对象。因此，<code>List&lt;String&gt;</code> 和 <code>List&lt;Integer&gt;</code> 在运行时实际上是相同的类型。它们都被擦除成原生类型 List，使用 getClass 得到的结果相同。</p><ul><li>特殊方式：当我们想要调用某个泛型类型的方法的时候，我们可以使用<code>&lt;T extends Sup&gt;</code>，这样我们才能调用 Sup 里面的相关方法。</li><li>擦除的问题：由于擦除的存在，所有关于参数的信息就丢失了。当你在编写泛型代码时，必须时刻提醒自己，你只是看起来拥有有关参数的类型信息而已。</li></ul><p>补偿擦除：由于擦除的存在，我们无法在运行时知道参数的确切类型，为了解决这个问题，我们显式传递一个 Class 对象，以在类型表达式中使用。</p><ul><li>创建类型的实例：直接通过<code>new T()</code>是行不通的，但是我们可以通过对应的 Class 对象的 newInstance 方法来创建新的实例</li><li>泛型数组：我们无法创建泛型数组，解决方式是在试图创建泛型数组的时候使用 ArrayList</li></ul><p>边界：由于擦除会删除类型信息，因此唯一可用的无限制泛型参数的方法是那些 Object 可用的方法。但是，如果将该参数限制为某类型的子集，则可以调用该子集中的方法。为了应用约束，Java 泛型使用了 extends 关键字。</p><p>通配符：使用<code>？</code>表示。使用<code>&lt;? extends Sup&gt;</code>表示继承自 Sup 的类，使用<code>&lt;? super Sub&gt;</code>表示 Sub 的基类，使用<code>&lt;?&gt;</code>表示任意一种类型。</p><p>使用泛型的问题：</p><ul><li><p>任何基本类型都不能作为类型参数</p></li><li><p>一个类不能实现同一个泛型接口的两种变体，由于擦除的原因，这两个变体会成为相同的接口</p></li><li><p>使用带有泛型类型参数的转型或 <strong>instanceof</strong> 不会有任何效果</p></li></ul><p>自限定的类型：下图代码展示了这种惯用法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SelfBounded</span>&lt;<span class="title">T</span> <span class="keyword">extends</span> <span class="title">SelfBounded</span>&lt;<span class="title">T</span>&gt;&gt; </span>&#123; <span class="comment">// ...</span></span><br></pre></td></tr></table></figure><ul><li><p>古怪的循环泛型（CRG）：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// generics/CuriouslyRecurringGeneric.java</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GenericType</span>&lt;<span class="title">T</span>&gt; </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CuriouslyRecurringGeneric</span></span></span><br><span class="line"><span class="class">  <span class="keyword">extends</span> <span class="title">GenericType</span>&lt;<span class="title">CuriouslyRecurringGeneric</span>&gt; </span>&#123;&#125;</span><br></pre></td></tr></table></figure></li><li><p>自限定：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">A</span> <span class="keyword">extends</span> <span class="title">SelfBounded</span>&lt;<span class="title">A</span>&gt;</span>&#123;&#125;</span><br></pre></td></tr></table></figure></li><li><p>参数协变：自限定类型的价值在于它们可以产生协变参数类型，即方法参数类型会随子类而变化。</p></li></ul><p>动态类型安全：Java5 中的 Collections 有一组便利工具函数，可以解决类型检查问题，如<code>checkedMap</code>等。</p><p>泛型异常：由于擦除的原因，catch 语句不能捕获泛型类型的异常，因为在编译期和运行时都必须知道异常的确切类型。</p><p>混型（Mixin）：最基本的概念是混合多个类的能力，以产生一个可以表示混型中所有类型的类。</p><ul><li>与接口混合</li><li>使用装饰器模式</li><li>与动态代理混合</li></ul><p>潜在类型机制：也称作鸭子类型机制，即“如果它走起来像鸭子，并且叫起来也像鸭子，那么你就可以将它当作鸭子对待”。</p><h2 id="第二十一章-数组"><a href="#第二十一章-数组" class="headerlink" title="第二十一章 数组"></a>第二十一章 数组</h2><p>数组特性：效率，类型，保存基本数据类型的能力。</p><p>一等对象：不管使用什么类型的数组，数组中的数据集实际上都是对堆中真正对象的引用。注意区分聚合初始化和动态聚合初始化。</p><p>返回数组：在 Java 中，可以直接返回一个数组，而不用担心其内存消耗情况，垃圾回收期会自动处理。</p><p>多维数组：使用多层方括号界定每个维度的大小，同样的也存在有不规则的数组。可以使用 Arrays.deepToString 来查看多维数组里面的内容。Arrays.setAll 方法用于初始化数组。</p><p>泛型数组：数组和泛型并不能很好的结合，不能实例化参数化类型的数组，但是允许您创建对此类数组的引用。</p><p>Arrays 相关方法：</p><ul><li>fill：将单个值复制到整个数组，或者在对象数组的情况下，将相同的引用复制到整个数组</li><li>setAll：使用一个生成器用于生成不同的值，生成器的参数是 int 数组索引</li><li>asList：将数组转换为列表</li><li>copyOf：以新的长度复制数组</li><li>copyOfRange：复制现有数组的一部分数据</li><li>equals：判断数组是否相同</li><li>deepEquals：多维数组相等性比较</li><li>stream：生成流</li><li>sort：排序</li><li>binarySearch：二分查找</li><li>toString，deepToString：数组的字符串表示</li></ul><p>数组元素修改：通过使用 setAll 方法来索引现有数据元素</p><h2 id="第二十二章-枚举"><a href="#第二十二章-枚举" class="headerlink" title="第二十二章 枚举"></a>第二十二章 枚举</h2><p>基本 enum 特性：调用 values 方法，可以返回对应的数组，同时调用 ordinal 方法可以知道某个 value 的次序，这个次序默认从 0 开始。可以使用 import static 导入 enum 类型。</p><p>方法添加：除了不能继承自一个 enum 之外，我们基本上可以将 enum 看作一个常规的类。如果你打算定义自己的方法，那么必须在 enum 实例序列的最后添加一个分号。</p><p>switch 语句中的 enum：enum 的 values 本来就具有顺序，可以搭配 switch 使用。</p><p>values 方法：enum 类型的对象会有一个 values 方法，这个方法是由编译器添加的 static 方法。</p><p>实现而非继承：enum 继承自 Enum 类，由于 Java 不支持多继承，enum 不能再次继承其他类，但是创建一个新的 enum 时，可以实现一个或者多个接口。</p><p>使用接口组织枚举：无法从 enum 继承子类很令人沮丧，但是我们可以尝试使用接口来组织枚举类。</p><p>使用 EnumSet 代替 Flags：EnumSet 中的元素必须来自一个 enum。EnumSet 基础是 long，只有 64 位，但是在需要的时候，会增加一个 long。</p><p>使用 EnumMap：要求键必须来自一个 enum，EnumMap 在内部使用数组实现。</p><p>使用 enum 的状态机：枚举类型很适合用于创建状态机。</p><h2 id="第二十三章-注解"><a href="#第二十三章-注解" class="headerlink" title="第二十三章 注解"></a>第二十三章 注解</h2><p>java.lang 中的注解包括：@Override，@Deprecated，@SuppressWarnings，@SafeVarargs，@FunctionalInterface。</p><p>基本语法：</p><ul><li><p>定义注解：注解的定义看起来很像接口的定义，事实上，他们和其他 Java 接口一样，也会被编译成 class 文件。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// onjava/atunit/Test.java</span></span><br><span class="line"><span class="comment">// The @Test tag</span></span><br><span class="line"><span class="keyword">package</span> onjava.atunit;</span><br><span class="line"><span class="keyword">import</span> java.lang.annotation.*;</span><br><span class="line"><span class="meta">@Target(ElementType.METHOD)</span></span><br><span class="line"><span class="meta">@Retention(RetentionPolicy.RUNTIME)</span></span><br><span class="line"><span class="keyword">public</span> <span class="meta">@interface</span> Test &#123;&#125;</span><br></pre></td></tr></table></figure><p>@target 标示注解的对象，@Retention 标示注解在哪里可用。</p></li><li><p>元注解：@target，@Retention，@Documented，@Inherited，@Repeatable</p></li></ul><p>编写注解处理器：使用反射机制 API 实现注解的读取。</p><ul><li>注解元素：基本类型，String，Class，enum，Annotation，以上类型的数组</li><li>默认值限制：首先，元素不能有不确定的值。也就是说，元素要么有默认值，要么就在使用注解时提供元素的值。任何非基本类型的元素，无论是在源代码声明时还是在注解接口中定义默认值时，都不能使用 null 作为其值。</li><li>生成外部文件：Web Service，自定义标签库以及对象/关系映射工具（例如 Toplink 和 Hibernate）通常都需要 XML 描述文件，而这些文件脱离于代码之外。除了定义 Java 类，程序员还必须忍受沉闷，重复的提供某些信息，例如类名和包名等已经在原始类中提供过的信息。每当你使用外部描述文件时，他就拥有了一个类的两个独立信息源，这经常导致代码的同步问题。</li><li>注解不支持继承：不能使用 extends 关键字来继承 @interfaces。</li><li>实现处理器：通过 getAnnotation 来检查是否存在注解，如果存在的话做出相应的操作</li></ul><p>基于注解的单元测试：如 JUnit。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hexo和typora搭配写博客</title>
      <link href="2020/10/21/hexo%E5%92%8Ctypora%E6%90%AD%E9%85%8D%E5%86%99%E5%8D%9A%E5%AE%A2/"/>
      <url>2020/10/21/hexo%E5%92%8Ctypora%E6%90%AD%E9%85%8D%E5%86%99%E5%8D%9A%E5%AE%A2/</url>
      
        <content type="html"><![CDATA[<p>本文介绍使用Typora写博客，使用Hexo发布文章的技巧。主要涉及图片的路径问题。</p><a id="more"></a><h2 id="解决Hexo图片路径问题"><a href="#解决Hexo图片路径问题" class="headerlink" title="解决Hexo图片路径问题"></a>解决Hexo图片路径问题</h2><p>在使用Typora的时候，首先进入到Typora的设置里面，将图片插入格式改为如下设置：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201021142301183.png" class="lazyload" data-srcset="image-20201021142301183.png" srcset="data:image/png;base64,666" alt="image-20201021142301183"/></div><span class="image-caption">image-20201021142301183</span></div><p>这样的话，在写作的时候，我们就可以实时预览到自己插入的图片了。</p><p>接着，在博客仓库的<code>_config.yml</code>中设置<code>post_asset_folder: true</code>。</p><p>但是这样设置的话会产生一个问题，就是在执行<code>hexo g</code>的时候，得到的博客文章路径会多一个<code>&#123;&#123;title&#125;&#125;</code>,导致图片在发布的时候渲染不出来。为了解决这个问题，可以使用<code>hexo-typora-img</code>，</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm i hexo-typora-img</span><br></pre></td></tr></table></figure><p>这个插件会将原来的路径在渲染前将其改为Hexo可以识别的图片路径，从而在预览发布的时候也可以看到图片。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Hexo </tag>
            
            <tag> Typora </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis设计与实现笔记</title>
      <link href="2020/10/18/Redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0%E7%AC%94%E8%AE%B0/"/>
      <url>2020/10/18/Redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<p>本文章是对《Redis设计与实现》书籍的一个整理笔记，记录了其中个人认为比较重要的部分。</p><a id="more"></a><h2 id="第二章-简单动态字符串"><a href="#第二章-简单动态字符串" class="headerlink" title="第二章 简单动态字符串"></a>第二章 简单动态字符串</h2><ul><li>SDS 定义：</li></ul><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201012191209564.png" class="lazyload" data-srcset="image-20201012191209564.png" srcset="data:image/png;base64,666" alt="image-20201012191209564"/></div><span class="image-caption">image-20201012191209564</span></div><ul><li>SDS 与 C 字符串的区别：<ul><li>常数复杂度获取字符串的长度</li><li>杜绝缓冲区溢出</li><li>减少修改字符串时带来的内存分配的次数，包括空间预分配和惰性空间释放</li><li>二进制安全</li><li>兼容部分 C 字符串函数</li></ul></li></ul><h2 id="第二章-链表"><a href="#第二章-链表" class="headerlink" title="第二章 链表"></a>第二章 链表</h2><ul><li><p>Redis 的链表实现的特性可以总结如下：</p><ul><li>双端</li><li>无环</li><li>带表头指针和表尾指针</li><li>带链表长度计数器</li><li>多态：链表节点使用void*指针来保存节点值, 并且可以通过 list 结构的dup, free, match三个属性为节点值设置类型特定函数,所以链表可以用于保存各种不同类型的值 </li></ul><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201012192406288.png" class="lazyload" data-srcset="image-20201012192406288.png" srcset="data:image/png;base64,666" alt="image-20201012192406288"/></div><span class="image-caption">image-20201012192406288</span></div></li></ul><h2 id="第三章-字典"><a href="#第三章-字典" class="headerlink" title="第三章 字典"></a>第三章 字典</h2><ul><li><p>Redis 普通状态下的字典：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201012194731429.png" class="lazyload" data-srcset="image-20201012194731429.png" srcset="data:image/png;base64,666" alt="image-20201012194731429"/></div><span class="image-caption">image-20201012194731429</span></div></li><li><p>哈希算法：首先计算哈希值，然后计算出索引值</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201012194922912.png" class="lazyload" data-srcset="image-20201012194922912.png" srcset="data:image/png;base64,666" alt="image-20201012194922912"/></div><span class="image-caption">image-20201012194922912</span></div><blockquote><p>Redis 使用的 MurmurHash 算法计算建的哈希值，该算法的优点在于即使输入的键时有规律的，算法仍然能给出一个很好的随机分布性。</p></blockquote></li><li><p>解决键冲突：使用链地址法解决键冲突，使用头插法进行插入。</p></li><li><p>rehash：当负载因子过大的时候，就会开始进行相应的扩展或者收缩。使用<code>ht[1]</code>协助扩展。</p></li><li><p>渐进式 rehash：扩展或收缩哈希表需要将<code>ht[0]</code>里面的所有键值对 rehash到<code>ht[1]</code> 里面, 但是, 这个 rehash动作并不是一次性、集中式地完成的,而是分多次、渐进式地完成。在渐进期间，字典会同时使用两个哈希表，但是插入的时候只会插入到<code>ht[1]</code>。</p></li></ul><h2 id="第五章-跳跃表"><a href="#第五章-跳跃表" class="headerlink" title="第五章 跳跃表"></a>第五章 跳跃表</h2><ul><li><p>跳跃表：有序的数据结构，通过在节点中维持多个指向其他节点的指针，从而达到快速访问节点的目的。支持 平均O(logn)，最坏O(N)复杂度的节点查找。</p></li><li><p>跳跃表结构示意图：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201013191437427.png" class="lazyload" data-srcset="image-20201013191437427.png" srcset="data:image/png;base64,666" alt="image-20201013191437427"/></div><span class="image-caption">image-20201013191437427</span></div><p>header和tail分别表示表头节点和表尾节点，level表示的层数，length时跳跃表的长度。BW表示的是回退指针，指向上一个跳跃表节点。箭头线上面的数字是跨度，表示跨过了几个节点。</p></li><li><p>在Redis中，每个节点的层高是1到32之间的随机数，在同一个跳跃表中，多个节点可以包含相同的分值，但是每个节点的额成员对象必须唯一，另外，跳跃表中的节点按照分值大小排序，如果分值大小相同，则按照成员对象的大小排序。</p></li></ul><h2 id="第六章-整数集合"><a href="#第六章-整数集合" class="headerlink" title="第六章 整数集合"></a>第六章 整数集合</h2><ul><li><p>整数集合实现：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201013192842489.png" class="lazyload" data-srcset="image-20201013192842489.png" srcset="data:image/png;base64,666" alt="image-20201013192842489"/></div><span class="image-caption">image-20201013192842489</span></div><p>虽然contents是int8_t类型的数组，但实际上数组并不保存任何int8_t类型的值，该数组的真正类型取决于encoding属性的值。</p></li><li><p>升级：每当我们要将一个新元素添加到整数集合里面，并且新元素的类型比整数集合现有所有元素的类型都要长时,整数集合需要先进行升级(upgrade)，然后才能将新元素添加到整数集合里面。首先根据新元素的类型，扩展整数集合底层数组的空间大小，并且为新元素分配相应的空间；将底层数组现有的所有元素都转换成与新元素相同的类型，并且将其放到正确的位置上，保持有序性不变；将新元素添加到底层数组里面（新元素要么在最后位置，要么在首位置）。</p></li><li><p>升级的好处：提升灵活性，节约内存。</p></li><li><p>降级：整数集合不支持降级操作，一旦对数据进行了升级，编码就会一直保持升级之后的状态。</p></li></ul><h2 id="第七章-压缩列表"><a href="#第七章-压缩列表" class="headerlink" title="第七章 压缩列表"></a>第七章 压缩列表</h2><ul><li><p>压缩列表的构成：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201013194653014.png" class="lazyload" data-srcset="image-20201013194653014.png" srcset="data:image/png;base64,666" alt="image-20201013194653014"/></div><span class="image-caption">image-20201013194653014</span></div><p>zlbytes记录整个压缩列表占用的内存字节数，zltail记录列表表位距离压缩列表的起始地址有多少字节，zllen记录节点个数，zlend特殊值0xFF，标记为压缩列表的末端。</p></li><li><p>压缩列表节点的构成：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201013195122854.png" class="lazyload" data-srcset="image-20201013195122854.png" srcset="data:image/png;base64,666" alt="image-20201013195122854"/></div><span class="image-caption">image-20201013195122854</span></div><p>根据previous_entry_length可以计算出上一个节点的地址，根据encoding可以知道存放的数据类型和长度，content则是一个字节数组或者整数。</p></li><li><p>连锁更新：当压缩列表的原来的节点的数值在250-254之间的时候，此时如果新增或者（删除）一个节点，会导致原来的首节点previous_entry_length大小从1字节转换为五个字节，从而引发连锁更新：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201013200603337.png" class="lazyload" data-srcset="image-20201013200603337.png" srcset="data:image/png;base64,666" alt="image-20201013200603337"/></div><span class="image-caption">image-20201013200603337</span></div><p>尽管连锁更新的复杂度较高，但是真正造成性能问题的几率还是很低的。</p></li></ul><h2 id="第八章-对象"><a href="#第八章-对象" class="headerlink" title="第八章 对象"></a>第八章 对象</h2><ul><li><p>对象的类型和编码：Redis中的对象的结构如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201013201146386.png" class="lazyload" data-srcset="image-20201013201146386.png" srcset="data:image/png;base64,666" alt="image-20201013201146386"/></div><span class="image-caption">image-20201013201146386</span></div><p>其中，type表示对象的类型：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201013201321101.png" class="lazyload" data-srcset="image-20201013201321101.png" srcset="data:image/png;base64,666" alt="image-20201013201321101"/></div><span class="image-caption">image-20201013201321101</span></div><p>对象的ptr指向对象的底层实现数据结构，而这些数据结构有对象的encoding属性决定：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201013201519317.png" class="lazyload" data-srcset="image-20201013201519317.png" srcset="data:image/png;base64,666" alt="image-20201013201519317"/></div><span class="image-caption">image-20201013201519317</span></div><p>每种类型的对象至少使用了两种不同的编码：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201013201632078.png" class="lazyload" data-srcset="image-20201013201632078.png" srcset="data:image/png;base64,666" alt="image-20201013201632078"/></div><span class="image-caption">image-20201013201632078</span></div><p>通过encoding来设定对象的编码，极大提高了Redis的灵活性和效率。</p></li><li><p>字符串对象：编码可以是int，raw或者embstr。</p></li><li><p>列表对象：编码可以是ziplist或者linkedlist。</p></li><li><p>哈希对象：编码可以是ziplist或者hashtable。</p></li><li><p>集合对象：编码可以是intset或者hashtable。</p></li><li><p>有序集合对象：编码可以是ziplist或者skiplist。有序集合同时使用跳跃表可字典来实现的原因是能够让有序集合的查找和范围型的操作都尽可能快的执行，减少时间复杂度。</p></li><li><p>类型检查和命令多态：类型检查的实现是通过键中的类型来进行的，命令的多态则是根据值对象的编码方式进行的。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201013203249016.png" class="lazyload" data-srcset="image-20201013203249016.png" srcset="data:image/png;base64,666" alt="image-20201013203249016"/></div><span class="image-caption">image-20201013203249016</span></div></li><li><p>内存回收：采用引用计数的方式实现垃圾回收。</p></li><li><p>对象共享：对象的引用计数属性还有对象共享的作用。目前来说, Redis会在初始化服务器时, 创建一万个字符串对象, 这些对象包含了从0 到9999的所有整数值, 当服务器需要用到值为0到9999的字符串对象时, 服务器就会使用这些共享对象, 而不是新创建对象。</p></li><li><p>对象的空转时间：redisObject结构还包含了一个属性lru，用于记录对象最后一次被命令程序访问的时间。</p></li></ul><h2 id="第九章-数据库"><a href="#第九章-数据库" class="headerlink" title="第九章 数据库"></a>第九章 数据库</h2><ul><li><p>服务器中的数据库：Redis服务器将所有的数据库保存在服务器状态中的redis.h/redisServer结构db数组中，每个redis.h/redisDb结构代表着一个数据库，另外程序会根据dbnum来决定应该创建多少个数据库：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">redisServer</span> &#123;</span></span><br><span class="line"><span class="comment">// 数据库</span></span><br><span class="line">redisDb *db;</span><br><span class="line"><span class="comment">// 数据库的数量</span></span><br><span class="line"><span class="keyword">int</span> dbnum;</span><br><span class="line"><span class="comment">// ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>切换数据库：通过SELECT命令实现，实际上是通过修改客户端的db指针来实现的</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201018131936321.png" class="lazyload" data-srcset="image-20201018131936321.png" srcset="data:image/png;base64,666" alt="image-20201018131936321"/></div><span class="image-caption">image-20201018131936321</span></div></li><li><p>数据库键空间：每个数据库由RedisDb保存，其中RedisDb.dict保存了数据库中的所有键值对。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201018132511374.png" class="lazyload" data-srcset="image-20201018132511374.png" srcset="data:image/png;base64,666" alt="image-20201018132511374"/></div><span class="image-caption">image-20201018132511374</span></div><p>增删查改都是在dict结构上进行的，另外，在读写键空间的时候，还会执行一些其他的额外操作，比如更新LRU时间，提前判断键是否过期，标记键为dirty等等维护数据库一致性的操作。</p></li><li><p>设置键的生存时间或过期时间：在Redis中有四个不同的命令来设置键的生存时间或者过期时间，分别是EXPIRE, PEXPIRE, EXPIREAT, PEXPIREAT命令，前三个命令都是转换为PEXPIREAT命令执行，转换图如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201018133226586.png" class="lazyload" data-srcset="image-20201018133226586.png" srcset="data:image/png;base64,666" alt="image-20201018133226586"/></div><span class="image-caption">image-20201018133226586</span></div><p>RedisDb结构中的expires字典保存着数据库中所有过期键的过期时间，称该字典是过期字典，其中键是一个指针，指向某个键空间的某个键对象，过期字典的值保存着long long类型的整数，保存着过期时间。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201018133620122.png" class="lazyload" data-srcset="image-20201018133620122.png" srcset="data:image/png;base64,666" alt="image-20201018133620122"/></div><span class="image-caption">image-20201018133620122</span></div><p>由此，查看某个键对应的值之前需要先判断一下是否在过期字典中，同时检测其是否过期。</p></li><li><p>过期键删除策略：定时删除，惰性删除，定期删除。定时删除策略对内存是最友好的:通过使用定时器,定时除策略可以保证过期键会尽 可能快地被删除,并释放过期键所占用的内存。惰性删除策略对CPU时间来说是最友好的:程序只会在取出键时才对键进行过期检查，这可以保证删除过期键的操作只会在非做不可的情况下进行,并且删除的目标仅限于当前处理的键,这个策略不会在删除其他无关的过期键上花费任何CPU时间。定期删除策略每隔一段时间执行一次删除过期键操作,并通过限制删除操作执行的时长和频率来减少删除操作对CPU时间的影响 。</p></li><li><p>Redis的过期键的删除策略：使用惰性删除和定期删除两种策略。惰性删除策略通过db.c/expireIfNeeded函数实现，定期删除则是通过redis.c/activeExpireCycle函数实现（分多次遍历服务器中的各个数据库，从过期字典中随机抽查一部分键的过期时间，并且删除其中的过期键，其中current_db全部变量保存着当前指向到那个数据库中了，下次便利的时候就可以接着从上次数据库的下一个接着检查）。</p></li><li><p>AOF，RDB和复制功能对过期键的处理：</p><ul><li>RDB：在执行SAWE命令或者BGSAVE命令创建一个新的RDB文件时,程序会对数据库中的 键进行检查,已过期的键不会被保存到新创建的RDB文件中。 载入RDB文件的时候，如果服务器以主服务器模式运行，那么在载入RDB文件的时候，程序会剔除过期的键，如果是以从服务器模式运行的话，那么就会保存所有的键。</li><li>AOF：AOF文件重写的时候，会对数据库中的键进行检查，已经过期的键不会保存到AOF文件中。</li><li>复制：当服务器运行在复制模式下面的时候，从服务器的过期键的删除动作由主服务控制，从服务器不会主动删除过期的键，除非主服务器发送DEL命令来显式删除某个键。</li></ul></li><li><p>数据库通知：通过发布订阅模式实现。</p></li></ul><h2 id="第十章-RDB持久化"><a href="#第十章-RDB持久化" class="headerlink" title="第十章 RDB持久化"></a>第十章 RDB持久化</h2><ul><li><p>RDB文件的创建和载入：有两个命令可以用于生成RDB文件，一个是SAVE，另外一个是BGSAVE，后者是非阻塞的。另外由于AOF文件的更新频率比RDB文件的更新频率高一些，会首选AOF文件来恢复数据库状态。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201018141926970.png" class="lazyload" data-srcset="image-20201018141926970.png" srcset="data:image/png;base64,666" alt="image-20201018141926970"/></div><span class="image-caption">image-20201018141926970</span></div><p>虽然BGSAVE执行的时候仍然可以继续处理客户端的请求，但是SAVE，BGSAVE和BGREWRITEAOF命令却不能再次执行。在服务器载入RDB文件的时候，会一直处于阻塞状态，直到载入工作完成为止。</p></li><li><p>自动间隔性保存：当服务器满足一定的条件的时候，就会自动执行相应BGSAVE命令，来及时保存数据库的状态。默认保存条件如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">save 900 1</span><br><span class="line">save 300 10</span><br><span class="line">save 60  10000</span><br></pre></td></tr></table></figure><p>上述代码的含义是900秒之内，至少修改了一次数据库，或者300秒之内，修改了至少10次数据库，或者60秒内，至少修改了10000次数据库，这些配置文件会被保存在saveparams属性中。除了saveparams数组之外，还有一个dirty计数器，以及一个lastsave属性，通过上述三个属性我们就可以判断是否存在必要来执行自动保存功能了。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">redisServer</span> &#123;</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">saveparam</span> *<span class="title">saveparams</span>;</span></span><br><span class="line"><span class="keyword">long</span> <span class="keyword">long</span> dirty;</span><br><span class="line"><span class="keyword">time_t</span> lastsave;</span><br><span class="line"><span class="comment">// ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>RDB文件结构如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201018143358528.png" class="lazyload" data-srcset="image-20201018143358528.png" srcset="data:image/png;base64,666" alt="image-20201018143358528"/></div><span class="image-caption">image-20201018143358528</span></div><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201018143504979.png" class="lazyload" data-srcset="image-20201018143504979.png" srcset="data:image/png;base64,666" alt="image-20201018143504979"/></div><span class="image-caption">image-20201018143504979</span></div><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201018143600755.png" class="lazyload" data-srcset="image-20201018143600755.png" srcset="data:image/png;base64,666" alt="image-20201018143600755"/></div><span class="image-caption">image-20201018143600755</span></div></li></ul><h2 id="第十一章-AOF持久化"><a href="#第十一章-AOF持久化" class="headerlink" title="第十一章 AOF持久化"></a>第十一章 AOF持久化</h2><ul><li><p>AOF持久化的实现：当AOF的功能打开的时候，服务器在完成一个命令的之后，会将其保存在redisServer的aof_buf缓冲区的末尾。Redis的服务器就是一个时间循环，这个循环中负责接受客户端的命令请求，以及向客户端发送命令回复，而时间事件则负责执行serverCron这样需要定时运行的函数。每次结束一个事件循环的时候，需要考虑是否需要将缓冲区的内容写入到AOF文件中。</p></li><li><p>由于AOF文件包含了重建数据库的所有写命令，所以数据库只需要读入并执行一遍AOF里面的命令就可以恢复数据库关闭前的状态。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201018150745174.png" class="lazyload" data-srcset="image-20201018150745174.png" srcset="data:image/png;base64,666" alt="image-20201018150745174"/></div><span class="image-caption">image-20201018150745174</span></div></li><li><p>AOF重写：随着时间的流逝，AOF文件的内容会越来越多，不加以控制的话，会很容易超过体积最大限制造成影响。为了解决这个问题，Redis提供了AOF文件重写的功能。重写功能是通过读取当前数据库的状态来实现的。另外为了提高服务器的可用性，一般执行AOF重写的时候采用的是后台重写，以此防止阻塞的问题。但是使用子进程进行AOF文件的重写的时候，服务器会接受客户端的命令，而新的命令可能会造成数据库状态的修改，从而使得当前数据库状态和重写后的AOF文件保存的数据库状态不一致。为了解决这种数据不一致问题, Redis服务器设置了一个AOF重写缓冲区,这个缓冲区在服务器创建子进程之后开始使用,当 Redis服务器执行完一个写命令之后,它会同时将这个写命令发送给AOF缓冲区和AOF重写缓冲区,如图11-4所示。 </p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201018151801586.png" class="lazyload" data-srcset="image-20201018151801586.png" srcset="data:image/png;base64,666" alt="image-20201018151801586"/></div><span class="image-caption">image-20201018151801586</span></div><p>当子进程完成重写操作的时候，会向父进程发送信号，父进程此时会将AOF重写缓冲区的内容写入到新的AOF文件中，最后执行改名覆盖现有的AOF文件，实现新旧两个AOF文件的替换。</p></li></ul><h2 id="第十二章-事件"><a href="#第十二章-事件" class="headerlink" title="第十二章 事件"></a>第十二章 事件</h2><ul><li><p>Redis服务器是一个事件驱动程序，服务器需要处理两类事件：文件事件，时间事件。文件事件是服务器对套接字的抽象，时间事件则是定时操作的抽象。</p></li><li><p>文件事件：Redis基于<code>Reactor</code>模式开发出了自己的网络事件处理器，这个处理器被称作为文件事件处理器，组成如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201018153202366.png" class="lazyload" data-srcset="image-20201018153202366.png" srcset="data:image/png;base64,666" alt="image-20201018153202366"/></div><span class="image-caption">image-20201018153202366</span></div><p>IO多路复用程序的实现，通过包装常见的select，epoll，evport和kqueue来实现的。</p></li><li><p>时间事件：分为定时事件和周期性事件。目前Redis中只是用了周期性事件，没有使用定时事件。服务器将所有时间事件都放在一个无序链表中,每当时间事件执行器运行时,它就<strong>遍历</strong>整个链表,査找所有已到达的时间事件,并调用相应的事件处理器。 持续运行的Redis服务器需要对自身的资源和状态进行检查和调整，从而可以确保服务器可以长期稳定的运行，这些定期操作被封装到redis.c/serverCron函数中执行。</p></li><li><p>事件的调度与执行：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201018154101415.png" class="lazyload" data-srcset="image-20201018154101415.png" srcset="data:image/png;base64,666" alt="image-20201018154101415"/></div><span class="image-caption">image-20201018154101415</span></div><p>由于时间事件在文件事件之后执行，并且事件之间不会出现抢占，所以时间事件的实际处理时间，通常会比时间事件设定的到达事件稍晚一些。</p></li></ul><h2 id="第十三章-客户端"><a href="#第十三章-客户端" class="headerlink" title="第十三章 客户端"></a>第十三章 客户端</h2><ul><li><p>Redis服务器会为每个客户端创建一个redis.h/redisClient结构，用于保存客户端的信息，Redis服务器中还会保存着一个clients的链表，用于保存所有和服务器相连接的客户端。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201018162408381.png" class="lazyload" data-srcset="image-20201018162408381.png" srcset="data:image/png;base64,666" alt="image-20201018162408381"/></div><span class="image-caption">image-20201018162408381</span></div></li><li><p>客户端属性：通用属性和特定属性。有以下几种属性：</p><ul><li>套接字描述符：fd，为客户端为-1，否则为大于-1的整数。</li><li>名字：name</li><li>标志：flags，记录了客户端的角色</li><li>输入缓冲区：querybuf，保存客户端发送的命令请求</li><li>命令和命令参数：argc和argv，服务器对querybuf解析后将参数的个数和参数存入这两个变量</li><li>命令的实现函数：cmd，当服务器解析出来命令之后，就可以查找对应的命令的实现函数，然后将其指针值复制到client中</li><li>输出缓冲区：buf[MAX_BYTES]，命令回复会保存在这里面</li><li>身份验证：authenticated，记录客户端是否通过了身份验证</li><li>时间：包含客户端创建的时间，最后一次和服务器互动的时间</li></ul></li><li><p>客户端的创建和关闭：如果是普通的客户端，那么就会在clients链表后面追加上一个redisClient结构。服务器使用两种模式来限制客户端缓冲区的大小：硬性限制，软性限制。另外，处理Lua脚本的为客户端在服务器初始化时创建，知道服务器关闭，而AOF文件载入的时候的伪客户端则在载入结束之后关闭。</p></li></ul><h2 id="第十四章-服务器"><a href="#第十四章-服务器" class="headerlink" title="第十四章 服务器"></a>第十四章 服务器</h2><ul><li>命令请求的执行过程：客户端发送命令请求，服务器端读取命令请求，接下来分析命令，查找命令表获取命令实现函数，调用获取到的命令实现函数，命令实现函数执行完后执行后续的工作，最后将命令回复发送给客户端，客户端接受并且打印命令回复。</li><li>ServerCron函数每隔100毫秒执行一次，这个函数负责管理服务器的资源，并且保持服务器自身的良好运转。它具有以下功能：<ul><li>更新服务器事件缓存</li><li>更新LRU时钟</li><li>更新服务器每秒执行命令次数</li><li>更新服务器内存峰值记录</li><li>处理SIGTERM信号</li><li>管理客户端的资源</li><li>管理数据库的资源</li><li>执行被延迟的BGREWRITEAOF</li><li>检查持久化操作的运行状态</li><li>将AOF缓冲区的内容写入AOF文件</li><li>关闭异步客户端</li><li>增加cronloops计数器的值</li></ul></li><li>初始化服务器：<ul><li>初始化服务器的状态结构</li><li>载入配置选项</li><li>初始化服务器数据结构</li><li>还原数据库状态</li><li>执行事件循环</li></ul></li></ul><h2 id="第十五章-复制"><a href="#第十五章-复制" class="headerlink" title="第十五章 复制"></a>第十五章 复制</h2><ul><li><p>在Redis中，用户通过命令SLAVEOF让一个服务器去复制另外一个服务器，被复制的服务器成为主服务器，对主服务器进行复制的服务器称为从服务器。</p></li><li><p>旧版复制功能的实现：</p><ul><li><p>同步：将从服务器的数据库状态更新至主服务器当前所处的数据库状态。通过SYNC命令完成：</p><ul><li>从服务器向主服务器发送SYNC命令</li><li>主服务器执行BGSAVE命令，后台生成RDB文件，同时用一个缓冲区记录从现在开始执行后的所有写命令</li><li>RDB生成后，将其发送给从服务器，从服务器加载RDB文件</li><li>从服务器加载完成后，主服务器将缓冲区里面的所有写命令发送给从服务器，保持一致性</li></ul><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201023194004571.png" class="lazyload" data-srcset="image-20201023194004571.png" srcset="data:image/png;base64,666" alt="image-20201023194004571"/></div><span class="image-caption">image-20201023194004571</span></div></li><li><p>命令传播：当主服务的数据库状态被修改的时候，此时造成数据库状态的不一致性，通过命令传播让主从服务器状态重新回到一致状态。</p></li></ul></li><li><p>旧版复制功能的缺陷：复制可以分为初次复制和断线后重复制，旧版复制功能并没有很好解决断线后重复制时间长的问题：只需要将断线后的命令发送给从服务器就行，不需要全部复制一遍。</p></li><li><p>新版复制功能的实现：新版复制功能使用PSYNC命令代替SYNC命令来执行同步操作。PSYNC命令有完整重同步和部分重同步两种模式，前者用于处理初次复制的情况，后者用于处理断线后重复制情况。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201023194735822.png" class="lazyload" data-srcset="image-20201023194735822.png" srcset="data:image/png;base64,666" alt="image-20201023194735822"/></div><span class="image-caption">image-20201023194735822</span></div></li><li><p>部分重同步的实现：</p><ul><li>主从服务器的复制偏移量：主服务器每次向从服务器传播N个字节的数据时，就将自己的复制偏移量加上N，从服务器每次收到主服务器传播过来的N个字节的数据时，就将自己的复制偏移量加上N，通过对比主从服务器的复制偏移量，可以很容易知道主从服务器是否处于一致状态</li><li>服务器的复制积压缓冲区：由主服务器维护的一个固定长度的先进先出的队列，默认1MB。当主服务器进行命令传播的时候，不仅将写命令发送到从服务器，还将写命令入队到复制积压缓冲区里面。当从服务器重新连接到主服务器的时候，根据offset偏移量之后的数据在缓冲区里面，执行部分重同步，否则执行完整重同步</li><li>服务器的运行ID：每个Redis服务器都有自己的运行ID。初次复制的时候，主服务器向从服务器发送自己的ID，从服务器重新连接的时候，通过ID和重连服务器的ID比对来判断是否重连到相同的主服务器</li></ul></li><li><p>PSYNC命令的实现：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201023201400872.png" class="lazyload" data-srcset="image-20201023201400872.png" srcset="data:image/png;base64,666" alt="image-20201023201400872"/></div><span class="image-caption">image-20201023201400872</span></div></li><li><p>复制的实现：</p><ul><li>设置主服务器的地址和端口</li><li>建立套接字连接</li><li>发送PING命令，检测网络是否通畅，不通畅的话断开并且重连</li><li>身份验证</li><li>发送端口信息</li><li>同步</li><li>命令传播</li></ul></li><li><p>心跳检测：在命令传播阶段，从服务器默认会每秒一次的频率，向主服务器发送<code>REPLCONF ACK &lt;replication_offset&gt;</code>，其作用有：</p><ul><li><p>检测主从服务器的网络连接状态</p></li><li><p>辅助实现min-slaves选项：可以防止主服务器在不安全的情况下执行写命令，如配置min-slaves-to-write为3，那么在从服务器的数量小于3时，拒接执行写命令</p></li><li><p>检测命令丢失：如果丢包的话，通过offset实现一致性</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201023202834446.png" class="lazyload" data-srcset="image-20201023202834446.png" srcset="data:image/png;base64,666" alt="image-20201023202834446"/></div><span class="image-caption">image-20201023202834446</span></div></li></ul></li></ul><h2 id="第十六章-Sentinel"><a href="#第十六章-Sentinel" class="headerlink" title="第十六章 Sentinel"></a>第十六章 Sentinel</h2><ul><li><p>Sentinel是Redis的高可用性解决方案：由一个或多个Sentinel实例组成的Sentinel系统可以监视任意多个主服务器，以及这些主服务器属下的所有从服务器，当被监视的主服务器进入下线的状态时，自动将下线服务器的某个从服务器升级为新的主服务器，然后由新的主服务器代替已经下线的主服务器处理命令请求，当原来的主服务器又重新上线的时候，将其设置为新的主服务器的一个从服务器。</p></li><li><p>启动并初始化Sentinel：</p><ul><li><p>初始化服务器：Sentinel本质上是一个运行在特殊模式下的Redis服务器，但是初始化的时候不载入数据</p></li><li><p>使用Sentinel专用代码</p></li><li><p>初始化Sentinel状态：服务器会初始化一个sentinelState结构</p></li><li><p>初始化Sentinel的masters属性：键是被监视主服务器的名字，值是被监视主服务器对应的sentinelRedisInstance结构，每个这样的结构代表一个被Sentinel监视的实例，可以是主服务器，从服务器，或者另外一个Sentinel</p></li><li><p>创建连向主服务器的网络连接：会创建两个连接，一个是命令链接，另外一个是订阅连接</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201023205141243.png" class="lazyload" data-srcset="image-20201023205141243.png" srcset="data:image/png;base64,666" alt="image-20201023205141243"/></div><span class="image-caption">image-20201023205141243</span></div></li></ul></li><li><p>获取主服务器信息：Sentinel没十秒一次的频率，向被监视的主服务器发送INFO命令，获取当前信息。当Sentinel分析INFo命令中包含的从服务器的信息的时候，会检查从服务器对应的实例是否存在于其主服务器实例slaves字典中，存在的话更新相关信息，否则的话创建新的实例</p></li><li><p>获取从服务器信息：Sentinel没十秒一次的频率，向被监视的从服务器发送INFO命令，获取当前信息。会对从服务器实例进行更新</p></li><li><p>向主服务器和从服务器发送信息：默认情况下，PUBLISH信息到主从服务器：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201023210209159.png" class="lazyload" data-srcset="image-20201023210209159.png" srcset="data:image/png;base64,666" alt="image-20201023210209159"/></div><span class="image-caption">image-20201023210209159</span></div></li><li><p>接收来自主从服务器的频道信息：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201023210251707.png" class="lazyload" data-srcset="image-20201023210251707.png" srcset="data:image/png;base64,666" alt="image-20201023210251707"/></div><span class="image-caption">image-20201023210251707</span></div><ul><li>更新sentinels字典</li><li>创建连接其他Sentinel的命令连接</li></ul><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201023210330916.png" class="lazyload" data-srcset="image-20201023210330916.png" srcset="data:image/png;base64,666" alt="image-20201023210330916"/></div><span class="image-caption">image-20201023210330916</span></div></li><li><p>检测主观下线行为：默认情况下，Sentinel每秒向其创建了命令连接的实例发送PING命令，通过PONG回复检测是否在线。如果一个实例在down-after-millseconds毫秒内，连续向Sentinel返回无效回复，那么Sentinel会修改这个实例的结构，将flags属性中的SRI_S_DOWN标示，表示其主观下线。</p></li><li><p>检查客观下线状态：当Sentinel讲一个服务器判断为主观下线之后，为了确保是否真的下线了，需要向其他监视了这个服务器的Sentinel进行询问，看他们是否也认为主服务器也已经进入了下线状态。当接收到足够的下线判断之后，Sentinel就会将从服务器判定为客观下线，并对主服务器执行故障转移操作。</p></li><li><p>选举领头Sentinel：当一个主服务器被判断为客观下线时，监视这个下线服务器的各个Sentinel会进行协商，选举出一个领头Snetinel，由领头Sentinel对下线服务器执行故障转移操作。</p><blockquote><p>Raft算法的领头选举方法的实现。</p></blockquote></li><li><p>故障转移：</p><ul><li>选出新的主服务器</li><li>修改从服务器的复制目标</li><li>将旧的主服务器变为从服务器</li></ul></li></ul><h2 id="第十七章-集群"><a href="#第十七章-集群" class="headerlink" title="第十七章 集群"></a>第十七章 集群</h2><ul><li><p>Redis 集群是 Redis 提供的分布式数据库方案, 集群通过分片(sharding)来进行数据共享, 并提供复制和故障转移功能。</p></li><li><p>节点：一个 Redis 集群通常由多个节点(node)组成，在刚开始的时候，每个节点都是相互独立的，它们都处于一个只包含自已的集群当中，要组建一个真正可工作的集群，我们必须将各个独立的节点连接起来，构成一个包含多个节点的集群。</p><ul><li><p>启动节点：节点实际上就是一个运行在集群模式下的 Redis 服务器，通过 cluster-enabled 选项进行配置。</p></li><li><p>集群数据结构：clusterNode 结构保存了一个节点的当前状态，CLusterState 结构记录了在当前节点的视角下，集群目前所处的状态</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201025134655648.png" class="lazyload" data-srcset="image-20201025134655648.png" srcset="data:image/png;base64,666" alt="image-20201025134655648"/></div><span class="image-caption">image-20201025134655648</span></div></li><li><p>CLUSTER MEET命令实现：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201025134751665.png" class="lazyload" data-srcset="image-20201025134751665.png" srcset="data:image/png;base64,666" alt="image-20201025134751665"/></div><span class="image-caption">image-20201025134751665</span></div></li></ul></li><li><p>槽指派：Redis 集群通过分片的方式来保存数据库中的键值对：集群的整个数据库被分为16384个槽(slot)，数据库中的每个键都属于这16384个槽的其中一个，集群中的每个节点可以处理0个或最多16384个槽。当数据库中的16384个槽都有节点在处理时，集群处于上线状态(ok)；相反地，如果数据库中有任何一个槽没有得到处理，那么集群处于下线状态(fail)。</p><ul><li><p>记录节点的槽指派信息：clusterNode 结构中的slots属性记录了节点当前负责处理那些槽：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201025135100354.png" class="lazyload" data-srcset="image-20201025135100354.png" srcset="data:image/png;base64,666" alt="image-20201025135100354"/></div><span class="image-caption">image-20201025135100354</span></div><p>slots数组是一个二进制数组，为 1 则该节点负责该槽，否则不负责该槽。</p></li><li><p>传播节点的槽指派信息：当节点 A 通过消息从节点 B 那里接收到节点 B 的 s1ots 数组时,节点 A 会在自已的 clusterState.nodes字典中査找节点 B 对应的 clusterNode 结构,并对结构中的 slots 数组进行保存或者更新</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201025135431790.png" class="lazyload" data-srcset="image-20201025135431790.png" srcset="data:image/png;base64,666" alt="image-20201025135431790"/></div><span class="image-caption">image-20201025135431790</span></div></li><li><p>记录集群所有槽的指派信息：clusterState 结构中的 slots 数组记录了集群中所有的 16384 个槽的指派信息</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201025135633822.png" class="lazyload" data-srcset="image-20201025135633822.png" srcset="data:image/png;base64,666" alt="image-20201025135633822"/></div><span class="image-caption">image-20201025135633822</span></div></li><li><p>CLUSTER ADDSLOTS命令的实现：首先改动 clusterState.slots 指针，将对应槽指向自己，然后修改clusterNode.slots 数组，将对应的 slots 置位。</p></li></ul></li><li><p>在集群中执行命令：当集群的16384个槽都指派后，集群就会进入上线状态，这时客户端就可以向集群中的节点发送命令了。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201025140106534.png" class="lazyload" data-srcset="image-20201025140106534.png" srcset="data:image/png;base64,666" alt="image-20201025140106534"/></div><span class="image-caption">image-20201025140106534</span></div><ul><li>计算键输入哪个槽：<code>CRC16(key) &amp; 16383</code></li><li>判断槽是否由当前节点负责处理：clusterState.slots[i] == clusterState.myself</li><li>MOVED 错误：当节点发现键所在的槽不由自己处理的时候，返回<code>MOVED &lt;SLOT&gt; &lt;ip&gt;:&lt;addr&gt;</code>，客户端自动转向到对应的节点，再次发送命令</li><li>节点数据库的实现：集群节点保存键值对的方式和单机 Redis 服务器保存方式完全相同。唯一区别是节点只能使用0号数据库。另外，节点会使用 clusterState.slots_of_keys 跳跃表保存槽和键之间的关系，命令<code>CLUSTER GETKEYSINSLOT &lt;slot&gt; &lt;count&gt;</code>就是建立在该结构上的。</li></ul></li><li><p>重新分片：Redis 集群的重新分片操作可以将任意数量已经指派给某个节点(源节点)的槽改为指派给另一个节点(目标节点)，并且相关槽所属的键值对也会从源节点被移动到目标节点。重新分片操作可以在线(online)进行,在重新分片的过程中，集群不需要下线，并且源节点和目标节点都可以继续处理命令请求。以下是对单个槽slot流程：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201025141051856.png" class="lazyload" data-srcset="image-20201025141051856.png" srcset="data:image/png;base64,666" alt="image-20201025141051856"/></div><span class="image-caption">image-20201025141051856</span></div></li><li><p>ASK错误：当执行分片期间，可能会存在这样一种情况：输入被迁移槽的一部分节点键值对保存在源节点里面，另外一部分保存在目标节点里面。此时响应客户端的命令如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201025141341148.png" class="lazyload" data-srcset="image-20201025141341148.png" srcset="data:image/png;base64,666" alt="image-20201025141341148"/></div><span class="image-caption">image-20201025141341148</span></div><ul><li><p><code>CLSUTER SETSLOT IMPORTING</code>命令的实现：clusterState.importing_slots_from 记录了当前节点正在从其他节点导入的槽。</p></li><li><p><code>CLUSTER SETSLOT MIGRATING</code>命令的实现：clusterState.migrating_slots_to 数组记录当前节点正在迁移至其他节点的槽。</p></li><li><p>ASK错误：如果槽正在迁移，会发送<code>ASK &lt;SLOT&gt; &lt;ip&gt;:&lt;port&gt;</code></p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201025142210744.png" class="lazyload" data-srcset="image-20201025142210744.png" srcset="data:image/png;base64,666" alt="image-20201025142210744"/></div><span class="image-caption">image-20201025142210744</span></div><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201025142157014.png" class="lazyload" data-srcset="image-20201025142157014.png" srcset="data:image/png;base64,666" alt="image-20201025142157014"/></div><span class="image-caption">image-20201025142157014</span></div></li><li><p>ASKING命令：打开发送该命令的客户端的 REDIS_ASKING 标示，该标示是一个一次性标示，当成功执行完一次命令的时候，此时该标示就会被移除。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201025142144327.png" class="lazyload" data-srcset="image-20201025142144327.png" srcset="data:image/png;base64,666" alt="image-20201025142144327"/></div><span class="image-caption">image-20201025142144327</span></div></li><li><p>ASK错误和MOVED错误：前者发生在节点间迁移槽的时候，是一种临时措施，后者发生在槽的负责权已经从一个节点迁移到了另外一个节点。</p></li></ul></li><li><p>复制与故障转移：Redis 集群中的节点分为主节点和从节点，主节点用于处理槽，从节点用于复制。故障转移措施和第十五章类似。</p><ul><li>设置从节点：<code>CLUSTER REPLICATE &lt;node_id&gt;</code>让接受命令的节点成为 node_id 所指向节点的从节点。此时从节点中设置 clusterState.myself.slaveof 属性，主节点设置 clusterNode.slaves 属性。</li><li>故障检测：集群中每个节点定期向其他节点发送 PING 消息，以此检测是否在线，如果超时，标记为 PFAIL（probable fail）。在集群中超过半数的节点都认为某个主节点 PFAIL，那么这个节点会被标记为下线（FAIL），同时广播这条消息。</li><li>故障转移：从FAIl 的主节点的从节点里面选择一个作为主节点，然后将原来主节点的额槽指派给自己，新的主节点广播 PONG 信息，让其他的节点知道这个节点已经选为主节点，最后新的节点开始接收和负责处理自己的槽有关的命令请求，故障转移完成。</li><li>选举新的节点：Raft 算法。</li></ul></li><li><p>消息：节点发送的消息一般有五种：MEET 消息，PING 消息，PONG 消息，FAIL 消息，PUBLISH 消息。</p></li></ul><h2 id="第十八章-发布与订阅"><a href="#第十八章-发布与订阅" class="headerlink" title="第十八章 发布与订阅"></a>第十八章 发布与订阅</h2><ul><li><p>Redis 的发布与订阅的功能由 PUBLISH，SUBSCRIBE，PSUBSCRIB 等命令组成，每当有其他客户端向被订阅的频道发送消息时，频道的所有订阅者都会收到这个消息。</p></li><li><p>频道的订阅与退订：Redis 将所有订阅关系保存在RedisServer.pubsub_channels 字典里面，键是某个被订阅的频道，键值则是一个链表，保存着所有订阅这个频道的客户端。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201019225402536.png" class="lazyload" data-srcset="image-20201019225402536.png" srcset="data:image/png;base64,666" alt="image-20201019225402536"/></div><span class="image-caption">image-20201019225402536</span></div><ul><li>订阅频道：如果有频道已经在字典中，直接尾部插入订阅者，否则创建字典项，键为频道，键值为该客户端</li><li>退订频道：根据被退订的频道名字，从订阅者链表中删去客户端，如果此时订阅者链表为空，则删除对应的字典项</li></ul></li><li><p>模式的订阅与退订：Redis 将所有模式的订阅关系保存在RedisServer.pubsub_patterns 属性里面。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201019225859198.png" class="lazyload" data-srcset="image-20201019225859198.png" srcset="data:image/png;base64,666" alt="image-20201019225859198"/></div><span class="image-caption">image-20201019225859198</span></div><ul><li>订阅模式：新建一个pubsubPattern结构，设置好client和pattern属性，然后将其加入到pubsub_patterns 链表的表尾。</li><li>退订模式：从pubsub_patterns中查找对应的被退订的pubsubPattern结构，然后将其删除。</li></ul></li><li><p>发送消息：当执行<code>PUBLISH &lt;channel&gt; &lt;message&gt;</code>时候，服务器需要将消息message发送到对应的channel的所有订阅者，另外如果有模式匹配这个channel，那么需要将message发送给pattern模式的订阅者。</p><ul><li>将消息发送给频道订阅者：从pubsub_channels 字典里面找到订阅者链表，然后将消息发送给名单上的所有客户端</li><li>将消息发送给模式订阅者：遍历pubsub_patterns链表，查找那些与channel频道匹配的模式，并且将消息发送到这些模式的客户端。</li></ul></li><li><p>查看订阅消息：PUBSUB命令可以查看频道或者模式的相关信息</p><ul><li>PUBSUB CHANNELS [pattern]：返回与pattern匹配的频道</li><li>PUBSUB NUMSUB [channel-1 channel-2]:返回频道对应订阅者的数量</li><li>PUBSUB NUMPAT: 返回当前服务器被订阅模式的数量</li></ul></li></ul><h2 id="第十九章-事务"><a href="#第十九章-事务" class="headerlink" title="第十九章 事务"></a>第十九章 事务</h2><ul><li><p>Redis通过MULTI，EXEC，WATCH等命令实现事务功能。在事务执行期间，服务器不会中断事务去执行其他客户端的请求，他会将事务中的命令执行完毕之后才去处理其他的客户端的请求。</p></li><li><p>事务的实现：包括三个部分，如下：</p><ul><li><p>事务开始：MULTI命令的执行标志者事务的开始，会将执行该命令的客户端从非事务状态转换为事务状态</p></li><li><p>命令入队：当客户端处于事务状态之后，如果客户端发送的指令是EXEC，DISCARD，WATCH，MULTI命令之一，那么立即执行，否则的话将其放入事务队列之中，然后返回QUEUED回复。每个Redis客户端都有自己的事务状态 mstate，里面包含一个事务队列：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201020233625705.png" class="lazyload" data-srcset="image-20201020233625705.png" srcset="data:image/png;base64,666" alt="image-20201020233625705"/></div><span class="image-caption">image-20201020233625705</span></div></li><li><p>执行事务：当发送EXEC命令的时候，此时就开始执行遍历这个客户端的事务队列，执行其中的所有命令，然后将得到的回复返回给客户端。</p></li></ul></li><li><p>WATCH命令的实现：WATCH命令是一个乐观锁，它可以在EXEC命令执行之前，监视任意数量的数据库键，并且在EXEC命令执行的时候，检查被监视的键中是否至少有一个已经被修改过了，如果是的话，服务器将拒绝执行事务，并向客户端返回执行失败的空回复。</p><ul><li><p>WATCH命令监视数据库键：每个Redis数据库都保存着一个watched_keys字典，字典的键是某个数据库键，而字典的值则是一个链表，记录所有的监视相应数据库键的客户端：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">redisDb</span> &#123;</span></span><br><span class="line">dict *watched_keys;</span><br><span class="line"><span class="comment">// ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>监视机制的触发：所有对数据库进行修改的命令，在执行之后会调用touchWatchKey函数对监视字典进行检查，如果某个键被修改，会将对应的客户端REDIS_DIRTY_CAS标示打开，表示客户端的安全性已经被破坏。</p></li><li><p>判断事务是否安全：服务器根据客户端的REDIS_DIRTY_CAS标识来决定是否执行事务：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201021120010867.png" class="lazyload" data-srcset="image-20201021120010867.png" srcset="data:image/png;base64,666" alt="image-20201021120010867"/></div><span class="image-caption">image-20201021120010867</span></div></li></ul></li><li><p>事务的ACID性质：在Redis中，事务总是具有原子性，一致性，隔离性，当Redis运行在某种持久化模式下，也具有持久性。</p><ul><li><p>原子性：数据库将事务中的多个操作当作一个整体来执行,服务器要么就执行事务中的所有操作,要么就一个操作也不执行。 Redis的事务和传统的关系型数据库事务的最大区别在于, Redis不支持事务回滚机制 (rollback),即使事务队列中的某个命令在执行期间出现了错误,整个事务也会继续执行下去,直到将事务队列中的所有命令都执行完毕为止。</p><blockquote><p>Redis的作者在事务功能的文档中解释说,不支持事务回滚是因为这种复杂的功能和 Redis追求简单高效的设计主旨不相符,并且他认为, Redis事务的执行时错误通常都是编 程错误产生的,这种错误通常只会出现在开发环境中,而很少会在实际的生产环境中出现 所以他认为没有必要为 Redis开发事务回滚功能。 </p></blockquote></li><li><p>一致性：如果数据库在执行事务之前是一致的，那么在事务执行之后，不论事务是否执行成功，数据库也应该仍然是一致的。Redis事务可能出错的地方有入队错误，执行错误，服务器宕机。</p></li><li><p>隔离性：即使数据库中有多个事务并发地执行,各个事务之间也不会互相影响,并且在并发状态下执行的事务和串行执行的事务产生的结果完全相同。 因为 Redis使用单线程的方式来执行事务(以及事务队列中的命令),并且服务器保证在执行事务期间不会对事务进行中断,因此, Redis的事务总是以串行的方式运行的,并且事务也总是具有隔离性的。</p></li><li><p>持久性：当一个事务执行完毕时,执行这个事务所得的结果已经被保存到永久性存储介质(比如硬盘)里面了, 即使服务器在事务执行完毕之后停机, 执行事务所得的结果也不会丢失。只有当服务器运行在AOF持久化模式下，并且appendfsync选项的值为ALWAYS的时候，这种配置下的事务是具有持久性的。</p></li></ul></li></ul><h2 id="第二十一章-排序"><a href="#第二十一章-排序" class="headerlink" title="第二十一章 排序"></a>第二十一章 排序</h2><ul><li><p><code>SORT &lt;key&gt;</code> 命令的实现：假设已经执行<code>RPUSH numbers 3 1 2</code>, 现在执行<code>SORT numbers</code>，</p><ul><li><p>首先创建一个和numbers列表长度相同的数组，数组的每一项是redis.h/redisSortObject结构</p></li><li><p>遍历数组，将数组项的obj指针指向对应的列表项，一一对应</p></li><li><p>遍历数组，将obj指针指向的列表项转换为一个double类型的浮点数，存到u.score中</p></li><li><p>根据u.score中的值，进行升序排序</p></li><li><p>遍历数组，将各个数组项的obj指针指向的列表项返回给客户端</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201021165824509.png" class="lazyload" data-srcset="image-20201021165824509.png" srcset="data:image/png;base64,666" alt="image-20201021165824509"/></div><span class="image-caption">image-20201021165824509</span></div><p>redisSortObject结构如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201021165903649.png" class="lazyload" data-srcset="image-20201021165903649.png" srcset="data:image/png;base64,666" alt="image-20201021165903649"/></div><span class="image-caption">image-20201021165903649</span></div></li></ul></li><li><p>ALPHA选项实现：字典序排序</p></li><li><p>ASC选项和DESC选项的实现：默认是升序排序，升序和降序排序只不过是排序算法使用的对比函数不同而已。</p></li><li><p>BY选项实现：默认情况下，SORT命令使用被排序键包含的元素作为排序的权重，元素本身决定了排序所处的位置。可以使用BY选项来改变这种情况。</p></li><li><p>带有ALPHA选项的BY选项的实现：BY选项默认权重值保存的值是数字值，如果是字符串值的话，需要在使用By选项的同时，配合使用ALPHA选项。</p></li><li><p>LIMIT选项的实现：<code>LIMIT &lt;offset&gt; &lt;count&gt;</code>。</p></li><li><p>GET选项的实现：更具被排序结果中的元素，查找相关的信息。</p></li><li><p>STORE选项的实现：STORE选项可以保存排序结果在指定的键里面</p></li><li><p>多个选项的执行顺序：排序，限制长度，获取外部键，保存排序结果集。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201021171157237.png" class="lazyload" data-srcset="image-20201021171157237.png" srcset="data:image/png;base64,666" alt="image-20201021171157237"/></div><span class="image-caption">image-20201021171157237</span></div><p>除了GET选项外，改变选项的摆放顺序不会影响SORT命令执行这些选项的顺序。</p></li></ul><h2 id="第二十三章-慢查询日志"><a href="#第二十三章-慢查询日志" class="headerlink" title="第二十三章 慢查询日志"></a>第二十三章 慢查询日志</h2><ul><li><p>慢查询日志：记录执行时间超过指定时长的命令请求，用户可以通过该功能产生的日志来优化查询速度。服务器有两个和慢查询日志相关的选项：</p><ul><li>slowlog-log-slower-than: 指定执行时间上限，超过上限的会被记录到日志上</li><li>slowlog-max-len: 记录慢查询日志最大条数</li></ul></li><li><p>慢查询日志记录的保存：服务器状态中有几个和慢查询日志有关的属性：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201021171836148.png" class="lazyload" data-srcset="image-20201021171836148.png" srcset="data:image/png;base64,666" alt="image-20201021171836148"/></div><span class="image-caption">image-20201021171836148</span></div><p>其中slowlog链表保存所有的慢查询日志。每个节点是一个slowlogEntry：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201021172036568.png" class="lazyload" data-srcset="image-20201021172036568.png" srcset="data:image/png;base64,666" alt="image-20201021172036568"/></div><span class="image-caption">image-20201021172036568</span></div></li><li><p>慢查询日志的阅览和删除：遍历查询和遍历删除</p></li><li><p>添加新日志：对慢查询日志进行头插法插入</p></li></ul><h2 id="第二十四章-监视器"><a href="#第二十四章-监视器" class="headerlink" title="第二十四章 监视器"></a>第二十四章 监视器</h2><ul><li><p>通过执行MONITOR命令，客户端可以将自己变为一个监视器，实时接收并打印服务器当前处理的命令请求。</p></li><li><p>成为监视器：执行MONITOR命令后。客户端的REDIS_MONITOR标志会被打开，并且这个客户端会被添加到monitors链表的表尾。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="image-20201021172607447.png" class="lazyload" data-srcset="image-20201021172607447.png" srcset="data:image/png;base64,666" alt="image-20201021172607447"/></div><span class="image-caption">image-20201021172607447</span></div></li><li><p>向监视器发送命令信息：服务器每次执行命令之前，都会调用replicationFeedMonitor函数，由这个函数将命令请求信息发送给各个监视器。</p></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>使用 Travis CI持续部署博客</title>
      <link href="2020/04/11/%E4%BD%BF%E7%94%A8-Travis-CI%E6%8C%81%E7%BB%AD%E9%83%A8%E7%BD%B2%E5%8D%9A%E5%AE%A2/"/>
      <url>2020/04/11/%E4%BD%BF%E7%94%A8-Travis-CI%E6%8C%81%E7%BB%AD%E9%83%A8%E7%BD%B2%E5%8D%9A%E5%AE%A2/</url>
      
        <content type="html"><![CDATA[<p>本文主要介绍使用 Travis 来自动将我们的博客内容 push 到 Github Page 上，也就是所谓的持续集成/持续部署。</p><a id="more"></a><h2 id="持续集成"><a href="#持续集成" class="headerlink" title="持续集成"></a>持续集成</h2><p>Travis CI 提供的是持续集成服务（Continuous Integration，简称 CI）。它绑定 Github 上面的项目，只要有新的代码，就会自动抓取。然后，提供一个运行环境，执行测试，完成构建，还能部署到服务器。</p><p>持续集成指的是只要代码有变更，就自动运行构建和测试，反馈运行结果。确保符合预期以后，再将新代码”集成”到主干。</p><p>持续集成的好处在于，每次代码的小幅变更，就能看到运行结果，从而不断累积小的变更，而不是在开发周期结束时，一下子合并一大块代码。</p><h2 id="使用-Travis-持续部署博客"><a href="#使用-Travis-持续部署博客" class="headerlink" title="使用 Travis 持续部署博客"></a>使用 Travis 持续部署博客</h2><p>我们的博客使用 Hexo 生成，博客的仓库是名是<code>&lt;username&gt;.github.io</code>。有两个分支，其中 master 分支用于放置我们的内容，而 hexo-project 分支用于存储我们的 hexo 工程文件。</p><p>首先登录到官网：travis-ci.org，接着点击右上角个人头像，选择博客的仓库，并且打开开关。一旦我们激活了这个仓库，那么 Travis 就能监听这个仓库的所有变化。</p><h2 id="travis-yml"><a href="#travis-yml" class="headerlink" title=".travis.yml"></a>.travis.yml</h2><p>Travis 要求项目的根目录下面，必须有一个.travis.yml文件。这是配置文件，指定了 Travis 的行为。该文件必须保存在 Github 仓库里面，一旦代码仓库有新的 Commit，Travis 就会去找这个文件，执行里面的命令。</p><p>对于我们的要求，我们只需要配置如下就行：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 开发语言和版本</span></span><br><span class="line"><span class="attr">language:</span> <span class="string">node_js</span></span><br><span class="line"><span class="attr">node_js:</span> <span class="string">stable</span></span><br><span class="line"><span class="comment"># 监听分支</span></span><br><span class="line"><span class="attr">branches:</span></span><br><span class="line">  <span class="attr">only:</span> <span class="string">hexo-project</span></span><br><span class="line"><span class="comment"># 缓存  </span></span><br><span class="line"><span class="attr">cache:</span> </span><br><span class="line">  <span class="attr">directories:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">node_modules</span></span><br><span class="line">    </span><br><span class="line"><span class="attr">before_install:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">npm</span> <span class="string">install</span> <span class="string">-g</span> <span class="string">hexo-cli</span></span><br><span class="line"><span class="comment"># 安装依赖  </span></span><br><span class="line"><span class="attr">install:</span> </span><br><span class="line">  <span class="bullet">-</span> <span class="string">npm</span> <span class="string">install</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">npm</span> <span class="string">install</span> <span class="string">hexo-deployer-git</span> <span class="string">--save</span></span><br><span class="line"><span class="comment"># 执行脚本  </span></span><br><span class="line"><span class="attr">script:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">hexo</span> <span class="string">clean</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">hexo</span> <span class="string">g</span></span><br><span class="line"><span class="comment"># 将博客内容部署到 master 分支中</span></span><br><span class="line"><span class="attr">after_success:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">cd</span> <span class="string">./public</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">git</span> <span class="string">init</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">git</span> <span class="string">add</span> <span class="string">--all</span> <span class="string">.</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">git</span> <span class="string">commit</span> <span class="string">-m</span> <span class="string">&quot;Travis CI Auto Build&quot;</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">git</span> <span class="string">config</span> <span class="string">user.name</span> <span class="string">&quot;username&quot;</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">git</span> <span class="string">config</span> <span class="string">user.email</span> <span class="string">&quot;emial&quot;</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">git</span> <span class="string">push</span> <span class="string">--quiet</span> <span class="string">--force</span> <span class="string">https://$&#123;GH_TOKEN&#125;@$&#123;GH_REF&#125;</span> <span class="string">master:master</span></span><br><span class="line"><span class="comment"># 设置环境变量  </span></span><br><span class="line"><span class="attr">env:</span></span><br><span class="line">  <span class="attr">global:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">GH_REF:</span> <span class="string">github.com/&lt;username&gt;/&lt;username&gt;.github.io.git</span></span><br></pre></td></tr></table></figure><p>其中，我们需要获取到<code>&#123;GH_TOKEN&#125;</code>，这是用于我们能够正常访问 Github API 的基础。</p><blockquote><p>Tokens you have generated that can be used to access the <a href="https://developer.github.com/">GitHub API</a>.</p></blockquote><p>可以在<code>用户-&gt;setting-&gt;Personal access token</code>中创建 Token。</p><p>之后，在 Travis 网站相应的仓库中设置环境变量就可以了。</p><p>另外，如果想要获取 build 的状态图片，可以在 Travis 中将图片的 markdown 格式复制下来，放在 readme.md 中。</p>]]></content>
      
      
      
        <tags>
            
            <tag> CI/CD </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Nodejs 用户注册登录和授权处理</title>
      <link href="2020/04/11/Nodejs-%E7%94%A8%E6%88%B7%E6%B3%A8%E5%86%8C%E7%99%BB%E5%BD%95%E5%92%8C%E6%8E%88%E6%9D%83%E5%A4%84%E7%90%86/"/>
      <url>2020/04/11/Nodejs-%E7%94%A8%E6%88%B7%E6%B3%A8%E5%86%8C%E7%99%BB%E5%BD%95%E5%92%8C%E6%8E%88%E6%9D%83%E5%A4%84%E7%90%86/</url>
      
        <content type="html"><![CDATA[<p>本文介绍 Nodejs 搭配 Express 框架实现服务器中常见的功能：用户注册登录和授权的处理。</p><a id="more"></a><h2 id="用户注册逻辑"><a href="#用户注册逻辑" class="headerlink" title="用户注册逻辑"></a>用户注册逻辑</h2><p>首先我们新建一个 Express 服务器：</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// server.js</span></span><br><span class="line"><span class="keyword">const</span> express = <span class="built_in">require</span>(<span class="string">&#x27;express&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> app = express()</span><br><span class="line"><span class="comment">// 处理 POST 中的 Body 数据</span></span><br><span class="line">app.use(express.json())</span><br><span class="line"></span><br><span class="line">app.listen(<span class="number">3000</span>)</span><br></pre></td></tr></table></figure><p>接着使用 MongoDB 来新建一个 Collection 的 Model 对象：</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// models.js</span></span><br><span class="line"><span class="keyword">const</span> mongoose = <span class="built_in">require</span>(<span class="string">&#x27;mongoose&#x27;</span>)</span><br><span class="line"></span><br><span class="line">mongoose.connect(<span class="string">&#x27;mongodb://localhost:27017/test&#x27;</span>, &#123;</span><br><span class="line">  useNewUrlParser: <span class="literal">true</span>,</span><br><span class="line">  useUnifiedTopology: <span class="literal">true</span>,</span><br><span class="line">  useCreateIndex: <span class="literal">true</span></span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> UserSchema = <span class="keyword">new</span> mongoose.Schema(&#123;</span><br><span class="line">  username: &#123;</span><br><span class="line">    type: <span class="built_in">String</span>,</span><br><span class="line">    required: <span class="literal">true</span>,</span><br><span class="line">    unique: <span class="literal">true</span></span><br><span class="line">  &#125;,</span><br><span class="line">  password: &#123;</span><br><span class="line">    type: <span class="built_in">String</span>,</span><br><span class="line">    required: <span class="literal">true</span>,</span><br><span class="line">  &#125;</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> User = mongoose.model(<span class="string">&#x27;User&#x27;</span>, UserSchema)</span><br><span class="line"></span><br><span class="line"><span class="built_in">module</span>.exports = &#123; User &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>其中，<code>username</code>是不能重复的。</p><p>接下来，创建用户注册请求路由：</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// server.js</span></span><br><span class="line">app.post(<span class="string">&#x27;/api/register&#x27;</span>, <span class="function">(<span class="params">req, res</span>) =&gt;</span> &#123; </span><br><span class="line">  <span class="keyword">const</span> jsonData = req.body</span><br><span class="line">  <span class="keyword">const</span> user = <span class="keyword">new</span> User(jsonData)</span><br><span class="line">  user.save(<span class="function">(<span class="params">err, user</span>) =&gt;</span> &#123;</span><br><span class="line">    <span class="keyword">if</span>(err)&#123;</span><br><span class="line">      res.json(&#123;<span class="attr">msg</span>: <span class="string">&#x27;failed to save&#x27;</span>&#125;)</span><br><span class="line">      <span class="keyword">return</span> <span class="built_in">console</span>.log(err)</span><br><span class="line">    &#125;</span><br><span class="line">    res.json(user)</span><br><span class="line">  &#125;)</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><p>为了测试接口，可以下载 VSCode 扩展商店中<code>REST Client</code>，用于发送 HTTP 请求和检测响应的数据。</p><p>安装完成后，编写用户注册请求：</p><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">// test.http</span><br><span class="line">@baseUrl=http://localhost:3000/api</span><br><span class="line"></span><br><span class="line">### 注册</span><br><span class="line">POST &#123;&#123;baseUrl&#125;&#125;/register HTTP/1.1</span><br><span class="line">Content-Type: application/json</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">    &quot;username&quot;: &quot;user1&quot;,</span><br><span class="line">    &quot;password&quot;: &quot;password1&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>当发送请求后，可以得到服务器返回的数据。</p><p>但是这样的话，<strong>我们存入的用户密码是明文存储的，不是很安全</strong>，为此我们需要在数据存入的时候，对密码进行 hash 处理，在此使用<code>bcrypt</code>进行哈希：</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// models.js</span></span><br><span class="line"><span class="keyword">const</span> bcrypt = <span class="built_in">require</span>(<span class="string">&#x27;bcrypt&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> UserSchema = <span class="keyword">new</span> mongoose.Schema(&#123;</span><br><span class="line">  username: &#123;</span><br><span class="line">    type: <span class="built_in">String</span>,</span><br><span class="line">    required: <span class="literal">true</span>,</span><br><span class="line">    unique: <span class="literal">true</span></span><br><span class="line">  &#125;,</span><br><span class="line">  password: &#123;</span><br><span class="line">    type: <span class="built_in">String</span>,</span><br><span class="line">    required: <span class="literal">true</span>,</span><br><span class="line">    set(val) &#123;<span class="comment">// 存入的时候先进行 hash </span></span><br><span class="line">      <span class="keyword">return</span> bcrypt.hashSync(val, <span class="number">10</span>)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><blockquote><p>A library to help you hash passwords. Based on the <a href="https://en.wikipedia.org/wiki/Blowfish_(cipher)">Blowfish</a> cipher.</p></blockquote><h2 id="用户登录"><a href="#用户登录" class="headerlink" title="用户登录"></a>用户登录</h2><p>接下来，创建用户登录请求路由：</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// server.js</span></span><br><span class="line">app.post(<span class="string">&#x27;/api/login&#x27;</span>, <span class="function">(<span class="params">req, res</span>) =&gt;</span> &#123;</span><br><span class="line">  <span class="keyword">const</span> userData = req.body</span><br><span class="line">  User.findOne(&#123;</span><br><span class="line">    username: userData.username</span><br><span class="line">  &#125;, <span class="function">(<span class="params">err, user</span>) =&gt;</span> &#123;</span><br><span class="line">    <span class="keyword">if</span>(err || !user) &#123;</span><br><span class="line">      <span class="keyword">return</span> res.status(<span class="number">422</span>).json(&#123;<span class="attr">msg</span>: <span class="string">&#x27;非法用户名&#x27;</span>&#125;)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">const</span> isValid = bcrypt.compareSync(userData.password, user.password)</span><br><span class="line">    <span class="keyword">if</span>(!isValid)&#123;</span><br><span class="line">      <span class="keyword">return</span> res.status(<span class="number">422</span>).json(&#123;<span class="attr">msg</span>: <span class="string">&#x27;密码错误&#x27;</span>&#125;)</span><br><span class="line">    &#125;</span><br><span class="line">    res.json(&#123;</span><br><span class="line">      user</span><br><span class="line">    &#125;)</span><br><span class="line">  &#125;)</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><p>根据用户输入的密码和哈希处理的密码进行比对，判断用户输入的密码是否正确。这是基本的用户登录流程的处理。</p><p>但是我们希望用户登录之后能够保存这些状态，传统处理方法是：用户登陆成功后，产生 Session_ID 并且将其发送给客户端使其保存在 Cookie 中，之后客户端每次请求都携带 Session_ID。</p><p>在此，我们使用 JsonWebToken 来保存我们的数据，将其发送到客户端，客户端保存在 LocalStorage 中，根据其中的数据来保存用户的状态。</p><p>修改用户登录路由：</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">app.post(<span class="string">&#x27;/api/login&#x27;</span>, <span class="function">(<span class="params">req, res</span>) =&gt;</span> &#123;</span><br><span class="line">  <span class="built_in">console</span>.log(req.body)</span><br><span class="line">  <span class="keyword">const</span> userData = req.body</span><br><span class="line">  User.findOne(&#123;</span><br><span class="line">    username: userData.username</span><br><span class="line">  &#125;, <span class="function">(<span class="params">err, user</span>) =&gt;</span> &#123;</span><br><span class="line">    <span class="keyword">if</span>(err || !user) &#123;</span><br><span class="line">      <span class="keyword">return</span> res.status(<span class="number">422</span>).json(&#123;<span class="attr">msg</span>: <span class="string">&#x27;非法用户名&#x27;</span>&#125;)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">const</span> isValid = bcrypt.compareSync(userData.password, user.password)</span><br><span class="line">    <span class="keyword">if</span>(!isValid)&#123;</span><br><span class="line">      <span class="keyword">return</span> res.status(<span class="number">422</span>).json(&#123;<span class="attr">msg</span>: <span class="string">&#x27;密码错误&#x27;</span>&#125;)</span><br><span class="line">    &#125;</span><br><span class="line">   <span class="comment">// jwt token</span></span><br><span class="line">    <span class="keyword">const</span> token = jwt.sign(&#123;</span><br><span class="line">      id: user._id</span><br><span class="line">    &#125;, SECRET)</span><br><span class="line">    res.json(&#123;</span><br><span class="line">      user,</span><br><span class="line">      token</span><br><span class="line">    &#125;)</span><br><span class="line">  &#125;)</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><p>注意，本文中为了演示，将<code>SECRET</code>硬编码进了 server.js 中，更实际的情况时我们将其保存在一个被 gitignore 的文件中，通过读取文件配置 <code>SECRET</code>。</p><h2 id="用户授权"><a href="#用户授权" class="headerlink" title="用户授权"></a>用户授权</h2><p>当用户登录之后，客户端保存下来了 token 值，接下来假设用户想要获取个人信息，这只有在用户登录之后才有权限进行操作，为此就需要 token 的帮助了：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">### 获取个人信息</span><br><span class="line">GET &#123;&#123;baseUrl&#125;&#125;&#x2F;profile HTTP&#x2F;1.1</span><br><span class="line">Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6IjVlOTE2OWVhYmNlZWNkM2I2YTI0NDg2OSIsImlhdCI6MTU4NjU4ODYyMn0.VZb_0Rlw27mAShcJCRpoURenfy8IoluGgQ-VDwkqyFM</span><br></pre></td></tr></table></figure><p>上面是用户发送的请求，其中 Authorization 头部的格式如下：</p><p><code>Authorization: &lt;type&gt; &lt;credentials&gt;</code></p><p>接下来处理这个请求路由：</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">app.get(<span class="string">&#x27;/api/profile&#x27;</span>, <span class="function">(<span class="params">req, res</span>) =&gt;</span> &#123;</span><br><span class="line">  <span class="keyword">const</span> tokenData = req.headers.authorization.split(<span class="string">&#x27; &#x27;</span>).pop()</span><br><span class="line">  <span class="keyword">const</span> token = jwt.verify(tokenData, SECRET)</span><br><span class="line">  User.findOne(&#123;</span><br><span class="line">    _id: token.id</span><br><span class="line">  &#125;, <span class="function">(<span class="params">err, user</span>) =&gt;</span> &#123;</span><br><span class="line">    <span class="keyword">if</span>(err)&#123;</span><br><span class="line">      <span class="keyword">return</span> res.json(&#123;<span class="attr">msg</span>: <span class="string">&#x27;error token&#x27;</span>&#125;)</span><br><span class="line">    &#125;</span><br><span class="line">    res.json(&#123;<span class="attr">msg</span>: <span class="string">&#x27;your profile&#x27;</span>, <span class="attr">user</span>: req.user&#125;)</span><br><span class="line">  &#125;)</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><p>这样我们就能够根据请求的 Authorization 头获取到用户的信息了。这就是用户授权的基本过程。</p><p>另外，如果有很多需要用户登陆之后操作，我们需要将用户验证这个操作转换成中间件的形式，这样就能够在多个路由中使用这个中间件了：</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> auth = <span class="function">(<span class="params">req, res, next</span>) =&gt;</span> &#123;</span><br><span class="line">  <span class="keyword">const</span> tokenData = req.headers.authorization.split(<span class="string">&#x27; &#x27;</span>).pop()</span><br><span class="line">  <span class="keyword">const</span> token = jwt.verify(tokenData, SECRET)</span><br><span class="line">  User.findOne(&#123;</span><br><span class="line">    _id: token.id</span><br><span class="line">  &#125;, <span class="function">(<span class="params">err, user</span>) =&gt;</span> &#123;</span><br><span class="line">    <span class="keyword">if</span>(err)&#123;</span><br><span class="line">      <span class="keyword">return</span> res.json(&#123;<span class="attr">msg</span>: <span class="string">&#x27;error token&#x27;</span>&#125;)</span><br><span class="line">    &#125;</span><br><span class="line">    req.user = user</span><br><span class="line">    next()</span><br><span class="line">  &#125;)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">app.get(<span class="string">&#x27;/api/profile&#x27;</span>, auth, <span class="function">(<span class="params">req, res</span>) =&gt;</span> &#123;</span><br><span class="line">  res.json(&#123;<span class="attr">msg</span>: <span class="string">&#x27;your profile&#x27;</span>, <span class="attr">user</span>: req.user&#125;)</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><p>至于 token 的过期时间我们可以使用预定义的键<code>exp</code>来设置过期时间。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Nodejs </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Vim常用命令</title>
      <link href="2020/02/23/Vim%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"/>
      <url>2020/02/23/Vim%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</url>
      
        <content type="html"><![CDATA[<p>本文介绍Vim中常用的命令，帮助我们快速使用Vim处理文本文档。</p><a id="more"></a><h2 id="基本操作"><a href="#基本操作" class="headerlink" title="基本操作"></a>基本操作</h2><p>在Vim中一共有三种模式：命令模式，插入模式和编辑模式（Visual mode）。</p><ul><li>在命令模式下可以使用<code>h，j，k，l</code>来移动，分别表示左下上右四个移动方向。</li><li>命令模式下使用<code>x</code>来删除单个字符。</li><li>命令模式下使用<code>u</code>来撤销，使用<code>CTRL-R</code>来取消撤销。</li><li>使用<code>:wq</code>保存文件并且退出，使用<code>:q!</code>强制退出。</li><li>使用<code>i</code>在光标前插入字符，使用<code>a</code>在光标后插入字符。</li><li>删除一整行使用<code>dd</code>命令。</li><li>在光标下插入新行使用<code>o</code>命令，在光标上插入新行使用<code>O</code>命令。</li><li>有些命令可以先输入Count值，再输入命令，表示的意思就是执行命令Count次。<code>9k</code>表示上移9行，<code>3x</code>表示删除三个字符。</li></ul><h2 id="快速操作"><a href="#快速操作" class="headerlink" title="快速操作"></a>快速操作</h2><ul><li>单词间移动：<code>w</code>表示后移到单词的开头，<code>b</code>表示前移到单词的开头。</li><li>行首和行末移动：<code>$</code>表示移动到本行行尾，<code>^</code>表示移动到本行开头。</li><li>行内单个字符查找：<code>fx</code>表示查找从光标向右查找字符x，<code>Fx</code>表示从光标向左查找字符x。</li><li>移动到特定行：<code>&lt;num&gt;G</code>表示移动到num行，<code>gg</code>表示移动到第一行，<code>G</code>表示移动到最后一行。</li><li>显示行号：<code>:set nu</code>。</li><li>滑动窗口：<code>CTRL-U</code>上滑半个屏幕，<code>CTRL-D</code>下滑半个屏幕。</li><li>删除文本：<code>dw</code>删除单个单词，<code>d$</code>删除光标到末尾的文本。</li><li>修改文本：<code>cw</code>修改单个单词，<code>c$</code>修改光标到末尾的文本。</li><li>重复上次删除或者修改命令：<code>.</code>。</li><li>连接不同行内容到一行上：使用<code>3J</code>将三行内容移动到一行上。</li><li>替换单个字符：<code>rx</code>将光标字符修改为x字符。</li><li>修改大小写：<code>~</code>将字符进行大小写转换。</li><li>键盘宏：使用<code>q[a-z]</code>开始记录，再次<code>q</code>结束，调用键盘宏使用<code>@[a-z]</code>，用于重复执行复杂操作。</li></ul><h2 id="搜索"><a href="#搜索" class="headerlink" title="搜索"></a>搜索</h2><ul><li>搜索文本：<code>/string</code>搜索string文本，使用<code>n</code>可以跳转到下一个被搜索到的文本。</li><li>取消高亮：被搜索到的文本会被高亮，当不再需要高亮的时候使用<code>:noh</code>命令。</li><li>反向搜索文本：<code>?string</code>反向搜索string文本，使用<code>n</code>跳转到下一个被搜索到的文本。</li><li>改变搜索反向：<code>n</code>跳转到下一个被搜索到的文本，<code>N</code>跳转到上一个被搜索到的文本。</li><li>正则搜索：<code>^</code>表示行首，<code>$</code>表示行尾，<code>\c</code>忽略大小写，同样可以使用其他的正则表达式。</li></ul><h2 id="多窗口与多文件"><a href="#多窗口与多文件" class="headerlink" title="多窗口与多文件"></a>多窗口与多文件</h2><ul><li><p>粘贴文本：<code>p</code>命令可以在光标后粘贴被保存的文本，<code>P</code>命令可以在光标前粘贴被保存的文本。被保存的文本包括用<code>x</code>，<code>d</code>删除的文本。</p></li><li><p>标记：使用<code>m[a-z]</code>对所在位置进行标记，``a<code>表示移动到刚刚被标记的位置，</code>‘a`表示移动到刚刚被标记位置的行首。</p></li><li><p>查看标记：<code>:marks</code>查看所作的标记。</p></li><li><p>复制文本：<code>y</code>命令可以复制文本，<code>Y</code>或者<code>yy</code>命令可以一整行的文本。</p></li><li><p>打开新的文件：使用<code>:vi file.txt</code>打开file.txt文件。</p></li><li><p>打开多个文件：使用<code>vim one.c two.c there.c</code>。</p></li><li><p>在多文件下转换：<code>:next</code>跳转到下一个文件并且打开该文件，<code>:previous</code>跳转到上一个文件并且打开该文件，<code>:first</code>跳转到第一个文件，<code>:last</code>跳转到最后一个文件。</p></li><li><p>查看当前所在的文件：<code>:args</code>可以查看自己所处的文件（用<code>[]</code>包括起来）。</p></li></ul><h2 id="窗口"><a href="#窗口" class="headerlink" title="窗口"></a>窗口</h2><ul><li>打开新的窗口：<code>:[count] split [filename]</code>水平打开一个新的窗口，大小为count值，文件是filename，<code>:[count] vsplit [filename]</code>垂直打开一个新的窗口，大小为count值，文件是filename。</li><li>窗口间移动：<code>CTRL-W[hjkl]</code>根据方向键改变窗口，<code>CTRL-W CTRL-W</code>在不同窗口间进行移动。</li><li>改变窗口大小：<code>CTRL-W+</code>增加窗口大小，<code>CTRL-W-</code>减小窗口大小，<code>CTRL-W=</code>使窗口大小相同。</li></ul><h2 id="基本的编辑模式"><a href="#基本的编辑模式" class="headerlink" title="基本的编辑模式"></a>基本的编辑模式</h2><ul><li>三种编辑模式：<code>v</code>字符编辑模式，<code>V</code>行编辑模式，<code>CTRL-V</code>矩形编辑模式。</li><li>删除文本：<code>d</code>删除所选的文本，<code>D</code>删除所选文本行（从光标到末尾）。</li><li>复制文本：<code>y</code>复制所选的文本，<code>Y</code>复制所选文本行（从光标到末尾）。</li><li>修改文本：<code>c</code>修改所选的文本，<code>C</code>修改所选的文本行（从光标到末尾）。</li><li>多行合并：<code>J</code>将所选的文本合并到一行。</li><li>缩进：<code>&lt;</code>和<code>&gt;</code>进行左缩进和右缩进。</li></ul><p>矩形编辑模式下的特殊操作：</p><ul><li>插入文本：<code>Istring&lt;Esc&gt;</code>在矩形前面插入string文本。</li><li>修改文本：<code>cstring&lt;Esc&gt;</code>修改矩形中的文本。</li><li>替换文本：<code>rchar&lt;Esc&gt;</code>替换矩形中的文本。</li></ul><h2 id="程序员相关指令"><a href="#程序员相关指令" class="headerlink" title="程序员相关指令"></a>程序员相关指令</h2><ul><li>打开语法高亮：<code>:syntax on</code>。</li><li>设置文件的格式以适应语法高亮：<code>:set filetype=c</code>。</li><li>行缩进：<code>&lt;&lt;</code>或者是<code>&gt;&gt;</code>。</li><li>行缩进大小：<code>:set shiftwidth=4</code>。</li><li>设置缩进方式：<code>:set (cindent|smartindent|autoindent)</code>。</li><li>自动缩进大括号内的内容：<code>=%</code>。</li><li>查找单词：<code>[CTRL-I</code>全文查找单词，<code>]CTRL-I</code>从光标到文件末尾查找单词。</li><li>跳转到变量定义：<code>gd</code>跳转到局部变量定义，<code>gD</code>跳转到全局变量定义。</li><li>跳转到宏定义：<code>[CTRL-D</code>跳转到第一个宏定义，<code>]CTRL-D</code>跳转到下一个宏定义。</li><li>查看宏定义：<code>[d</code>查找显示第一个宏定义，<code>]d</code>从光标处开始查找宏定义。<code>[D</code>显示所有匹配的宏定义列表，<code>]D</code>显示光标后所有匹配的宏定义的列表。</li><li>查看匹配的括号对：<code>%</code>查找并且跳转到匹配的括号对上。</li><li>缩进代码块：<code>&gt;%</code>或者<code>&lt;%</code>。</li><li>自动补全：<code>CTRL-P</code>前向搜索补全词汇，<code>CTRL-N</code>后向搜索补全词汇。</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Vim </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL基本操作</title>
      <link href="2020/02/19/MySQL%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/"/>
      <url>2020/02/19/MySQL%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/</url>
      
        <content type="html"><![CDATA[<p>本文介绍MySQL数据库的简单使用方法，包括数据库的启动和连接，以及数据的增删改查等。操作环境在CentOS 7中。</p><a id="more"></a><h2 id="数据库连接和断开连接"><a href="#数据库连接和断开连接" class="headerlink" title="数据库连接和断开连接"></a>数据库连接和断开连接</h2><p>在进行数据库的连接之前，我们需要先启动数据库服务：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">shell&gt; systemctl start mysqld.service</span><br></pre></td></tr></table></figure><p>数据库连接命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">shell&gt; mysql [-h host] -u root -p</span><br><span class="line">Enter password: *****</span><br></pre></td></tr></table></figure><p>缺省host就表示连接本地的mysql数据库。</p><p>数据库断开连接：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; quit</span><br><span class="line">Bye</span><br></pre></td></tr></table></figure><h2 id="查询"><a href="#查询" class="headerlink" title="查询"></a>查询</h2><p>连接到mysql后，可以查询版本信息，当前日期和时间和当前用户：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; SELECT VERSION(), CURRENT_DATE, NOW(), USER();</span><br><span class="line">+-----------+--------------+---------------------+----------------+</span><br><span class="line">| VERSION() | CURRENT_DATE | NOW()               | USER()         |</span><br><span class="line">+-----------+--------------+---------------------+----------------+</span><br><span class="line">| 8.0.19    | 2020-02-19   | 2020-02-19 18:03:54 | root@localhost |</span><br><span class="line">+-----------+--------------+---------------------+----------------+</span><br><span class="line">1 row <span class="keyword">in</span> <span class="built_in">set</span> (0.00 sec)</span><br></pre></td></tr></table></figure><h2 id="创建和使用数据库"><a href="#创建和使用数据库" class="headerlink" title="创建和使用数据库"></a>创建和使用数据库</h2><p>查询当前服务器中的数据库有哪些：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; SHOW DATABASES;</span><br><span class="line">+--------------------+</span><br><span class="line">| Database           |</span><br><span class="line">+--------------------+</span><br><span class="line">| information_schema |</span><br><span class="line">| mysql              |</span><br><span class="line">| performance_schema |</span><br><span class="line">| sys                |</span><br><span class="line">| <span class="built_in">test</span>               |</span><br><span class="line">+--------------------+</span><br><span class="line">5 rows <span class="keyword">in</span> <span class="built_in">set</span> (0.01 sec)</span><br></pre></td></tr></table></figure><p>使用某个数据库：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; USE <span class="built_in">test</span>;</span><br><span class="line">Database changed</span><br></pre></td></tr></table></figure><p>在test数据库中创建的任何数据可能会被别人删除，可以让管理员执行以下命令使得只有你能使用某个数据库(menagerie)：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; GRANT ALL ON menagerie.* TO <span class="string">&#x27;your_mysql_name&#x27;</span>@<span class="string">&#x27;your_client_host&#x27;</span>;</span><br></pre></td></tr></table></figure><h3 id="创建和选择数据库"><a href="#创建和选择数据库" class="headerlink" title="创建和选择数据库"></a>创建和选择数据库</h3><p>创建新的数据库：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; CREATE DATABASE menagerie;</span><br><span class="line">Query OK, 1 row affected (0.00 sec)</span><br></pre></td></tr></table></figure><p>选择数据库：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; USE menagerie;</span><br><span class="line">Database changed</span><br></pre></td></tr></table></figure><p>查询当前使用的数据库：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; SELECT DATABASE();</span><br><span class="line">+------------+</span><br><span class="line">| DATABASE() |</span><br><span class="line">+------------+</span><br><span class="line">| menagerie  |</span><br><span class="line">+------------+</span><br><span class="line">1 row <span class="keyword">in</span> <span class="built_in">set</span> (0.00 sec)</span><br></pre></td></tr></table></figure><h3 id="创建表格"><a href="#创建表格" class="headerlink" title="创建表格"></a>创建表格</h3><p>展示当前数据库中有哪些表格：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; SHOW TABLES;</span><br><span class="line">Empty <span class="built_in">set</span> (0.00 sec)</span><br></pre></td></tr></table></figure><p>创建新的表格：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; CREATE TABLE pet (</span><br><span class="line">    -&gt; name VARCHAR(20),</span><br><span class="line">    -&gt; owner VARCHAR(20),</span><br><span class="line">    -&gt; species VARCHAR(20),</span><br><span class="line">    -&gt; sex CHAR(1),</span><br><span class="line">    -&gt; birth DATE,</span><br><span class="line">    -&gt; death DATE);</span><br><span class="line">Query OK, 0 rows affected (0.06 sec)</span><br></pre></td></tr></table></figure><p>查看表格的表头和描述：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; DESCRIBE pet;</span><br><span class="line">+---------+-------------+------+-----+---------+-------+</span><br><span class="line">| Field   | Type        | Null | Key | Default | Extra |</span><br><span class="line">+---------+-------------+------+-----+---------+-------+</span><br><span class="line">| name    | varchar(20) | YES  |     | NULL    |       |</span><br><span class="line">| owner   | varchar(20) | YES  |     | NULL    |       |</span><br><span class="line">| species | varchar(20) | YES  |     | NULL    |       |</span><br><span class="line">| sex     | char(1)     | YES  |     | NULL    |       |</span><br><span class="line">| birth   | date        | YES  |     | NULL    |       |</span><br><span class="line">| death   | date        | YES  |     | NULL    |       |</span><br><span class="line">+---------+-------------+------+-----+---------+-------+</span><br></pre></td></tr></table></figure><h3 id="写入数据"><a href="#写入数据" class="headerlink" title="写入数据"></a>写入数据</h3><p>使用文件载入数据：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; LOAD DATA LOCAL INFILE <span class="string">&#x27;/usr/local/src/pet.txt&#x27;</span> INTO TABLE pet;</span><br><span class="line">Query OK, 8 rows affected, 1 warning (0.00 sec)</span><br><span class="line">Records: 8  Deleted: 0  Skipped: 0  Warnings: 1</span><br></pre></td></tr></table></figure><p>pet.txt 的内容如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">FluffyHaroldcatf1993-02-04\N</span><br><span class="line">ClawsGwencatm1994-03-17\N</span><br><span class="line">BuffyHarolddogf1989-05-13\N</span><br><span class="line">FangBennydogm1990-08-27\N</span><br><span class="line">BowserDianedogm1979-08-311995-07-29</span><br><span class="line">ChirpyGwenbirdf1998-09-11\N</span><br><span class="line">WhistlerGwenbird\N1997-12-09</span><br><span class="line">SlimBennysnakem1996-04-29\N</span><br></pre></td></tr></table></figure><p>其中每条记录之间使用TAB分割，每个行结束符是<code>\r</code>，<code>\N</code>表示的是NULL值。</p><blockquote><p>如果执行命令出错，可能需要先开启local_infile变量：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; <span class="built_in">set</span> global local_infile = <span class="string">&#x27;ON&#x27;</span>;</span><br></pre></td></tr></table></figure><p>然后通过下述命令进入mysql交互环境：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ mysql --<span class="built_in">local</span>-infile=1 -u root -p</span><br></pre></td></tr></table></figure></blockquote><p>同样地，我们可以通过INSERT语句来插入数据：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; INSERT INTO pet</span><br><span class="line">    -&gt; VALUES (<span class="string">&#x27;Puffball&#x27;</span>, <span class="string">&#x27;Diane&#x27;</span>, <span class="string">&#x27;hamster&#x27;</span>, <span class="string">&#x27;f&#x27;</span>, <span class="string">&#x27;1999-3-30&#x27;</span>, NULL);</span><br><span class="line">Query OK, 1 row affected (0.00 sec)</span><br></pre></td></tr></table></figure><h3 id="从表格中获取信息"><a href="#从表格中获取信息" class="headerlink" title="从表格中获取信息"></a>从表格中获取信息</h3><p>从表格获取信息的方式一般形式是：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SELECT what_to_select</span><br><span class="line">FROM which_table</span><br><span class="line">WHERE conditions_to_satisfy;</span><br></pre></td></tr></table></figure><p>选择全部数据：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; SELECT * FROM pet;</span><br><span class="line">+----------+--------+---------+------+------------+------------+</span><br><span class="line">| name     | owner  | species | sex  | birth      | death      |</span><br><span class="line">+----------+--------+---------+------+------------+------------+</span><br><span class="line">| Fluffy   | Harold | cat     | f    | 1993-02-04 | NULL       |</span><br><span class="line">| Claws    | Gwen   | cat     | m    | 1994-03-17 | NULL       |</span><br><span class="line">| Buffy    | Harold | dog     | f    | 1989-05-13 | NULL       |</span><br><span class="line">| Fang     | Benny  | dog     | m    | 1990-08-27 | NULL       |</span><br><span class="line">| Bowser   | Diane  | dog     | m    | 1979-08-31 | 1995-07-29 |</span><br><span class="line">| Chirpy   | Gwen   | bird    | f    | 1998-09-11 | NULL       |</span><br><span class="line">| Whistler | Gwen   | bird    | NULL | 1997-12-09 | 0000-00-00 |</span><br><span class="line">| Slim     | Benny  | snake   | m    | 1996-04-29 | NULL       |</span><br><span class="line">| Puffball | Diane  | hamster | f    | 1999-03-30 | NULL       |</span><br><span class="line">+----------+--------+---------+------+------------+------------+</span><br></pre></td></tr></table></figure><p>从表中我们发现Bowser的birth值不太正确，我们可以</p><ul><li><p>在pet.txt中修改文件，然后清空pet表格，接着载入数据</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; DELETE FROM pet;</span><br><span class="line">mysql&gt; LOAD DATA LOCAL INFILE <span class="string">&#x27;/usr/local/src/pet.txt&#x27;</span> INTO TABLE pet;</span><br></pre></td></tr></table></figure></li><li><p>使用UPDATE语句：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; UPDATE pet SET birth = <span class="string">&#x27;1989-08-31&#x27;</span> WHERE name = <span class="string">&#x27;Bowser&#x27;</span>;</span><br><span class="line">Query OK, 1 row affected (0.00 sec)</span><br></pre></td></tr></table></figure></li></ul><p>有条件地选择可以通过WHERE来实现：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; SELECT * FROM pet WHERE name = <span class="string">&#x27;Bowser&#x27;</span>;</span><br><span class="line">+--------+-------+---------+------+------------+------------+</span><br><span class="line">| name   | owner | species | sex  | birth      | death      |</span><br><span class="line">+--------+-------+---------+------+------------+------------+</span><br><span class="line">| Bowser | Diane | dog     | m    | 1989-08-31 | 1995-07-29 |</span><br><span class="line">+--------+-------+---------+------+------------+------------+</span><br><span class="line"></span><br><span class="line">mysql&gt; SELECT * FROM pet WHERE birth &gt;= <span class="string">&#x27;1998-1-1&#x27;</span>;</span><br><span class="line">+----------+-------+---------+------+------------+-------+</span><br><span class="line">| name     | owner | species | sex  | birth      | death |</span><br><span class="line">+----------+-------+---------+------+------------+-------+</span><br><span class="line">| Chirpy   | Gwen  | bird    | f    | 1998-09-11 | NULL  |</span><br><span class="line">| Puffball | Diane | hamster | f    | 1999-03-30 | NULL  |</span><br><span class="line">+----------+-------+---------+------+------------+-------+</span><br><span class="line"></span><br><span class="line">mysql&gt; SELECT * FROM pet WHERE species = <span class="string">&#x27;dog&#x27;</span> AND sex = <span class="string">&#x27;f&#x27;</span>;</span><br><span class="line">+-------+--------+---------+------+------------+-------+</span><br><span class="line">| name  | owner  | species | sex  | birth      | death |</span><br><span class="line">+-------+--------+---------+------+------------+-------+</span><br><span class="line">| Buffy | Harold | dog     | f    | 1989-05-13 | NULL  |</span><br><span class="line">+-------+--------+---------+------+------------+-------+</span><br><span class="line"></span><br><span class="line">mysql&gt; SELECT * FROM pet WHERE species = <span class="string">&#x27;snake&#x27;</span> OR species = <span class="string">&#x27;bird&#x27;</span>;</span><br><span class="line">+----------+-------+---------+------+------------+-------+</span><br><span class="line">| name     | owner | species | sex  | birth      | death |</span><br><span class="line">+----------+-------+---------+------+------------+-------+</span><br><span class="line">| Chirpy   | Gwen  | bird    | f    | 1998-09-11 | NULL  |</span><br><span class="line">| Whistler | Gwen  | bird    | NULL | 1997-12-09 | NULL  |</span><br><span class="line">| Slim     | Benny | snake   | m    | 1996-04-29 | NULL  |</span><br><span class="line">+----------+-------+---------+------+------------+-------+</span><br><span class="line"></span><br><span class="line">mysql&gt; SELECT * FROM pet WHERE (species = <span class="string">&#x27;cat&#x27;</span> AND sex = <span class="string">&#x27;m&#x27;</span>)</span><br><span class="line">       OR (species = <span class="string">&#x27;dog&#x27;</span> AND sex = <span class="string">&#x27;f&#x27;</span>);</span><br><span class="line">+-------+--------+---------+------+------------+-------+</span><br><span class="line">| name  | owner  | species | sex  | birth      | death |</span><br><span class="line">+-------+--------+---------+------+------------+-------+</span><br><span class="line">| Claws | Gwen   | cat     | m    | 1994-03-17 | NULL  |</span><br><span class="line">| Buffy | Harold | dog     | f    | 1989-05-13 | NULL  |</span><br><span class="line">+-------+--------+---------+------+------------+-------+</span><br></pre></td></tr></table></figure><p>选择特定的列可以通过SELECT语句实现：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; SELECT name, birth FROM pet;</span><br><span class="line">+----------+------------+</span><br><span class="line">| name     | birth      |</span><br><span class="line">+----------+------------+</span><br><span class="line">| Fluffy   | 1993-02-04 |</span><br><span class="line">| Claws    | 1994-03-17 |</span><br><span class="line">| Buffy    | 1989-05-13 |</span><br><span class="line">| Fang     | 1990-08-27 |</span><br><span class="line">| Bowser   | 1989-08-31 |</span><br><span class="line">| Chirpy   | 1998-09-11 |</span><br><span class="line">| Whistler | 1997-12-09 |</span><br><span class="line">| Slim     | 1996-04-29 |</span><br><span class="line">| Puffball | 1999-03-30 |</span><br><span class="line">+----------+------------+</span><br><span class="line"></span><br><span class="line">mysql&gt; SELECT owner FROM pet;</span><br><span class="line">+--------+</span><br><span class="line">| owner  |</span><br><span class="line">+--------+</span><br><span class="line">| Harold |</span><br><span class="line">| Gwen   |</span><br><span class="line">| Harold |</span><br><span class="line">| Benny  |</span><br><span class="line">| Diane  |</span><br><span class="line">| Gwen   |</span><br><span class="line">| Gwen   |</span><br><span class="line">| Benny  |</span><br><span class="line">| Diane  |</span><br><span class="line">+--------+</span><br><span class="line"></span><br><span class="line">mysql&gt; SELECT DISTINCT owner FROM pet;</span><br><span class="line">+--------+</span><br><span class="line">| owner  |</span><br><span class="line">+--------+</span><br><span class="line">| Benny  |</span><br><span class="line">| Diane  |</span><br><span class="line">| Gwen   |</span><br><span class="line">| Harold |</span><br><span class="line">+--------+</span><br><span class="line"></span><br><span class="line">mysql&gt; SELECT name, species, birth FROM pet</span><br><span class="line">       WHERE species = <span class="string">&#x27;dog&#x27;</span> OR species = <span class="string">&#x27;cat&#x27;</span>;</span><br><span class="line">+--------+---------+------------+</span><br><span class="line">| name   | species | birth      |</span><br><span class="line">+--------+---------+------------+</span><br><span class="line">| Fluffy | cat     | 1993-02-04 |</span><br><span class="line">| Claws  | cat     | 1994-03-17 |</span><br><span class="line">| Buffy  | dog     | 1989-05-13 |</span><br><span class="line">| Fang   | dog     | 1990-08-27 |</span><br><span class="line">| Bowser | dog     | 1989-08-31 |</span><br><span class="line">+--------+---------+------------+</span><br></pre></td></tr></table></figure><p>数据间的排序可以通过<code>ORDER BY</code>实现：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; SELECT name, birth FROM pet ORDER BY birth;</span><br><span class="line">+----------+------------+</span><br><span class="line">| name     | birth      |</span><br><span class="line">+----------+------------+</span><br><span class="line">| Buffy    | 1989-05-13 |</span><br><span class="line">| Bowser   | 1989-08-31 |</span><br><span class="line">| Fang     | 1990-08-27 |</span><br><span class="line">| Fluffy   | 1993-02-04 |</span><br><span class="line">| Claws    | 1994-03-17 |</span><br><span class="line">| Slim     | 1996-04-29 |</span><br><span class="line">| Whistler | 1997-12-09 |</span><br><span class="line">| Chirpy   | 1998-09-11 |</span><br><span class="line">| Puffball | 1999-03-30 |</span><br><span class="line">+----------+------------+</span><br><span class="line"></span><br><span class="line">mysql&gt; SELECT name, birth FROM pet ORDER BY birth DESC;</span><br><span class="line">+----------+------------+</span><br><span class="line">| name     | birth      |</span><br><span class="line">+----------+------------+</span><br><span class="line">| Puffball | 1999-03-30 |</span><br><span class="line">| Chirpy   | 1998-09-11 |</span><br><span class="line">| Whistler | 1997-12-09 |</span><br><span class="line">| Slim     | 1996-04-29 |</span><br><span class="line">| Claws    | 1994-03-17 |</span><br><span class="line">| Fluffy   | 1993-02-04 |</span><br><span class="line">| Fang     | 1990-08-27 |</span><br><span class="line">| Bowser   | 1989-08-31 |</span><br><span class="line">| Buffy    | 1989-05-13 |</span><br><span class="line">+----------+------------+</span><br><span class="line"></span><br><span class="line">mysql&gt; SELECT name, species, birth FROM pet</span><br><span class="line">       ORDER BY species, birth DESC;</span><br><span class="line">+----------+---------+------------+</span><br><span class="line">| name     | species | birth      |</span><br><span class="line">+----------+---------+------------+</span><br><span class="line">| Chirpy   | bird    | 1998-09-11 |</span><br><span class="line">| Whistler | bird    | 1997-12-09 |</span><br><span class="line">| Claws    | cat     | 1994-03-17 |</span><br><span class="line">| Fluffy   | cat     | 1993-02-04 |</span><br><span class="line">| Fang     | dog     | 1990-08-27 |</span><br><span class="line">| Bowser   | dog     | 1989-08-31 |</span><br><span class="line">| Buffy    | dog     | 1989-05-13 |</span><br><span class="line">| Puffball | hamster | 1999-03-30 |</span><br><span class="line">| Slim     | snake   | 1996-04-29 |</span><br><span class="line">+----------+---------+------------+</span><br></pre></td></tr></table></figure><p>和时间相关的处理：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; SELECT name, birth, CURDATE(),</span><br><span class="line">       TIMESTAMPDIFF(YEAR,birth,CURDATE()) AS age</span><br><span class="line">       FROM pet;</span><br><span class="line">+----------+------------+------------+------+</span><br><span class="line">| name     | birth      | CURDATE()  | age  |</span><br><span class="line">+----------+------------+------------+------+</span><br><span class="line">| Fluffy   | 1993-02-04 | 2003-08-19 |   10 |</span><br><span class="line">| Claws    | 1994-03-17 | 2003-08-19 |    9 |</span><br><span class="line">| Buffy    | 1989-05-13 | 2003-08-19 |   14 |</span><br><span class="line">| Fang     | 1990-08-27 | 2003-08-19 |   12 |</span><br><span class="line">| Bowser   | 1989-08-31 | 2003-08-19 |   13 |</span><br><span class="line">| Chirpy   | 1998-09-11 | 2003-08-19 |    4 |</span><br><span class="line">| Whistler | 1997-12-09 | 2003-08-19 |    5 |</span><br><span class="line">| Slim     | 1996-04-29 | 2003-08-19 |    7 |</span><br><span class="line">| Puffball | 1999-03-30 | 2003-08-19 |    4 |</span><br><span class="line">+----------+------------+------------+------+</span><br><span class="line"></span><br><span class="line">mysql&gt; SELECT name, birth, CURDATE(),</span><br><span class="line">       TIMESTAMPDIFF(YEAR,birth,CURDATE()) AS age</span><br><span class="line">       FROM pet ORDER BY name;</span><br><span class="line">+----------+------------+------------+------+</span><br><span class="line">| name     | birth      | CURDATE()  | age  |</span><br><span class="line">+----------+------------+------------+------+</span><br><span class="line">| Bowser   | 1989-08-31 | 2003-08-19 |   13 |</span><br><span class="line">| Buffy    | 1989-05-13 | 2003-08-19 |   14 |</span><br><span class="line">| Chirpy   | 1998-09-11 | 2003-08-19 |    4 |</span><br><span class="line">| Claws    | 1994-03-17 | 2003-08-19 |    9 |</span><br><span class="line">| Fang     | 1990-08-27 | 2003-08-19 |   12 |</span><br><span class="line">| Fluffy   | 1993-02-04 | 2003-08-19 |   10 |</span><br><span class="line">| Puffball | 1999-03-30 | 2003-08-19 |    4 |</span><br><span class="line">| Slim     | 1996-04-29 | 2003-08-19 |    7 |</span><br><span class="line">| Whistler | 1997-12-09 | 2003-08-19 |    5 |</span><br><span class="line">+----------+------------+------------+------+</span><br><span class="line"></span><br><span class="line">mysql&gt; SELECT name, birth, CURDATE(),</span><br><span class="line">       TIMESTAMPDIFF(YEAR,birth,CURDATE()) AS age</span><br><span class="line">       FROM pet ORDER BY age;</span><br><span class="line">+----------+------------+------------+------+</span><br><span class="line">| name     | birth      | CURDATE()  | age  |</span><br><span class="line">+----------+------------+------------+------+</span><br><span class="line">| Chirpy   | 1998-09-11 | 2003-08-19 |    4 |</span><br><span class="line">| Puffball | 1999-03-30 | 2003-08-19 |    4 |</span><br><span class="line">| Whistler | 1997-12-09 | 2003-08-19 |    5 |</span><br><span class="line">| Slim     | 1996-04-29 | 2003-08-19 |    7 |</span><br><span class="line">| Claws    | 1994-03-17 | 2003-08-19 |    9 |</span><br><span class="line">| Fluffy   | 1993-02-04 | 2003-08-19 |   10 |</span><br><span class="line">| Fang     | 1990-08-27 | 2003-08-19 |   12 |</span><br><span class="line">| Bowser   | 1989-08-31 | 2003-08-19 |   13 |</span><br><span class="line">| Buffy    | 1989-05-13 | 2003-08-19 |   14 |</span><br><span class="line">+----------+------------+------------+------+</span><br><span class="line"></span><br><span class="line">mysql&gt; SELECT name, birth, death,</span><br><span class="line">       TIMESTAMPDIFF(YEAR,birth,death) AS age</span><br><span class="line">       FROM pet WHERE death IS NOT NULL ORDER BY age;</span><br><span class="line">+--------+------------+------------+------+</span><br><span class="line">| name   | birth      | death      | age  |</span><br><span class="line">+--------+------------+------------+------+</span><br><span class="line">| Bowser | 1989-08-31 | 1995-07-29 |    5 |</span><br><span class="line">+--------+------------+------------+------+</span><br><span class="line"></span><br><span class="line">mysql&gt; SELECT name, birth, MONTH(birth) FROM pet;</span><br><span class="line">+----------+------------+--------------+</span><br><span class="line">| name     | birth      | MONTH(birth) |</span><br><span class="line">+----------+------------+--------------+</span><br><span class="line">| Fluffy   | 1993-02-04 |            2 |</span><br><span class="line">| Claws    | 1994-03-17 |            3 |</span><br><span class="line">| Buffy    | 1989-05-13 |            5 |</span><br><span class="line">| Fang     | 1990-08-27 |            8 |</span><br><span class="line">| Bowser   | 1989-08-31 |            8 |</span><br><span class="line">| Chirpy   | 1998-09-11 |            9 |</span><br><span class="line">| Whistler | 1997-12-09 |           12 |</span><br><span class="line">| Slim     | 1996-04-29 |            4 |</span><br><span class="line">| Puffball | 1999-03-30 |            3 |</span><br><span class="line">+----------+------------+--------------+</span><br><span class="line"></span><br><span class="line">mysql&gt; SELECT name, birth FROM pet WHERE MONTH(birth) &#x3D; 5;</span><br><span class="line">+-------+------------+</span><br><span class="line">| name  | birth      |</span><br><span class="line">+-------+------------+</span><br><span class="line">| Buffy | 1989-05-13 |</span><br><span class="line">+-------+------------+</span><br></pre></td></tr></table></figure><p>模式匹配的规则如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; SELECT * FROM pet WHERE name LIKE &#39;b%&#39;;</span><br><span class="line">+--------+--------+---------+------+------------+------------+</span><br><span class="line">| name   | owner  | species | sex  | birth      | death      |</span><br><span class="line">+--------+--------+---------+------+------------+------------+</span><br><span class="line">| Buffy  | Harold | dog     | f    | 1989-05-13 | NULL       |</span><br><span class="line">| Bowser | Diane  | dog     | m    | 1989-08-31 | 1995-07-29 |</span><br><span class="line">+--------+--------+---------+------+------------+------------+</span><br><span class="line"></span><br><span class="line">mysql&gt; SELECT * FROM pet WHERE name LIKE &#39;%fy&#39;;</span><br><span class="line">+--------+--------+---------+------+------------+-------+</span><br><span class="line">| name   | owner  | species | sex  | birth      | death |</span><br><span class="line">+--------+--------+---------+------+------------+-------+</span><br><span class="line">| Fluffy | Harold | cat     | f    | 1993-02-04 | NULL  |</span><br><span class="line">| Buffy  | Harold | dog     | f    | 1989-05-13 | NULL  |</span><br><span class="line">+--------+--------+---------+------+------------+-------+</span><br><span class="line"></span><br><span class="line">mysql&gt; SELECT * FROM pet WHERE name LIKE &#39;%w%&#39;;</span><br><span class="line">+----------+-------+---------+------+------------+------------+</span><br><span class="line">| name     | owner | species | sex  | birth      | death      |</span><br><span class="line">+----------+-------+---------+------+------------+------------+</span><br><span class="line">| Claws    | Gwen  | cat     | m    | 1994-03-17 | NULL       |</span><br><span class="line">| Bowser   | Diane | dog     | m    | 1989-08-31 | 1995-07-29 |</span><br><span class="line">| Whistler | Gwen  | bird    | NULL | 1997-12-09 | NULL       |</span><br><span class="line">+----------+-------+---------+------+------------+------------+</span><br><span class="line"></span><br><span class="line">mysql&gt; SELECT * FROM pet WHERE name LIKE &#39;_____&#39;;</span><br><span class="line">+-------+--------+---------+------+------------+-------+</span><br><span class="line">| name  | owner  | species | sex  | birth      | death |</span><br><span class="line">+-------+--------+---------+------+------------+-------+</span><br><span class="line">| Claws | Gwen   | cat     | m    | 1994-03-17 | NULL  |</span><br><span class="line">| Buffy | Harold | dog     | f    | 1989-05-13 | NULL  |</span><br><span class="line">+-------+--------+---------+------+------------+-------+</span><br><span class="line"></span><br><span class="line">mysql&gt; SELECT * FROM pet WHERE REGEXP_LIKE(name, &#39;^b&#39;);</span><br><span class="line">+--------+--------+---------+------+------------+------------+</span><br><span class="line">| name   | owner  | species | sex  | birth      | death      |</span><br><span class="line">+--------+--------+---------+------+------------+------------+</span><br><span class="line">| Buffy  | Harold | dog     | f    | 1989-05-13 | NULL       |</span><br><span class="line">| Bowser | Diane  | dog     | m    | 1979-08-31 | 1995-07-29 |</span><br><span class="line">+--------+--------+---------+------+------------+------------+</span><br><span class="line"></span><br><span class="line">mysql&gt; SELECT * FROM pet WHERE REGEXP_LIKE(name, &#39;fy$&#39;);</span><br><span class="line">+--------+--------+---------+------+------------+-------+</span><br><span class="line">| name   | owner  | species | sex  | birth      | death |</span><br><span class="line">+--------+--------+---------+------+------------+-------+</span><br><span class="line">| Fluffy | Harold | cat     | f    | 1993-02-04 | NULL  |</span><br><span class="line">| Buffy  | Harold | dog     | f    | 1989-05-13 | NULL  |</span><br><span class="line">+--------+--------+---------+------+------------+-------+</span><br></pre></td></tr></table></figure><p>统计查询数目的条数：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; SELECT COUNT(*) FROM pet;</span><br><span class="line">+----------+</span><br><span class="line">| COUNT(*) |</span><br><span class="line">+----------+</span><br><span class="line">|        9 |</span><br><span class="line">+----------+</span><br><span class="line"></span><br><span class="line">mysql&gt; SELECT owner, COUNT(*) FROM pet GROUP BY owner;</span><br><span class="line">+--------+----------+</span><br><span class="line">| owner  | COUNT(*) |</span><br><span class="line">+--------+----------+</span><br><span class="line">| Benny  |        2 |</span><br><span class="line">| Diane  |        2 |</span><br><span class="line">| Gwen   |        3 |</span><br><span class="line">| Harold |        2 |</span><br><span class="line">+--------+----------+</span><br><span class="line"></span><br><span class="line">mysql&gt; SELECT species, COUNT(*) FROM pet GROUP BY species;</span><br><span class="line">+---------+----------+</span><br><span class="line">| species | COUNT(*) |</span><br><span class="line">+---------+----------+</span><br><span class="line">| bird    |        2 |</span><br><span class="line">| cat     |        2 |</span><br><span class="line">| dog     |        3 |</span><br><span class="line">| hamster |        1 |</span><br><span class="line">| snake   |        1 |</span><br><span class="line">+---------+----------+</span><br><span class="line"></span><br><span class="line">mysql&gt; SELECT sex, COUNT(*) FROM pet GROUP BY sex;</span><br><span class="line">+------+----------+</span><br><span class="line">| sex  | COUNT(*) |</span><br><span class="line">+------+----------+</span><br><span class="line">| NULL |        1 |</span><br><span class="line">| f    |        4 |</span><br><span class="line">| m    |        4 |</span><br><span class="line">+------+----------+</span><br><span class="line"></span><br><span class="line">mysql&gt; SELECT species, sex, COUNT(*) FROM pet GROUP BY species, sex;</span><br><span class="line">+---------+------+----------+</span><br><span class="line">| species | sex  | COUNT(*) |</span><br><span class="line">+---------+------+----------+</span><br><span class="line">| bird    | NULL |        1 |</span><br><span class="line">| bird    | f    |        1 |</span><br><span class="line">| cat     | f    |        1 |</span><br><span class="line">| cat     | m    |        1 |</span><br><span class="line">| dog     | f    |        1 |</span><br><span class="line">| dog     | m    |        2 |</span><br><span class="line">| hamster | f    |        1 |</span><br><span class="line">| snake   | m    |        1 |</span><br><span class="line">+---------+------+----------+</span><br><span class="line"></span><br><span class="line">mysql&gt; SELECT species, sex, COUNT(*) FROM pet</span><br><span class="line">       WHERE species &#x3D; &#39;dog&#39; OR species &#x3D; &#39;cat&#39;</span><br><span class="line">       GROUP BY species, sex;</span><br><span class="line">+---------+------+----------+</span><br><span class="line">| species | sex  | COUNT(*) |</span><br><span class="line">+---------+------+----------+</span><br><span class="line">| cat     | f    |        1 |</span><br><span class="line">| cat     | m    |        1 |</span><br><span class="line">| dog     | f    |        1 |</span><br><span class="line">| dog     | m    |        2 |</span><br><span class="line">+---------+------+----------+</span><br><span class="line"></span><br><span class="line">mysql&gt; SELECT species, sex, COUNT(*) FROM pet</span><br><span class="line">       WHERE sex IS NOT NULL</span><br><span class="line">       GROUP BY species, sex;</span><br><span class="line">+---------+------+----------+</span><br><span class="line">| species | sex  | COUNT(*) |</span><br><span class="line">+---------+------+----------+</span><br><span class="line">| bird    | f    |        1 |</span><br><span class="line">| cat     | f    |        1 |</span><br><span class="line">| cat     | m    |        1 |</span><br><span class="line">| dog     | f    |        1 |</span><br><span class="line">| dog     | m    |        2 |</span><br><span class="line">| hamster | f    |        1 |</span><br><span class="line">| snake   | m    |        1 |</span><br><span class="line">+---------+------+----------+</span><br></pre></td></tr></table></figure><p>使用多个表格：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; LOAD DATA LOCAL INFILE &#39;event.txt&#39; INTO TABLE event;</span><br><span class="line"></span><br><span class="line">mysql&gt; SELECT pet.name,</span><br><span class="line">       TIMESTAMPDIFF(YEAR,birth,date) AS age,</span><br><span class="line">       remark</span><br><span class="line">       FROM pet INNER JOIN event</span><br><span class="line">         ON pet.name &#x3D; event.name</span><br><span class="line">       WHERE event.type &#x3D; &#39;litter&#39;;</span><br><span class="line">+--------+------+-----------------------------+</span><br><span class="line">| name   | age  | remark                      |</span><br><span class="line">+--------+------+-----------------------------+</span><br><span class="line">| Fluffy |    2 | 4 kittens, 3 female, 1 male |</span><br><span class="line">| Buffy  |    4 | 5 puppies, 2 female, 3 male |</span><br><span class="line">| Buffy  |    5 | 3 puppies, 3 female         |</span><br><span class="line">+--------+------+-----------------------------+</span><br><span class="line"></span><br><span class="line">mysql&gt; SELECT p1.name, p1.sex, p2.name, p2.sex, p1.species</span><br><span class="line">       FROM pet AS p1 INNER JOIN pet AS p2</span><br><span class="line">         ON p1.species &#x3D; p2.species</span><br><span class="line">         AND p1.sex &#x3D; &#39;f&#39; AND p1.death IS NULL</span><br><span class="line">         AND p2.sex &#x3D; &#39;m&#39; AND p2.death IS NULL;</span><br><span class="line">+--------+------+-------+------+---------+</span><br><span class="line">| name   | sex  | name  | sex  | species |</span><br><span class="line">+--------+------+-------+------+---------+</span><br><span class="line">| Fluffy | f    | Claws | m    | cat     |</span><br><span class="line">| Buffy  | f    | Fang  | m    | dog     |</span><br><span class="line">+--------+------+-------+------+---------+</span><br></pre></td></tr></table></figure><h3 id="从数据库或者表格中获取相关信息"><a href="#从数据库或者表格中获取相关信息" class="headerlink" title="从数据库或者表格中获取相关信息"></a>从数据库或者表格中获取相关信息</h3><p>查询当前所有的数据库：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; SHOW DATABASES;</span><br></pre></td></tr></table></figure><p>查询当前数据库中含有的表格：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; SHOW TABLES;</span><br></pre></td></tr></table></figure><p>查询某个表格的表头和属性：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; DESCRIBE pet;</span><br></pre></td></tr></table></figure><p>查询当前所在的数据库：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; SELECT DATABASE();</span><br></pre></td></tr></table></figure><h3 id="使用脚本运行MySQL指令"><a href="#使用脚本运行MySQL指令" class="headerlink" title="使用脚本运行MySQL指令"></a>使用脚本运行MySQL指令</h3><p>运行脚本的指令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">shell&gt; mysql -u root -p &lt; batch-file</span><br><span class="line">Enter password: *****</span><br></pre></td></tr></table></figure><p>可以通过如下方法来查看或者将输出保存到文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">shell&gt; mysql -u root -p &lt; batch-file | more</span><br><span class="line">shell&gt; mysql -u root -p &lt; batch-file &gt; mysql.out</span><br></pre></td></tr></table></figure><p>在batch模式和交互模式输出的内容会有不同，可以使用<code>-t</code>参数来得到交互模式下的输出；想要在输出语句中包含执行的指令，可以使用<code>-v</code>参数。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="1582114003008.png" class="lazyload" data-srcset="1582114003008.png" srcset="data:image/png;base64,666" alt="1582114003008"/></div><span class="image-caption">1582114003008</span></div><p>也可以在连接mysql后通过<code>source</code>或者<code>\</code>来运行脚本：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; source batch-file</span><br><span class="line">mysql&gt; \ filename</span><br></pre></td></tr></table></figure><h3 id="常用的查询语句"><a href="#常用的查询语句" class="headerlink" title="常用的查询语句"></a>常用的查询语句</h3><p>首先创建shop表单：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; CREATE TABLE shop(</span><br><span class="line">    -&gt; article INT UNSIGNED DEFAULT &#39;0000&#39; NOT NULL,</span><br><span class="line">    -&gt; dealer CHAR(20) DEFAULT &#39;&#39; NOT NULL,</span><br><span class="line">    -&gt; price DECIMAL(16, 2) DEFAULT &#39;0.00&#39; NOT NULL,</span><br><span class="line">    -&gt; PRIMARY KEY(article, dealer));</span><br></pre></td></tr></table></figure><p>接着插入数据：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; INSERT INTO shop VALUES</span><br><span class="line">    -&gt; (1, &#39;A&#39;, 3.45), (1, &#39;B&#39;, 3.99), (2, &#39;A&#39;, 10.99), (3, &#39;B&#39;, 1.45),</span><br><span class="line">    -&gt; (3, &#39;C&#39;, 1.69), (3, &#39;D&#39;, 1.25), (4, &#39;D&#39;, 19.95);</span><br></pre></td></tr></table></figure><ol><li><p>最大的article值：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; SELECT MAX(ARTICLE) FROM shop;</span><br></pre></td></tr></table></figure></li><li><p>找到价格最大的记录：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; SELECT * FROM shop WHERE price &#x3D; (SELECT MAX(price) FROM shop);</span><br></pre></td></tr></table></figure></li><li><p>找到每种物品的最大价格：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; SELECT article, MAX(price) FROM shop</span><br><span class="line">    -&gt; GROUP BY article;</span><br></pre></td></tr></table></figure></li><li><p>对每种物品，找到最贵价格的dealer：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; SELECT article, dealer, price</span><br><span class="line">  FROM   shop s1</span><br><span class="line">  WHERE  price&#x3D;(SELECT MAX(s2.price)</span><br><span class="line">              FROM shop s2</span><br><span class="line">                  WHERE s1.article &#x3D; s2.article)</span><br><span class="line">  ORDER BY article;</span><br></pre></td></tr></table></figure></li><li><p>使用用户定义的变量：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; SELECT @min_price:=MIN(price),@max_price:=MAX(price) FROM shop;</span><br><span class="line">mysql&gt; SELECT * FROM shop WHERE price=@min_price OR price=@max_price;</span><br></pre></td></tr></table></figure></li></ol><h3 id="使用AUTO-INCREMENT"><a href="#使用AUTO-INCREMENT" class="headerlink" title="使用AUTO_INCREMENT"></a>使用AUTO_INCREMENT</h3><p>我们可以创建animals的表格：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE animals (</span><br><span class="line">     id MEDIUMINT NOT NULL AUTO_INCREMENT,</span><br><span class="line">     name CHAR(30) NOT NULL,</span><br><span class="line">     PRIMARY KEY (id)</span><br><span class="line">);</span><br></pre></td></tr></table></figure><p>然后在插入的时候可以不用设置id的值：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">INSERT INTO animals VALUES (NULL, &#39;dog&#39;), (NULL, &#39;pig&#39;);</span><br></pre></td></tr></table></figure><h2 id="MySQL备份和恢复"><a href="#MySQL备份和恢复" class="headerlink" title="MySQL备份和恢复"></a>MySQL备份和恢复</h2><h3 id="SQL文件格式"><a href="#SQL文件格式" class="headerlink" title="SQL文件格式"></a>SQL文件格式</h3><p>备份全部数据库：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">shell&gt; mysqldump -u root -p --all-databases &gt; dump.sql</span><br></pre></td></tr></table></figure><p>备份某些特定的数据库：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">shell&gt; mysqldump -u root -p --databases db1 db2 &gt; dump.sql</span><br></pre></td></tr></table></figure><p>备份某个数据库的某些表格：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">shell&gt; mysqldump -u root -p db1 tb1 tb2 &gt; dump.sql</span><br></pre></td></tr></table></figure><p>恢复文件内容：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">shell&gt; mysql -u root -p &lt; dump.sql</span><br></pre></td></tr></table></figure><p>对于那些SQL文件中没有事先选择数据库的，可以先进入mysql，然后使用：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; USE db1;</span><br><span class="line">mysql&gt; source dump.sql;</span><br></pre></td></tr></table></figure><h3 id="使用分割文本格式"><a href="#使用分割文本格式" class="headerlink" title="使用分割文本格式"></a>使用分割文本格式</h3><p>备份数据库：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">shell&gt; mysqldump -u root -p --tab&#x3D;&#x2F;dir_name db1</span><br></pre></td></tr></table></figure><blockquote><p>如果报错：Got error: 1290: The MySQL server is running with the –secure-file-priv option so it cannot execute this statement when executing ‘SELECT INTO OUTFILE’，我们可以使用如下方法来解决：</p><p><code>mysql&gt; show global variables like &#39;%secure%&#39;</code></p><p>查看secure-file-priv对用的目录，然后将上面的<code>dirname</code>改为对应的目录就可以。</p></blockquote><p>恢复文件内容：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">shell&gt; mysql -u root -p db1 &lt; t1.sql</span><br><span class="line">shell&gt; mysqlimport db1 t1.txt</span><br></pre></td></tr></table></figure><p>或者在mysql环境下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; USE db1;</span><br><span class="line">mysql&gt; LOAD DATA INFILE &#39;t1.txt&#39; INTO TABLE t1;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> MySQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CentOS 7安装常用软件方法</title>
      <link href="2020/02/18/CentOS-7%E5%AE%89%E8%A3%85%E5%B8%B8%E7%94%A8%E8%BD%AF%E4%BB%B6%E6%96%B9%E6%B3%95/"/>
      <url>2020/02/18/CentOS-7%E5%AE%89%E8%A3%85%E5%B8%B8%E7%94%A8%E8%BD%AF%E4%BB%B6%E6%96%B9%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<p>本文将会在CentOS 7的情况下安装一下常用的开发软件，主要记录在软件安装中遇到的问题和解决问题的方法。</p><a id="more"></a><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>由于国内的网络等原因，国外的一些资源或者被墙，或者是网络连接的速度慢，这个时候就需要我们使用镜像等网络资源来提高自己获取资源的速度。</p><h2 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h2><h3 id="MySQL-8-0安装"><a href="#MySQL-8-0安装" class="headerlink" title="MySQL 8.0安装"></a>MySQL 8.0安装</h3><p>CentOS 7中可能已经预安装了Mariadb，我们首先可以查询一下是否安装了Mariadb，如果安装了就直接卸载这个数据库：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rpm -qa | grep mariadb*</span><br><span class="line">rpm -e --nodeps mariadb*</span><br></pre></td></tr></table></figure><p>接下来下载MySQL官方的Yum Repository并且进行安装，注意具体的版本可以自己选择：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">wget http://repo.mysql.com/mysql-community-release-el7-5.noarch.rpm <span class="comment">#根据版本选择</span></span><br><span class="line">rpm -ivh mysql-community-release-el7-5.noarch.rpm</span><br><span class="line">yum install mysql-server <span class="comment"># 安装</span></span><br></pre></td></tr></table></figure><p>但是由于网络原因，资源下载速率很慢，这个时候我们可以根据输出信息来决定下载的包。可以在<a href="https://mirrors.tuna.tsinghua.edu.cn/mysql/yum/mysql80-community-el7/">清华镜像源</a>中下载相应的包，然后按照依赖的关系依次安装。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="1582026273567.png" class="lazyload" data-srcset="1582026273567.png" srcset="data:image/png;base64,666" alt="1582026273567"/></div><span class="image-caption">1582026273567</span></div><p>成功安装完成后，我们使用<code>systemctl start mysqld.service</code>来启动MySQL，然后通过下面命令登录：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql -u root -p<span class="comment"># 无密码登录，输入密码行回车就行</span></span><br></pre></td></tr></table></figure><p>进入到了mysql后，首先赋予用户密码：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; ALTER user <span class="string">&#x27;root&#x27;</span>@<span class="string">&#x27;localhost&#x27;</span> IDENTIFIED BY <span class="string">&#x27;123456&#x27;</span>;</span><br><span class="line">mysql&gt; FLUSH PRIVILEGES;</span><br></pre></td></tr></table></figure><p>如果执行第一步报错，说密码太简单：ERROR 1819 (HY000): Your password does not satisfy the current policy requirements。我们可以设置密码的规则：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; <span class="built_in">set</span> global validate_password.policy=0;</span><br><span class="line">mysql&gt; <span class="built_in">set</span> global validate_password.length=1;</span><br></pre></td></tr></table></figure><p>需要注意的是，在MySQL 5.7中应该按照下列方法设置：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; <span class="built_in">set</span> global validate_password_policy=0;</span><br><span class="line">mysql&gt; <span class="built_in">set</span> global validate_password_length=1;</span><br></pre></td></tr></table></figure><h3 id="Python-3-7安装"><a href="#Python-3-7安装" class="headerlink" title="Python 3.7安装"></a>Python 3.7安装</h3><p>在CentOS 7中，安装Python 3.7的步骤通常如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装相关编译工具</span></span><br><span class="line">yum -y install zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel gdbm-devel db4-devel libpcap-devel xz-devel</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载安装包并且解压</span></span><br><span class="line">wget https://www.python.org/ftp/python/3.7.0/Python-3.7.0.tar.xz</span><br><span class="line">tar -xvJf Python-3.7.0.tar.xz</span><br><span class="line"></span><br><span class="line"><span class="comment"># 编译安装</span></span><br><span class="line"><span class="built_in">cd</span> Python-3.7.0</span><br><span class="line">./configure</span><br><span class="line">make &amp;&amp; make install</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检验是否成功安装</span></span><br><span class="line">python3 -V</span><br><span class="line">pip3 -V</span><br></pre></td></tr></table></figure><p>问题的关键点在于python.org被GFW墙了，根本不能下载Python源码。为此，我们可以在<a href="https://npm.taobao.org/mirrors/python/">淘宝镜像</a>上先下载源码包，然后按照上述方法安装就行。</p><h3 id="pip2安装"><a href="#pip2安装" class="headerlink" title="pip2安装"></a>pip2安装</h3><p>CentOS 7中默认安装了Python 2.7，但是没有预安装pip2命令，使用下面的方法安装就行：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 先安装EPEL(Extra Packages for Enterprise Linux)源</span></span><br><span class="line">yum -y install epel-release</span><br><span class="line"><span class="comment"># 接下来安装pip2</span></span><br><span class="line">yum install python-pip</span><br><span class="line"><span class="comment"># 检验安装是否成功</span></span><br><span class="line">pip2 -V</span><br></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>遇到外网下载资源不佳的情况下，可以考虑使用国内的镜像源，根据自己下载的软件版本和系统的架构选择相应的软件下载下来，然后编译安装就行。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> MySQL </tag>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Nginx 使用教程</title>
      <link href="2020/02/17/Nginx-%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/"/>
      <url>2020/02/17/Nginx-%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<p>本章学习如何在 CentOS 7下使用 Nginx 来搭建反向代理和配置动静分离以及负载均衡过程的步骤。</p><a id="more"></a><h2 id="Nginx-基本概念"><a href="#Nginx-基本概念" class="headerlink" title="Nginx 基本概念"></a>Nginx 基本概念</h2><h3 id="Nginx简介"><a href="#Nginx简介" class="headerlink" title="Nginx简介"></a>Nginx简介</h3><p>Nginx是以一个高性能的HTTP和反向代理服务器，特点是内存占用小，并发能力强，事实上Nginx的并发能力确实在同类型的网页服务器中表现良好。Nginx专为性能优化而开发，性能是其最重要的考量，实现上非常注重效率，能够经受高负载的考验，有报告表明它能支持高达50000个并发连接数。</p><h3 id="反向代理"><a href="#反向代理" class="headerlink" title="反向代理"></a>反向代理</h3><p>在介绍反向代理之前，我们先介绍一下<strong>正向代理</strong>。正向代理是一个位于客户端和目标服务器之间的代理服务器(中间服务器)。为了从原始服务器取得内容，客户端向代理服务器发送一个请求，并且指定目标服务器，之后代理向目标服务器转交并且将获得的内容返回给客户端。正向代理的情况下客户端必须要进行一些特别的设置才能使用。正向代理实际上代理的是用户。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="1581916914941.png" class="lazyload" data-srcset="1581916914941.png" srcset="data:image/png;base64,666" alt="1581916914941"/></div><span class="image-caption">1581916914941</span></div><p>反向代理正好相反。对于客户端来说，反向代理就好像目标服务器。并且客户端不需要进行任何设置。客户端向反向代理发送请求，接着反向代理判断请求走向何处，并将请求转交给客户端，使得这些内容就好似他自己一样，一次客户端并不会感知到反向代理后面的服务，也因此不需要客户端做任何设置，只需要把反向代理服务器当成真正的服务器就好了。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="1581916934765.png" class="lazyload" data-srcset="1581916934765.png" srcset="data:image/png;base64,666" alt="1581916934765"/></div><span class="image-caption">1581916934765</span></div><h3 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h3><p>在因特网中，用户对服务器的访问并发量是很高的，通常单个服务器不可能完成对用户的响应。此时我们可以增加服务器的数量，然后将请求分发到各个服务器上，将原来请求集中到单个服务器上的情况改为将请求分发到多个服务器上，将负载分发到不同的服务器上，这也就是通常所说的负载均衡。</p><h3 id="动静分离"><a href="#动静分离" class="headerlink" title="动静分离"></a>动静分离</h3><p>动静分离是指在web服务器架构中，将静态页面与动态页面或者静态内容接口和动态内容接口分开不同系统访问的架构设计方法，进而提升整个服务访问性能和可维护性。</p><h2 id="Nginx基本使用"><a href="#Nginx基本使用" class="headerlink" title="Nginx基本使用"></a>Nginx基本使用</h2><h3 id="Nginx安装"><a href="#Nginx安装" class="headerlink" title="Nginx安装"></a>Nginx安装</h3><p>安装Nginx需要先安装该软件的依赖：pcre，openssl，zlib，最后安装Nginx。可通过如下命令安装：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum -y install gcc zlib zlib-devel pcre-devel openssl openssl-devel</span><br></pre></td></tr></table></figure><p>接下来安装Nginx。首先下载nginx的源码包：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget http://nginx.org/download/nginx-1.16.2.tar.gz</span><br></pre></td></tr></table></figure><p>接下来，解压配置编译安装就行：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf nginx-1.16.2.tar.gz</span><br><span class="line"><span class="built_in">cd</span> nginx-1.16.2</span><br><span class="line">./configure</span><br><span class="line">make &amp;&amp; make install</span><br></pre></td></tr></table></figure><p>至此，Nginx安装成功，转到/usr/local/nginx/sbin目录下，查看版本号：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./nginx -v</span><br></pre></td></tr></table></figure><h3 id="Nginx常用命令"><a href="#Nginx常用命令" class="headerlink" title="Nginx常用命令"></a>Nginx常用命令</h3><ul><li><p>启动Nginx：<code>./nginx</code></p><p>如果没有修改Nginx的配置文件，我们现在就可以在内网中通过访问该服务器的地址获得Nginx的主页，如果没有看到Nginx的主页，此时需要配置防火墙开放80端口。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="1581928110804.png" class="lazyload" data-srcset="1581928110804.png" srcset="data:image/png;base64,666" alt="1581928110804"/></div><span class="image-caption">1581928110804</span></div><blockquote><ol><li>查看开放的端口：<code>firewall-cmd --list-all</code></li><li>设置开放的端口：<code>firewall-cmd --add-port=80/tcp --permanent</code></li><li>设置开放的服务：<code>firewall-cmd --add-service=http --permanent</code></li><li>设置之后重启防火墙：<code>firewall-cmd --reload</code></li></ol></blockquote></li><li><p>停止Nginx：<code>./nginx -s stop</code></p></li><li><p>重加载Nginx：<code>./nginx -s reload</code></p></li></ul><h3 id="Nginx配置文件"><a href="#Nginx配置文件" class="headerlink" title="Nginx配置文件"></a>Nginx配置文件</h3><p>配置文件位于/usr/local/nginx/conf/nginx.conf，配置文件可以划分为三个部分：</p><ul><li><p>全局块：配置服务器整体运行的配置指令</p><p>从配置文件开始到events块之间的内容，主要会设置一些影响 nginx 服务器整体运行的配置指令，主要包括配置运行 Nginx 服务器的用户（组）、允许生成的 worker process 数，进程 PID 存放路径、日志存放路径和类型以及配置文件的引入等。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="1581927474071.png" class="lazyload" data-srcset="1581927474071.png" srcset="data:image/png;base64,666" alt="1581927474071"/></div><span class="image-caption">1581927474071</span></div><p>上面的第一行配置的就是worker进程的数目，进程数目越大，相应的并发能力也就也强，通常将它的值设置为CPU的核数目。</p></li><li><p>events块：影响 Nginx 服务器与用户的网络连接</p><p>events 块涉及的指令主要影响 Nginx 服务器与用户的网络连接，常用的设置包括是否开启对多 worker进程下的网络连接进行序列化，是否允许同时接收多个网络连接，选取哪种事件驱动模型来处理连接请求，每个 worker进程可以同时支持的最大连接数等。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="1581927674793.png" class="lazyload" data-srcset="1581927674793.png" srcset="data:image/png;base64,666" alt="1581927674793"/></div><span class="image-caption">1581927674793</span></div><p>上面的例子表示的是一个worker进程支持的最大连接数。</p></li><li><p>http块</p><p>这算是 Nginx 服务器配置中最频繁的部分，代理、缓存和日志定义等绝大多数功能和第三方模块的配置都在这里。需要注意的是http块也可以进一步划分为http全局块核server块。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="1581927895940.png" class="lazyload" data-srcset="1581927895940.png" srcset="data:image/png;base64,666" alt="1581927895940"/></div><span class="image-caption">1581927895940</span></div><ul><li>http全局块：http 全局块配置的指令包括文件引入、MIME-TYPE 定义、日志自定义、连接超时时间、单链接请求数上限等。</li><li>server块：这块和虚拟主机有密切关系，虚拟主机从用户角度看，和一台独立的硬件主机是完全一样的，该技术的产生是为了节省互联网服务器硬件成本。每个 http 块可以包括多个 server 块，而每个 server 块就相当于一个虚拟主机。而每个 server 块也分为全局 server 块，以及可以同时包含多个 locaton 块。<ul><li>全局server块：最常见的配置是本虚拟机主机的监听配置和本虚拟主机的名称或 IP 配置。</li><li>location块：一个 server 块可以配置多个 location 块。这块的主要作用是基于 Nginx 服务器接收到的请求字符串（例如 server_name/uri-string），对虚拟主机名称（也可以是 IP 别名）之外的字符串（例如 前面的 /uri-string）进行匹配，对特定的请求进行处理。地址定向、数据缓存和应答控制等功能，还有许多第三方模块的配置也在这里进行。</li></ul></li></ul></li></ul><h2 id="Nginx配置实例"><a href="#Nginx配置实例" class="headerlink" title="Nginx配置实例"></a>Nginx配置实例</h2><h3 id="反向代理-1"><a href="#反向代理-1" class="headerlink" title="反向代理 1"></a>反向代理 1</h3><ol><li><p>实现效果：打开浏览器，在浏览器地址栏输入地址<code>server.test.com</code>，跳转到 liunx 系统 tomcat 主页</p><p>面中。</p></li><li><p>准备工作</p><ol><li><p>在CentOS中安装tomcat，使用默认的端口8080启动服务，即进入tomcat的bin目录中，运行<code>./startup.sh</code>启动tomcat服务器</p></li><li><p>修改防火墙，使其对外开放8080端口：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">firewall-cmd --add-port=8080/tcp --permanent</span><br><span class="line">firewall-cmd --reload</span><br></pre></td></tr></table></figure></li><li><p>在windows中通过浏览器<code>ip:8080</code>访问tomcat服务器</p></li></ol></li><li><p>具体配置</p><ol><li><p>打开windows的host文件，添加<code>192.168.85.129 server.test.com</code>。</p></li><li><p>在nginx进行请求转发的配置</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="1581939678141.png" class="lazyload" data-srcset="1581939678141.png" srcset="data:image/png;base64,666" alt="1581939678141"/></div><span class="image-caption">1581939678141</span></div></li><li><p>接着重启以下nginx：<code>./nginx -s reload</code>。然后在浏览器中输入<code>server.test.com</code>，就可以得到tomcat的网页：</p><p><img src="1581939968797.png" class="lazyload" data-srcset="1581939968797.png" srcset="data:image/png;base64,666" alt="1581939968797">  </p></li></ol></li></ol><h3 id="反向代理2"><a href="#反向代理2" class="headerlink" title="反向代理2"></a>反向代理2</h3><ol><li><p>实现效果：使用nginx反向代理，根据访问的路径跳转到不同端口的服务中，nginx监听端口9001，当访问<code>ip:9001/edu</code>直接跳转到<code>127.0.0.1:8080</code>，当访问<code>ip:9001/vod</code>，直接跳转到<code>127.0.0.1:8081</code>。</p></li><li><p>准备工作</p><ol><li>准备两个tomcat服务器，一个配置在8080端口，一个配置在8081端口。修改conf/server.xml里面的两个端口，使得两个tomcat能够同时运行起来。</li><li>创建文件夹和测试文件。创建的文件夹和文件等会在被解析的时候用到。</li></ol></li><li><p>具体配置</p><ol><li><p>找到nginx配置文件，进行反向代理配置：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="1581940620095.png" class="lazyload" data-srcset="1581940620095.png" srcset="data:image/png;base64,666" alt="1581940620095"/></div><span class="image-caption">1581940620095</span></div></li><li><p>防火墙对外开放9001，8080和8081端口。</p></li><li><p>测试如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="1581943507419.png" class="lazyload" data-srcset="1581943507419.png" srcset="data:image/png;base64,666" alt="1581943507419"/></div><span class="image-caption">1581943507419</span></div><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="1581943526797.png" class="lazyload" data-srcset="1581943526797.png" srcset="data:image/png;base64,666" alt="1581943526797"/></div><span class="image-caption">1581943526797</span></div></li></ol></li></ol><h3 id="负载均衡-1"><a href="#负载均衡-1" class="headerlink" title="负载均衡"></a>负载均衡</h3><ol><li><p>实现效果：浏览器地址栏输入地址<code>ip:9002/edu/</code>，使得后台的服务器均匀负载，将请求平均分发到8080和8081端口的服务器上。</p></li><li><p>准备工作</p><ol><li>准备两台服务器，一台8080，另外一台8081</li><li>在两台tomcat服务器的webapps目录，创建edu文件夹，同时在edu文件里面创建index.html</li></ol></li><li><p>具体配置</p><ol><li><p>找到nginx配置文件，进行负载均衡的配置</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="1581944619600.png" class="lazyload" data-srcset="1581944619600.png" srcset="data:image/png;base64,666" alt="1581944619600"/></div><span class="image-caption">1581944619600</span></div></li><li><p>防火墙开放9002端口。</p></li><li><p>测试如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="1581944727364.png" class="lazyload" data-srcset="1581944727364.png" srcset="data:image/png;base64,666" alt="1581944727364"/></div><span class="image-caption">1581944727364</span></div><p><img src="1581944749452.png" class="lazyload" data-srcset="1581944749452.png" srcset="data:image/png;base64,666" alt="1581944749452">   </p></li></ol></li><li><p>Nginx分配服务器策略</p><ol><li><p>轮询（默认）：每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器 down 掉，能自动剔除。</p></li><li><p>权重（weight）：weight 代表权重默认为 1,权重越高被分配的客户端越多。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="1455597-20191029103434709-133983538-1581944951431.png" class="lazyload" data-srcset="1455597-20191029103434709-133983538-1581944951431.png" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div></li><li><p>ip_hash：每个请求按访问 ip 的 hash 结果分配，这样每个访客固定访问一个后端服务器。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="1455597-20191029103440910-1253898902.png" class="lazyload" data-srcset="1455597-20191029103440910-1253898902.png" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div></li><li><p>fair：按后端服务器的响应时间来分配请求，响应时间短的优先分配。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="1455597-20191029103448391-1932086344.png" class="lazyload" data-srcset="1455597-20191029103448391-1932086344.png" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div></li></ol></li></ol><h3 id="动静分离-1"><a href="#动静分离-1" class="headerlink" title="动静分离"></a>动静分离</h3><ol><li><p>动静分离：Nginx 动静分离简单来说就是把动态跟静态请求分开，不能理解成只是单纯的把动态页面和静态页面物理分离。严格意义上说应该是动态请求跟静态请求分开，可以理解成使用 Nginx处理静态页面，Tomcat 处理动态页面。动静分离从目前实现角度来讲大致分为两种，一种是纯粹把静态文件独立成单独的域名，放在独立的服务器上，也是目前主流推崇的方案；另外一种方法就是动态跟静态文件混合在一起发布，通过 nginx 来分开。通过 location 指定不同的后缀名实现不同的请求转发。通过 expires 参数设置，可以使浏览器缓存过期时间，减少与服务器之前的请求和流量。具体 Expires 定义：是给一个资源设定一个过期时间，也就是说无需去服务端验证，直接通过浏览器自身确认是否过期即可，所以不会产生额外的流量。此种方法非常适合不经常变动的资源。（如果经常更新的文件，不建议使用 Expires 来缓存），我这里设置 3d，表示在这 3 天之内访问这个 URL，发送一个请求，比对服务器该文件最后更新时间没有变化，则不会从服务器抓取，返回状态码 304，如果有修改，则直接从服务器重新下载，返回状态码 200。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="1455597-20191029103503613-506507153.png" class="lazyload" data-srcset="1455597-20191029103503613-506507153.png" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div></li><li><p>准备工作：在CentOS中，创建/static/www，/static/image文件夹，接着放入静态文件。</p></li><li><p>Nginx配置：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="1581946029645.png" class="lazyload" data-srcset="1581946029645.png" srcset="data:image/png;base64,666" alt="1581946029645"/></div><span class="image-caption">1581946029645</span></div><blockquote><p><code>autoindex</code>能够为目录下的文件自动创建索引。</p></blockquote></li><li><p>效果：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="1581946053128.png" class="lazyload" data-srcset="1581946053128.png" srcset="data:image/png;base64,666" alt="1581946053128"/></div><span class="image-caption">1581946053128</span></div><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="1581946068998.png" class="lazyload" data-srcset="1581946068998.png" srcset="data:image/png;base64,666" alt="1581946068998"/></div><span class="image-caption">1581946068998</span></div></li></ol><h3 id="高可用集群"><a href="#高可用集群" class="headerlink" title="高可用集群"></a>高可用集群</h3><p>下面将使用keepalived实现服务器的高可用性。详细的讲解见<strong>Nginx原理</strong>一节。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="1581947505380.png" class="lazyload" data-srcset="1581947505380.png" srcset="data:image/png;base64,666" alt="1581947505380"/></div><span class="image-caption">1581947505380</span></div><ol><li><p>两台Nginx服务器</p><p>准备两台服务器，在此地址是<code>192.168.85.129</code>和<code>192.168.85.130</code>。然后再在两台服务器上安装Nginx软件。</p></li><li><p>keepalived软件</p><p>使用以下命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install keepalived -y</span><br></pre></td></tr></table></figure><p>安装完成后，可以在/etc/keepalived中找到配置文件。</p></li><li><p>完成高可用的配置</p><ol><li><p>修改/etc/keepalived/keepalived.conf</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">! Configuration File for keepalived</span><br><span class="line">global_defs &#123;</span><br><span class="line">   router_id LVS_DEVEL</span><br><span class="line">&#125;</span><br><span class="line">vrrp_script chk_http_port &#123;</span><br><span class="line">    script &quot;&#x2F;usr&#x2F;local&#x2F;src&#x2F;nginx_check.sh&quot;</span><br><span class="line">    interval 2</span><br><span class="line">    weight 2</span><br><span class="line">&#125;</span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">    state BACKUP</span><br><span class="line">    interface ens33</span><br><span class="line">    virtual_router_id 51</span><br><span class="line">    priority 90</span><br><span class="line">    advert_int 1</span><br><span class="line">    authentication &#123;</span><br><span class="line">        auth_type PASS</span><br><span class="line">        auth_pass 1111</span><br><span class="line">    &#125;</span><br><span class="line">    track_script &#123;</span><br><span class="line">        chk_http_port</span><br><span class="line">    &#125;</span><br><span class="line">    virtual_ipaddress &#123;</span><br><span class="line">        192.168.85.120</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>在/usr/local/src/中添加nginx_check.sh文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line">A=`ps -C nginx --no-header | wc -l`</span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$A</span> -eq 0 ];<span class="keyword">then</span></span><br><span class="line">        /usr/<span class="built_in">local</span>/nginx/sbin/nginx</span><br><span class="line">        sleep 2</span><br><span class="line">        <span class="keyword">if</span> [`ps -C nginx --no-header | wc -l` -eq 0];<span class="keyword">then</span></span><br><span class="line">                killall keepalived</span><br><span class="line">        <span class="keyword">fi</span></span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure></li></ol></li><li><p>测试</p><ol><li><p>启动nginx：<code>./nginx</code></p></li><li><p>启动keepalived：<code>systemctl start keepalived.service</code></p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="1581993867642.png" class="lazyload" data-srcset="1581993867642.png" srcset="data:image/png;base64,666" alt="1581993867642"/></div><span class="image-caption">1581993867642</span></div></li><li><p>关闭主服务器上的nginx，再次访问虚拟地址</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="1581993920791.png" class="lazyload" data-srcset="1581993920791.png" srcset="data:image/png;base64,666" alt="1581993920791"/></div><span class="image-caption">1581993920791</span></div></li></ol></li></ol><h2 id="Nginx原理"><a href="#Nginx原理" class="headerlink" title="Nginx原理"></a>Nginx原理</h2><p>Nginx在启动时会以daemon形式在后台运行，采用多进程+异步非阻塞IO事件模型来处理各种连接请求。多进程模型包括一个master进程，多个worker进程，一般worker进程个数是根据服务器CPU核数来决定的。master进程负责管理Nginx本身和其他worker进程。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="6807865-b1413f8b819b7d44.webp" class="lazyload" data-srcset="6807865-b1413f8b819b7d44.webp" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><p>Master进程作用是读取并验证配置文件nginx.conf，管理worker进程；每一个Worker进程都维护一个线程（避免线程切换），处理连接和请求；注意Worker进程的个数由配置文件决定，一般和CPU个数相关（有利于进程切换），配置几个就有几个Worker进程。</p><p>Nginx热部署的方式：修改配置文件nginx.conf后，重新生成新的worker进程，当然会以新的配置进行处理请求，而且新的请求必须都交给新的worker进程，至于老的worker进程，等把那些以前的请求处理完毕后，kill掉即可。</p><p>Nginx的高并发：Nginx采用了Linux的epoll模型，epoll模型基于事件驱动机制，它可以监控多个事件是否准备完毕，如果OK，那么放入epoll队列中，这个过程是异步的。worker只需要从epoll队列循环处理即可。</p><p>Nginx的高可用性：Keepalived是一个高可用解决方案，主要是用来防止服务器单点发生故障，可以通过和Nginx配合来实现Web服务的高可用（其实，Keepalived不仅仅可以和Nginx配合，还可以和很多其他服务配合）。Keepalived+Nginx实现高可用的思路：第一：请求不要直接打到Nginx上，应该先通过Keepalived（这就是所谓虚拟IP，VIP）第二：Keepalived应该能监控Nginx的生命状态（提供一个用户自定义的脚本，定期检查Nginx进程状态，进行权重变化,，从而实现Nginx故障切换）</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="6807865-d87387daf7a20f64.webp" class="lazyload" data-srcset="6807865-d87387daf7a20f64.webp" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div>]]></content>
      
      
      
        <tags>
            
            <tag> Nginx </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>训练和评估</title>
      <link href="2020/02/15/%E8%AE%AD%E7%BB%83%E5%92%8C%E8%AF%84%E4%BC%B0/"/>
      <url>2020/02/15/%E8%AE%AD%E7%BB%83%E5%92%8C%E8%AF%84%E4%BC%B0/</url>
      
        <content type="html"><![CDATA[<p>本节主要从两方面学习模型的训练和评估：使用内建的API进行训练和评估或者是自定义函数实现训练和评估。不管使用哪种方法，不同方式构建的模型的训练和评估方式是一样的。</p><a id="more"></a><h2 id="使用内建API"><a href="#使用内建API" class="headerlink" title="使用内建API"></a>使用内建API</h2><p> 当我们使用内建的API来进行训练和评估时，我们传入的数据必须是<strong>Numpy arrays</strong>或者是<strong>tf.data.Dataset</strong>对象，在接下来的几个小节里，我们将会使用MNIST数据集作为示例。</p><h3 id="内建API总览"><a href="#内建API总览" class="headerlink" title="内建API总览"></a>内建API总览</h3><p>首先创建一个模型，如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers</span><br><span class="line"></span><br><span class="line">inputs = keras.Input(shape=(<span class="number">784</span>,), name=<span class="string">&#x27;digits&#x27;</span>)</span><br><span class="line">x = layers.Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>, name=<span class="string">&#x27;dense_1&#x27;</span>)(inputs)</span><br><span class="line">x = layers.Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>, name=<span class="string">&#x27;dense_2&#x27;</span>)(x)</span><br><span class="line">outputs = layers.Dense(<span class="number">10</span>, name=<span class="string">&#x27;predictions&#x27;</span>)(x)</span><br><span class="line"></span><br><span class="line">model = keras.Model(inputs=inputs, outputs=outputs)</span><br></pre></td></tr></table></figure><p>接下来，我们定义一个如下一个数据集：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Preprocess the data (these are Numpy arrays)</span></span><br><span class="line">x_train = x_train.reshape(<span class="number">60000</span>, <span class="number">784</span>).astype(<span class="string">&#x27;float32&#x27;</span>) / <span class="number">255</span></span><br><span class="line">x_test = x_test.reshape(<span class="number">10000</span>, <span class="number">784</span>).astype(<span class="string">&#x27;float32&#x27;</span>) / <span class="number">255</span></span><br><span class="line"></span><br><span class="line">y_train = y_train.astype(<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">y_test = y_test.astype(<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Reserve 10,000 samples for validation</span></span><br><span class="line">x_val = x_train[<span class="number">-10000</span>:]</span><br><span class="line">y_val = y_train[<span class="number">-10000</span>:]</span><br><span class="line">x_train = x_train[:<span class="number">-10000</span>]</span><br><span class="line">y_train = y_train[:<span class="number">-10000</span>]</span><br></pre></td></tr></table></figure><p>然后配置训练参数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">model.compile(optimizer=keras.optimizers.RMSprop(),  <span class="comment"># Optimizer</span></span><br><span class="line">              <span class="comment"># Loss function to minimize</span></span><br><span class="line">              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">True</span>),</span><br><span class="line">              <span class="comment"># List of metrics to monitor</span></span><br><span class="line">              metrics=[<span class="string">&#x27;sparse_categorical_accuracy&#x27;</span>])</span><br></pre></td></tr></table></figure><p>接下来按照小批次的数目（batch_size）来训练这个模型，迭代整个数据集次数通过epochs设置：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">&#x27;# Fit model on training data&#x27;</span>)</span><br><span class="line">history = model.fit(x_train, y_train,</span><br><span class="line">                    batch_size=<span class="number">64</span>,</span><br><span class="line">                    epochs=<span class="number">3</span>,</span><br><span class="line">                    <span class="comment"># We pass some validation for</span></span><br><span class="line">                    <span class="comment"># monitoring validation loss and metrics</span></span><br><span class="line">                    <span class="comment"># at the end of each epoch</span></span><br><span class="line">                    validation_data=(x_val, y_val))</span><br><span class="line"></span><br><span class="line">print(<span class="string">&#x27;\nhistory dict:&#x27;</span>, history.history)</span><br><span class="line">&gt;&gt; history dict: &#123;<span class="string">&#x27;loss&#x27;</span>: [<span class="number">0.34013055738687514</span>, <span class="number">0.15638909303188325</span>, <span class="number">0.11687878879904746</span>], <span class="string">&#x27;sparse_categorical_accuracy&#x27;</span>: [<span class="number">0.90308</span>, <span class="number">0.95404</span>, <span class="number">0.96512</span>], <span class="string">&#x27;val_loss&#x27;</span>: [<span class="number">0.18770194243788718</span>, <span class="number">0.13478265590667723</span>, <span class="number">0.11865641107037664</span>], <span class="string">&#x27;val_sparse_categorical_accuracy&#x27;</span>: [<span class="number">0.9454</span>, <span class="number">0.9615</span>, <span class="number">0.9672</span>]&#125;</span><br></pre></td></tr></table></figure><p>返回的对象记录了训练过程中损失值（loss value）和度量值（metrics）。下面的代码用于评估和预测：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Evaluate the model on the test data using `evaluate`</span></span><br><span class="line">print(<span class="string">&#x27;\n# Evaluate on test data&#x27;</span>)</span><br><span class="line">results = model.evaluate(x_test, y_test, batch_size=<span class="number">128</span>)</span><br><span class="line">print(<span class="string">&#x27;test loss, test acc:&#x27;</span>, results)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Generate predictions (probabilities -- the output of the last layer)</span></span><br><span class="line"><span class="comment"># on new data using `predict`</span></span><br><span class="line">print(<span class="string">&#x27;\n# Generate predictions for 3 samples&#x27;</span>)</span><br><span class="line">predictions = model.predict(x_test[:<span class="number">3</span>])</span><br><span class="line">print(<span class="string">&#x27;predictions shape:&#x27;</span>, predictions.shape)</span><br></pre></td></tr></table></figure><h3 id="定义损失函数，评价指标和优化器"><a href="#定义损失函数，评价指标和优化器" class="headerlink" title="定义损失函数，评价指标和优化器"></a>定义损失函数，评价指标和优化器</h3><p>为了训练模型，我们需要定义损失函数，评价指标和优化器。我们可以再模型编译期间传入这些参数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model.compile(optimizer=keras.optimizers.RMSprop(learning_rate=<span class="number">1e-3</span>),</span><br><span class="line">              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">True</span>),</span><br><span class="line">              metrics=[<span class="string">&#x27;sparse_categorical_accuracy&#x27;</span>])</span><br></pre></td></tr></table></figure><p>注意，metrics参数必须是一个列表，可以传入多个评价指标。对于含有多个输出的模型，我们可以分别为其定义损失函数，评价指标和优化器。同时，一些默认的参数值我们也可以使用字符串。为了重用，我们定义如下代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_uncompiled_model</span>():</span></span><br><span class="line">  inputs = keras.Input(shape=(<span class="number">784</span>,), name=<span class="string">&#x27;digits&#x27;</span>)</span><br><span class="line">  x = layers.Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>, name=<span class="string">&#x27;dense_1&#x27;</span>)(inputs)</span><br><span class="line">  x = layers.Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>, name=<span class="string">&#x27;dense_2&#x27;</span>)(x)</span><br><span class="line">  outputs = layers.Dense(<span class="number">10</span>, name=<span class="string">&#x27;predictions&#x27;</span>)(x)</span><br><span class="line">  model = keras.Model(inputs=inputs, outputs=outputs)</span><br><span class="line">  <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_compiled_model</span>():</span></span><br><span class="line">  model = get_uncompiled_model()</span><br><span class="line">  model.compile(optimizer=keras.optimizers.RMSprop(learning_rate=<span class="number">1e-3</span>),</span><br><span class="line">                loss=keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">True</span>),</span><br><span class="line">                metrics=[<span class="string">&#x27;sparse_categorical_accuracy&#x27;</span>])</span><br><span class="line">  <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure><h4 id="内建的损失函数，评价指标和优化器"><a href="#内建的损失函数，评价指标和优化器" class="headerlink" title="内建的损失函数，评价指标和优化器"></a>内建的损失函数，评价指标和优化器</h4><p>内建优化器：SGD，RMSprop，Adam；内建损失函数：MeanSquareError，KLDivergence，CosineSimilarity；内建评估指标：AUC，Precision，Recall。</p><h4 id="自定义损失函数"><a href="#自定义损失函数" class="headerlink" title="自定义损失函数"></a>自定义损失函数</h4><p>有两种方法来自定义我们的损失函数，第一种是定义一个函数，接受<code>y_true</code>和<code>y_pred</code>参数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">basic_loss_function</span>(<span class="params">y_true, y_pred</span>):</span></span><br><span class="line">    <span class="keyword">return</span> tf.math.reduce_mean(tf.abs(y_true - y_pred))</span><br><span class="line"></span><br><span class="line">model.compile(optimizer=keras.optimizers.Adam(),</span><br><span class="line">              loss=basic_loss_function)</span><br><span class="line"></span><br><span class="line">model.fit(x_train, y_train, batch_size=<span class="number">64</span>, epochs=<span class="number">3</span>)</span><br></pre></td></tr></table></figure><p>另外一种方法是构造<code>tf.keras.losses.Loss</code>的子类，并且实现以下两个方法：</p><ul><li><code>__init__</code>：接受传向损失函数的参数</li><li><code>call(self, y_true, y_pred)</code>：用于计算模型的损失</li></ul><p>传向<code>__init__</code>的参数可以被<code>call</code>方法调用。以下方法实现实现了<code>BinaryCrossEntropy</code>损失函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">WeightedBinaryCrossEntropy</span>(<span class="params">keras.losses.Loss</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">      pos_weight: Scalar to affect the positive labels of the loss function.</span></span><br><span class="line"><span class="string">      weight: Scalar to affect the entirety of the loss function.</span></span><br><span class="line"><span class="string">      from_logits: Whether to compute loss from logits or the probability.</span></span><br><span class="line"><span class="string">      reduction: Type of tf.keras.losses.Reduction to apply to loss.</span></span><br><span class="line"><span class="string">      name: Name of the loss function.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, pos_weight, weight, from_logits=False,</span></span></span><br><span class="line"><span class="function"><span class="params">                 reduction=keras.losses.Reduction.AUTO,</span></span></span><br><span class="line"><span class="function"><span class="params">                 name=<span class="string">&#x27;weighted_binary_crossentropy&#x27;</span></span>):</span></span><br><span class="line">        super().__init__(reduction=reduction, name=name)</span><br><span class="line">        self.pos_weight = pos_weight</span><br><span class="line">        self.weight = weight</span><br><span class="line">        self.from_logits = from_logits</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, y_true, y_pred</span>):</span></span><br><span class="line">        ce = tf.losses.binary_crossentropy(</span><br><span class="line">            y_true, y_pred, from_logits=self.from_logits)[:,<span class="literal">None</span>]</span><br><span class="line">        ce = self.weight * (ce*(<span class="number">1</span>-y_true) + self.pos_weight*ce*(y_true))</span><br><span class="line">        <span class="keyword">return</span> ce</span><br></pre></td></tr></table></figure><p>由于数据集由10个类别，但我们使用的是二元损失，所以我们只考虑每个类别的预测，这样就能基于二元损失来计算了。首先创建独热码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">one_hot_y_train = tf.one_hot(y_train.astype(np.int32), depth=<span class="number">10</span>)</span><br></pre></td></tr></table></figure><p>接下俩训练模型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">model = get_uncompiled_model()</span><br><span class="line"></span><br><span class="line">model.compile(</span><br><span class="line">    optimizer=keras.optimizers.Adam(),</span><br><span class="line">    loss=WeightedBinaryCrossEntropy(</span><br><span class="line">        pos_weight=<span class="number">0.5</span>, weight = <span class="number">2</span>, from_logits=<span class="literal">True</span>)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">model.fit(x_train, one_hot_y_train, batch_size=<span class="number">64</span>, epochs=<span class="number">5</span>)</span><br></pre></td></tr></table></figure><h3 id="自定义评估指标"><a href="#自定义评估指标" class="headerlink" title="自定义评估指标"></a>自定义评估指标</h3><p>可以通过创建<code>Metric</code>来实现自定义的评价指标，需要实现下列四种方法：</p><ul><li><code>__init__</code>：用于创建状态变量</li><li><code>update_state(self, y_true, y_pred, sample_weight=None)</code>：用于更新状态</li><li><code>result(self)</code>：使用状态变量计算最终结果</li><li><code>reset_states(self)</code>：重新初始化状态</li></ul><p>下面是一个实现了<code>CategoricalTruePositive</code>评价指标：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CategoricalTruePositives</span>(<span class="params">keras.metrics.Metric</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, name=<span class="string">&#x27;categorical_true_positives&#x27;</span>, **kwargs</span>):</span></span><br><span class="line">      super(CategoricalTruePositives, self).__init__(name=name, **kwargs)</span><br><span class="line">      self.true_positives = self.add_weight(name=<span class="string">&#x27;tp&#x27;</span>, initializer=<span class="string">&#x27;zeros&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">update_state</span>(<span class="params">self, y_true, y_pred, sample_weight=None</span>):</span></span><br><span class="line">      y_pred = tf.reshape(tf.argmax(y_pred, axis=<span class="number">1</span>), shape=(<span class="number">-1</span>, <span class="number">1</span>))</span><br><span class="line">      values = tf.cast(y_true, <span class="string">&#x27;int32&#x27;</span>) == tf.cast(y_pred, <span class="string">&#x27;int32&#x27;</span>)</span><br><span class="line">      values = tf.cast(values, <span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">      <span class="keyword">if</span> sample_weight <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        sample_weight = tf.cast(sample_weight, <span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">        values = tf.multiply(values, sample_weight)</span><br><span class="line">      self.true_positives.assign_add(tf.reduce_sum(values))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">result</span>(<span class="params">self</span>):</span></span><br><span class="line">      <span class="keyword">return</span> self.true_positives</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">reset_states</span>(<span class="params">self</span>):</span></span><br><span class="line">      <span class="comment"># The state of the metric will be reset at the start of each epoch.</span></span><br><span class="line">      self.true_positives.assign(<span class="number">0.</span>)</span><br></pre></td></tr></table></figure><p>下面是使用评价指标的代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">model.compile(optimizer=keras.optimizers.RMSprop(learning_rate=<span class="number">1e-3</span>),</span><br><span class="line">              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">True</span>),</span><br><span class="line">              metrics=[CategoricalTruePositives()])</span><br><span class="line">model.fit(x_train, y_train,</span><br><span class="line">          batch_size=<span class="number">64</span>,</span><br><span class="line">          epochs=<span class="number">3</span>)</span><br></pre></td></tr></table></figure><h4 id="处理非常规的损失函数和评价指标"><a href="#处理非常规的损失函数和评价指标" class="headerlink" title="处理非常规的损失函数和评价指标"></a>处理非常规的损失函数和评价指标</h4><p>可以通过<code>y_pred</code>和<code>y_true</code>来计算损失函数和评价指标，然而，并非对所有的损失函数和评价指标都是如此。比如，一个正则化的损失函数可能需要某个层的激励值，而这个激励值并非是模型的输出。处理此类问题，我们可以再自定义层中的call方法中加入<code>self.add_loss(loss_value)</code>:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ActivityRegularizationLayer</span>(<span class="params">layers.Layer</span>):</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, inputs</span>):</span></span><br><span class="line">    self.add_loss(tf.reduce_sum(inputs) * <span class="number">0.1</span>)</span><br><span class="line">    <span class="keyword">return</span> inputs  <span class="comment"># Pass-through layer.</span></span><br><span class="line"></span><br><span class="line">inputs = keras.Input(shape=(<span class="number">784</span>,), name=<span class="string">&#x27;digits&#x27;</span>)</span><br><span class="line">x = layers.Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>, name=<span class="string">&#x27;dense_1&#x27;</span>)(inputs)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Insert activity regularization as a layer</span></span><br><span class="line">x = ActivityRegularizationLayer()(x)</span><br><span class="line"></span><br><span class="line">x = layers.Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>, name=<span class="string">&#x27;dense_2&#x27;</span>)(x)</span><br><span class="line">outputs = layers.Dense(<span class="number">10</span>, name=<span class="string">&#x27;predictions&#x27;</span>)(x)</span><br><span class="line"></span><br><span class="line">model = keras.Model(inputs=inputs, outputs=outputs)</span><br><span class="line">model.compile(optimizer=keras.optimizers.RMSprop(learning_rate=<span class="number">1e-3</span>),</span><br><span class="line">              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">True</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># The displayed loss will be much higher than before</span></span><br><span class="line"><span class="comment"># due to the regularization component.</span></span><br><span class="line">model.fit(x_train, y_train,</span><br><span class="line">          batch_size=<span class="number">64</span>,</span><br><span class="line">          epochs=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>同样，对于评价指标也是如此：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MetricLoggingLayer</span>(<span class="params">layers.Layer</span>):</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, inputs</span>):</span></span><br><span class="line">    <span class="comment"># The `aggregation` argument defines</span></span><br><span class="line">    <span class="comment"># how to aggregate the per-batch values</span></span><br><span class="line">    <span class="comment"># over each epoch:</span></span><br><span class="line">    <span class="comment"># in this case we simply average them.</span></span><br><span class="line">    self.add_metric(keras.backend.std(inputs),</span><br><span class="line">                    name=<span class="string">&#x27;std_of_activation&#x27;</span>,</span><br><span class="line">                    aggregation=<span class="string">&#x27;mean&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> inputs  <span class="comment"># Pass-through layer.</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">inputs = keras.Input(shape=(<span class="number">784</span>,), name=<span class="string">&#x27;digits&#x27;</span>)</span><br><span class="line">x = layers.Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>, name=<span class="string">&#x27;dense_1&#x27;</span>)(inputs)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Insert std logging as a layer.</span></span><br><span class="line">x = MetricLoggingLayer()(x)</span><br><span class="line"></span><br><span class="line">x = layers.Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>, name=<span class="string">&#x27;dense_2&#x27;</span>)(x)</span><br><span class="line">outputs = layers.Dense(<span class="number">10</span>, name=<span class="string">&#x27;predictions&#x27;</span>)(x)</span><br><span class="line"></span><br><span class="line">model = keras.Model(inputs=inputs, outputs=outputs)</span><br><span class="line">model.compile(optimizer=keras.optimizers.RMSprop(learning_rate=<span class="number">1e-3</span>),</span><br><span class="line">              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">True</span>))</span><br><span class="line">model.fit(x_train, y_train,</span><br><span class="line">          batch_size=<span class="number">64</span>,</span><br><span class="line">          epochs=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>再函数式API中，我们可以通过<code>model.add_loss(loss_tensor)</code>和<code>model.add_metric(metric_tensor, name, aggregation)</code>来实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">inputs = keras.Input(shape=(<span class="number">784</span>,), name=<span class="string">&#x27;digits&#x27;</span>)</span><br><span class="line">x1 = layers.Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>, name=<span class="string">&#x27;dense_1&#x27;</span>)(inputs)</span><br><span class="line">x2 = layers.Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>, name=<span class="string">&#x27;dense_2&#x27;</span>)(x1)</span><br><span class="line">outputs = layers.Dense(<span class="number">10</span>, name=<span class="string">&#x27;predictions&#x27;</span>)(x2)</span><br><span class="line">model = keras.Model(inputs=inputs, outputs=outputs)</span><br><span class="line"></span><br><span class="line">model.add_loss(tf.reduce_sum(x1) * <span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line">model.add_metric(keras.backend.std(x1),</span><br><span class="line">                 name=<span class="string">&#x27;std_of_activation&#x27;</span>,</span><br><span class="line">                 aggregation=<span class="string">&#x27;mean&#x27;</span>)</span><br><span class="line"></span><br><span class="line">model.compile(optimizer=keras.optimizers.RMSprop(<span class="number">1e-3</span>),</span><br><span class="line">              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">True</span>))</span><br><span class="line">model.fit(x_train, y_train,</span><br><span class="line">          batch_size=<span class="number">64</span>,</span><br><span class="line">          epochs=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><h4 id="自动设置验证集"><a href="#自动设置验证集" class="headerlink" title="自动设置验证集"></a>自动设置验证集</h4><p>再第一个实例中，我们使用<code>validation_data</code>来手动设置验证集。其实我们还可以使用<code>validation_split</code>参数来定义我们验证集的比例，需要注意的是，验证集在<code>fit</code>之前选取原数据集的前$ x% $比例的数据作为验证集。<code>validation_split</code>参数只能在训练Numpy数据集时使用：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = get_compiled_model()</span><br><span class="line">model.fit(x_train, y_train, batch_size=<span class="number">64</span>, validation_split=<span class="number">0.2</span>, epochs=<span class="number">1</span>, steps_per_epoch=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><h3 id="从Datasets中训练和评估"><a href="#从Datasets中训练和评估" class="headerlink" title="从Datasets中训练和评估"></a>从Datasets中训练和评估</h3><p>在TF2中，tf.data下的API用于加载数据和数据预处理。我们可以直接将Dataset的实例传给<code>fit</code>,<code>evaluate</code>,<code>predoct</code>等函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">model = get_compiled_model()</span><br><span class="line"></span><br><span class="line"><span class="comment"># First, let&#x27;s create a training Dataset instance.</span></span><br><span class="line"><span class="comment"># For the sake of our example, we&#x27;ll use the same MNIST data as before.</span></span><br><span class="line">train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))</span><br><span class="line"><span class="comment"># Shuffle and slice the dataset.</span></span><br><span class="line">train_dataset = train_dataset.shuffle(buffer_size=<span class="number">1024</span>).batch(<span class="number">64</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Now we get a test dataset.</span></span><br><span class="line">test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))</span><br><span class="line">test_dataset = test_dataset.batch(<span class="number">64</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Since the dataset already takes care of batching,</span></span><br><span class="line"><span class="comment"># we don&#x27;t pass a `batch_size` argument.</span></span><br><span class="line">model.fit(train_dataset, epochs=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># You can also evaluate or predict on a dataset.</span></span><br><span class="line">print(<span class="string">&#x27;\n# Evaluate&#x27;</span>)</span><br><span class="line">result = model.evaluate(test_dataset)</span><br><span class="line">dict(zip(model.metrics_names, result))</span><br></pre></td></tr></table></figure><p>注意Dataset在每次迭代结束后都会被重置，以此让我们在下次迭代中可以重新使用。如果我们想要定义每次迭代的步数，我们可以使用<code>take</code>参数。在达到指定的步数时，Dataset不会重置，除非它已经被遍历完了：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">model = get_compiled_model()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Prepare the training dataset</span></span><br><span class="line">train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))</span><br><span class="line">train_dataset = train_dataset.shuffle(buffer_size=<span class="number">1024</span>).batch(<span class="number">64</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Only use the 100 batches per epoch (that&#x27;s 64 * 100 samples)</span></span><br><span class="line">model.fit(train_dataset.take(<span class="number">100</span>), epochs=<span class="number">3</span>)</span><br></pre></td></tr></table></figure><h4 id="使用测试数据集"><a href="#使用测试数据集" class="headerlink" title="使用测试数据集"></a>使用测试数据集</h4><p>可以给fit函数传入<code>validation_data</code>:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">model = get_compiled_model()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Prepare the training dataset</span></span><br><span class="line">train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))</span><br><span class="line">train_dataset = train_dataset.shuffle(buffer_size=<span class="number">1024</span>).batch(<span class="number">64</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Prepare the validation dataset</span></span><br><span class="line">val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))</span><br><span class="line">val_dataset = val_dataset.batch(<span class="number">64</span>)</span><br><span class="line"></span><br><span class="line">model.fit(train_dataset, epochs=<span class="number">3</span>, validation_data=val_dataset)</span><br></pre></td></tr></table></figure><p>同样，如果我们定义每次迭代时使用验证集的次数，可以定义<code>validation_steps</code>:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">model = get_compiled_model()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Prepare the training dataset</span></span><br><span class="line">train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))</span><br><span class="line">train_dataset = train_dataset.shuffle(buffer_size=<span class="number">1024</span>).batch(<span class="number">64</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Prepare the validation dataset</span></span><br><span class="line">val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))</span><br><span class="line">val_dataset = val_dataset.batch(<span class="number">64</span>)</span><br><span class="line"></span><br><span class="line">model.fit(train_dataset, epochs=<span class="number">3</span>,</span><br><span class="line">          <span class="comment"># Only run validation using the first 10 batches of the dataset</span></span><br><span class="line">          <span class="comment"># using the `validation_steps` argument</span></span><br><span class="line">          validation_data=val_dataset, validation_steps=<span class="number">10</span>)</span><br></pre></td></tr></table></figure><p>注意，此时不管测试数据集是否遍历完，都会被重置。</p><h3 id="其他输入格式的数据"><a href="#其他输入格式的数据" class="headerlink" title="其他输入格式的数据"></a>其他输入格式的数据</h3><p>除了Numpy中的数组和TF2中的Dataset对象，我们还可以使用Pandas的dataframs，或者是Python的generator（能够yield小批次数据）。</p><p>总体来说，对于少量数据，可以在内存中保存的，推荐使用Numpy中array，否则使用TF2中Dataset对象。</p><h3 id="使用样本权重和类标权重"><a href="#使用样本权重和类标权重" class="headerlink" title="使用样本权重和类标权重"></a>使用样本权重和类标权重</h3><p>我们可以在使用fit方法的时候传入样本的权重和类标的权重：</p><ul><li>当使用Numpy数据时：通过<code>sample_weight</code>和<code>class_weight</code>参数</li><li>当使用TF2的Dataset时：让其返回一个这样的元组：<code>(input_batch, target_batch, sample_weight_batch)</code></li></ul><p>下面是使用Numpy数据进行训练的例子：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">class_weight = &#123;<span class="number">0</span>: <span class="number">1.</span>, <span class="number">1</span>: <span class="number">1.</span>, <span class="number">2</span>: <span class="number">1.</span>, <span class="number">3</span>: <span class="number">1.</span>, <span class="number">4</span>: <span class="number">1.</span>,</span><br><span class="line">                <span class="comment"># Set weight &quot;2&quot; for class &quot;5&quot;,</span></span><br><span class="line">                <span class="comment"># making this class 2x more important</span></span><br><span class="line">                <span class="number">5</span>: <span class="number">2.</span>,</span><br><span class="line">                <span class="number">6</span>: <span class="number">1.</span>, <span class="number">7</span>: <span class="number">1.</span>, <span class="number">8</span>: <span class="number">1.</span>, <span class="number">9</span>: <span class="number">1.</span>&#125;</span><br><span class="line">print(<span class="string">&#x27;Fit with class weight&#x27;</span>)</span><br><span class="line">model.fit(x_train, y_train,</span><br><span class="line">          class_weight=class_weight,</span><br><span class="line">          batch_size=<span class="number">64</span>,</span><br><span class="line">          epochs=<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Here&#x27;s the same example using `sample_weight` instead:</span></span><br><span class="line">sample_weight = np.ones(shape=(len(y_train),))</span><br><span class="line">sample_weight[y_train == <span class="number">5</span>] = <span class="number">2.</span></span><br><span class="line">print(<span class="string">&#x27;\nFit with sample weight&#x27;</span>)</span><br><span class="line"></span><br><span class="line">model = get_compiled_model()</span><br><span class="line">model.fit(x_train, y_train,</span><br><span class="line">          sample_weight=sample_weight,</span><br><span class="line">          batch_size=<span class="number">64</span>,</span><br><span class="line">          epochs=<span class="number">4</span>)</span><br></pre></td></tr></table></figure><p>下面是使用Dataset数据集的例子：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">sample_weight = np.ones(shape=(len(y_train),))</span><br><span class="line">sample_weight[y_train == <span class="number">5</span>] = <span class="number">2.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a Dataset that includes sample weights</span></span><br><span class="line"><span class="comment"># (3rd element in the return tuple).</span></span><br><span class="line">train_dataset = tf.data.Dataset.from_tensor_slices(</span><br><span class="line">    (x_train, y_train, sample_weight))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Shuffle and slice the dataset.</span></span><br><span class="line">train_dataset = train_dataset.shuffle(buffer_size=<span class="number">1024</span>).batch(<span class="number">64</span>)</span><br><span class="line"></span><br><span class="line">model = get_compiled_model()</span><br><span class="line">model.fit(train_dataset, epochs=<span class="number">3</span>)</span><br></pre></td></tr></table></figure><h3 id="将数据传入多输入输出模型"><a href="#将数据传入多输入输出模型" class="headerlink" title="将数据传入多输入输出模型"></a>将数据传入多输入输出模型</h3><p>考虑这样一个模型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers</span><br><span class="line"></span><br><span class="line">image_input = keras.Input(shape=(<span class="number">32</span>, <span class="number">32</span>, <span class="number">3</span>), name=<span class="string">&#x27;img_input&#x27;</span>)</span><br><span class="line">timeseries_input = keras.Input(shape=(<span class="literal">None</span>, <span class="number">10</span>), name=<span class="string">&#x27;ts_input&#x27;</span>)</span><br><span class="line"></span><br><span class="line">x1 = layers.Conv2D(<span class="number">3</span>, <span class="number">3</span>)(image_input)</span><br><span class="line">x1 = layers.GlobalMaxPooling2D()(x1)</span><br><span class="line"></span><br><span class="line">x2 = layers.Conv1D(<span class="number">3</span>, <span class="number">3</span>)(timeseries_input)</span><br><span class="line">x2 = layers.GlobalMaxPooling1D()(x2)</span><br><span class="line"></span><br><span class="line">x = layers.concatenate([x1, x2])</span><br><span class="line"></span><br><span class="line">score_output = layers.Dense(<span class="number">1</span>, name=<span class="string">&#x27;score_output&#x27;</span>)(x)</span><br><span class="line">class_output = layers.Dense(<span class="number">5</span>, name=<span class="string">&#x27;class_output&#x27;</span>)(x)</span><br><span class="line"></span><br><span class="line">model = keras.Model(inputs=[image_input, timeseries_input],</span><br><span class="line">                    outputs=[score_output, class_output])</span><br></pre></td></tr></table></figure><p>这个模型有两个输入两个输出。在模型编译期间，我们传入不同的损失函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">model.compile(</span><br><span class="line">    optimizer=keras.optimizers.RMSprop(<span class="number">1e-3</span>),</span><br><span class="line">    loss=[keras.losses.MeanSquaredError(),</span><br><span class="line">          keras.losses.CategoricalCrossentropy(from_logits=<span class="literal">True</span>)])</span><br></pre></td></tr></table></figure><p>同样可以传入不同的评价指标：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">model.compile(</span><br><span class="line">    optimizer=keras.optimizers.RMSprop(<span class="number">1e-3</span>),</span><br><span class="line">    loss=[keras.losses.MeanSquaredError(),</span><br><span class="line">          keras.losses.CategoricalCrossentropy(from_logits=<span class="literal">True</span>)],</span><br><span class="line">    metrics=[[keras.metrics.MeanAbsolutePercentageError(),</span><br><span class="line">              keras.metrics.MeanAbsoluteError()],</span><br><span class="line">             [keras.metrics.CategoricalAccuracy()]])</span><br></pre></td></tr></table></figure><p>由于我们已经为输出层赋予了 名字，我们可以使用字典的方式传递参数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">model.compile(</span><br><span class="line">    optimizer=keras.optimizers.RMSprop(<span class="number">1e-3</span>),</span><br><span class="line">    loss=&#123;<span class="string">&#x27;score_output&#x27;</span>: keras.losses.MeanSquaredError(),</span><br><span class="line">          <span class="string">&#x27;class_output&#x27;</span>: keras.losses.CategoricalCrossentropy(from_logits=<span class="literal">True</span>)&#125;,</span><br><span class="line">    metrics=&#123;<span class="string">&#x27;score_output&#x27;</span>: [keras.metrics.MeanAbsolutePercentageError(),</span><br><span class="line">                              keras.metrics.MeanAbsoluteError()],</span><br><span class="line">             <span class="string">&#x27;class_output&#x27;</span>: [keras.metrics.CategoricalAccuracy()]&#125;)</span><br></pre></td></tr></table></figure><p>同样的，我们可以定义损失权重：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">model.compile(</span><br><span class="line">    optimizer=keras.optimizers.RMSprop(<span class="number">1e-3</span>),</span><br><span class="line">    loss=&#123;<span class="string">&#x27;score_output&#x27;</span>: keras.losses.MeanSquaredError(),</span><br><span class="line">          <span class="string">&#x27;class_output&#x27;</span>: keras.losses.CategoricalCrossentropy(from_logits=<span class="literal">True</span>)&#125;,</span><br><span class="line">    metrics=&#123;<span class="string">&#x27;score_output&#x27;</span>: [keras.metrics.MeanAbsolutePercentageError(),</span><br><span class="line">                              keras.metrics.MeanAbsoluteError()],</span><br><span class="line">             <span class="string">&#x27;class_output&#x27;</span>: [keras.metrics.CategoricalAccuracy()]&#125;,</span><br><span class="line">    loss_weights=&#123;<span class="string">&#x27;score_output&#x27;</span>: <span class="number">2.</span>, <span class="string">&#x27;class_output&#x27;</span>: <span class="number">1.</span>&#125;)</span><br></pre></td></tr></table></figure><p>我们可以为某个输出定义损失函数，而另外一个输出不定义损失函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># List loss version</span></span><br><span class="line">model.compile(</span><br><span class="line">    optimizer=keras.optimizers.RMSprop(<span class="number">1e-3</span>),</span><br><span class="line">    loss=[<span class="literal">None</span>, keras.losses.CategoricalCrossentropy(from_logits=<span class="literal">True</span>)])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Or dict loss version</span></span><br><span class="line">model.compile(</span><br><span class="line">    optimizer=keras.optimizers.RMSprop(<span class="number">1e-3</span>),</span><br><span class="line">    loss=&#123;<span class="string">&#x27;class_output&#x27;</span>:keras.losses.CategoricalCrossentropy(from_logits=<span class="literal">True</span>)&#125;)</span><br></pre></td></tr></table></figure><p>传入训练数据集的方式和上述介绍的方式差不多：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">model.compile(</span><br><span class="line">    optimizer=keras.optimizers.RMSprop(<span class="number">1e-3</span>),</span><br><span class="line">    loss=[keras.losses.MeanSquaredError(),</span><br><span class="line">          keras.losses.CategoricalCrossentropy(from_logits=<span class="literal">True</span>)])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Generate dummy Numpy data</span></span><br><span class="line">img_data = np.random.random_sample(size=(<span class="number">100</span>, <span class="number">32</span>, <span class="number">32</span>, <span class="number">3</span>))</span><br><span class="line">ts_data = np.random.random_sample(size=(<span class="number">100</span>, <span class="number">20</span>, <span class="number">10</span>))</span><br><span class="line">score_targets = np.random.random_sample(size=(<span class="number">100</span>, <span class="number">1</span>))</span><br><span class="line">class_targets = np.random.random_sample(size=(<span class="number">100</span>, <span class="number">5</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Fit on lists</span></span><br><span class="line">model.fit([img_data, ts_data], [score_targets, class_targets],</span><br><span class="line">          batch_size=<span class="number">32</span>,</span><br><span class="line">          epochs=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Alternatively, fit on dicts</span></span><br><span class="line">model.fit(&#123;<span class="string">&#x27;img_input&#x27;</span>: img_data, <span class="string">&#x27;ts_input&#x27;</span>: ts_data&#125;,</span><br><span class="line">          &#123;<span class="string">&#x27;score_output&#x27;</span>: score_targets, <span class="string">&#x27;class_output&#x27;</span>: class_targets&#125;,</span><br><span class="line">          batch_size=<span class="number">32</span>,</span><br><span class="line">          epochs=<span class="number">3</span>)</span><br></pre></td></tr></table></figure><p>而Dataset的使用方式如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">train_dataset = tf.data.Dataset.from_tensor_slices(</span><br><span class="line">    (&#123;<span class="string">&#x27;img_input&#x27;</span>: img_data, <span class="string">&#x27;ts_input&#x27;</span>: ts_data&#125;,</span><br><span class="line">     &#123;<span class="string">&#x27;score_output&#x27;</span>: score_targets, <span class="string">&#x27;class_output&#x27;</span>: class_targets&#125;))</span><br><span class="line">train_dataset = train_dataset.shuffle(buffer_size=<span class="number">1024</span>).batch(<span class="number">64</span>)</span><br><span class="line"></span><br><span class="line">model.fit(train_dataset, epochs=<span class="number">3</span>)</span><br></pre></td></tr></table></figure><h3 id="使用回调"><a href="#使用回调" class="headerlink" title="使用回调"></a>使用回调</h3><p>回调对象可以在不同的时间点（每轮迭代的开始，每个批次的结束，每个迭代的结束）被调用来实现不同的功能。回调对象可以被传入<code>fit</code>:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">model = get_compiled_model()</span><br><span class="line"></span><br><span class="line">callbacks = [</span><br><span class="line">    keras.callbacks.EarlyStopping(</span><br><span class="line">        <span class="comment"># Stop training when `val_loss` is no longer improving</span></span><br><span class="line">        monitor=<span class="string">&#x27;val_loss&#x27;</span>,</span><br><span class="line">        <span class="comment"># &quot;no longer improving&quot; being defined as &quot;no better than 1e-2 less&quot;</span></span><br><span class="line">        min_delta=<span class="number">1e-2</span>,</span><br><span class="line">        <span class="comment"># &quot;no longer improving&quot; being further defined as &quot;for at least 2 epochs&quot;</span></span><br><span class="line">        patience=<span class="number">2</span>,</span><br><span class="line">        verbose=<span class="number">1</span>)</span><br><span class="line">]</span><br><span class="line">model.fit(x_train, y_train,</span><br><span class="line">          epochs=<span class="number">20</span>,</span><br><span class="line">          batch_size=<span class="number">64</span>,</span><br><span class="line">          callbacks=callbacks,</span><br><span class="line">          validation_split=<span class="number">0.2</span>)</span><br></pre></td></tr></table></figure><h4 id="内建的回调对象"><a href="#内建的回调对象" class="headerlink" title="内建的回调对象"></a>内建的回调对象</h4><ul><li><code>ModelCheckpoint</code>: 定时保存模型检查点</li><li><code>EarlyStopping</code>: 当评估指数没有改进的时候提前停止</li><li><code>TensorBoard</code>: 记录模型的参数值</li><li><code>CSVLogger</code>: 将模型的损失值和评价指标保存到CSV文件中</li></ul><h4 id="自建回调对象"><a href="#自建回调对象" class="headerlink" title="自建回调对象"></a>自建回调对象</h4><p>我们可以通过继承<code>Callback</code>对象实现自定义的回调对象，回调对象可以通过<code>self.model</code>获取相关联的模型，下面是一个实例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LossHistory</span>(<span class="params">keras.callbacks.Callback</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">on_train_begin</span>(<span class="params">self, logs</span>):</span></span><br><span class="line">        self.losses = []</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">on_batch_end</span>(<span class="params">self, batch, logs</span>):</span></span><br><span class="line">        self.losses.append(logs.get(<span class="string">&#x27;loss&#x27;</span>))</span><br></pre></td></tr></table></figure><h3 id="保存模型的检查点"><a href="#保存模型的检查点" class="headerlink" title="保存模型的检查点"></a>保存模型的检查点</h3><p>当我们的训练集很大的时候，我们需要定期保存模型的检查点，最简单的方式是使用<code>ModelCheckpoint</code>回调：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">model = get_compiled_model()</span><br><span class="line"></span><br><span class="line">callbacks = [</span><br><span class="line">    keras.callbacks.ModelCheckpoint(</span><br><span class="line">        filepath=<span class="string">&#x27;mymodel_&#123;epoch&#125;&#x27;</span>,</span><br><span class="line">        <span class="comment"># Path where to save the model</span></span><br><span class="line">        <span class="comment"># The two parameters below mean that we will overwrite</span></span><br><span class="line">        <span class="comment"># the current checkpoint if and only if</span></span><br><span class="line">        <span class="comment"># the `val_loss` score has improved.</span></span><br><span class="line">        save_best_only=<span class="literal">True</span>,</span><br><span class="line">        monitor=<span class="string">&#x27;val_loss&#x27;</span>,</span><br><span class="line">        verbose=<span class="number">1</span>)</span><br><span class="line">]</span><br><span class="line">model.fit(x_train, y_train,</span><br><span class="line">          epochs=<span class="number">3</span>,</span><br><span class="line">          batch_size=<span class="number">64</span>,</span><br><span class="line">          callbacks=callbacks,</span><br><span class="line">          validation_split=<span class="number">0.2</span>)</span><br></pre></td></tr></table></figure><h3 id="使用学习速率表"><a href="#使用学习速率表" class="headerlink" title="使用学习速率表"></a>使用学习速率表</h3><p>深度学习中一个常见的训练模式是递减我们的学习速率，学习速率递减可以实静态的或者是动态的。</p><h4 id="将学习速率表传给优化器"><a href="#将学习速率表传给优化器" class="headerlink" title="将学习速率表传给优化器"></a>将学习速率表传给优化器</h4><p>我们可以将一个静态的学习速率表通过参数传递给优化器：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">initial_learning_rate = <span class="number">0.1</span></span><br><span class="line">lr_schedule = keras.optimizers.schedules.ExponentialDecay(</span><br><span class="line">    initial_learning_rate,</span><br><span class="line">    decay_steps=<span class="number">100000</span>,</span><br><span class="line">    decay_rate=<span class="number">0.96</span>,</span><br><span class="line">    staircase=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">optimizer = keras.optimizers.RMSprop(learning_rate=lr_schedule)</span><br></pre></td></tr></table></figure><p>内建的学习速率表还有：<code>ExponentialDecay</code>, <code>PiecewiseConstantDecay</code>, <code>PolynomialDecay</code>, and <code>InverseTimeDecay</code>。</p><h4 id="使用回调实现动态学习速率表"><a href="#使用回调实现动态学习速率表" class="headerlink" title="使用回调实现动态学习速率表"></a>使用回调实现动态学习速率表</h4><p>由于优化器不能获取评估指标，所以动态的学习速率表不能通过内建的学习速率表实现。但是，我们可以通过回调来实现动态学习速率表，因为回调能够获取所有的评价指标。实际上，这已经内建在<code>ReduceLROnPlateau</code> 这个回调中了。</p><h3 id="可视化损失和评估值"><a href="#可视化损失和评估值" class="headerlink" title="可视化损失和评估值"></a>可视化损失和评估值</h3><p>最好的方法是使用TensorBoard，它可以帮助我们实时可视化损失值和评估值。启动Tensorboard的方法如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensorboard --logdir=/full_path_to_your_logs</span><br></pre></td></tr></table></figure><h4 id="使用Tensorboard回调"><a href="#使用Tensorboard回调" class="headerlink" title="使用Tensorboard回调"></a>使用Tensorboard回调</h4><p>最简单的方法就是在fit的时候传入Tensorboard回调：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tensorboard_cbk = keras.callbacks.TensorBoard(log_dir=<span class="string">&#x27;/full_path_to_your_logs&#x27;</span>)</span><br><span class="line">model.fit(dataset, epochs=<span class="number">10</span>, callbacks=[tensorboard_cbk])</span><br></pre></td></tr></table></figure><p>Tensorboard还有一些其他参数可供选择：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">keras.callbacks.TensorBoard(</span><br><span class="line">  log_dir=<span class="string">&#x27;/full_path_to_your_logs&#x27;</span>,</span><br><span class="line">  histogram_freq=<span class="number">0</span>,  <span class="comment"># How often to log histogram visualizations</span></span><br><span class="line">  embeddings_freq=<span class="number">0</span>,  <span class="comment"># How often to log embedding visualizations</span></span><br><span class="line">  update_freq=<span class="string">&#x27;epoch&#x27;</span>)  <span class="comment"># How often to write logs (default: once per epoch)</span></span><br></pre></td></tr></table></figure><h2 id="编写自己的训练和评估方法"><a href="#编写自己的训练和评估方法" class="headerlink" title="编写自己的训练和评估方法"></a>编写自己的训练和评估方法</h2><h3 id="使用GradientTape"><a href="#使用GradientTape" class="headerlink" title="使用GradientTape"></a>使用GradientTape</h3><p>在GradientTape作用域中调用模型会使你很容易得到相关参数的梯度值。下面是一个MNIST模型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Get the model.</span></span><br><span class="line">inputs = keras.Input(shape=(<span class="number">784</span>,), name=<span class="string">&#x27;digits&#x27;</span>)</span><br><span class="line">x = layers.Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>, name=<span class="string">&#x27;dense_1&#x27;</span>)(inputs)</span><br><span class="line">x = layers.Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>, name=<span class="string">&#x27;dense_2&#x27;</span>)(x)</span><br><span class="line">outputs = layers.Dense(<span class="number">10</span>, name=<span class="string">&#x27;predictions&#x27;</span>)(x)</span><br><span class="line">model = keras.Model(inputs=inputs, outputs=outputs)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Instantiate an optimizer.</span></span><br><span class="line">optimizer = keras.optimizers.SGD(learning_rate=<span class="number">1e-3</span>)</span><br><span class="line"><span class="comment"># Instantiate a loss function.</span></span><br><span class="line">loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Prepare the training dataset.</span></span><br><span class="line">batch_size = <span class="number">64</span></span><br><span class="line">train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))</span><br><span class="line">train_dataset = train_dataset.shuffle(buffer_size=<span class="number">1024</span>).batch(batch_size)</span><br></pre></td></tr></table></figure><p>训练方法如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">epochs = <span class="number">3</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(epochs):</span><br><span class="line">  print(<span class="string">&#x27;Start of epoch %d&#x27;</span> % (epoch,))</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Iterate over the batches of the dataset.</span></span><br><span class="line">  <span class="keyword">for</span> step, (x_batch_train, y_batch_train) <span class="keyword">in</span> enumerate(train_dataset):</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Open a GradientTape to record the operations run</span></span><br><span class="line">    <span class="comment"># during the forward pass, which enables autodifferentiation.</span></span><br><span class="line">    <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line"></span><br><span class="line">      <span class="comment"># Run the forward pass of the layer.</span></span><br><span class="line">      <span class="comment"># The operations that the layer applies</span></span><br><span class="line">      <span class="comment"># to its inputs are going to be recorded</span></span><br><span class="line">      <span class="comment"># on the GradientTape.</span></span><br><span class="line">      logits = model(x_batch_train, training=<span class="literal">True</span>)  <span class="comment"># Logits for this minibatch</span></span><br><span class="line"></span><br><span class="line">      <span class="comment"># Compute the loss value for this minibatch.</span></span><br><span class="line">      loss_value = loss_fn(y_batch_train, logits)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Use the gradient tape to automatically retrieve</span></span><br><span class="line">    <span class="comment"># the gradients of the trainable variables with respect to the loss.</span></span><br><span class="line">    grads = tape.gradient(loss_value, model.trainable_weights)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Run one step of gradient descent by updating</span></span><br><span class="line">    <span class="comment"># the value of the variables to minimize the loss.</span></span><br><span class="line">    optimizer.apply_gradients(zip(grads, model.trainable_weights))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Log every 200 batches.</span></span><br><span class="line">    <span class="keyword">if</span> step % <span class="number">200</span> == <span class="number">0</span>:</span><br><span class="line">        print(<span class="string">&#x27;Training loss (for one batch) at step %s: %s&#x27;</span> % (step, float(loss_value)))</span><br><span class="line">        print(<span class="string">&#x27;Seen so far: %s samples&#x27;</span> % ((step + <span class="number">1</span>) * <span class="number">64</span>))</span><br></pre></td></tr></table></figure><h3 id="实现自定义评估值"><a href="#实现自定义评估值" class="headerlink" title="实现自定义评估值"></a>实现自定义评估值</h3><p>接着我们添加自定义的评估值，下面是工作流：</p><ul><li>在每次迭代前初始化评价指标</li><li>在每个批次结束时调用<code>metric.update_state</code></li><li>在需要展示结果的时候调用<code>metric.result</code></li><li>在需要重置的时候（如每次迭代的末尾）调用<code>metric.reset_states</code></li></ul><p>接下来手动实现<code>SparseCategoricalAccuracy</code> 评价指标，下面是模型创建时的代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Get model</span></span><br><span class="line">inputs = keras.Input(shape=(<span class="number">784</span>,), name=<span class="string">&#x27;digits&#x27;</span>)</span><br><span class="line">x = layers.Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>, name=<span class="string">&#x27;dense_1&#x27;</span>)(inputs)</span><br><span class="line">x = layers.Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>, name=<span class="string">&#x27;dense_2&#x27;</span>)(x)</span><br><span class="line">outputs = layers.Dense(<span class="number">10</span>, name=<span class="string">&#x27;predictions&#x27;</span>)(x)</span><br><span class="line">model = keras.Model(inputs=inputs, outputs=outputs)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Instantiate an optimizer to train the model.</span></span><br><span class="line">optimizer = keras.optimizers.SGD(learning_rate=<span class="number">1e-3</span>)</span><br><span class="line"><span class="comment"># Instantiate a loss function.</span></span><br><span class="line">loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Prepare the metrics.</span></span><br><span class="line">train_acc_metric = keras.metrics.SparseCategoricalAccuracy()</span><br><span class="line">val_acc_metric = keras.metrics.SparseCategoricalAccuracy()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Prepare the training dataset.</span></span><br><span class="line">batch_size = <span class="number">64</span></span><br><span class="line">train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))</span><br><span class="line">train_dataset = train_dataset.shuffle(buffer_size=<span class="number">1024</span>).batch(batch_size)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Prepare the validation dataset.</span></span><br><span class="line">val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))</span><br><span class="line">val_dataset = val_dataset.batch(<span class="number">64</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>自定义训练的迭代如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">epochs = <span class="number">3</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(epochs):</span><br><span class="line">  print(<span class="string">&#x27;Start of epoch %d&#x27;</span> % (epoch,))</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Iterate over the batches of the dataset.</span></span><br><span class="line">  <span class="keyword">for</span> step, (x_batch_train, y_batch_train) <span class="keyword">in</span> enumerate(train_dataset):</span><br><span class="line">    <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">      logits = model(x_batch_train)</span><br><span class="line">      loss_value = loss_fn(y_batch_train, logits)</span><br><span class="line">    grads = tape.gradient(loss_value, model.trainable_weights)</span><br><span class="line">    optimizer.apply_gradients(zip(grads, model.trainable_weights))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Update training metric.</span></span><br><span class="line">    train_acc_metric(y_batch_train, logits)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Log every 200 batches.</span></span><br><span class="line">    <span class="keyword">if</span> step % <span class="number">200</span> == <span class="number">0</span>:</span><br><span class="line">        print(<span class="string">&#x27;Training loss (for one batch) at step %s: %s&#x27;</span> % (step, float(loss_value)))</span><br><span class="line">        print(<span class="string">&#x27;Seen so far: %s samples&#x27;</span> % ((step + <span class="number">1</span>) * <span class="number">64</span>))</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Display metrics at the end of each epoch.</span></span><br><span class="line">  train_acc = train_acc_metric.result()</span><br><span class="line">  print(<span class="string">&#x27;Training acc over epoch: %s&#x27;</span> % (float(train_acc),))</span><br><span class="line">  <span class="comment"># Reset training metrics at the end of each epoch</span></span><br><span class="line">  train_acc_metric.reset_states()</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Run a validation loop at the end of each epoch.</span></span><br><span class="line">  <span class="keyword">for</span> x_batch_val, y_batch_val <span class="keyword">in</span> val_dataset:</span><br><span class="line">    val_logits = model(x_batch_val)</span><br><span class="line">    <span class="comment"># Update val metrics</span></span><br><span class="line">    val_acc_metric(y_batch_val, val_logits)</span><br><span class="line">  val_acc = val_acc_metric.result()</span><br><span class="line">  val_acc_metric.reset_states()</span><br><span class="line">  print(<span class="string">&#x27;Validation acc: %s&#x27;</span> % (float(val_acc),))</span><br></pre></td></tr></table></figure><h3 id="处理额外的损失值"><a href="#处理额外的损失值" class="headerlink" title="处理额外的损失值"></a>处理额外的损失值</h3><p>在前面的小节中我们在<code>call</code>方法中调用<code>self.add_loss(values)</code>来正则化损失值，通常来说我们需要将这些额外的损失值也考虑在内，下面是我们实现的其中一个模型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ActivityRegularizationLayer</span>(<span class="params">layers.Layer</span>):</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, inputs</span>):</span></span><br><span class="line">    self.add_loss(<span class="number">1e-2</span> * tf.reduce_sum(inputs))</span><br><span class="line">    <span class="keyword">return</span> inputs</span><br><span class="line"></span><br><span class="line">inputs = keras.Input(shape=(<span class="number">784</span>,), name=<span class="string">&#x27;digits&#x27;</span>)</span><br><span class="line">x = layers.Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>, name=<span class="string">&#x27;dense_1&#x27;</span>)(inputs)</span><br><span class="line"><span class="comment"># Insert activity regularization as a layer</span></span><br><span class="line">x = ActivityRegularizationLayer()(x)</span><br><span class="line">x = layers.Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>, name=<span class="string">&#x27;dense_2&#x27;</span>)(x)</span><br><span class="line">outputs = layers.Dense(<span class="number">10</span>, name=<span class="string">&#x27;predictions&#x27;</span>)(x)</span><br><span class="line"></span><br><span class="line">model = keras.Model(inputs=inputs, outputs=outputs)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>当我们调用模型的时候：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">logits = model(x_train)</span><br></pre></td></tr></table></figure><p>在前向传播过程中的损失值会被加到<code>model.losses</code>属性中。</p><p>为了将额外的损失值考虑在内，我们需要修改我们自定义的训练循环体中的代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">optimizer = keras.optimizers.SGD(learning_rate=<span class="number">1e-3</span>)</span><br><span class="line"></span><br><span class="line">epochs = <span class="number">3</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(epochs):</span><br><span class="line">  print(<span class="string">&#x27;Start of epoch %d&#x27;</span> % (epoch,))</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> step, (x_batch_train, y_batch_train) <span class="keyword">in</span> enumerate(train_dataset):</span><br><span class="line">    <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">      logits = model(x_batch_train)</span><br><span class="line">      loss_value = loss_fn(y_batch_train, logits)</span><br><span class="line"></span><br><span class="line">      <span class="comment"># Add extra losses created during this forward pass:</span></span><br><span class="line">      loss_value += sum(model.losses)</span><br><span class="line"></span><br><span class="line">    grads = tape.gradient(loss_value, model.trainable_weights)</span><br><span class="line">    optimizer.apply_gradients(zip(grads, model.trainable_weights))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Log every 200 batches.</span></span><br><span class="line">    <span class="keyword">if</span> step % <span class="number">200</span> == <span class="number">0</span>:</span><br><span class="line">        print(<span class="string">&#x27;Training loss (for one batch) at step %s: %s&#x27;</span> % (step, float(loss_value)))</span><br><span class="line">        print(<span class="string">&#x27;Seen so far: %s samples&#x27;</span> % ((step + <span class="number">1</span>) * <span class="number">64</span>))</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> TensorFlow </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Keras函数式API</title>
      <link href="2020/02/14/Keras%E5%87%BD%E6%95%B0%E5%BC%8FAPI/"/>
      <url>2020/02/14/Keras%E5%87%BD%E6%95%B0%E5%BC%8FAPI/</url>
      
        <content type="html"><![CDATA[<p>本章了解Keras的函数式API以及灵活使用它们的方法。</p><a id="more"></a><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>我们已经熟悉了如何使用<code>keras.Sequential</code>函数来创建我们的层叠模型，而函数式API是比它更加灵活的创建模型的方法：它可以允许我们创建非线性的模型，共用层的模型以及多个输入输出的模型。函数式API的基本思路是深度学习网络是一种有向无环图（DAG），我们可以使用函数式API来创建这些层。</p><p>如下一个包含了3个层的模型：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">(input: 784-dimensional vectors)</span><br><span class="line">       ↧</span><br><span class="line">[Dense (64 units, relu activation)]</span><br><span class="line">       ↧</span><br><span class="line">[Dense (64 units, relu activation)]</span><br><span class="line">       ↧</span><br><span class="line">[Dense (10 units, softmax activation)]</span><br><span class="line">       ↧</span><br><span class="line">(output: logits of a probability distribution over 10 classes)</span><br></pre></td></tr></table></figure><p>为了使用函数式API来创建相同的模型，我们首先创建输入节点：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"></span><br><span class="line">inputs = keras.Input(shape=(<span class="number">784</span>,))</span><br></pre></td></tr></table></figure><p>我们声明了输入的数据是一个784维的向量，注意这里的shape是单个样本的shape，不是批次的shape。对于图片，假设数据是（32，32，3）类型的，我们可以使用以下代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Just for demonstration purposes</span></span><br><span class="line">img_inputs = keras.Input(shape=(<span class="number">32</span>, <span class="number">32</span>, <span class="number">3</span>))</span><br></pre></td></tr></table></figure><p>我们得到的返回值inputs包含了输入数据的shape和类型。为了创建层节点，我们使用如下方法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers</span><br><span class="line"></span><br><span class="line">dense = layers.Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">x = dense(inputs)</span><br></pre></td></tr></table></figure><p>调用层函数的作用相当于在两个节点之间画一条有向线，我们得到了经过第一层处理后的返回值<code>x</code>，接着，我们创建完剩余的层：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = layers.Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>)(x)</span><br><span class="line">outputs = layers.Dense(<span class="number">10</span>)(x)</span><br></pre></td></tr></table></figure><p>到了这一步，我们现在可以创建我们的模型了：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model = keras.Model(inputs=inputs, outputs=outputs)</span><br></pre></td></tr></table></figure><p>至此，我们的模型就创建成功了。</p><h2 id="训练评估和预测"><a href="#训练评估和预测" class="headerlink" title="训练评估和预测"></a>训练评估和预测</h2><p>训练评估和预测的使用方法其实和在Sequential中创建模型一致。下面是使用我们刚刚创建的模型进行训练评估和预测的代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()</span><br><span class="line">x_train = x_train.reshape(<span class="number">60000</span>, <span class="number">784</span>).astype(<span class="string">&#x27;float32&#x27;</span>) / <span class="number">255</span></span><br><span class="line">x_test = x_test.reshape(<span class="number">10000</span>, <span class="number">784</span>).astype(<span class="string">&#x27;float32&#x27;</span>) / <span class="number">255</span></span><br><span class="line"></span><br><span class="line">model.compile(loss=keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">True</span>),</span><br><span class="line">              optimizer=keras.optimizers.RMSprop(),</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">history = model.fit(x_train, y_train,</span><br><span class="line">                    batch_size=<span class="number">64</span>,</span><br><span class="line">                    epochs=<span class="number">5</span>,</span><br><span class="line">                    validation_split=<span class="number">0.2</span>)</span><br><span class="line">test_scores = model.evaluate(x_test, y_test, verbose=<span class="number">2</span>)</span><br><span class="line">print(<span class="string">&#x27;Test loss:&#x27;</span>, test_scores[<span class="number">0</span>])</span><br><span class="line">print(<span class="string">&#x27;Test accuracy:&#x27;</span>, test_scores[<span class="number">1</span>])</span><br></pre></td></tr></table></figure><h2 id="序列化"><a href="#序列化" class="headerlink" title="序列化"></a>序列化</h2><p>同样地，使用函数式APiece创建出来的模型序列化和反序列化和使用Sequential创建的模型一致。最常用的方法是使用<code>save</code>方法，它会保存：</p><ul><li>模型的架构</li><li>模型权重值（在训练中得到）</li><li>模型训练配置（在<code>compile</code>的时候得到）</li><li>模型优化配置</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">model.save(<span class="string">&#x27;path_to_my_model&#x27;</span>)</span><br><span class="line"><span class="keyword">del</span> model</span><br><span class="line"><span class="comment"># Recreate the exact same model purely from the file:</span></span><br><span class="line">model = keras.models.load_model(<span class="string">&#x27;path_to_my_model&#x27;</span>)</span><br></pre></td></tr></table></figure><h2 id="使用相同的层来创建多个模型"><a href="#使用相同的层来创建多个模型" class="headerlink" title="使用相同的层来创建多个模型"></a>使用相同的层来创建多个模型</h2><p>在使用函数式API创建模型时，我们只需要声明模型的输入和输出即可，这也就意味着我们可以使用相同的层来创建多个模型，以下是一个实例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">encoder_input = keras.Input(shape=(<span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>), name=<span class="string">&#x27;img&#x27;</span>)</span><br><span class="line">x = layers.Conv2D(<span class="number">16</span>, <span class="number">3</span>, activation=<span class="string">&#x27;relu&#x27;</span>)(encoder_input)</span><br><span class="line">x = layers.Conv2D(<span class="number">32</span>, <span class="number">3</span>, activation=<span class="string">&#x27;relu&#x27;</span>)(x)</span><br><span class="line">x = layers.MaxPooling2D(<span class="number">3</span>)(x)</span><br><span class="line">x = layers.Conv2D(<span class="number">32</span>, <span class="number">3</span>, activation=<span class="string">&#x27;relu&#x27;</span>)(x)</span><br><span class="line">x = layers.Conv2D(<span class="number">16</span>, <span class="number">3</span>, activation=<span class="string">&#x27;relu&#x27;</span>)(x)</span><br><span class="line">encoder_output = layers.GlobalMaxPooling2D()(x)</span><br><span class="line"></span><br><span class="line">encoder = keras.Model(encoder_input, encoder_output, name=<span class="string">&#x27;encoder&#x27;</span>)</span><br><span class="line">encoder.summary()</span><br><span class="line"></span><br><span class="line">x = layers.Reshape((<span class="number">4</span>, <span class="number">4</span>, <span class="number">1</span>))(encoder_output)</span><br><span class="line">x = layers.Conv2DTranspose(<span class="number">16</span>, <span class="number">3</span>, activation=<span class="string">&#x27;relu&#x27;</span>)(x)</span><br><span class="line">x = layers.Conv2DTranspose(<span class="number">32</span>, <span class="number">3</span>, activation=<span class="string">&#x27;relu&#x27;</span>)(x)</span><br><span class="line">x = layers.UpSampling2D(<span class="number">3</span>)(x)</span><br><span class="line">x = layers.Conv2DTranspose(<span class="number">16</span>, <span class="number">3</span>, activation=<span class="string">&#x27;relu&#x27;</span>)(x)</span><br><span class="line">decoder_output = layers.Conv2DTranspose(<span class="number">1</span>, <span class="number">3</span>, activation=<span class="string">&#x27;relu&#x27;</span>)(x)</span><br><span class="line"></span><br><span class="line">autoencoder = keras.Model(encoder_input, decoder_output, name=<span class="string">&#x27;autoencoder&#x27;</span>)</span><br><span class="line">autoencoder.summary()</span><br></pre></td></tr></table></figure><h2 id="模型可调用"><a href="#模型可调用" class="headerlink" title="模型可调用"></a>模型可调用</h2><p>我们可以将模型看作是特殊的层，因为它接收Input或者其他层的输出作为参数。注意，我们调用模型的时候不仅仅只是使用了它的架构，还使用了它的权重：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">encoder_input = keras.Input(shape=(<span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>), name=<span class="string">&#x27;original_img&#x27;</span>)</span><br><span class="line">x = layers.Conv2D(<span class="number">16</span>, <span class="number">3</span>, activation=<span class="string">&#x27;relu&#x27;</span>)(encoder_input)</span><br><span class="line">x = layers.Conv2D(<span class="number">32</span>, <span class="number">3</span>, activation=<span class="string">&#x27;relu&#x27;</span>)(x)</span><br><span class="line">x = layers.MaxPooling2D(<span class="number">3</span>)(x)</span><br><span class="line">x = layers.Conv2D(<span class="number">32</span>, <span class="number">3</span>, activation=<span class="string">&#x27;relu&#x27;</span>)(x)</span><br><span class="line">x = layers.Conv2D(<span class="number">16</span>, <span class="number">3</span>, activation=<span class="string">&#x27;relu&#x27;</span>)(x)</span><br><span class="line">encoder_output = layers.GlobalMaxPooling2D()(x)</span><br><span class="line"></span><br><span class="line">encoder = keras.Model(encoder_input, encoder_output, name=<span class="string">&#x27;encoder&#x27;</span>)</span><br><span class="line">encoder.summary()</span><br><span class="line"></span><br><span class="line">decoder_input = keras.Input(shape=(<span class="number">16</span>,), name=<span class="string">&#x27;encoded_img&#x27;</span>)</span><br><span class="line">x = layers.Reshape((<span class="number">4</span>, <span class="number">4</span>, <span class="number">1</span>))(decoder_input)</span><br><span class="line">x = layers.Conv2DTranspose(<span class="number">16</span>, <span class="number">3</span>, activation=<span class="string">&#x27;relu&#x27;</span>)(x)</span><br><span class="line">x = layers.Conv2DTranspose(<span class="number">32</span>, <span class="number">3</span>, activation=<span class="string">&#x27;relu&#x27;</span>)(x)</span><br><span class="line">x = layers.UpSampling2D(<span class="number">3</span>)(x)</span><br><span class="line">x = layers.Conv2DTranspose(<span class="number">16</span>, <span class="number">3</span>, activation=<span class="string">&#x27;relu&#x27;</span>)(x)</span><br><span class="line">decoder_output = layers.Conv2DTranspose(<span class="number">1</span>, <span class="number">3</span>, activation=<span class="string">&#x27;relu&#x27;</span>)(x)</span><br><span class="line"></span><br><span class="line">decoder = keras.Model(decoder_input, decoder_output, name=<span class="string">&#x27;decoder&#x27;</span>)</span><br><span class="line">decoder.summary()</span><br><span class="line"></span><br><span class="line">autoencoder_input = keras.Input(shape=(<span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>), name=<span class="string">&#x27;img&#x27;</span>)</span><br><span class="line">encoded_img = encoder(autoencoder_input)</span><br><span class="line">decoded_img = decoder(encoded_img)</span><br><span class="line">autoencoder = keras.Model(autoencoder_input, decoded_img, name=<span class="string">&#x27;autoencoder&#x27;</span>)</span><br><span class="line">autoencoder.summary()</span><br></pre></td></tr></table></figure><p>可以发现，模型可以包含子模型，一个常见的用途是用于模型的聚合：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_model</span>():</span></span><br><span class="line">  inputs = keras.Input(shape=(<span class="number">128</span>,))</span><br><span class="line">  outputs = layers.Dense(<span class="number">1</span>)(inputs)</span><br><span class="line">  <span class="keyword">return</span> keras.Model(inputs, outputs)</span><br><span class="line"></span><br><span class="line">model1 = get_model()</span><br><span class="line">model2 = get_model()</span><br><span class="line">model3 = get_model()</span><br><span class="line"></span><br><span class="line">inputs = keras.Input(shape=(<span class="number">128</span>,))</span><br><span class="line">y1 = model1(inputs)</span><br><span class="line">y2 = model2(inputs)</span><br><span class="line">y3 = model3(inputs)</span><br><span class="line">outputs = layers.average([y1, y2, y3])</span><br><span class="line">ensemble_model = keras.Model(inputs=inputs, outputs=outputs)</span><br></pre></td></tr></table></figure><h2 id="生成复杂模型"><a href="#生成复杂模型" class="headerlink" title="生成复杂模型"></a>生成复杂模型</h2><h3 id="包含多个输入和输出的模型"><a href="#包含多个输入和输出的模型" class="headerlink" title="包含多个输入和输出的模型"></a>包含多个输入和输出的模型</h3><p>我们可以使用函数式API生成包含多个输入输出的模型，这在Sequential中是不能被实现的。接下来我们创建一个将用户问题分类并且将其转交给哪个部门的模型，这个模型含有3个输入：</p><ul><li>问题的标题</li><li>问题的内容</li><li>用户添加的问题的标签（分类输入）</li></ul><p>含有2个输出：</p><ul><li>优先级<code>[0, 1]</code></li><li>这个问题该交给哪个部门</li></ul><p>下面是代码实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">num_tags = <span class="number">12</span>  <span class="comment"># Number of unique issue tags</span></span><br><span class="line">num_words = <span class="number">10000</span>  <span class="comment"># Size of vocabulary obtained when preprocessing text data</span></span><br><span class="line">num_departments = <span class="number">4</span>  <span class="comment"># Number of departments for predictions</span></span><br><span class="line"></span><br><span class="line">title_input = keras.Input(shape=(<span class="literal">None</span>,), name=<span class="string">&#x27;title&#x27;</span>)  <span class="comment"># Variable-length sequence of ints</span></span><br><span class="line">body_input = keras.Input(shape=(<span class="literal">None</span>,), name=<span class="string">&#x27;body&#x27;</span>)  <span class="comment"># Variable-length sequence of ints</span></span><br><span class="line">tags_input = keras.Input(shape=(num_tags,), name=<span class="string">&#x27;tags&#x27;</span>)  <span class="comment"># Binary vectors of size `num_tags`</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Embed each word in the title into a 64-dimensional vector</span></span><br><span class="line">title_features = layers.Embedding(num_words, <span class="number">64</span>)(title_input)</span><br><span class="line"><span class="comment"># Embed each word in the text into a 64-dimensional vector</span></span><br><span class="line">body_features = layers.Embedding(num_words, <span class="number">64</span>)(body_input)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Reduce sequence of embedded words in the title into a single 128-dimensional vector</span></span><br><span class="line">title_features = layers.LSTM(<span class="number">128</span>)(title_features)</span><br><span class="line"><span class="comment"># Reduce sequence of embedded words in the body into a single 32-dimensional vector</span></span><br><span class="line">body_features = layers.LSTM(<span class="number">32</span>)(body_features)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Merge all available features into a single large vector via concatenation</span></span><br><span class="line">x = layers.concatenate([title_features, body_features, tags_input])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Stick a logistic regression for priority prediction on top of the features</span></span><br><span class="line">priority_pred = layers.Dense(<span class="number">1</span>, name=<span class="string">&#x27;priority&#x27;</span>)(x)</span><br><span class="line"><span class="comment"># Stick a department classifier on top of the features</span></span><br><span class="line">department_pred = layers.Dense(num_departments, name=<span class="string">&#x27;department&#x27;</span>)(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Instantiate an end-to-end model predicting both priority and department</span></span><br><span class="line">model = keras.Model(inputs=[title_input, body_input, tags_input],</span><br><span class="line">                    outputs=[priority_pred, department_pred])</span><br></pre></td></tr></table></figure><p>至此我们完成的模型的创建，接下里需要完成模型的编译：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">model.compile(optimizer&#x3D;keras.optimizers.RMSprop(1e-3),</span><br><span class="line">              loss&#x3D;[keras.losses.BinaryCrossentropy(from_logits&#x3D;True),</span><br><span class="line">                      keras.losses.CategoricalCrossentropy(from_logits&#x3D;True)],</span><br><span class="line">              loss_weights&#x3D;[1., 0.2])</span><br></pre></td></tr></table></figure><p>如上，我们可以为输出赋予不同的误差函数，以帮助我们控制他们两个输出对误差的贡献。由于我们已经为输出层赋予了名字，我们也可以使用如下方式编译：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">model.compile(optimizer=keras.optimizers.RMSprop(<span class="number">1e-3</span>),</span><br><span class="line">              loss=&#123;<span class="string">&#x27;priority&#x27;</span>:keras.losses.BinaryCrossentropy(from_logits=<span class="literal">True</span>),</span><br><span class="line">                      <span class="string">&#x27;department&#x27;</span>: keras.losses.CategoricalCrossentropy(from_logits=<span class="literal">True</span>)&#125;,</span><br><span class="line">              loss_weights=[<span class="number">1.</span>, <span class="number">0.2</span>])</span><br></pre></td></tr></table></figure><p>接下来进行训练，对于在NumPy产生的数据：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># Dummy input data</span></span><br><span class="line">title_data = np.random.randint(num_words, size=(<span class="number">1280</span>, <span class="number">10</span>))</span><br><span class="line">body_data = np.random.randint(num_words, size=(<span class="number">1280</span>, <span class="number">100</span>))</span><br><span class="line">tags_data = np.random.randint(<span class="number">2</span>, size=(<span class="number">1280</span>, num_tags)).astype(<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line"><span class="comment"># Dummy target data</span></span><br><span class="line">priority_targets = np.random.random(size=(<span class="number">1280</span>, <span class="number">1</span>))</span><br><span class="line">dept_targets = np.random.randint(<span class="number">2</span>, size=(<span class="number">1280</span>, num_departments))</span><br><span class="line"></span><br><span class="line">model.fit(&#123;<span class="string">&#x27;title&#x27;</span>: title_data, <span class="string">&#x27;body&#x27;</span>: body_data, <span class="string">&#x27;tags&#x27;</span>: tags_data&#125;,</span><br><span class="line">          &#123;<span class="string">&#x27;priority&#x27;</span>: priority_targets, <span class="string">&#x27;department&#x27;</span>: dept_targets&#125;,</span><br><span class="line">          epochs=<span class="number">2</span>,</span><br><span class="line">          batch_size=<span class="number">32</span>)</span><br></pre></td></tr></table></figure><p>当我们使用<code>Dataset</code>对象时，它要么yield数组元组：<code>([title_data, body_data, tags_data], [priority_targets, dept_targets])</code>，要么yield字典元组：<code>(&#123;&#39;title&#39;: title_data, &#39;body&#39;: body_data, &#39;tags&#39;: tags_data&#125;, &#123;&#39;priority&#39;: priority_targets, &#39;department&#39;: dept_targets&#125;)</code>。</p><h3 id="一个简单的残差网络模型"><a href="#一个简单的残差网络模型" class="headerlink" title="一个简单的残差网络模型"></a>一个简单的残差网络模型</h3><p>函数式API还可以创建非线性的模型，一个常见的应用是构建残差模型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">inputs = keras.Input(shape=(<span class="number">32</span>, <span class="number">32</span>, <span class="number">3</span>), name=<span class="string">&#x27;img&#x27;</span>)</span><br><span class="line">x = layers.Conv2D(<span class="number">32</span>, <span class="number">3</span>, activation=<span class="string">&#x27;relu&#x27;</span>)(inputs)</span><br><span class="line">x = layers.Conv2D(<span class="number">64</span>, <span class="number">3</span>, activation=<span class="string">&#x27;relu&#x27;</span>)(x)</span><br><span class="line">block_1_output = layers.MaxPooling2D(<span class="number">3</span>)(x)</span><br><span class="line"></span><br><span class="line">x = layers.Conv2D(<span class="number">64</span>, <span class="number">3</span>, activation=<span class="string">&#x27;relu&#x27;</span>, padding=<span class="string">&#x27;same&#x27;</span>)(block_1_output)</span><br><span class="line">x = layers.Conv2D(<span class="number">64</span>, <span class="number">3</span>, activation=<span class="string">&#x27;relu&#x27;</span>, padding=<span class="string">&#x27;same&#x27;</span>)(x)</span><br><span class="line">block_2_output = layers.add([x, block_1_output])</span><br><span class="line"></span><br><span class="line">x = layers.Conv2D(<span class="number">64</span>, <span class="number">3</span>, activation=<span class="string">&#x27;relu&#x27;</span>, padding=<span class="string">&#x27;same&#x27;</span>)(block_2_output)</span><br><span class="line">x = layers.Conv2D(<span class="number">64</span>, <span class="number">3</span>, activation=<span class="string">&#x27;relu&#x27;</span>, padding=<span class="string">&#x27;same&#x27;</span>)(x)</span><br><span class="line">block_3_output = layers.add([x, block_2_output])</span><br><span class="line"></span><br><span class="line">x = layers.Conv2D(<span class="number">64</span>, <span class="number">3</span>, activation=<span class="string">&#x27;relu&#x27;</span>)(block_3_output)</span><br><span class="line">x = layers.GlobalAveragePooling2D()(x)</span><br><span class="line">x = layers.Dense(<span class="number">256</span>, activation=<span class="string">&#x27;relu&#x27;</span>)(x)</span><br><span class="line">x = layers.Dropout(<span class="number">0.5</span>)(x)</span><br><span class="line">outputs = layers.Dense(<span class="number">10</span>)(x)</span><br><span class="line"></span><br><span class="line">model = keras.Model(inputs, outputs, name=<span class="string">&#x27;toy_resnet&#x27;</span>)</span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure><p>训练方法如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()</span><br><span class="line">x_train = x_train.astype(<span class="string">&#x27;float32&#x27;</span>) / <span class="number">255.</span></span><br><span class="line">x_test = x_test.astype(<span class="string">&#x27;float32&#x27;</span>) / <span class="number">255.</span></span><br><span class="line">y_train = keras.utils.to_categorical(y_train, <span class="number">10</span>)</span><br><span class="line">y_test = keras.utils.to_categorical(y_test, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">model.compile(optimizer=keras.optimizers.RMSprop(<span class="number">1e-3</span>),</span><br><span class="line">              loss=keras.losses.CategoricalCrossentropy(from_logits=<span class="literal">True</span>),</span><br><span class="line">              metrics=[<span class="string">&#x27;acc&#x27;</span>])</span><br><span class="line">model.fit(x_train, y_train,</span><br><span class="line">          batch_size=<span class="number">64</span>,</span><br><span class="line">          epochs=<span class="number">1</span>,</span><br><span class="line">          validation_split=<span class="number">0.2</span>)</span><br></pre></td></tr></table></figure><h2 id="共享层"><a href="#共享层" class="headerlink" title="共享层"></a>共享层</h2><p>函数式API的另外一个优点是我们可以使用共享层。为了创建共享层，我们只需要创建层的实例，然后再不断调用即可：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Embedding for 1000 unique words mapped to 128-dimensional vectors</span></span><br><span class="line">shared_embedding = layers.Embedding(<span class="number">1000</span>, <span class="number">128</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Variable-length sequence of integers</span></span><br><span class="line">text_input_a = keras.Input(shape=(<span class="literal">None</span>,), dtype=<span class="string">&#x27;int32&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Variable-length sequence of integers</span></span><br><span class="line">text_input_b = keras.Input(shape=(<span class="literal">None</span>,), dtype=<span class="string">&#x27;int32&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># We reuse the same layer to encode both inputs</span></span><br><span class="line">encoded_input_a = shared_embedding(text_input_a)</span><br><span class="line">encoded_input_b = shared_embedding(text_input_b)</span><br></pre></td></tr></table></figure><h2 id="提取和重用节点"><a href="#提取和重用节点" class="headerlink" title="提取和重用节点"></a>提取和重用节点</h2><p>由于我们使用函数式API创建的模型是静态的，所以它容易被存取和检查。这个过程和画图差不多。这也就意味着我们可以获取模型中节点并且重用他们。接下来我们看一下带有权重的VGG19模型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.keras.applications <span class="keyword">import</span> VGG19</span><br><span class="line"></span><br><span class="line">vgg19 = VGG19()</span><br></pre></td></tr></table></figure><p>可以通过模型的结构获取到中间的层（节点）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">features_list = [layer.output <span class="keyword">for</span> layer <span class="keyword">in</span> vgg19.layers]</span><br></pre></td></tr></table></figure><p>我们可以通过这些节点来构建一个模型，用于获取通过每个层的中间值：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">feat_extraction_model = keras.Model(inputs=vgg19.input, outputs=features_list)</span><br><span class="line"></span><br><span class="line">img = np.random.random((<span class="number">1</span>, <span class="number">224</span>, <span class="number">224</span>, <span class="number">3</span>)).astype(<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">extracted_features = feat_extraction_model(img)</span><br></pre></td></tr></table></figure><h2 id="自定义层来扩展API"><a href="#自定义层来扩展API" class="headerlink" title="自定义层来扩展API"></a>自定义层来扩展API</h2><p><code>tf.keras</code>含有大量的内建层：</p><ul><li>卷积层：<code>Conv1D</code>, <code>Conv2D</code>, <code>Conv3D</code>, <code>Conv2DTranspose</code></li><li>池化层：<code>MaxPooling1D</code>, <code>MaxPooling2D</code>, <code>MaxPooling3D</code>, <code>AveragePooling1D</code></li><li>RNN层：<code>GRU</code>, <code>LSTM</code>, <code>ConvLSTM2D</code></li><li><code>BatchNormalization</code>, <code>Dropout</code>, <code>Embedding</code>，etc.</li></ul><p>如果这些都不能满足要求，我们可以创建Layer的子类，每个子类需要实现：</p><ul><li>call：定义这一层完成的运算</li><li>build：创建这一层的权重</li></ul><p>下面是Dense层的简单实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CustomDense</span>(<span class="params">layers.Layer</span>):</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, units=<span class="number">32</span></span>):</span></span><br><span class="line">    super(CustomDense, self).__init__()</span><br><span class="line">    self.units = units</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">build</span>(<span class="params">self, input_shape</span>):</span></span><br><span class="line">    self.w = self.add_weight(shape=(input_shape[<span class="number">-1</span>], self.units),</span><br><span class="line">                             initializer=<span class="string">&#x27;random_normal&#x27;</span>,</span><br><span class="line">                             trainable=<span class="literal">True</span>)</span><br><span class="line">    self.b = self.add_weight(shape=(self.units,),</span><br><span class="line">                             initializer=<span class="string">&#x27;random_normal&#x27;</span>,</span><br><span class="line">                             trainable=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, inputs</span>):</span></span><br><span class="line">    <span class="keyword">return</span> tf.matmul(inputs, self.w) + self.b</span><br><span class="line"></span><br><span class="line">inputs = keras.Input((<span class="number">4</span>,))</span><br><span class="line">outputs = CustomDense(<span class="number">10</span>)(inputs)</span><br><span class="line"></span><br><span class="line">model = keras.Model(inputs, outputs)</span><br></pre></td></tr></table></figure><p>如果想支持序列化，这时也需要实现get_config方法，该方法将会返回构造器的参数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CustomDense</span>(<span class="params">layers.Layer</span>):</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, units=<span class="number">32</span></span>):</span></span><br><span class="line">    super(CustomDense, self).__init__()</span><br><span class="line">    self.units = units</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">build</span>(<span class="params">self, input_shape</span>):</span></span><br><span class="line">    self.w = self.add_weight(shape=(input_shape[<span class="number">-1</span>], self.units),</span><br><span class="line">                             initializer=<span class="string">&#x27;random_normal&#x27;</span>,</span><br><span class="line">                             trainable=<span class="literal">True</span>)</span><br><span class="line">    self.b = self.add_weight(shape=(self.units,),</span><br><span class="line">                             initializer=<span class="string">&#x27;random_normal&#x27;</span>,</span><br><span class="line">                             trainable=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, inputs</span>):</span></span><br><span class="line">    <span class="keyword">return</span> tf.matmul(inputs, self.w) + self.b</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">get_config</span>(<span class="params">self</span>):</span></span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&#x27;units&#x27;</span>: self.units&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">inputs = keras.Input((<span class="number">4</span>,))</span><br><span class="line">outputs = CustomDense(<span class="number">10</span>)(inputs)</span><br><span class="line"></span><br><span class="line">model = keras.Model(inputs, outputs)</span><br><span class="line">config = model.get_config()</span><br><span class="line"></span><br><span class="line">new_model = keras.Model.from_config(</span><br><span class="line">    config, custom_objects=&#123;<span class="string">&#x27;CustomDense&#x27;</span>: CustomDense&#125;)</span><br></pre></td></tr></table></figure><p>同样可以实现from_config方法来实现层的重构，默认的from_config方法如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">from_config</span>(<span class="params">cls, config</span>):</span></span><br><span class="line">  <span class="keyword">return</span> cls(**config)</span><br></pre></td></tr></table></figure><h2 id="使用函数式API的时机"><a href="#使用函数式API的时机" class="headerlink" title="使用函数式API的时机"></a>使用函数式API的时机</h2><p>什么时候该使用函数式API构建模型，什么时候使用模型子类构建模型？总体来说，函数式API是一种更加易用安全，多特性的方法，而模型子类则提供了更高的灵活性。</p><p>函数式API的优点如下：</p><ul><li><p>简洁的：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 函数式API</span></span><br><span class="line">inputs = keras.Input(shape=(<span class="number">32</span>,))</span><br><span class="line">x = layers.Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>)(inputs)</span><br><span class="line">outputs = layers.Dense(<span class="number">10</span>)(x)</span><br><span class="line">mlp = keras.Model(inputs, outputs)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型子类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MLP</span>(<span class="params">keras.Model</span>):</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, **kwargs</span>):</span></span><br><span class="line">    super(MLP, self).__init__(**kwargs)</span><br><span class="line">    self.dense_1 = layers.Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">    self.dense_2 = layers.Dense(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, inputs</span>):</span></span><br><span class="line">    x = self.dense_1(inputs)</span><br><span class="line">    <span class="keyword">return</span> self.dense_2(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Instantiate the model.</span></span><br><span class="line">mlp = MLP()</span><br><span class="line"><span class="comment"># Necessary to create the model&#x27;s state.</span></span><br><span class="line"><span class="comment"># The model doesn&#x27;t have a state until it&#x27;s called at least once.</span></span><br><span class="line">_ = mlp(tf.zeros((<span class="number">1</span>, <span class="number">32</span>)))</span><br></pre></td></tr></table></figure></li><li><p>在构建模型的时候提供检查：每一层可以根据输入数据的shape和dtype判断是否是合法的输入</p></li><li><p>模型更易构建：构建模型就像是画图一样简单</p></li><li><p>模型可以被序列化和克隆</p></li></ul><p>函数式API缺点如下：</p><ul><li>不支持动态架构</li></ul><h2 id="混合模式构建模型"><a href="#混合模式构建模型" class="headerlink" title="混合模式构建模型"></a>混合模式构建模型</h2><p>我们可以混合使用函数式API和模型子类方式来构建模型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">units = <span class="number">32</span></span><br><span class="line">timesteps = <span class="number">10</span></span><br><span class="line">input_dim = <span class="number">5</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Define a Functional model</span></span><br><span class="line">inputs = keras.Input((<span class="literal">None</span>, units))</span><br><span class="line">x = layers.GlobalAveragePooling1D()(inputs)</span><br><span class="line">outputs = layers.Dense(<span class="number">1</span>)(x)</span><br><span class="line">model = keras.Model(inputs, outputs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CustomRNN</span>(<span class="params">layers.Layer</span>):</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">    super(CustomRNN, self).__init__()</span><br><span class="line">    self.units = units</span><br><span class="line">    self.projection_1 = layers.Dense(units=units, activation=<span class="string">&#x27;tanh&#x27;</span>)</span><br><span class="line">    self.projection_2 = layers.Dense(units=units, activation=<span class="string">&#x27;tanh&#x27;</span>)</span><br><span class="line">    <span class="comment"># Our previously-defined Functional model</span></span><br><span class="line">    self.classifier = model</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, inputs</span>):</span></span><br><span class="line">    outputs = []</span><br><span class="line">    state = tf.zeros(shape=(inputs.shape[<span class="number">0</span>], self.units))</span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> range(inputs.shape[<span class="number">1</span>]):</span><br><span class="line">      x = inputs[:, t, :]</span><br><span class="line">      h = self.projection_1(x)</span><br><span class="line">      y = h + self.projection_2(state)</span><br><span class="line">      state = y</span><br><span class="line">      outputs.append(y)</span><br><span class="line">    features = tf.stack(outputs, axis=<span class="number">1</span>)</span><br><span class="line">    print(features.shape)</span><br><span class="line">    <span class="keyword">return</span> self.classifier(features)</span><br><span class="line"></span><br><span class="line">rnn_model = CustomRNN()</span><br><span class="line">_ = rnn_model(tf.zeros((<span class="number">1</span>, timesteps, input_dim)))</span><br></pre></td></tr></table></figure><p>下面是一个使用函数式模型构建RNN网络：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">units = <span class="number">32</span></span><br><span class="line">timesteps = <span class="number">10</span></span><br><span class="line">input_dim = <span class="number">5</span></span><br><span class="line">batch_size = <span class="number">16</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CustomRNN</span>(<span class="params">layers.Layer</span>):</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">    super(CustomRNN, self).__init__()</span><br><span class="line">    self.units = units</span><br><span class="line">    self.projection_1 = layers.Dense(units=units, activation=<span class="string">&#x27;tanh&#x27;</span>)</span><br><span class="line">    self.projection_2 = layers.Dense(units=units, activation=<span class="string">&#x27;tanh&#x27;</span>)</span><br><span class="line">    self.classifier = layers.Dense(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, inputs</span>):</span></span><br><span class="line">    outputs = []</span><br><span class="line">    state = tf.zeros(shape=(inputs.shape[<span class="number">0</span>], self.units))</span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> range(inputs.shape[<span class="number">1</span>]):</span><br><span class="line">      x = inputs[:, t, :]</span><br><span class="line">      h = self.projection_1(x)</span><br><span class="line">      y = h + self.projection_2(state)</span><br><span class="line">      state = y</span><br><span class="line">      outputs.append(y)</span><br><span class="line">    features = tf.stack(outputs, axis=<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> self.classifier(features)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Note that we specify a static batch size for the inputs with the `batch_shape`</span></span><br><span class="line"><span class="comment"># arg, because the inner computation of `CustomRNN` requires a static batch size</span></span><br><span class="line"><span class="comment"># (when we create the `state` zeros tensor).</span></span><br><span class="line">inputs = keras.Input(batch_shape=(batch_size, timesteps, input_dim))</span><br><span class="line">x = layers.Conv1D(<span class="number">32</span>, <span class="number">3</span>)(inputs)</span><br><span class="line">outputs = CustomRNN()(x)</span><br><span class="line"></span><br><span class="line">model = keras.Model(inputs, outputs)</span><br><span class="line"></span><br><span class="line">rnn_model = CustomRNN()</span><br><span class="line">_ = rnn_model(tf.zeros((<span class="number">1</span>, <span class="number">10</span>, <span class="number">5</span>)))</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> TensorFlow </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Keras概览</title>
      <link href="2020/02/13/Keras%E6%A6%82%E8%A7%88/"/>
      <url>2020/02/13/Keras%E6%A6%82%E8%A7%88/</url>
      
        <content type="html"><![CDATA[<p>本节介绍Keras及其相关模块，以帮助我们快速构建人工神经网络。</p><a id="more"></a><h2 id="构建一个简单模型"><a href="#构建一个简单模型" class="headerlink" title="构建一个简单模型"></a>构建一个简单模型</h2><h3 id="层叠式模型"><a href="#层叠式模型" class="headerlink" title="层叠式模型"></a>层叠式模型</h3><p>在Keras中，我们使用层（layers）来构建我们的模型，模型通常是一个由多个层构成的流程图，最简单模型类型是层叠式（Sequential）类型。为了构建一个简单全连接的MLP，我们用如下代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers</span><br><span class="line"></span><br><span class="line">model = tf.keras.Sequential()</span><br><span class="line"><span class="comment"># Adds a densely-connected layer with 64 units to the model:</span></span><br><span class="line">model.add(layers.Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line"><span class="comment"># Add another:</span></span><br><span class="line">model.add(layers.Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line"><span class="comment"># Add an output layer with 10 output units:</span></span><br><span class="line">model.add(layers.Dense(<span class="number">10</span>))</span><br></pre></td></tr></table></figure><h3 id="调整层参数"><a href="#调整层参数" class="headerlink" title="调整层参数"></a>调整层参数</h3><p>有很多内建的层，它们都有一些公用的构造参数：</p><ul><li>activation：设置激活函数</li><li>kernel_initializer和bias_initializer：用于初始化权重的方法</li><li>kernel_regularizer和bias_regularizer：定义正则化的方法</li></ul><p>下面的代码构造使用不同的参数构造层：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create a relu layer:</span></span><br><span class="line">layers.Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line"><span class="comment"># Or:</span></span><br><span class="line">layers.Dense(<span class="number">64</span>, activation=tf.nn.relu)</span><br><span class="line"></span><br><span class="line"><span class="comment"># A linear layer with L1 regularization of factor 0.01 applied to the kernel matrix:</span></span><br><span class="line">layers.Dense(<span class="number">64</span>, kernel_regularizer=tf.keras.regularizers.l1(<span class="number">0.01</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># A linear layer with L2 regularization of factor 0.01 applied to the bias vector:</span></span><br><span class="line">layers.Dense(<span class="number">64</span>, bias_regularizer=tf.keras.regularizers.l2(<span class="number">0.01</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># A linear layer with a kernel initialized to a random orthogonal matrix:</span></span><br><span class="line">layers.Dense(<span class="number">64</span>, kernel_initializer=<span class="string">&#x27;orthogonal&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># A linear layer with a bias vector initialized to 2.0s:</span></span><br><span class="line">layers.Dense(<span class="number">64</span>, bias_initializer=tf.keras.initializers.Constant(<span class="number">2.0</span>))</span><br></pre></td></tr></table></figure><h2 id="训练和评估"><a href="#训练和评估" class="headerlink" title="训练和评估"></a>训练和评估</h2><h3 id="训练时的设置"><a href="#训练时的设置" class="headerlink" title="训练时的设置"></a>训练时的设置</h3><p>当模型被构建后，我们可以通过调用compile方法来调整学习过程：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">model = tf.keras.Sequential([</span><br><span class="line"><span class="comment"># Adds a densely-connected layer with 64 units to the model:</span></span><br><span class="line">layers.Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>, input_shape=(<span class="number">32</span>,)),</span><br><span class="line"><span class="comment"># Add another:</span></span><br><span class="line">layers.Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line"><span class="comment"># Add an output layer with 10 output units:</span></span><br><span class="line">layers.Dense(<span class="number">10</span>)])</span><br><span class="line"></span><br><span class="line">model.compile(optimizer=tf.keras.optimizers.Adam(<span class="number">0.01</span>),</span><br><span class="line">      loss=tf.keras.losses.CategoricalCrossentropy(from_logits=<span class="literal">True</span>),</span><br><span class="line">      metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br></pre></td></tr></table></figure><p>compile有以下重要参数：</p><ul><li>optimizer：定义优化算法</li><li>loss：定义误差函数</li><li>metrix：用于观察训练的情况</li></ul><p>下面的示例展示了调整模型的情况：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Configure a model for mean-squared error regression.</span></span><br><span class="line">model.compile(optimizer=tf.keras.optimizers.Adam(<span class="number">0.01</span>),</span><br><span class="line">              loss=<span class="string">&#x27;mse&#x27;</span>,       <span class="comment"># mean squared error</span></span><br><span class="line">              metrics=[<span class="string">&#x27;mae&#x27;</span>])  <span class="comment"># mean absolute error</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Configure a model for categorical classification.</span></span><br><span class="line">model.compile(optimizer=tf.keras.optimizers.RMSprop(<span class="number">0.01</span>),</span><br><span class="line">              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=<span class="literal">True</span>),</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br></pre></td></tr></table></figure><h3 id="从NumPy数据训练"><a href="#从NumPy数据训练" class="headerlink" title="从NumPy数据训练"></a>从NumPy数据训练</h3><p>对于小型的数据集，我们可以用如下方法训练：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">data = np.random.random((<span class="number">1000</span>, <span class="number">32</span>))</span><br><span class="line">labels = np.random.random((<span class="number">1000</span>, <span class="number">10</span>))</span><br><span class="line"></span><br><span class="line">model.fit(data, labels, epochs=<span class="number">10</span>, batch_size=<span class="number">32</span>)</span><br></pre></td></tr></table></figure><p><code>fit</code>方法有以下重要的参数：</p><ul><li>epochs：训练的迭代次数</li><li>batch_size：每个批次的样本数量</li><li>validation_data：用于定义验证集</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">data = np.random.random((<span class="number">1000</span>, <span class="number">32</span>))</span><br><span class="line">labels = np.random.random((<span class="number">1000</span>, <span class="number">10</span>))</span><br><span class="line"></span><br><span class="line">val_data = np.random.random((<span class="number">100</span>, <span class="number">32</span>))</span><br><span class="line">val_labels = np.random.random((<span class="number">100</span>, <span class="number">10</span>))</span><br><span class="line"></span><br><span class="line">model.fit(data, labels, epochs=<span class="number">10</span>, batch_size=<span class="number">32</span>,</span><br><span class="line">          validation_data=(val_data, val_labels))</span><br></pre></td></tr></table></figure><h3 id="从tf-data中的datasets训练"><a href="#从tf-data中的datasets训练" class="headerlink" title="从tf.data中的datasets训练"></a>从tf.data中的datasets训练</h3><p>使用Datasets中的方法来构建训练数据集：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Instantiates a toy dataset instance:</span></span><br><span class="line">dataset = tf.data.Dataset.from_tensor_slices((data, labels))</span><br><span class="line">dataset = dataset.batch(<span class="number">32</span>)</span><br><span class="line"></span><br><span class="line">model.fit(dataset, epochs=<span class="number">10</span>)</span><br></pre></td></tr></table></figure><p>Dataset数据会不断yield小批次的数据，因此不需要batch_size参数。</p><p>同样，Dataset可以用于验证：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">dataset = tf.data.Dataset.from_tensor_slices((data, labels))</span><br><span class="line">dataset = dataset.batch(<span class="number">32</span>)</span><br><span class="line"></span><br><span class="line">val_dataset = tf.data.Dataset.from_tensor_slices((val_data, val_labels))</span><br><span class="line">val_dataset = val_dataset.batch(<span class="number">32</span>)</span><br><span class="line"></span><br><span class="line">model.fit(dataset, epochs=<span class="number">10</span>,</span><br><span class="line">          validation_data=val_dataset)</span><br></pre></td></tr></table></figure><h3 id="评估和预测"><a href="#评估和预测" class="headerlink" title="评估和预测"></a>评估和预测</h3><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># With Numpy arrays</span></span><br><span class="line">data = np.random.random((<span class="number">1000</span>, <span class="number">32</span>))</span><br><span class="line">labels = np.random.random((<span class="number">1000</span>, <span class="number">10</span>))</span><br><span class="line"></span><br><span class="line">model.evaluate(data, labels, batch_size=<span class="number">32</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># With a Dataset</span></span><br><span class="line">dataset = tf.data.Dataset.from_tensor_slices((data, labels))</span><br><span class="line">dataset = dataset.batch(<span class="number">32</span>)</span><br><span class="line"></span><br><span class="line">model.evaluate(dataset)</span><br></pre></td></tr></table></figure><p>同样，我们可以使用以下代码进行预测：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">result = model.predict(data, batch_size=<span class="number">32</span>)</span><br><span class="line">print(result.shape)</span><br></pre></td></tr></table></figure><h2 id="构建复杂模型"><a href="#构建复杂模型" class="headerlink" title="构建复杂模型"></a>构建复杂模型</h2><h3 id="函数式API"><a href="#函数式API" class="headerlink" title="函数式API"></a>函数式API</h3><p>层叠式模型是一种将多个层之间连接的简单模型，我们可以使用Keras中的函数式API来构建复杂的模型：</p><ul><li>多个输入模型</li><li>多个输出模型</li><li>包含共享层（同一个层被多次调用）的模型</li><li>不包含顺序流的模型（如残差模型）</li></ul><p>接下来我们使用函数式API来构建这样的一个模型：</p><ol><li>一个层实例是可以被调用的并且可以返回一个张量</li><li>输入输出张量可以被用来定义模型实例</li><li>该模型训练方法和层叠模型一致</li></ol><p>下面的代码用于构建一个简单全连接的网络：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">inputs = tf.keras.Input(shape=(<span class="number">32</span>,))  <span class="comment"># Returns an input placeholder</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># A layer instance is callable on a tensor, and returns a tensor.</span></span><br><span class="line">x = layers.Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>)(inputs)</span><br><span class="line">x = layers.Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>)(x)</span><br><span class="line">predictions = layers.Dense(<span class="number">10</span>)(x)</span><br></pre></td></tr></table></figure><p>接下来实例化模型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">model = tf.keras.Model(inputs=inputs, outputs=predictions)</span><br><span class="line"></span><br><span class="line"><span class="comment"># The compile step specifies the training configuration.</span></span><br><span class="line">model.compile(optimizer=tf.keras.optimizers.RMSprop(<span class="number">0.001</span>),</span><br><span class="line">              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=<span class="literal">True</span>),</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Trains for 5 epochs</span></span><br><span class="line">model.fit(data, labels, batch_size=<span class="number">32</span>, epochs=<span class="number">5</span>)</span><br></pre></td></tr></table></figure><h3 id="模型子类化"><a href="#模型子类化" class="headerlink" title="模型子类化"></a>模型子类化</h3><p>为了构建一个高度定制的模型，我们可以构造模型的子类。我们可以在<code>__init__</code>方法中定义层和层的属性，同时在<code>call</code>方法中定义前向传播。代码示例如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyModel</span>(<span class="params">tf.keras.Model</span>):</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, num_classes=<span class="number">10</span></span>):</span></span><br><span class="line">    super(MyModel, self).__init__(name=<span class="string">&#x27;my_model&#x27;</span>)</span><br><span class="line">    self.num_classes = num_classes</span><br><span class="line">    <span class="comment"># Define your layers here.</span></span><br><span class="line">    self.dense_1 = layers.Dense(<span class="number">32</span>, activation=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">    self.dense_2 = layers.Dense(num_classes)</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, inputs</span>):</span></span><br><span class="line">    <span class="comment"># Define your forward pass here,</span></span><br><span class="line">    <span class="comment"># using layers you previously defined (in `__init__`).</span></span><br><span class="line">    x = self.dense_1(inputs)</span><br><span class="line">    <span class="keyword">return</span> self.dense_2(x)</span><br></pre></td></tr></table></figure><p>接下来定义新的模型子类：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">model = MyModel(num_classes=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># The compile step specifies the training configuration.</span></span><br><span class="line">model.compile(optimizer=tf.keras.optimizers.RMSprop(<span class="number">0.001</span>),</span><br><span class="line">              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=<span class="literal">True</span>),</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Trains for 5 epochs.</span></span><br><span class="line">model.fit(data, labels, batch_size=<span class="number">32</span>, epochs=<span class="number">5</span>)</span><br></pre></td></tr></table></figure><h3 id="自定义层"><a href="#自定义层" class="headerlink" title="自定义层"></a>自定义层</h3><p>自定义的层可以通过构建<code>tf.keras.layers.Layer</code>的子类来进行，需要实现如下方法：</p><ul><li><code>__init__</code>：可选，用于定义这一层中将要使用子层</li><li><code>build</code>：创建层的权重，可以通过<code>add_weight</code>方法来添加权重</li><li><code>call</code>：定义前向传播</li><li>可选，可以通过实现get_config和from_config方法实现序列化和反序列化</li></ul><p>下面代码实现了一个矩阵相乘的层：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyLayer</span>(<span class="params">layers.Layer</span>):</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, output_dim, **kwargs</span>):</span></span><br><span class="line">    self.output_dim = output_dim</span><br><span class="line">    super(MyLayer, self).__init__(**kwargs)</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">build</span>(<span class="params">self, input_shape</span>):</span></span><br><span class="line">    <span class="comment"># Create a trainable weight variable for this layer.</span></span><br><span class="line">    self.kernel = self.add_weight(name=<span class="string">&#x27;kernel&#x27;</span>,</span><br><span class="line">                                  shape=(input_shape[<span class="number">1</span>], self.output_dim),</span><br><span class="line">                                  initializer=<span class="string">&#x27;uniform&#x27;</span>,</span><br><span class="line">                                  trainable=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, inputs</span>):</span></span><br><span class="line">    <span class="keyword">return</span> tf.matmul(inputs, self.kernel)</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">get_config</span>(<span class="params">self</span>):</span></span><br><span class="line">    base_config = super(MyLayer, self).get_config()</span><br><span class="line">    base_config[<span class="string">&#x27;output_dim&#x27;</span>] = self.output_dim</span><br><span class="line">    <span class="keyword">return</span> base_config</span><br><span class="line"></span><br><span class="line"><span class="meta">  @classmethod</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">from_config</span>(<span class="params">cls, config</span>):</span></span><br><span class="line">    <span class="keyword">return</span> cls(**config)</span><br></pre></td></tr></table></figure><p>使用自定义层来构建模型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">model = tf.keras.Sequential([</span><br><span class="line">    MyLayer(<span class="number">10</span>)])</span><br><span class="line"></span><br><span class="line"><span class="comment"># The compile step specifies the training configuration</span></span><br><span class="line">model.compile(optimizer=tf.keras.optimizers.RMSprop(<span class="number">0.001</span>),</span><br><span class="line">              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=<span class="literal">True</span>),</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Trains for 5 epochs.</span></span><br><span class="line">model.fit(data, labels, batch_size=<span class="number">32</span>, epochs=<span class="number">5</span>)</span><br></pre></td></tr></table></figure><h2 id="Callbacks"><a href="#Callbacks" class="headerlink" title="Callbacks"></a>Callbacks</h2><p>callback对象用于传给模型以此在训练期间被使用，可以使用自定义的callback，同样可以使用内建的callback：</p><ul><li><a href="https://tensorflow.google.cn/api_docs/python/tf/keras/callbacks/ModelCheckpoint"><code>tf.keras.callbacks.ModelCheckpoint</code></a>: 每次迭代保存检验点</li><li><a href="https://tensorflow.google.cn/api_docs/python/tf/keras/callbacks/LearningRateScheduler"><code>tf.keras.callbacks.LearningRateScheduler</code></a>: 动态改变学习速率</li><li><a href="https://tensorflow.google.cn/api_docs/python/tf/keras/callbacks/EarlyStopping"><code>tf.keras.callbacks.EarlyStopping</code></a>: 如果模型没有改经就停止训练</li><li><a href="https://tensorflow.google.cn/api_docs/python/tf/keras/callbacks/TensorBoard"><code>tf.keras.callbacks.TensorBoard</code></a>: 监视模型的行为</li></ul><p>使用方法如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">callbacks = [</span><br><span class="line">  <span class="comment"># Interrupt training if `val_loss` stops improving for over 2 epochs</span></span><br><span class="line">  tf.keras.callbacks.EarlyStopping(patience=<span class="number">2</span>, monitor=<span class="string">&#x27;val_loss&#x27;</span>),</span><br><span class="line">  <span class="comment"># Write TensorBoard logs to `./logs` directory</span></span><br><span class="line">  tf.keras.callbacks.TensorBoard(log_dir=<span class="string">&#x27;./logs&#x27;</span>)</span><br><span class="line">]</span><br><span class="line">model.fit(data, labels, batch_size=<span class="number">32</span>, epochs=<span class="number">5</span>, callbacks=callbacks,</span><br><span class="line">          validation_data=(val_data, val_labels))</span><br></pre></td></tr></table></figure><h2 id="保存和恢复"><a href="#保存和恢复" class="headerlink" title="保存和恢复"></a>保存和恢复</h2><h3 id="保存权重值"><a href="#保存权重值" class="headerlink" title="保存权重值"></a>保存权重值</h3><p>使用方法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Save weights to a TensorFlow Checkpoint file</span></span><br><span class="line">model.save_weights(<span class="string">&#x27;./weights/my_model&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Restore the model&#x27;s state,</span></span><br><span class="line"><span class="comment"># this requires a model with the same architecture.</span></span><br><span class="line">model.load_weights(<span class="string">&#x27;./weights/my_model&#x27;</span>)</span><br></pre></td></tr></table></figure><p>同样，可以将文件格式保存为HDF5类型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Save weights to a HDF5 file</span></span><br><span class="line">model.save_weights(<span class="string">&#x27;my_model.h5&#x27;</span>, save_format=<span class="string">&#x27;h5&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Restore the model&#x27;s state</span></span><br><span class="line">model.load_weights(<span class="string">&#x27;my_model.h5&#x27;</span>)</span><br></pre></td></tr></table></figure><h3 id="保存模型配置参数"><a href="#保存模型配置参数" class="headerlink" title="保存模型配置参数"></a>保存模型配置参数</h3><p>一个模型的配置参数可以被保存（但是不保存权重），即使是在没有代码定义，一个模型的配置可以用于创建和初始化同样的模型。Keras支持JSON和YAML的两种序列化的格式：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Serialize a model to JSON format</span></span><br><span class="line">json_string = model.to_json()<span class="comment"># save</span></span><br><span class="line">fresh_model = tf.keras.models.model_from_json(json_string)<span class="comment"># restore</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Serialize a model to YAML format</span></span><br><span class="line">yaml_string = model.to_yaml()</span><br><span class="line">fresh_model = tf.keras.models.model_from_yaml(yaml_string)</span><br></pre></td></tr></table></figure><h3 id="保存整个模型到一个文件"><a href="#保存整个模型到一个文件" class="headerlink" title="保存整个模型到一个文件"></a>保存整个模型到一个文件</h3><p>整个模型的权重值，模型配置参数和优化配置参数可以被保存在一个文件中，这样可以让我们的模型在检查点处保存和恢复：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create a simple model</span></span><br><span class="line">model = tf.keras.Sequential([</span><br><span class="line">  layers.Dense(<span class="number">10</span>, activation=<span class="string">&#x27;relu&#x27;</span>, input_shape=(<span class="number">32</span>,)),</span><br><span class="line">  layers.Dense(<span class="number">10</span>)</span><br><span class="line">])</span><br><span class="line">model.compile(optimizer=<span class="string">&#x27;rmsprop&#x27;</span>,</span><br><span class="line">              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=<span class="literal">True</span>),</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">model.fit(data, labels, batch_size=<span class="number">32</span>, epochs=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Save entire model to a HDF5 file</span></span><br><span class="line">model.save(<span class="string">&#x27;my_model&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Recreate the exact same model, including weights and optimizer.</span></span><br><span class="line">model = tf.keras.models.load_model(<span class="string">&#x27;my_model&#x27;</span>)</span><br></pre></td></tr></table></figure><h2 id="分布式运行"><a href="#分布式运行" class="headerlink" title="分布式运行"></a>分布式运行</h2><h3 id="在GPUs上运行"><a href="#在GPUs上运行" class="headerlink" title="在GPUs上运行"></a>在GPUs上运行</h3><p>首先需要在分布策略范围内定义模型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">strategy = tf.distribute.MirroredStrategy()</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> strategy.scope():</span><br><span class="line">  model = tf.keras.Sequential()</span><br><span class="line">  model.add(layers.Dense(<span class="number">16</span>, activation=<span class="string">&#x27;relu&#x27;</span>, input_shape=(<span class="number">10</span>,)))</span><br><span class="line">  model.add(layers.Dense(<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">  optimizer = tf.keras.optimizers.SGD(<span class="number">0.2</span>)</span><br><span class="line"></span><br><span class="line">  model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=<span class="literal">True</span>),</span><br><span class="line">                optimizer=optimizer)</span><br><span class="line"></span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure><p>接下来，按照平常的方式进行训练：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">x = np.random.random((<span class="number">1024</span>, <span class="number">10</span>))</span><br><span class="line">y = np.random.randint(<span class="number">2</span>, size=(<span class="number">1024</span>, <span class="number">1</span>))</span><br><span class="line">x = tf.cast(x, tf.float32)</span><br><span class="line">dataset = tf.data.Dataset.from_tensor_slices((x, y))</span><br><span class="line">dataset = dataset.shuffle(buffer_size=<span class="number">1024</span>).batch(<span class="number">32</span>)</span><br><span class="line"></span><br><span class="line">model.fit(dataset, epochs=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> TensorFlow </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>TF2初始教程</title>
      <link href="2020/02/12/TF2%E5%88%9D%E5%A7%8B%E6%95%99%E7%A8%8B/"/>
      <url>2020/02/12/TF2%E5%88%9D%E5%A7%8B%E6%95%99%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<p>本节我们学习一些TensorFlow的基本使用方法，包括使用TensorFlow构建神经网络来对MNIST数据集进行划分以及学习一下数据的加载方法。</p><a id="more"></a><h2 id="使用TensorFlow对MNIST数据集进行划分"><a href="#使用TensorFlow对MNIST数据集进行划分" class="headerlink" title="使用TensorFlow对MNIST数据集进行划分"></a>使用TensorFlow对MNIST数据集进行划分</h2><p>首先，我们加载MNIST数据集，同时将数据映射到$ [0, 1] $上：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">mnist = tf.keras.datasets.mnist</span><br><span class="line">(X_train, y_train), (X_test, y_test) = mnist.load_data()</span><br><span class="line">X_train, X_test = X_train / <span class="number">255.0</span>, X_test / <span class="number">255.0</span></span><br></pre></td></tr></table></figure><p>接下来将各层堆叠起来，来搭建<code>tf.keras.Sequential</code>模型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">model = tf.keras.models.Sequential([</span><br><span class="line">    tf.keras.layers.Flatten(input_shape=(<span class="number">28</span>, <span class="number">28</span>)),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">128</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    tf.keras.layers.Dropout(<span class="number">0.2</span>),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line">])</span><br></pre></td></tr></table></figure><p>接下来我们将已经搭建的模型进行编译：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model.compile(optimizer=<span class="string">&#x27;adam&#x27;</span>, loss=<span class="string">&#x27;sparse_categorical_crossentropy&#x27;</span>, </span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br></pre></td></tr></table></figure><p>接下来，训练并且验证模型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model.fit(X_train, y_train, epochs=<span class="number">5</span>)</span><br><span class="line">model.evaluate(X_test, y_test, verbose=<span class="number">2</span>)</span><br></pre></td></tr></table></figure><p>得到的结果如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Train on 60000 samples</span><br><span class="line">Epoch 1&#x2F;5</span><br><span class="line">60000&#x2F;60000 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 5s 87us&#x2F;sample - loss: 0.2942 - accuracy: 0.9140</span><br><span class="line">Epoch 2&#x2F;5</span><br><span class="line">60000&#x2F;60000 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 5s 75us&#x2F;sample - loss: 0.1416 - accuracy: 0.9582</span><br><span class="line">Epoch 3&#x2F;5</span><br><span class="line">60000&#x2F;60000 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 4s 75us&#x2F;sample - loss: 0.1056 - accuracy: 0.9681</span><br><span class="line">Epoch 4&#x2F;5</span><br><span class="line">60000&#x2F;60000 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 4s 73us&#x2F;sample - loss: 0.0888 - accuracy: 0.9724</span><br><span class="line">Epoch 5&#x2F;5</span><br><span class="line">60000&#x2F;60000 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 4s 73us&#x2F;sample - loss: 0.0752 - accuracy: 0.9761</span><br><span class="line">10000&#x2F;1 - 1s - loss: 0.0385 - accuracy: 0.9779</span><br><span class="line">[0.07606992674819194, 0.9779]</span><br></pre></td></tr></table></figure><p>现在，我们得到的照片分类器的准确率已经达到了98%。相较于之前我们实现的分类器，这个分类器的准确率更加优良。</p><h2 id="对Fashion-MNIST数据集划分"><a href="#对Fashion-MNIST数据集划分" class="headerlink" title="对Fashion MNIST数据集划分"></a>对Fashion MNIST数据集划分</h2><p>这一节我们会构建一个神经网络模型来区分关于衣物的图片，首先导入我们需要的库：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">print(tf.__version__)</span><br><span class="line">&gt;&gt; <span class="number">2.0</span><span class="number">.0</span></span><br></pre></td></tr></table></figure><p>接下来导入Fashion MNIST数据集，这个数据集包含了共70000张10个类别的图片，每个图片用$ 28 \times 28 $的矩阵来表示。我们将60000张图片用作是训练，10000章图片用作是评估。代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">fashion_mnist = keras.datasets.fashion_mnist</span><br><span class="line">(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()</span><br></pre></td></tr></table></figure><p>该数据集的类标对应关系如下：</p><table><thead><tr><th align="left">Label</th><th align="left">Class</th></tr></thead><tbody><tr><td align="left">0</td><td align="left">T-shirt/top</td></tr><tr><td align="left">1</td><td align="left">Trouser</td></tr><tr><td align="left">2</td><td align="left">Pullover</td></tr><tr><td align="left">3</td><td align="left">Dress</td></tr><tr><td align="left">4</td><td align="left">Coat</td></tr><tr><td align="left">5</td><td align="left">Sandal</td></tr><tr><td align="left">6</td><td align="left">Shirt</td></tr><tr><td align="left">7</td><td align="left">Sneaker</td></tr><tr><td align="left">8</td><td align="left">Bag</td></tr><tr><td align="left">9</td><td align="left">Ankle boot</td></tr></tbody></table><p>我们可以构建一个列表，来映射相应类标对应的类别：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">class_names = [<span class="string">&#x27;T-shirt/top&#x27;</span>, <span class="string">&#x27;Trouser&#x27;</span>, <span class="string">&#x27;Pullover&#x27;</span>, <span class="string">&#x27;Dress&#x27;</span>, <span class="string">&#x27;Coat&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;Sandal&#x27;</span>, <span class="string">&#x27;Shirt&#x27;</span>, <span class="string">&#x27;Sneaker&#x27;</span>, <span class="string">&#x27;Bag&#x27;</span>, <span class="string">&#x27;Ankle boot&#x27;</span>]</span><br></pre></td></tr></table></figure><p>下面我们看一下训练集中的第一张图片：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">plt.figure()</span><br><span class="line">plt.imshow(train_images[<span class="number">0</span>])</span><br><span class="line">plt.colorbar()</span><br><span class="line">plt.grid(<span class="literal">False</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>得到的图像如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="Wed,%2012%20Feb%202020%20150702.png" class="lazyload" data-srcset="Wed,%2012%20Feb%202020%20150702.png" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><p>接下来我们需要进行特征缩放：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train_images = train_images / <span class="number">255.0</span></span><br><span class="line">test_images = test_images / <span class="number">255.0</span></span><br></pre></td></tr></table></figure><p>然后，看一下训练集中的前25张图片：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># first 25 pic</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">10</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">25</span>):</span><br><span class="line">    plt.subplot(<span class="number">5</span>, <span class="number">5</span>, i+<span class="number">1</span>)</span><br><span class="line">    plt.xticks([])</span><br><span class="line">    plt.yticks([])</span><br><span class="line">    plt.grid(<span class="literal">False</span>)</span><br><span class="line">    plt.imshow(train_images[i], cmap=plt.cm.binary)</span><br><span class="line">    plt.xlabel(class_names[train_labels[i]])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>图像如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="Wed,%2012%20Feb%202020%20150922.png" class="lazyload" data-srcset="Wed,%2012%20Feb%202020%20150922.png" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><p>至此，我们来构建并且编译模型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># build model</span></span><br><span class="line"><span class="comment">## set up layers</span></span><br><span class="line">model = keras.Sequential([</span><br><span class="line">    keras.layers.Flatten(input_shape=(<span class="number">28</span>, <span class="number">28</span>)),</span><br><span class="line">    keras.layers.Dense(<span class="number">128</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    keras.layers.Dense(<span class="number">10</span>)</span><br><span class="line">])</span><br><span class="line"><span class="comment">## compile the model</span></span><br><span class="line">model.compile(optimizer=<span class="string">&#x27;adam&#x27;</span>, </span><br><span class="line">             loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">True</span>),</span><br><span class="line">             metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br></pre></td></tr></table></figure><p>然后，训练这个模型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.fit(train_images, train_labels, epochs=<span class="number">10</span>)</span><br></pre></td></tr></table></figure><p>运行结果如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">Train on 60000 samples</span><br><span class="line">Epoch 1&#x2F;10</span><br><span class="line">60000&#x2F;60000 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 5s 76us&#x2F;sample - loss: 0.5019 - accuracy: 0.8227</span><br><span class="line">Epoch 2&#x2F;10</span><br><span class="line">60000&#x2F;60000 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 4s 67us&#x2F;sample - loss: 0.3747 - accuracy: 0.8639</span><br><span class="line">Epoch 3&#x2F;10</span><br><span class="line">60000&#x2F;60000 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 4s 68us&#x2F;sample - loss: 0.3375 - accuracy: 0.8772</span><br><span class="line">Epoch 4&#x2F;10</span><br><span class="line">60000&#x2F;60000 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 4s 68us&#x2F;sample - loss: 0.3132 - accuracy: 0.8858</span><br><span class="line">Epoch 5&#x2F;10</span><br><span class="line">60000&#x2F;60000 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 4s 72us&#x2F;sample - loss: 0.2913 - accuracy: 0.8926</span><br><span class="line">Epoch 6&#x2F;10</span><br><span class="line">60000&#x2F;60000 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 4s 73us&#x2F;sample - loss: 0.2791 - accuracy: 0.8977</span><br><span class="line">Epoch 7&#x2F;10</span><br><span class="line">60000&#x2F;60000 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 4s 74us&#x2F;sample - loss: 0.2660 - accuracy: 0.9014</span><br><span class="line">Epoch 8&#x2F;10</span><br><span class="line">60000&#x2F;60000 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 5s 82us&#x2F;sample - loss: 0.2538 - accuracy: 0.9048</span><br><span class="line">Epoch 9&#x2F;10</span><br><span class="line">60000&#x2F;60000 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 5s 78us&#x2F;sample - loss: 0.2454 - accuracy: 0.9086</span><br><span class="line">Epoch 10&#x2F;10</span><br><span class="line">60000&#x2F;60000 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 5s 90us&#x2F;sample - loss: 0.2362 - accuracy: 0.9113</span><br></pre></td></tr></table></figure><p>接下来，我们看一下模型在评估集上面的准确率：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=<span class="number">2</span>)</span><br><span class="line">print(<span class="string">&#x27;Acc: %.2f&#x27;</span> % test_acc)</span><br><span class="line">&gt;&gt; Acc: <span class="number">0.88</span></span><br></pre></td></tr></table></figure><p>可以发现我们的模型在评估集上面的准确率比在训练集上面的准确率低，说明我们的模型过拟合了。</p><p>接下来，我们来进行预测：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">predictions = model.predict(test_images)</span><br><span class="line">predictions[<span class="number">0</span>]</span><br><span class="line">&gt;&gt; array([<span class="number">-10.688818</span> , <span class="number">-11.685984</span> , <span class="number">-11.544111</span> , <span class="number">-15.445654</span> ,  <span class="number">-9.708677</span> ,</span><br><span class="line">&gt;&gt;        <span class="number">-1.1382349</span>, <span class="number">-10.859651</span> ,   <span class="number">2.193298</span> , <span class="number">-12.344756</span> ,   <span class="number">6.487081</span> ],</span><br><span class="line">&gt;&gt;      dtype=float32)</span><br></pre></td></tr></table></figure><p>可以发现一个预测的结果是一个包含10个数字的数组，数字代表着这张图片属于某个类标的可信度。同样可以使用<code>argmax</code>函数来得到最高可信度对应的类标：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">np.argmax(predictions[<span class="number">0</span>])</span><br><span class="line">&gt;&gt; <span class="number">9</span></span><br></pre></td></tr></table></figure><p>同样的，当我们需要对单独一个未知的数据进行预测的时候，需要将其转换为$ (n,28,28) $的shape：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">img = test_images[<span class="number">1</span>]</span><br><span class="line">img = np.expand_dims(img, <span class="number">0</span>)</span><br><span class="line">print(img.shape)</span><br><span class="line">&gt;&gt; (<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>)</span><br></pre></td></tr></table></figure><p>接下里就可以进行预测了：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">predictions_single = model.predict(img)</span><br><span class="line">print(predictions_single)</span><br><span class="line">&gt;&gt; [[ <span class="number">-2.5079174</span>  <span class="number">-16.936686</span>     <span class="number">8.989066</span>   <span class="number">-12.332449</span>     <span class="number">2.5185988</span></span><br><span class="line">&gt;&gt;    <span class="number">-2.7389777</span>   <span class="number">-0.61303186</span> <span class="number">-22.695055</span>   <span class="number">-13.934152</span>   <span class="number">-30.008425</span>  ]]</span><br></pre></td></tr></table></figure><p>相应的类标如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">np.argmax(predictions_single[<span class="number">0</span>])</span><br><span class="line">&gt;&gt; <span class="number">2</span></span><br></pre></td></tr></table></figure><h2 id="加载CSV数据"><a href="#加载CSV数据" class="headerlink" title="加载CSV数据"></a>加载CSV数据</h2><p>本节学习如何将CSV文件加载到<code>tf.data.Dataset</code>中，将要使用的是泰坦尼克号乘客的数据，模型会根据乘客的年龄，性别，票务舱和是否独立旅行等特征来预测乘客生还的可能性。</p><p>首先，导入必要的库：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> functools</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> tensorflow_datasets <span class="keyword">as</span> tfds</span><br></pre></td></tr></table></figure><p>接下来，下载数据文件：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">TRAIN_DATA_URL = <span class="string">&quot;https://storage.googleapis.com/tf-datasets/titanic/train.csv&quot;</span></span><br><span class="line">TEST_DATA_URL = <span class="string">&quot;https://storage.googleapis.com/tf-datasets/titanic/eval.csv&quot;</span></span><br><span class="line"></span><br><span class="line">train_file_path = tf.keras.utils.get_file(<span class="string">&quot;train.csv&quot;</span>, TRAIN_DATA_URL)</span><br><span class="line">test_file_path = tf.keras.utils.get_file(<span class="string">&quot;eval.csv&quot;</span>, TEST_DATA_URL)</span><br></pre></td></tr></table></figure><p>同时设置一下numpy的输出设置，让他的输出精度是3位：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">np.set_printoptions(precision=<span class="number">3</span>, suppress=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p>首先，来看一下CSV文件的前面几行：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!head &#123;train_file_path&#125;</span><br></pre></td></tr></table></figure><p>得到的输出如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">survived,sex,age,n_siblings_spouses,parch,fare,class,deck,embark_town,alone</span><br><span class="line">0,male,22.0,1,0,7.25,Third,unknown,Southampton,n</span><br><span class="line">1,female,38.0,1,0,71.2833,First,C,Cherbourg,n</span><br><span class="line">1,female,26.0,0,0,7.925,Third,unknown,Southampton,y</span><br><span class="line">1,female,35.0,1,0,53.1,First,C,Southampton,n</span><br><span class="line">0,male,28.0,0,0,8.4583,Third,unknown,Queenstown,y</span><br><span class="line">0,male,2.0,3,1,21.075,Third,unknown,Southampton,n</span><br><span class="line">1,female,27.0,0,2,11.1333,Third,unknown,Southampton,n</span><br><span class="line">1,female,14.0,1,0,30.0708,Second,unknown,Cherbourg,n</span><br><span class="line">1,female,4.0,1,1,16.7,Third,G,Southampton,n</span><br></pre></td></tr></table></figure><p>可以发现，CSV文件的每列都有一个列名。dataset构造函数会自动识别这些列名。如果某个CSV文件不包含列名，我们可以自己手动设置：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">CSV_COLUMNS = [<span class="string">&#x27;survived&#x27;</span>, <span class="string">&#x27;sex&#x27;</span>, <span class="string">&#x27;age&#x27;</span>, <span class="string">&#x27;n_siblings_spouses&#x27;</span>, <span class="string">&#x27;parch&#x27;</span>, <span class="string">&#x27;fare&#x27;</span>, <span class="string">&#x27;class&#x27;</span>, <span class="string">&#x27;deck&#x27;</span>, <span class="string">&#x27;embark_town&#x27;</span>, <span class="string">&#x27;alone&#x27;</span>]</span><br><span class="line"></span><br><span class="line">dataset = tf.data.experimental.make_csv_dataset(</span><br><span class="line">     ...,</span><br><span class="line">     column_names=CSV_COLUMNS,</span><br><span class="line">     ...)</span><br><span class="line">  </span><br></pre></td></tr></table></figure><p>这个示例使用了所有的列，当然我们也可以只使用某些选中的列：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">dataset = tf.data.experimental.make_csv_dataset(</span><br><span class="line">  ...,</span><br><span class="line">  select_columns = columns_to_use, </span><br><span class="line">  ...)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>对于包含模型需要预测的值的列是需要显式指定的：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">LABEL_COLUMN = <span class="string">&#x27;survived&#x27;</span></span><br><span class="line">LABELS = [<span class="number">0</span>, <span class="number">1</span>]</span><br></pre></td></tr></table></figure><p>现在从文件中读取CSV数据并创建dataset：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_dataset</span>(<span class="params">file_path</span>):</span></span><br><span class="line">  dataset = tf.data.experimental.make_csv_dataset(</span><br><span class="line">      file_path,</span><br><span class="line">      batch_size=<span class="number">12</span>, <span class="comment"># 为了示例更容易展示，手动设置较小的值</span></span><br><span class="line">      label_name=LABEL_COLUMN,</span><br><span class="line">      na_value=<span class="string">&quot;?&quot;</span>,</span><br><span class="line">      num_epochs=<span class="number">1</span>,</span><br><span class="line">      ignore_errors=<span class="literal">True</span>)</span><br><span class="line">  <span class="keyword">return</span> dataset</span><br><span class="line"></span><br><span class="line">raw_train_data = get_dataset(train_file_path)</span><br><span class="line">raw_test_data = get_dataset(test_file_path)</span><br></pre></td></tr></table></figure><p>dataset中的每个条目都是一个批次，用一个元组表示（多个样本，多个标签）。样本中的数据组织形式是<strong>以列为主</strong>的张量，每个条目中包含的元素个数就是批次大小（本例中是12）。</p><p>我们首先获取第一个条目的数据：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">examples, labels = next(iter(raw_train_data)) <span class="comment"># 第一个批次</span></span><br><span class="line">print(<span class="string">&quot;EXAMPLES: \n&quot;</span>, examples, <span class="string">&quot;\n&quot;</span>)</span><br><span class="line">print(<span class="string">&quot;LABELS: \n&quot;</span>, labels)</span><br></pre></td></tr></table></figure><p>输出：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">EXAMPLES: </span><br><span class="line"> OrderedDict([(&#39;sex&#39;, &lt;tf.Tensor: id&#x3D;170, shape&#x3D;(12,), dtype&#x3D;string, numpy&#x3D;</span><br><span class="line">array([b&#39;male&#39;, b&#39;male&#39;, b&#39;female&#39;, b&#39;female&#39;, b&#39;female&#39;, b&#39;male&#39;,</span><br><span class="line">       b&#39;male&#39;, b&#39;male&#39;, b&#39;male&#39;, b&#39;male&#39;, b&#39;male&#39;, b&#39;male&#39;], dtype&#x3D;object)&gt;), (&#39;age&#39;, &lt;tf.Tensor: id&#x3D;162, shape&#x3D;(12,), dtype&#x3D;float32, numpy&#x3D;</span><br><span class="line">array([19., 17., 42., 22.,  9., 24., 28., 36., 37., 32., 28., 28.],</span><br><span class="line">      dtype&#x3D;float32)&gt;), (&#39;n_siblings_spouses&#39;, &lt;tf.Tensor: id&#x3D;168, shape&#x3D;(12,), dtype&#x3D;int32, numpy&#x3D;array([0, 0, 1, 1, 4, 1, 0, 0, 2, 0, 1, 0], dtype&#x3D;int32)&gt;), (&#39;parch&#39;, &lt;tf.Tensor: id&#x3D;169, shape&#x3D;(12,), dtype&#x3D;int32, numpy&#x3D;array([0, 2, 0, 1, 2, 0, 0, 1, 0, 0, 0, 0], dtype&#x3D;int32)&gt;), (&#39;fare&#39;, &lt;tf.Tensor: id&#x3D;167, shape&#x3D;(12,), dtype&#x3D;float32, numpy&#x3D;</span><br><span class="line">array([  6.75 , 110.883,  26.   ,  29.   ,  31.275,  16.1  ,  13.863,</span><br><span class="line">       512.329,   7.925,   7.896,  19.967,  26.55 ], dtype&#x3D;float32)&gt;), (&#39;class&#39;, &lt;tf.Tensor: id&#x3D;164, shape&#x3D;(12,), dtype&#x3D;string, numpy&#x3D;</span><br><span class="line">array([b&#39;Third&#39;, b&#39;First&#39;, b&#39;Second&#39;, b&#39;Second&#39;, b&#39;Third&#39;, b&#39;Third&#39;,</span><br><span class="line">       b&#39;Second&#39;, b&#39;First&#39;, b&#39;Third&#39;, b&#39;Third&#39;, b&#39;Third&#39;, b&#39;First&#39;],</span><br><span class="line">      dtype&#x3D;object)&gt;), (&#39;deck&#39;, &lt;tf.Tensor: id&#x3D;165, shape&#x3D;(12,), dtype&#x3D;string, numpy&#x3D;</span><br><span class="line">array([b&#39;unknown&#39;, b&#39;C&#39;, b&#39;unknown&#39;, b&#39;unknown&#39;, b&#39;unknown&#39;, b&#39;unknown&#39;,</span><br><span class="line">       b&#39;unknown&#39;, b&#39;B&#39;, b&#39;unknown&#39;, b&#39;unknown&#39;, b&#39;unknown&#39;, b&#39;C&#39;],</span><br><span class="line">      dtype&#x3D;object)&gt;), (&#39;embark_town&#39;, &lt;tf.Tensor: id&#x3D;166, shape&#x3D;(12,), dtype&#x3D;string, numpy&#x3D;</span><br><span class="line">array([b&#39;Queenstown&#39;, b&#39;Cherbourg&#39;, b&#39;Southampton&#39;, b&#39;Southampton&#39;,</span><br><span class="line">       b&#39;Southampton&#39;, b&#39;Southampton&#39;, b&#39;Cherbourg&#39;, b&#39;Cherbourg&#39;,</span><br><span class="line">       b&#39;Southampton&#39;, b&#39;Southampton&#39;, b&#39;Southampton&#39;, b&#39;Southampton&#39;],</span><br><span class="line">      dtype&#x3D;object)&gt;), (&#39;alone&#39;, &lt;tf.Tensor: id&#x3D;163, shape&#x3D;(12,), dtype&#x3D;string, numpy&#x3D;</span><br><span class="line">array([b&#39;y&#39;, b&#39;n&#39;, b&#39;n&#39;, b&#39;n&#39;, b&#39;n&#39;, b&#39;n&#39;, b&#39;y&#39;, b&#39;n&#39;, b&#39;n&#39;, b&#39;y&#39;, b&#39;n&#39;,</span><br><span class="line">       b&#39;y&#39;], dtype&#x3D;object)&gt;)]) </span><br><span class="line"></span><br><span class="line">LABELS: </span><br><span class="line"> tf.Tensor([0 1 1 1 0 0 1 1 0 0 0 1], shape&#x3D;(12,), dtype&#x3D;int32)</span><br></pre></td></tr></table></figure><p>接下来，我们进行数据的预处理。</p><p>CSV数据中有些列是分类的列，也就是这些列中的值只能在有限的集合中取值。使用<code>tf.feature_column</code>API创建一个<code>tf.feture_column.indicator_column</code>集合，集合中每个元素对应着一个分类的列。我们先将其转换：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">CATEGORIES = &#123;</span><br><span class="line">    <span class="string">&#x27;sex&#x27;</span>: [<span class="string">&#x27;male&#x27;</span>, <span class="string">&#x27;female&#x27;</span>],</span><br><span class="line">    <span class="string">&#x27;class&#x27;</span> : [<span class="string">&#x27;First&#x27;</span>, <span class="string">&#x27;Second&#x27;</span>, <span class="string">&#x27;Third&#x27;</span>],</span><br><span class="line">    <span class="string">&#x27;deck&#x27;</span> : [<span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;B&#x27;</span>, <span class="string">&#x27;C&#x27;</span>, <span class="string">&#x27;D&#x27;</span>, <span class="string">&#x27;E&#x27;</span>, <span class="string">&#x27;F&#x27;</span>, <span class="string">&#x27;G&#x27;</span>, <span class="string">&#x27;H&#x27;</span>, <span class="string">&#x27;I&#x27;</span>, <span class="string">&#x27;J&#x27;</span>],</span><br><span class="line">    <span class="string">&#x27;embark_town&#x27;</span> : [<span class="string">&#x27;Cherbourg&#x27;</span>, <span class="string">&#x27;Southhampton&#x27;</span>, <span class="string">&#x27;Queenstown&#x27;</span>],</span><br><span class="line">    <span class="string">&#x27;alone&#x27;</span> : [<span class="string">&#x27;y&#x27;</span>, <span class="string">&#x27;n&#x27;</span>]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">categorical_columns = []</span><br><span class="line"><span class="keyword">for</span> feature, vocab <span class="keyword">in</span> CATEGORIES.items():</span><br><span class="line">    cat_col = tf.feature_column.categorical_column_with_vocabulary_list(</span><br><span class="line">    key=feature, vocabulary_list=vocab)</span><br><span class="line">    categorical_columns.append(tf.feature_column.indicator_column(cat_col)</span><br><span class="line">    </span><br><span class="line">categorical_columns    </span><br></pre></td></tr></table></figure><p>得到的输出如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key=<span class="string">&#x27;sex&#x27;</span>, vocabulary_list=(<span class="string">&#x27;male&#x27;</span>, <span class="string">&#x27;female&#x27;</span>), dtype=tf.string, default_value=<span class="number">-1</span>, num_oov_buckets=<span class="number">0</span>)),</span><br><span class="line"> IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key=<span class="string">&#x27;class&#x27;</span>, vocabulary_list=(<span class="string">&#x27;First&#x27;</span>, <span class="string">&#x27;Second&#x27;</span>, <span class="string">&#x27;Third&#x27;</span>), dtype=tf.string, default_value=<span class="number">-1</span>, num_oov_buckets=<span class="number">0</span>)),</span><br><span class="line"> IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key=<span class="string">&#x27;deck&#x27;</span>, vocabulary_list=(<span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;B&#x27;</span>, <span class="string">&#x27;C&#x27;</span>, <span class="string">&#x27;D&#x27;</span>, <span class="string">&#x27;E&#x27;</span>, <span class="string">&#x27;F&#x27;</span>, <span class="string">&#x27;G&#x27;</span>, <span class="string">&#x27;H&#x27;</span>, <span class="string">&#x27;I&#x27;</span>, <span class="string">&#x27;J&#x27;</span>), dtype=tf.string, default_value=<span class="number">-1</span>, num_oov_buckets=<span class="number">0</span>)),</span><br><span class="line"> IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key=<span class="string">&#x27;embark_town&#x27;</span>, vocabulary_list=(<span class="string">&#x27;Cherbourg&#x27;</span>, <span class="string">&#x27;Southhampton&#x27;</span>, <span class="string">&#x27;Queenstown&#x27;</span>), dtype=tf.string, default_value=<span class="number">-1</span>, num_oov_buckets=<span class="number">0</span>)),</span><br><span class="line"> IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key=<span class="string">&#x27;alone&#x27;</span>, vocabulary_list=(<span class="string">&#x27;y&#x27;</span>, <span class="string">&#x27;n&#x27;</span>), dtype=tf.string, default_value=<span class="number">-1</span>, num_oov_buckets=<span class="number">0</span>))]</span><br></pre></td></tr></table></figure><p>这是后续构建模型时处理输入数据的一部分。</p><p>而对于连续数据，我们需要将其进行标准化，写一个函数标准化这些值，然后将这些值改造成2维德张量：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">process_continuous_data</span>(<span class="params">mean, data</span>):</span></span><br><span class="line">  <span class="comment"># 标准化数据</span></span><br><span class="line">  data = tf.cast(data, tf.float32) * <span class="number">1</span>/(<span class="number">2</span>*mean)</span><br><span class="line">  <span class="keyword">return</span> tf.reshape(data, [<span class="number">-1</span>, <span class="number">1</span>])</span><br></pre></td></tr></table></figure><p>现在创建一个数值列的集合。<code>tf.feature_columns.numeric_column</code> API 会使用 <code>normalizer_fn</code> 参数。在传参的时候使用 <a href="https://docs.python.org/3/library/functools.html#functools.partial"><code>functools.partial</code></a>，<code>functools.partial</code> 由使用每个列的均值进行标准化的函数构成。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">MEANS = &#123;</span><br><span class="line">    <span class="string">&#x27;age&#x27;</span> : <span class="number">29.631308</span>,</span><br><span class="line">    <span class="string">&#x27;n_siblings_spouses&#x27;</span> : <span class="number">0.545455</span>,</span><br><span class="line">    <span class="string">&#x27;parch&#x27;</span> : <span class="number">0.379585</span>,</span><br><span class="line">    <span class="string">&#x27;fare&#x27;</span> : <span class="number">34.385399</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">numerical_columns = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> feature <span class="keyword">in</span> MEANS.keys():</span><br><span class="line">    num_col = tf.feature_column.numeric_column(feature,</span><br><span class="line">    normalizer_fn=functools.partial(process_continuous_data, MEANS[feature]))</span><br><span class="line">    numerical_columns.append(num_col)</span><br></pre></td></tr></table></figure><p>接下来创建预处理层：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">preprocessing_layer = tf.keras.layers.DenseFeatures(categorical_columns+numerical_columns)</span><br></pre></td></tr></table></figure><p>然后基于预处理层构建并编译模型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">model = tf.keras.Sequential([</span><br><span class="line">    preprocessing_layer,</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">128</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">128</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">1</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>),</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">model.compile(</span><br><span class="line">    loss=<span class="string">&#x27;binary_crossentropy&#x27;</span>,</span><br><span class="line">    optimizer=<span class="string">&#x27;adam&#x27;</span>,</span><br><span class="line">    metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br></pre></td></tr></table></figure><p>接下来，我们就可以实例化和训练模型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">train_data = raw_train_data.shuffle(<span class="number">500</span>)</span><br><span class="line">test_data = raw_test_data</span><br><span class="line">model.fit(train_data, epochs=<span class="number">20</span>)</span><br></pre></td></tr></table></figure><p>训练完成后，我们可以在测试集上检查准确性：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">test_loss, test_accuracy = model.evaluate(test_data)</span><br><span class="line">print(<span class="string">&#x27;\n\nTest Loss &#123;&#125;, Test Accuracy &#123;&#125;&#x27;</span>.format(test_loss, test_accuracy))</span><br><span class="line">&gt;&gt; Test Loss <span class="number">0.44521663270213385</span>, Test Accuracy <span class="number">0.814393937587738</span></span><br></pre></td></tr></table></figure><p>可以发现，该模型的预测准确率是81%。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> TensorFlow </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SSR更新PAC文件</title>
      <link href="2020/02/11/SSR%E6%9B%B4%E6%96%B0PAC%E6%96%87%E4%BB%B6/"/>
      <url>2020/02/11/SSR%E6%9B%B4%E6%96%B0PAC%E6%96%87%E4%BB%B6/</url>
      
        <content type="html"><![CDATA[<p>SSR项目已经不再维护，它的PAC文件更新功能已经失效，本文我们将gfwlist.txt转换为pac.txt给SSR软件使用。</p><a id="more"></a><p>虽然原来的PAC地址已经失效了，但是gfwlist项目组维护了被墙的网站，GitHub地址：<a href="https://github.com/gfwlist/gfwlist/">https://github.com/gfwlist/gfwlist/</a> 。首先，我们下载gfwlist.txt：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl https://raw.githubusercontent.com/gfwlist/gfwlist/master/gfwlist.txt &gt; gfwlist.txt</span><br></pre></td></tr></table></figure><p>接下来，我们需要安装Python的包<code>genpac</code>：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install genpac</span><br></pre></td></tr></table></figure><p>安装完成后，使用<code>genpac</code>将文件gfwlist.txt转换为pac.txt：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">genpac --pac-proxy=<span class="string">&quot;SOCKS 127.0.0.1:1080&quot;</span> --gfwlist-local=<span class="string">&quot;./gfwlist.txt&quot;</span> -o pac.txt</span><br></pre></td></tr></table></figure><p>接下来将生成的pac.txt文件覆盖掉原来SSR软件的pac.txt即可。</p>]]></content>
      
      
      
        <tags>
            
            <tag> SSR </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>实现多层人工神经网络</title>
      <link href="2020/02/09/%E5%AE%9E%E7%8E%B0%E5%A4%9A%E5%B1%82%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
      <url>2020/02/09/%E5%AE%9E%E7%8E%B0%E5%A4%9A%E5%B1%82%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
      
        <content type="html"><![CDATA[<p>本章中，我们将会学习人工神经网络的基本概念以帮助我们学习后面几章中的内容。</p><a id="more"></a><h2 id="使用人工神经网络对复杂函数建模"><a href="#使用人工神经网络对复杂函数建模" class="headerlink" title="使用人工神经网络对复杂函数建模"></a>使用人工神经网络对复杂函数建模</h2><p>我们在第二章中从人工神经元入手，开始了机器学习算法的探索。对于本章中将要讨论的多层人工神经网络来说，人工神经元是其构建的基石。</p><h3 id="单层神经网络回顾"><a href="#单层神经网络回顾" class="headerlink" title="单层神经网络回顾"></a>单层神经网络回顾</h3><p>先来回顾一下自适应线性神经元（Adaline）算法：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="1581236309775.png" class="lazyload" data-srcset="1581236309775.png" srcset="data:image/png;base64,666" alt="1581236309775"/></div><span class="image-caption">1581236309775</span></div><p>我们实现了二分类类别的Adaline算法，并通过<strong>梯度下降</strong>优化算法来学习模型的权重系数：<br>$$<br>w:=w+\Delta w,其中\Delta w = -\eta \nabla J(w)<br>$$<br>在梯度下降优化过程中，我们在每次迭代后同时更新所有权重。此外，将<strong>激励函数</strong>定义为：<br>$$<br>\phi(z)=z=a<br>$$<br>其中，净输入z时输入和权重的线性组合，使用激励函数来计算梯度更新时，我们定义了一个<strong>阈值函数</strong>将连续的输出值转换为二类别分类的预测类标：<br>$$<br>\hat{y}=\begin{cases}<br>1 &amp; 若g(z) \ge 0\<br>-1 &amp; 其他<br>\end{cases}<br>$$</p><h3 id="多层神经网络架构简介"><a href="#多层神经网络架构简介" class="headerlink" title="多层神经网络架构简介"></a>多层神经网络架构简介</h3><p>本节中，我们将会看到如何将多个单独的神经元连接为一个<strong>多层前反馈神经网络</strong>。这种特殊的网络也被称作是<strong>多层感知器</strong>（MLP）。MLP的示例图如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="1581237705175.png" class="lazyload" data-srcset="1581237705175.png" srcset="data:image/png;base64,666" alt="1581237705175"/></div><span class="image-caption">1581237705175</span></div><p>MLP包含一个输入层，一个隐层以及一个输出层。如果这样的网络中包含不只一个隐层，我们称其为<strong>深度神经网络</strong>。如图所示，我们将第l层中第i个激励单元记作$ a_i^l $，同时我们将激励单元$ a_0^{in} $和$ a_0^{h} $为偏置单元（bias unit），我们均设定为1。输入层各单元的激励为输入加上偏置单元：<br>$$<br>a^{in} = \begin{bmatrix}<br>a^{in}<em>0 \<br>a^{in}_1 \<br>\vdots \<br>a^{in}_m<br>\end{bmatrix}<br>$$<br>对于第l层的各单元，均通过一个权重系数连接到$ l+1 $层中的所有单元上。如连接第l层中第k个单元与第$ l+1 $层中第j个单元的连接可记为$ w</em>{j,k}^l $。下图是一个3-4-3多层感知器：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="1581239165942.png" class="lazyload" data-srcset="1581239165942.png" srcset="data:image/png;base64,666" alt="1581239165942"/></div><span class="image-caption">1581239165942</span></div><h3 id="通过正向传播构造神经网络"><a href="#通过正向传播构造神经网络" class="headerlink" title="通过正向传播构造神经网络"></a>通过正向传播构造神经网络</h3><p>本节中，我们将使用<strong>正向传播</strong>来计算多层感知器（MLP）模型的输出。我们将多层感知器的学习过程总结为三个步骤：</p><ol><li>从输入层开始，通过网络向前传播（也就是正向传播）训练数据中的模式，以生成输出</li><li>基于网络的输出，通过一个代价函数计算所需最小化的误差</li><li>反向传播误差，计算其对于网络中每个权重的导数，并且更新模型</li></ol><p>最终通过多层感知器模型权重的多次迭代和学习，我们使用正向传播来计算输出，并使用阈值函数获得独热法所表示的预测类标。</p><p>现在，我们根据正向传播算法逐步从训练数据的模式中生成一个输出。由于隐层每个节点均完全连接到所有输入层节点，我们首先通过以下公式计算$ a_1^2 $的激励：<br>$$<br>z_1^2 = a_0^1w_{1,0}^1+a_1^1w_{1,1}^1+\cdots+a_m^1w_{1,m}^1\<br>a_1^2 = \phi(z_1^2)<br>$$<br>激励函数可以使用sigmoid激励函数以解决图像分类等复杂问题。</p><p>多层感知器是一个典型的前馈人工神经网络，此处的前馈指的是每一层的输出都直接作为下一层的输入。为了提高代码的执行效率和可读性，我们将使用线性代数中的基本概念：<br>$$<br>Z^2 = W^1[A^1]^T<br>$$<br>接下来我们可以将激励函数$ \phi(\cdot) $应用于净输入矩阵中的每个值，便于获取下一个激励矩阵$ A^2 $:<br>$$<br>A^2 = \phi(Z^2)<br>$$<br>类似地，我们以向量的形式重写输入层的激励：<br>$$<br>Z^3 = W^2A^2<br>$$<br>最后，通过sigmoid激励函数，我们可以得到神经网络的连续型输出：<br>$$<br>A^3 = \phi(Z^3)<br>$$</p><h2 id="手写数字的识别"><a href="#手写数字的识别" class="headerlink" title="手写数字的识别"></a>手写数字的识别</h2><p>接下来我们看一下神经网络在实际中的应用，通过MNIST数据集上对手写数字的识别，来完成我们第一个多层神经网络的训练。MNIST是机器学习算法中常用的一个基准数据集。</p><h3 id="获取MNIST数据集"><a href="#获取MNIST数据集" class="headerlink" title="获取MNIST数据集"></a>获取MNIST数据集</h3><p>MNIST数据集可以通过链接<a href="http://yann.lecun.com/exdb/mnist/%E4%B8%8B%E8%BD%BD%EF%BC%8C%E5%8C%85%E5%90%AB%E4%B8%8B%E5%88%97%E5%9B%9B%E4%B8%AA%E9%83%A8%E5%88%86%EF%BC%9A">http://yann.lecun.com/exdb/mnist/下载，包含下列四个部分：</a></p><ul><li>训练集图像：train-images-idx3-ubyte.gz</li><li>训练集类标：train-labels-idx1-ubyte.gz</li><li>测试集图像：t10k-images-idx3-ubyte.gz</li><li>测试集类标：t10k-labels-idx1-ubyte.gz</li></ul><p>下载完数据后并解压，接下来将其读入数组并且用于训练感知器模型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> struct</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_mnist</span>(<span class="params">path, kind=<span class="string">&#x27;train&#x27;</span></span>):</span></span><br><span class="line">    labels_path = os.path.join(path, <span class="string">&#x27;%s-labels-idx1-ubyte&#x27;</span> % kind)</span><br><span class="line">    images_path = os.path.join(path, <span class="string">&#x27;%s-images-idx3-ubyte&#x27;</span> % kind)</span><br><span class="line">    <span class="keyword">with</span> open(labels_path, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> lbpath:</span><br><span class="line">        magic, c = struct.unpack(<span class="string">&#x27;&gt;II&#x27;</span>, lbpath.read(<span class="number">8</span>))</span><br><span class="line">        labels = np.fromfile(lbpath, dtype=np.uint8)</span><br><span class="line">    <span class="keyword">with</span> open(images_path, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> imgpath:</span><br><span class="line">        magic, num, rows, cols = struct.unpack(<span class="string">&#x27;&gt;IIII&#x27;</span>, imgpath.read(<span class="number">16</span>))</span><br><span class="line">        images = np.fromfile(imgpath, dtype=np.uint8).reshape(len(labels), <span class="number">784</span>)</span><br><span class="line">    <span class="keyword">return</span> images, labels</span><br></pre></td></tr></table></figure><p>load_mnist函数返回值返回两个数组，第一个是$ n\times m $维NumPy数组（存储图像），返回的第二个数组（类标）包含对应的目标变量，也即手写数字对应的类标，struct.unpack函数中的fmt参数的实参值：<code>&gt;II</code>。<code>&gt;</code>这是表示大端字节序，<code>I</code>表示一个无符号整数。</p><p>接下来我们读取数据：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">X_train, y_train = load_mnist(<span class="string">&#x27;mnist&#x27;</span>, kind=<span class="string">&#x27;train&#x27;</span>)</span><br><span class="line">print(<span class="string">&#x27;Rows: %d, columns: %d&#x27;</span> % (X_train.shape[<span class="number">0</span>], X_train.shape[<span class="number">1</span>]))</span><br><span class="line">X_test, y_test = load_mnist(<span class="string">&#x27;mnist&#x27;</span>, kind=<span class="string">&#x27;t10k&#x27;</span>)</span><br><span class="line">print(<span class="string">&#x27;Rows: %d, columns: %d&#x27;</span> % (X_test.shape[<span class="number">0</span>], X_test.shape[<span class="number">1</span>]))</span><br><span class="line">&gt;&gt; Rows: <span class="number">60000</span>, columns: <span class="number">784</span></span><br><span class="line">&gt;&gt; Rows: <span class="number">10000</span>, columns: <span class="number">784</span></span><br></pre></td></tr></table></figure><p>为了解MNIST数据集中图像的样子，我们可以将特征矩阵中的784像素向量还原为$ 28 \times 28 $图像：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">fig, ax = plt.subplots(nrows=<span class="number">2</span>, ncols=<span class="number">5</span>, sharex=<span class="literal">True</span>, sharey=<span class="literal">True</span>)</span><br><span class="line">ax = ax.flatten()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">    img = X_train[y_train==i][<span class="number">0</span>].reshape(<span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line">    ax[i].imshow(img, cmap=<span class="string">&#x27;Greys&#x27;</span>, interpolation=<span class="string">&#x27;nearest&#x27;</span>)</span><br><span class="line">ax[<span class="number">0</span>].set_xticks([])</span><br><span class="line">ax[<span class="number">0</span>].set_yticks([])</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>图像如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="Sun,%2009%20Feb%202020%20184326.png" class="lazyload" data-srcset="Sun,%2009%20Feb%202020%20184326.png" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><p>此外，我们绘制一下相同数字的多个示例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">fig, ax = plt.subplots(nrows=<span class="number">5</span>, ncols=<span class="number">5</span>, sharex=<span class="literal">True</span>, sharey=<span class="literal">True</span>)</span><br><span class="line">ax = ax.flatten()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">25</span>):</span><br><span class="line">    img = X_train[y_train==<span class="number">7</span>][i].reshape(<span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line">    ax[i].imshow(img, cmap=<span class="string">&#x27;Greys&#x27;</span>, interpolation=<span class="string">&#x27;nearest&#x27;</span>)</span><br><span class="line">ax[<span class="number">0</span>].set_xticks([])</span><br><span class="line">ax[<span class="number">0</span>].set_yticks([])</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>图像如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="Sun,%2009%20Feb%202020%20184540.png" class="lazyload" data-srcset="Sun,%2009%20Feb%202020%20184540.png" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><h3 id="实现一个多层感知器"><a href="#实现一个多层感知器" class="headerlink" title="实现一个多层感知器"></a>实现一个多层感知器</h3><p>接下来，我们实现一个包含一个输入层，一个隐层和一个输出层的多层感知器，并且将其用来识别MNIST数据集中的图像，整体代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">NeuralNetMLP</span>(<span class="params">object</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, n_hidden=<span class="number">30</span>, l2=<span class="number">0.</span>, epochs=<span class="number">100</span>, eta=<span class="number">0.001</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                shuffle=True, minibatch_size=<span class="number">1</span>, seed=None</span>):</span></span><br><span class="line">        self.random = np.random.RandomState(seed)</span><br><span class="line">        self.n_hidden = n_hidden</span><br><span class="line">        self.l2 = l2</span><br><span class="line">        self.epochs = epochs</span><br><span class="line">        self.eta = eta</span><br><span class="line">        self.shuffle = shuffle</span><br><span class="line">        self.minibatch_size = minibatch_size</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_onehot</span>(<span class="params">self, y, n_classes</span>):</span></span><br><span class="line">        onehot = np.zeros((n_classes, y.shape[<span class="number">0</span>]))</span><br><span class="line">        <span class="keyword">for</span> idx, val <span class="keyword">in</span> enumerate(y.astype(int)):</span><br><span class="line">            onehot[val, idx] = <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> onehot.T</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_sigmoid</span>(<span class="params">self, Z</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">1.</span> / (<span class="number">1.</span> + np.exp(-np.clip(z, <span class="number">-250</span>, <span class="number">250</span>)))</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_forward</span>(<span class="params">self, X</span>):</span></span><br><span class="line">        <span class="comment"># step 1: net input of hidden layer</span></span><br><span class="line">        z_h = np.dot(X, self.w_h) + self.b_h</span><br><span class="line">        <span class="comment"># step 2: activation of hidden layer</span></span><br><span class="line">        a_h = self._sigmoid(z_h)</span><br><span class="line">        <span class="comment"># step 3: net input of output layer</span></span><br><span class="line">        z_out = np.dot(a_h, self.w_out) + self.b_out</span><br><span class="line">        <span class="comment"># step 4: activation output layer</span></span><br><span class="line">        a_out = self._sigmoid(z_out)</span><br><span class="line">        <span class="keyword">return</span> z_h, a_h, z_out, a_out</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_compute_cost</span>(<span class="params">self, y_enc, output</span>):</span></span><br><span class="line">        L2_term = (self.l2 * (np.sum(self.w_h ** <span class="number">2.</span>) + np.sum(self.w_out ** <span class="number">2.</span>)))</span><br><span class="line">        term1 = -y_enc * (np.log(output))</span><br><span class="line">        term2 = (<span class="number">1.</span> - y_enc) * np.log(<span class="number">1.</span> - output)</span><br><span class="line">        cost = np.sum(term1 - term2) + L2_term</span><br><span class="line">        <span class="keyword">return</span> cost</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self, X</span>):</span></span><br><span class="line">        z_h, a_h, z_out, a_out = self._forward(X)</span><br><span class="line">        y_pred = np.argmax(z_out, axis=<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> y_pred</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, X_train, y_train, X_valid, y_valid</span>):</span></span><br><span class="line">        n_output = np.unique(y_train).shape[<span class="number">0</span>]</span><br><span class="line">        n_features = X_train.shape[<span class="number">1</span>]</span><br><span class="line">        <span class="comment"># weight initialization</span></span><br><span class="line">        <span class="comment"># weights for input -&gt; hidden</span></span><br><span class="line">        self.b_h = np.zeros(self.n_hidden)</span><br><span class="line">        self.w_h = self.random.normal(loc=<span class="number">0.0</span>, scale=<span class="number">0.1</span>, size=(n_features, self.n_hidden))</span><br><span class="line">        <span class="comment"># weights for hidden -&gt; output</span></span><br><span class="line">        self.b_out = np.zeros(n_output)</span><br><span class="line">        self.w_out = self.random.normal(loc=<span class="number">0.0</span>, scale=<span class="number">0.1</span>, size=(self.n_hidden, n_output))</span><br><span class="line">        epoch_strlen = len(str(self.epochs))</span><br><span class="line">        self.eval_ = &#123;<span class="string">&#x27;cost&#x27;</span>: [], <span class="string">&#x27;train_acc&#x27;</span>: [], <span class="string">&#x27;valid_acc&#x27;</span>: []&#125;</span><br><span class="line">        y_train_enc = self._onehot(y_train, n_output)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># iteration over training epochs</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(self.epochs):</span><br><span class="line">            indices = np.arange(X_train.shape[<span class="number">0</span>])</span><br><span class="line">            <span class="keyword">if</span> self.shuffle:</span><br><span class="line">                self.random.shuffle(indices)</span><br><span class="line">            <span class="keyword">for</span> start_idx <span class="keyword">in</span> range(<span class="number">0</span>, indices.shape[<span class="number">0</span>] - self.minibatch_size + <span class="number">1</span>, self.minibatch_size):</span><br><span class="line">                batch_idx = indices[start_idx:start_idx + self.minibatch_size]</span><br><span class="line">                z_h, a_h, z_out, a_out = self._forward(X_train[batch_idx])</span><br><span class="line">                <span class="comment"># Backpropagation</span></span><br><span class="line">                sigma_out = a_out - y_train_enc[batch_idx]</span><br><span class="line">                sigmoid_derivative_h = a_h * (<span class="number">1.</span> - a_h)</span><br><span class="line">                sigma_h = (np.dot(sigma_out, self.w_out.T) * sigmoid_derivative_h)</span><br><span class="line">                grad_w_h = np.dot(a_h.T, sigma_out)</span><br><span class="line">                grad_b_out = np.sum(sigma_out, axis=<span class="number">0</span>)</span><br><span class="line">                delta_w_h = (grad_w_h + self.l2*self.w_h)</span><br><span class="line">                delta_b_h = grad_b_h <span class="comment"># bias is not regularized</span></span><br><span class="line">                self.w_h -= self.eta * delta_w_h</span><br><span class="line">                self.b_h -= self.eta * delta_b_h</span><br><span class="line">                delta_w_out = (grad_w_out + self.l2*self.w_out)</span><br><span class="line">                delta_b_out = grad_b_out <span class="comment"># bias is not regularized</span></span><br><span class="line">                self.w_out -= self.eta * delta_w_out</span><br><span class="line">                self.b_out -= self.eta * delta_b_out</span><br><span class="line">            <span class="comment"># evaluation</span></span><br><span class="line">            z_h, a_h, z_out, a_out = self._forward(X_train)</span><br><span class="line">            cost = self._compute_cost(y_enc=y_train_enc, output=a_out)</span><br><span class="line">            y_train_pred = self.predict(X_train)</span><br><span class="line">            y_valid_pred = self.predict(X_valid)</span><br><span class="line">            train_acc = ((np.sum(y_train ==y_train_pred)).astype(np.float) / X_train.shape[<span class="number">0</span>])</span><br><span class="line">            valid_acc = ((np.sum(y_valid == y_valid_pred)).astype(np.float) / X_valid.shape[<span class="number">0</span>])</span><br><span class="line">            sys.stderr.write(<span class="string">&#x27;\r%0*d/%d | Cost: %.2f &#x27;</span><span class="string">&#x27;| Train/Valid Acc.: %.2f%%/%.2f%% &#x27;</span> %</span><br><span class="line">                            (epoch_strlen, i+<span class="number">1</span>, self.epochs, cost, train_acc*<span class="number">100</span>, valid_acc*<span class="number">100</span>))</span><br><span class="line">            sys.stderr.flush()</span><br><span class="line">            self.eval_[<span class="string">&#x27;cost&#x27;</span>].append(cost)</span><br><span class="line">            self.eval_[<span class="string">&#x27;train_acc&#x27;</span>].append(train_acc)</span><br><span class="line">            self.eval_[<span class="string">&#x27;valid_acc&#x27;</span>].append(valid_acc)</span><br><span class="line">        <span class="keyword">return</span> self</span><br></pre></td></tr></table></figure><p>接下来我们初始化一下784-100-10的MLP：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nn = NeuralNetMLP(n_hidden=<span class="number">100</span>, l2=<span class="number">0.01</span>, epochs=<span class="number">200</span>, eta=<span class="number">0.0005</span>,</span><br><span class="line">                 minibatch_size=<span class="number">100</span>, shuffle=<span class="literal">True</span>, seed=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>首先看一下参数的含义：</p><ul><li>l2:：l2正则化系数$ \lambda $</li><li>epochs：遍历训练集的次数（遍历次数）</li><li>eta：学习速率$ \eta $</li><li>shuffle：每次迭代前打乱训练集的数据</li><li>seed：打乱数据和权重初始化的随机种子</li><li>minibatch_size：在每个小批次中训练样本的数目</li></ul><p>梯度每个批次分别计算，而不是在整个训练数据集上进行计算，这样做是为了加快学习的速率。</p><p>接下来进行训练：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">nn.fit(X_train=X_train[:<span class="number">55000</span>], y_train=y_train[:<span class="number">55000</span>],</span><br><span class="line">      X_valid=X_train[<span class="number">55000</span>:], y_valid=y_train[<span class="number">55000</span>:])</span><br><span class="line">&gt;&gt; <span class="number">200</span>/<span class="number">200</span> | Cost: <span class="number">15345.39</span> | Train/Valid Acc.: <span class="number">96.10</span>%/<span class="number">96.40</span>% </span><br></pre></td></tr></table></figure><p>我们在上述实现中，我们也定义了<code>eval_</code>用来保存每次迭代后的代价值，我们将其绘制出来：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.plot(range(nn.epochs), nn.eval_[<span class="string">&#x27;cost&#x27;</span>])</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Cost&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Epochs&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>得到的图像如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="Sun,%2009%20Feb%202020%20211630.png" class="lazyload" data-srcset="Sun,%2009%20Feb%202020%20211630.png" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><p>可以得到前100次cost的值下降得很快，之后随着迭代次数增加，cost值下降不明显。</p><p>接下来看一下训练和验证率得变化：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(range(nn.epochs), nn.eval_[<span class="string">&#x27;train_acc&#x27;</span>], label=<span class="string">&#x27;training&#x27;</span>)</span><br><span class="line">plt.plot(range(nn.epochs), nn.eval_[<span class="string">&#x27;valid_acc&#x27;</span>], label=<span class="string">&#x27;validation&#x27;</span>, linestyle=<span class="string">&#x27;--&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Accuracy&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Epochs&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>图像如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="Sun,%2009%20Feb%202020%20211951.png" class="lazyload" data-srcset="Sun,%2009%20Feb%202020%20211951.png" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><p>可以发现在迭代次数175之前，拟合模型有点欠拟合。最后我们看一下预测准确率：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">y_test_pred = nn.predict(X_test)</span><br><span class="line">acc = (np.sum(y_test == y_test_pred)).astype(np.float) / X_test.shape[<span class="number">0</span>]</span><br><span class="line">print(<span class="string">&#x27;Acc: %.3f&#x27;</span> % acc)</span><br><span class="line">&gt;&gt; Acc: <span class="number">0.959</span></span><br></pre></td></tr></table></figure><p>可以发现我们的模型在测试集上准确率差不多是96%，在数值上接近训练集中验证的准确率，表明模型拟合程度较好。</p><p>最后，看一下一些图片和我们MLP预测结果的示例图：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">miscl_img = X_test[y_test != y_test_pred][<span class="number">125</span>:<span class="number">150</span>]</span><br><span class="line">correct_lab = y_test[y_test != y_test_pred][<span class="number">125</span>:<span class="number">150</span>]</span><br><span class="line">miscl_lab = y_test_pred[y_test != y_test_pred][<span class="number">25</span>:<span class="number">50</span>]</span><br><span class="line">fig, ax = plt.subplots(nrows=<span class="number">5</span>, ncols=<span class="number">5</span>, sharex=<span class="literal">True</span>, sharey=<span class="literal">True</span>)</span><br><span class="line">ax = ax.flatten()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">25</span>):</span><br><span class="line">    img = miscl_img[i].reshape(<span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line">    ax[i].imshow(img, cmap=<span class="string">&#x27;Greys&#x27;</span>, interpolation=<span class="string">&#x27;nearest&#x27;</span>)</span><br><span class="line">    ax[i].set_title(<span class="string">&#x27;%d) t: %d p: %d&#x27;</span> % (i+<span class="number">1</span>, correct_lab[i], miscl_lab[i]))</span><br><span class="line">ax[<span class="number">0</span>].set_xticks([])</span><br><span class="line">ax[<span class="number">0</span>].set_yticks([])</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>得到的图像如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="Sun,%2009%20Feb%202020%20213712.png" class="lazyload" data-srcset="Sun,%2009%20Feb%202020%20213712.png" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><p>图片上的第二个数字表示的是正确的类标（true class），第三个数字表示的是预测的类标（predicted class）。可以发现，某些图像即便让人工分类也存在一定的困难度。</p><h2 id="训练人工神经网络"><a href="#训练人工神经网络" class="headerlink" title="训练人工神经网络"></a>训练人工神经网络</h2><p>接下来我们看一下人工神经网络的一些深层的概念，如用于权值更新过程中的<strong>逻辑斯蒂代价函数</strong>和<strong>反向传播算法</strong>。</p><h3 id="计算逻辑斯蒂代价函数"><a href="#计算逻辑斯蒂代价函数" class="headerlink" title="计算逻辑斯蒂代价函数"></a>计算逻辑斯蒂代价函数</h3><p>在<code>_compute_cost</code>方法中实现的逻辑斯蒂代价函数如下：<br>$$<br>J(w) = -\sum_{i=1}^{n}y^ilog(a^i)+(1-y^i)log(1-a^i)<br>$$<br>其中，$ a^i $是前向传播过程中，用来计算第i个单元的sigmoid激励函数：<br>$$<br>a^i = \phi(z^i)<br>$$<br>接下来，我们添加一个正则化项，它可以降低过拟合的程度，L2正则化定义如下：<br>$$<br>L2：=\lambda ||w||^2_2 = \lambda\sum_{j=1}^{m}w_j^2<br>$$<br>通过在逻辑斯蒂代价函数中加入L2正则化项，得到：<br>$$<br>J(w) = -\sum_{i=1}^{n}y^ilog(a^i)+(1-y^i)log(1-a^i) =\lambda ||w||^2_2<br>$$<br>我们已经实现了一个用于多分类的MLP，它返回一个包含t个元素的输出向量，我们需要将这个输出向量和使用独热编码表示的 $ t \times 1 $维目标向量进行比较。例如，对于一个样本，它在第三层的激励和目标类别（此处是2）可能如下：<br>$$<br>a^3 = \begin{bmatrix}<br>0.1 \<br>0.9 \<br>\vdots \<br>0.3<br>\end{bmatrix}<br>,<br>y = \begin{bmatrix}<br>0 \<br>1 \<br>\vdots \<br>0<br>\end{bmatrix}<br>$$<br>由此，我们需要逻辑斯蒂函数应用到网络中的所有激励单元j中。因此代价函数（未增加正则化项）：<br>$$<br>J(w) = -\sum_{i=1}^{n}\sum_{j=1}^{t}y^i_jlog(a^i_j)+(1-y^i_j)log(1-a^i_j)<br>$$<br>这里，上标i表示的是第在训练集中的第i个样本。加入正则化项的公式如下：<br>$$<br>J(w) = -\left[\sum_{i=1}^{n}\sum_{j=1}^{t}y^i_jlog(a^i_j)+(1-y^i_j)log(1-a^i_j)\right]</p><ul><li>\frac{\lambda}{2}\sum_{l=1}^{L-1}\sum_{i=1}^{u_l}\sum_{j=1}^{u_l+1}(w_{j,i}^l)^2<br>$$<br>在这里，$ u_l $表示第$ l $层的数目。我们的目标是最小化$ j(W) $代价函数，因此我们需要计算出网络中各层权重的偏导：<br>$$<br>\frac{\partial}{\partial{w_{j,i}^l}}J(W)<br>$$<br>注意$ W $包含多个矩阵，在一个仅仅包含一个隐层单元的MLP中，$ W^h $连接输入层和隐层，$ W^{out} $连接隐层和输出层。下图对$ W $进行可视化：</li></ul><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="1581315911089.png" class="lazyload" data-srcset="1581315911089.png" srcset="data:image/png;base64,666" alt="1581315911089"/></div><span class="image-caption">1581315911089</span></div><h3 id="通过反向传播来训练神经网络"><a href="#通过反向传播来训练神经网络" class="headerlink" title="通过反向传播来训练神经网络"></a>通过反向传播来训练神经网络</h3><p>回忆本章中介绍的内容，我们需要通过正向传播来获得输出层的激励：<br>$$<br>Z^h = A^{in}W^h (隐层的净输入)\<br>A^h = \phi(Z^h) (隐层的激励)\<br>Z^{out} = A^hW^{out} (输出层的净输出)\<br>A^{out} = \phi(Z^{out})(输出层的激励)<br>$$<br>简单说，我们按照下图处理输入：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="1581317066461.png" class="lazyload" data-srcset="1581317066461.png" srcset="data:image/png;base64,666" alt="1581317066461"/></div><span class="image-caption">1581317066461</span></div><p>后向传播中，我们将误差从右向左传递。首先计算输出层的误差向量：<br>$$<br>\delta^{out} = a^{out} - y<br>$$<br>其中，$ y $是真实类标的向量。接下来，我们计算隐层的误差项：<br>$$<br>\delta^{h} = \delta^{out}(W^{out})^T \odot \frac{\partial\phi(z^h)}{\partial z^h}<br>$$<br>这里，$ \frac{\partial\phi(z^h)}{\partial z^h} $计算公式如下：<br>$$<br>\frac{\partial\phi(z^h)}{\partial z^h} = \left(<br>a^h \odot (1-a^h)<br>\right)<br>$$<br>在这里，$ \odot $表示的是<strong>数组元素依次相乘</strong>符号。</p><p>相应的，$ \delta^h $计算公式如下：<br>$$<br>\delta^{h} = \delta^{out}(W^{out})^T \odot \left(<br>a^h \odot (1-a^h)<br>\right)<br>$$<br>在得到$ \delta $后，我们可以将代价函数的偏导记作：<br>$$<br>\frac{\partial}{\partial w_{i, j}^{out}}J(W) = a_j^h\delta_i^{out}\<br>\frac{\partial}{\partial w_{i, j}^h}J(W) = a_j^{in}\delta_i^h<br>$$<br>综上，我们通过下图进行反向传播总结：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="1581317962693.png" class="lazyload" data-srcset="1581317962693.png" srcset="data:image/png;base64,666" alt="1581317962693"/></div><span class="image-caption">1581317962693</span></div><h2 id="神经网络的收敛性"><a href="#神经网络的收敛性" class="headerlink" title="神经网络的收敛性"></a>神经网络的收敛性</h2><p>在前面实现的训练手写数字的神经网络过程中，没有使用传统的梯度下降，而是使用小批次样本学习来替代。随机梯度下降每次仅使用一个样本（k=1）更新权重来进行，虽然这是一种随机的方法，但相较于传统梯度下降，它通常嗯能得到精度极高的训练结果，并且收敛速度更快。子批次学习是随机梯度下降的一个特例：从包含n个样本的训练数据中随机抽取k个用于训练，其中1&lt;k&lt;n。</p><p>神经网络的输出函数的曲线并不平滑，而且容易陷入局部最优值，如下图：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="1581318745918.png" class="lazyload" data-srcset="1581318745918.png" srcset="data:image/png;base64,666" alt="1581318745918"/></div><span class="image-caption">1581318745918</span></div>]]></content>
      
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>聚类分析之处理无类标数据</title>
      <link href="2020/02/09/%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E4%B9%8B%E5%A4%84%E7%90%86%E6%97%A0%E7%B1%BB%E6%A0%87%E6%95%B0%E6%8D%AE/"/>
      <url>2020/02/09/%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E4%B9%8B%E5%A4%84%E7%90%86%E6%97%A0%E7%B1%BB%E6%A0%87%E6%95%B0%E6%8D%AE/</url>
      
        <content type="html"><![CDATA[<p>前面几章中，我们使用的数据都是事先已经直到预测结果的，即训练数据中已提供了数据的类标。在本章中，我们转而研究聚类分析，它是一种<strong>无监督学习</strong>技术，可以在事先不知道正确结果的情况下，发现数据本身所蕴含的结构等信息。</p><a id="more"></a><h2 id="使用k-means算法对相似对象进行分组"><a href="#使用k-means算法对相似对象进行分组" class="headerlink" title="使用k-means算法对相似对象进行分组"></a>使用k-means算法对相似对象进行分组</h2><p>本节讨论最流行的聚类算法：<strong>k-means算法</strong>，它在学术邻域及业界都得到了广泛应用。聚类是一种可以找到相似对象群组的技术，与组间对象相比，组内对象之间具有更高的相似度。</p><p>尽管k-means算法适用于高维数据，但出于可视化需要，我们使用一个二维数据集的例子演示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_blobs</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">X, y = make_blobs(n_samples=<span class="number">150</span>,</span><br><span class="line">                 n_features=<span class="number">2</span>,</span><br><span class="line">                 centers=<span class="number">3</span>,</span><br><span class="line">                 cluster_std=<span class="number">0.5</span>,</span><br><span class="line">                 shuffle=<span class="literal">True</span>,</span><br><span class="line">                 random_state=<span class="number">0</span>)</span><br><span class="line">plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=<span class="string">&#x27;blue&#x27;</span>, marker=<span class="string">&#x27;o&#x27;</span>, s=<span class="number">50</span>)</span><br><span class="line">plt.grid()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>图像如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="Sun,%2009%20Feb%202020%20115154.png" class="lazyload" data-srcset="Sun,%2009%20Feb%202020%20115154.png" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><p>k-means算法具体有四个步骤：</p><ol><li>从样本点随机选择k个点作为初始簇中心</li><li>将每个样本点划分到距离它最近的中心点$ \mu^j, j\in{1,\cdots ,k} $所代表的簇中</li><li>用各簇中所有样本的中心点替代原有的中心点</li><li>重复步骤2和3，直到中心点不变或者达到预定迭代次数时，算法终止</li></ol><p>度量对象之间的相似性可以用欧几里得距离的平方：<br>$$<br>d(x, y)^2 = \sum_{j=1}^{m}(x_j-y_j)^2=||x-y||^2_2<br>$$<br>基于欧几里得标准，我们可以将k-means算法描述为一个简单的优化问题，也就是使得<strong>簇内误差平方和（SSE）</strong>最小：<br>$$<br>SSE = \sum_{j=1}^n\sum_{j=1}^{k}w^{i,j}=||x^i-\mu^j||_2^2<br>$$<br>现在借助scikit-learn中的KMeans类将k-means算法应用于我们的示例数据集：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br><span class="line">km = KMeans(n_clusters=<span class="number">3</span>,</span><br><span class="line">           init=<span class="string">&#x27;random&#x27;</span>,</span><br><span class="line">           n_init=<span class="number">10</span>,</span><br><span class="line">           max_iter=<span class="number">300</span>,</span><br><span class="line">           tol=<span class="number">1e-04</span>,</span><br><span class="line">           random_state=<span class="number">0</span>)</span><br><span class="line">y_km = km.fit_predict(X)</span><br></pre></td></tr></table></figure><p>在k-means算法的某次迭代中，可能会发生无法收敛的问题，特别是我们设置了较大的max_iter。解决这个问题的方法是为tol参数设置一个较大的值，上述容忍度为1e-04。</p><h3 id="k-means"><a href="#k-means" class="headerlink" title="k-means++"></a>k-means++</h3><p>我们讨论了经典的k-means算法，它使用随机点作为初始中心点，但是初始中心点选择不当，就会导致收敛速度慢的问题。解决此问题的方法是在数据集上多次运行k-mean算法，并且根据SSE选择性能更好的模型。另外一种方案是使用k-means++算法让初始中心点彼此尽可能远离，相比传统的k-means算法，它能够产生更好的结果。k-means++算法的初始化过程如下：</p><ol><li>初始化一个空的集合M，用于存储选定的k个中心点</li><li>从输入样本中随机选定第一个中心点$ \mu^j $，并且将其加入到集合M中</li><li>对于集合M之外的任一样本点$ x^i $，通过计算找到与其平方距离最小的样本$ d(x^i, M)^2 $</li><li>使用加权概率分布$ \frac{d(\mu, M)^2}{\sum_id(x^i, M)^2} $来随机选择下一个中心点$ \mu^p $</li><li>重复步骤2，3，直到选定k个中心点</li><li>基于选定的中心点执行k-means算法</li></ol><p>现在对k-means算法的结果做可视化展示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">plt.scatter(X[y_km==<span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">           X[y_km==<span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">           s=<span class="number">50</span>,</span><br><span class="line">           c=<span class="string">&#x27;lightgreen&#x27;</span>,</span><br><span class="line">           marker=<span class="string">&#x27;s&#x27;</span>,</span><br><span class="line">           label=<span class="string">&#x27;cluster 1&#x27;</span>)</span><br><span class="line">plt.scatter(X[y_km==<span class="number">1</span>, <span class="number">0</span>],</span><br><span class="line">           X[y_km==<span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">           s=<span class="number">50</span>,</span><br><span class="line">           c=<span class="string">&#x27;orange&#x27;</span>,</span><br><span class="line">           marker=<span class="string">&#x27;o&#x27;</span>,</span><br><span class="line">           label=<span class="string">&#x27;cluster 2&#x27;</span>)</span><br><span class="line">plt.scatter(X[y_km==<span class="number">2</span>, <span class="number">0</span>],</span><br><span class="line">           X[y_km==<span class="number">2</span>, <span class="number">1</span>],</span><br><span class="line">           s=<span class="number">50</span>,</span><br><span class="line">           c=<span class="string">&#x27;lightblue&#x27;</span>,</span><br><span class="line">           marker=<span class="string">&#x27;v&#x27;</span>,</span><br><span class="line">           label=<span class="string">&#x27;cluster 3&#x27;</span>)</span><br><span class="line">plt.scatter(km.cluster_centers_[:, <span class="number">0</span>],</span><br><span class="line">           km.cluster_centers_[:, <span class="number">1</span>],</span><br><span class="line">           s=<span class="number">250</span>,</span><br><span class="line">           marker=<span class="string">&#x27;*&#x27;</span>,</span><br><span class="line">           c=<span class="string">&#x27;red&#x27;</span>,</span><br><span class="line">           label=<span class="string">&#x27;centroids&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.grid()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>图像如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="Sun,%2009%20Feb%202020%20122642.png" class="lazyload" data-srcset="Sun,%2009%20Feb%202020%20122642.png" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><p>散点图显示的结果中3个中心点位于各个簇的中心，分组结果看起来是合理的。</p><p>k-means算法的一个缺点是我们必须先指定一个簇数量k，但是在实际应用中，簇数量并不总是显而易见的。</p><h3 id="硬聚类与软聚类"><a href="#硬聚类与软聚类" class="headerlink" title="硬聚类与软聚类"></a>硬聚类与软聚类</h3><p><strong>硬聚类</strong>指每个样本只能划至一个簇的算法，如k-means算法；<strong>软聚类</strong>算法可以将样本划分到一个或多个簇，如FCM算法。</p><p>FCM算法和k-means算法十分相似，k-means算法某个样本预测结果是$ [0,1,0] $，表明该样本属于簇2。FCM中可以允许预测的结果中含有分数，如$ [0.7, 0.2, 0.1] $表明该样本属于簇1的概率是0.7，簇2的概率是0.2。FCM的步骤如下：</p><ol><li>指定k个中心点，并随机将样本点划分至某个簇</li><li>计算各个簇的中心$ \mu^j ,j\in{1, \cdots,k}$</li><li>更新各样本点所属簇的成员隶属度</li><li>重复步骤2，3，直到各个样本点所属簇成员隶属度不变或者是达到最大的迭代次数</li></ol><p>FCM的目标函数如下：<br>$$<br>J_m = \sum_{i=1}^{n}\sum_{j=1}^{m}w^m(i,j)||x^i-\mu^j||^2_2<br>$$</p><h3 id="使用肘方法确定簇的最佳数量"><a href="#使用肘方法确定簇的最佳数量" class="headerlink" title="使用肘方法确定簇的最佳数量"></a>使用肘方法确定簇的最佳数量</h3><p>簇内误差平方和可以通过<code>inertia</code>访问，基于簇内误差平方和，我们可以使用图形工具，即所谓的肘方法，针对特定任务估计出最优的簇数量k。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">distortions = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">11</span>):</span><br><span class="line">    km = KMeans(n_clusters=i,</span><br><span class="line">               init=<span class="string">&#x27;k-means++&#x27;</span>,</span><br><span class="line">               n_init=<span class="number">10</span>,</span><br><span class="line">               max_iter=<span class="number">300</span>,</span><br><span class="line">               random_state=<span class="number">0</span>)</span><br><span class="line">    km.fit(X)</span><br><span class="line">    distortions.append(km.inertia_)</span><br><span class="line">plt.plot(range(<span class="number">1</span>, <span class="number">11</span>), distortions, marker=<span class="string">&#x27;o&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Number of clusters&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Distortion&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>图像如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="Sun,%2009%20Feb%202020%20125357.png" class="lazyload" data-srcset="Sun,%2009%20Feb%202020%20125357.png" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><p>如图，当k=3时团呈现肘形，这表明对于此数据来说，k=3是一个好的选择。</p><h3 id="通过轮廓图定量分析聚类质量"><a href="#通过轮廓图定量分析聚类质量" class="headerlink" title="通过轮廓图定量分析聚类质量"></a>通过轮廓图定量分析聚类质量</h3><p>另外一种聚类质量的评估方法时<strong>轮廓分析</strong>，此方法用于k-means算法之外的其他聚类方法。我们通过以下步骤计算<strong>轮廓系数</strong>：</p><ol><li><p>将某样本$ x^i $与簇内其他点之间的平均距离看作是簇的内聚度$ a^i $</p></li><li><p>将样本$ x^i $与其最近簇中所有点之间的平均距离看作是与下一最近簇的分离度$ b^i $</p></li><li><p>轮廓系数如下：<br>$$<br>s^i = \frac{b^i - a^i}{max{b^i, a^i}}<br>$$</p></li></ol><p>可以发现，理想的轮廓系数时1，轮廓系数代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">km = KMeans(n_clusters=<span class="number">3</span>,</span><br><span class="line">           init=<span class="string">&#x27;k-means++&#x27;</span>,</span><br><span class="line">           n_init=<span class="number">10</span>,</span><br><span class="line">           max_iter=<span class="number">300</span>,</span><br><span class="line">           tol=<span class="number">1e-04</span>, </span><br><span class="line">           random_state=<span class="number">0</span>)</span><br><span class="line">y_km = km.fit_predict(X)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> cm</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> silhouette_samples</span><br><span class="line">cluster_labels = np.unique(y_km)</span><br><span class="line">n_clusters = cluster_labels.shape[<span class="number">0</span>]</span><br><span class="line">silhouette_vals = silhouette_samples(X,</span><br><span class="line">                                    y_km,</span><br><span class="line">                                    metric=<span class="string">&#x27;euclidean&#x27;</span>)</span><br><span class="line">y_ax_lower, y_ax_upper = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">yticks = []</span><br><span class="line"><span class="keyword">for</span> i, c <span class="keyword">in</span> enumerate(cluster_labels):</span><br><span class="line">    c_silhouette_vals = silhouette_vals[y_km == c]</span><br><span class="line">    c_silhouette_vals.sort()</span><br><span class="line">    y_ax_upper += len(c_silhouette_vals)</span><br><span class="line">    color = cm.jet(float(i) / n_clusters)</span><br><span class="line">    plt.barh(range(y_ax_lower, y_ax_upper),</span><br><span class="line">                    c_silhouette_vals,</span><br><span class="line">                    height=<span class="number">1.0</span>,</span><br><span class="line">                    edgecolor=<span class="string">&#x27;none&#x27;</span>,</span><br><span class="line">                    color=color)</span><br><span class="line">    yticks.append((y_ax_lower + y_ax_upper) / <span class="number">2.</span>)</span><br><span class="line">    y_ax_lower += len(c_silhouette_vals)</span><br><span class="line">silhouette_avg = np.mean(silhouette_vals)</span><br><span class="line">plt.axvline(silhouette_avg,</span><br><span class="line">            color=<span class="string">&quot;red&quot;</span>,</span><br><span class="line">            linestyle=<span class="string">&quot;--&quot;</span>)</span><br><span class="line">plt.yticks(yticks, cluster_labels + <span class="number">1</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Cluster&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Silhouette coefficient&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>图像如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="Sun,%2009%20Feb%202020%20140933.png" class="lazyload" data-srcset="Sun,%2009%20Feb%202020%20140933.png" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><p>从上图可见，轮廓系数未接近0点，此指标显示聚类效果不错。为了解聚类效果不佳的轮廓图的形状，我们使用两个中心点来初始化k-means算法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">km = KMeans(n_clusters=<span class="number">2</span>,</span><br><span class="line">           init=<span class="string">&#x27;k-means++&#x27;</span>,</span><br><span class="line">           n_init=<span class="number">10</span>,</span><br><span class="line">           max_iter=<span class="number">300</span>,</span><br><span class="line">           tol=<span class="number">1e-04</span>,</span><br><span class="line">           random_state=<span class="number">0</span>)</span><br><span class="line">y_km = km.fit_predict(X)</span><br><span class="line"></span><br><span class="line">plt.scatter(X[y_km==<span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">           X[y_km==<span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">           s=<span class="number">50</span>,</span><br><span class="line">           c=<span class="string">&#x27;lightgreen&#x27;</span>,</span><br><span class="line">           marker=<span class="string">&#x27;s&#x27;</span>,</span><br><span class="line">           label=<span class="string">&#x27;cluster 1&#x27;</span>)</span><br><span class="line">plt.scatter(X[y_km==<span class="number">1</span>, <span class="number">0</span>],</span><br><span class="line">           X[y_km==<span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">           s=<span class="number">50</span>,</span><br><span class="line">           c=<span class="string">&#x27;orange&#x27;</span>,</span><br><span class="line">           marker=<span class="string">&#x27;o&#x27;</span>,</span><br><span class="line">           label=<span class="string">&#x27;cluster 2&#x27;</span>)</span><br><span class="line">plt.scatter(km.cluster_centers_[:, <span class="number">0</span>],</span><br><span class="line">           km.cluster_centers_[:, <span class="number">1</span>],</span><br><span class="line">           s=<span class="number">250</span>,</span><br><span class="line">           marker=<span class="string">&#x27;*&#x27;</span>,</span><br><span class="line">           c=<span class="string">&#x27;red&#x27;</span>,</span><br><span class="line">           label=<span class="string">&#x27;centroids&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.grid()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>图像如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="Sun,%2009%20Feb%202020%20141417.png" class="lazyload" data-srcset="Sun,%2009%20Feb%202020%20141417.png" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><p>接下来，我们绘制轮廓图来对聚类结果进行评估：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">cluster_labels = np.unique(y_km)</span><br><span class="line">n_clusters = cluster_labels.shape[<span class="number">0</span>]</span><br><span class="line">silhouette_vals = silhouette_samples(X,</span><br><span class="line">                                    y_km,</span><br><span class="line">                                    metric=<span class="string">&#x27;euclidean&#x27;</span>)</span><br><span class="line">y_ax_lower, y_ax_upper = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">yticks = []</span><br><span class="line"><span class="keyword">for</span> i, c <span class="keyword">in</span> enumerate(cluster_labels):</span><br><span class="line">    c_silhouette_vals = silhouette_vals[y_km == c]</span><br><span class="line">    c_silhouette_vals.sort()</span><br><span class="line">    y_ax_upper += len(c_silhouette_vals)</span><br><span class="line">    color = cm.jet(float(i) / n_clusters)</span><br><span class="line">    plt.barh(range(y_ax_lower, y_ax_upper),</span><br><span class="line">                    c_silhouette_vals,</span><br><span class="line">                    height=<span class="number">1.0</span>,</span><br><span class="line">                    edgecolor=<span class="string">&#x27;none&#x27;</span>,</span><br><span class="line">                    color=color)</span><br><span class="line">    yticks.append((y_ax_lower + y_ax_upper) / <span class="number">2.</span>)</span><br><span class="line">    y_ax_lower += len(c_silhouette_vals)</span><br><span class="line">silhouette_avg = np.mean(silhouette_vals)</span><br><span class="line">plt.axvline(silhouette_avg,</span><br><span class="line">            color=<span class="string">&quot;red&quot;</span>,</span><br><span class="line">            linestyle=<span class="string">&quot;--&quot;</span>)</span><br><span class="line">plt.yticks(yticks, cluster_labels + <span class="number">1</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Cluster&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Silhouette coefficient&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>由结果可见，轮廓图由明显不同的长度和宽度，这说明该聚类并非最优结果：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="Sun,%2009%20Feb%202020%20141646.png" class="lazyload" data-srcset="Sun,%2009%20Feb%202020%20141646.png" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><h2 id="层次聚类"><a href="#层次聚类" class="headerlink" title="层次聚类"></a>层次聚类</h2><p>本节中，我们将学习另外一种基于原型的聚类：<strong>层次聚类</strong>。层次聚类算法的优势在于：他能够使我们绘制出树状图，这有助于我们使用有意义的分类解释聚类结果。层次聚类的另外一个优势在于我们无需指定簇数量。</p><p>层次聚类有两种主要方法：<strong>凝聚</strong>层次聚类和<strong>分裂</strong>层次聚类。在凝聚层次聚类中，判定簇间距离的两个标准方法分别是<strong>单连接</strong>和<strong>全连接</strong>。单连接方法计算每一对簇中最相似两个样本的距离，并且合并距离最近的两个样本所属簇。与之相反，全连接方法是通过比较找到分布于两个簇中最不相似的样本（距离最远的样本），进而完成簇的合并。</p><p>本节中，我们主要关注基于全连接方法的凝聚层次聚类，迭代过程如下：</p><ol><li>计算得到所有样本间的距离矩阵</li><li>将每个数据点看作是一个单独的簇</li><li>基于最不相似（距离最远）样本的距离，合并两个最接近的簇</li><li>更新相似矩阵</li><li>重复步骤2到4，直到所有样本都合并到一个簇为止</li></ol><p>计算距离矩阵的方式如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">np.random.seed(<span class="number">123</span>)</span><br><span class="line">variables = [<span class="string">&#x27;X&#x27;</span>, <span class="string">&#x27;Y&#x27;</span>, <span class="string">&#x27;Z&#x27;</span>]</span><br><span class="line">labels = [<span class="string">&#x27;ID_0&#x27;</span>, <span class="string">&#x27;ID_1&#x27;</span>, <span class="string">&#x27;ID_2&#x27;</span>, <span class="string">&#x27;ID_3&#x27;</span>, <span class="string">&#x27;ID_4&#x27;</span>]</span><br><span class="line">X = np.random.random_sample([<span class="number">5</span>, <span class="number">3</span>])*<span class="number">10</span></span><br><span class="line">df = pd.DataFrame(X, columns=variables, index=labels)</span><br><span class="line">df</span><br></pre></td></tr></table></figure><p>得到的数据如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="1581229979827.png" class="lazyload" data-srcset="1581229979827.png" srcset="data:image/png;base64,666" alt="1581229979827"/></div><span class="image-caption">1581229979827</span></div><h3 id="基于距离矩阵进行层次聚类"><a href="#基于距离矩阵进行层次聚类" class="headerlink" title="基于距离矩阵进行层次聚类"></a>基于距离矩阵进行层次聚类</h3><p>我们基于SciPy来计算距离矩阵：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">from scipy.spatial.distance import pdist, squareform</span><br><span class="line">row_dist &#x3D; pd.DataFrame(squareform(pdist(df, metric&#x3D;&#39;euclidean&#39;)), columns&#x3D;labels, index&#x3D;labels)</span><br><span class="line">row_dist</span><br></pre></td></tr></table></figure><p>得到的数据如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="1581230299131.png" class="lazyload" data-srcset="1581230299131.png" srcset="data:image/png;base64,666" alt="1581230299131"/></div><span class="image-caption">1581230299131</span></div><p>接下来我们使用linkage函数，此函数以全连接作为距离判定标准：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.cluster.hierarchy <span class="keyword">import</span> linkage</span><br><span class="line">row_clusters = linkage(df.values, method=<span class="string">&#x27;complete&#x27;</span>, metric=<span class="string">&#x27;euclidean&#x27;</span>)</span><br><span class="line">pd.DataFrame(row_clusters, columns=[<span class="string">&#x27;row label 1&#x27;</span>, <span class="string">&#x27;row label 2&#x27;</span>, <span class="string">&#x27;distance&#x27;</span>, <span class="string">&#x27;no. of items&#x27;</span>], </span><br><span class="line">            index=[<span class="string">&#x27;cluster %d&#x27;</span> % (i+<span class="number">1</span>) <span class="keyword">for</span> i <span class="keyword">in</span> range(row_clusters.shape[<span class="number">0</span>])])</span><br></pre></td></tr></table></figure><p>得到的数据如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="1581230747985.png" class="lazyload" data-srcset="1581230747985.png" srcset="data:image/png;base64,666" alt="1581230747985"/></div><span class="image-caption">1581230747985</span></div><p>接下来采用树状图的形式对聚类结果进行可视化展示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.cluster.hierarchy <span class="keyword">import</span> dendrogram</span><br><span class="line">row_dendr = dendrogram(row_clusters, labels=labels)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Euclidean distance&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>得到的图像如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="Sun,%2009%20Feb%202020%20144813.png" class="lazyload" data-srcset="Sun,%2009%20Feb%202020%20144813.png" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><p>此树状图采用了凝聚层次聚类合并生成不同簇的过程，从图中可见，首先ID_0和ID_4合并，解下来是ID_1和ID_2合并。</p><h3 id="树状图与热度图的关联"><a href="#树状图与热度图的关联" class="headerlink" title="树状图与热度图的关联"></a>树状图与热度图的关联</h3><p>实际应用中，层次聚类的树状图与热度图结合使用，本节中我们讨论如何将树状图附加到热度图上：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">fig = plt.figure(figsize=(<span class="number">8</span>, <span class="number">8</span>))</span><br><span class="line">axd = fig.add_axes([<span class="number">0.09</span>, <span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.6</span>])</span><br><span class="line">row_dendr = dendrogram(row_clusters, orientation=<span class="string">&#x27;left&#x27;</span>)</span><br><span class="line">df_rowclust = df.ix[row_dendr[<span class="string">&#x27;leaves&#x27;</span>][::<span class="number">-1</span>]]</span><br><span class="line">axm = fig.add_axes([<span class="number">0.23</span>, <span class="number">0.1</span>, <span class="number">0.6</span>, <span class="number">0.6</span>])</span><br><span class="line">cax = axm.matshow(df_rowclust, interpolation=<span class="string">&#x27;nearest&#x27;</span>, cmap=<span class="string">&#x27;hot_r&#x27;</span>)</span><br><span class="line">axd.set_xticks([])</span><br><span class="line">axd.set_yticks([])</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> axd.spines.values():</span><br><span class="line">    i.set_visible(<span class="literal">False</span>)</span><br><span class="line">fig.colorbar(cax)</span><br><span class="line">axm.set_xticklabels([<span class="string">&#x27;&#x27;</span>] + list(df_rowclust.columns))</span><br><span class="line">axm.set_yticklabels([<span class="string">&#x27;&#x27;</span>] + list(df_rowclust.index))</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>得到图像可得：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="Sun,%2009%20Feb%202020%20145923.png" class="lazyload" data-srcset="Sun,%2009%20Feb%202020%20145923.png" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><h3 id="通过scikit-learn进行凝聚聚类"><a href="#通过scikit-learn进行凝聚聚类" class="headerlink" title="通过scikit-learn进行凝聚聚类"></a>通过scikit-learn进行凝聚聚类</h3><p>本节使用scikit-learn进行基于凝聚的层次聚类：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> AgglomerativeClustering</span><br><span class="line">ac = AgglomerativeClustering(n_clusters=<span class="number">2</span>, affinity=<span class="string">&#x27;euclidean&#x27;</span>, linkage=<span class="string">&#x27;complete&#x27;</span>)</span><br><span class="line">labels = ac.fit_predict(X)</span><br><span class="line">print(<span class="string">&#x27;Cluster labels: %s&#x27;</span> % labels)</span><br><span class="line">&gt;&gt; Cluster labels: [<span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span>]</span><br></pre></td></tr></table></figure><p>通过对簇类标的预测结果进行分析，我们可以看出第一第四第五样本被划分至第一个簇，第二第三样本被划分到第二个簇。</p><h2 id="使用DBSCAN划分高密度区域"><a href="#使用DBSCAN划分高密度区域" class="headerlink" title="使用DBSCAN划分高密度区域"></a>使用DBSCAN划分高密度区域</h2><p>接下来我们介绍另外一种聚类方法：<strong>基于密度空间的聚类算法</strong>。在DBSCAN中，基于一下标准，每个样本都被赋予了一个特殊的标签：</p><ul><li>如果一个点周边的指定半径$ \epsilon $内，其他样本点的数量不小于指定数量（MinPts），则此样本点称为核心点（core point）</li><li>在指定半径$ \epsilon $内，如果一个点的邻居数量小于MinPts时，但是却包含一个核心点，则此点称为边界点（border point）</li><li>除了核心点和边界点外的其他样本点称为噪声点（noise point）</li></ul><p>完成对核心点，边界点和噪声点的标记后，DBSCAN算法可以总结为两个简单的步骤：</p><ol><li>基于每个核心点或者一组相连的核心点形成一个单独的簇</li><li>将每个边界点划分到对应核心点所在的簇中</li></ol><p>为了给出一个更能说明问题的例子，我们创建一个半月形的数据集，以及k-means聚类，层次聚类和DBSCAN聚类进行比较，首先得到半月形数据集：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_moons</span><br><span class="line">X, y = make_moons(n_samples=<span class="number">200</span>, noise=<span class="number">0.05</span>, random_state=<span class="number">0</span>)</span><br><span class="line">plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>得到的图像如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="Sun,%2009%20Feb%202020%20152126.png" class="lazyload" data-srcset="Sun,%2009%20Feb%202020%20152126.png" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><p>下面首先使用前面讨论过的k-means算法和基于全连接的层次聚类算法，算法如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">f, (ax1, ax2) = plt.subplots(<span class="number">1</span>, <span class="number">2</span>, figsize=(<span class="number">8</span>, <span class="number">3</span>))</span><br><span class="line">km = KMeans(n_clusters=<span class="number">2</span>, random_state=<span class="number">0</span>)</span><br><span class="line">y_km = km.fit_predict(X)</span><br><span class="line">ax1.scatter(X[y_km==<span class="number">0</span>,<span class="number">0</span>], X[y_km==<span class="number">0</span>,<span class="number">1</span>],</span><br><span class="line">            c=<span class="string">&#x27;lightblue&#x27;</span>,</span><br><span class="line">            edgecolor=<span class="string">&#x27;black&#x27;</span>,</span><br><span class="line">            marker=<span class="string">&#x27;o&#x27;</span>,</span><br><span class="line">            s=<span class="number">40</span>,</span><br><span class="line">            label=<span class="string">&#x27;cluster 1&#x27;</span>)</span><br><span class="line">ax1.scatter(X[y_km==<span class="number">1</span>,<span class="number">0</span>],</span><br><span class="line">            X[y_km==<span class="number">1</span>,<span class="number">1</span>],</span><br><span class="line">            c=<span class="string">&#x27;red&#x27;</span>,</span><br><span class="line">            edgecolor=<span class="string">&#x27;black&#x27;</span>,</span><br><span class="line">            marker=<span class="string">&#x27;s&#x27;</span>,</span><br><span class="line">            s=<span class="number">40</span>,</span><br><span class="line">            label=<span class="string">&#x27;cluster 2&#x27;</span>)</span><br><span class="line">ax1.set_title(<span class="string">&#x27;K-means clustering&#x27;</span>)</span><br><span class="line">ac = AgglomerativeClustering(n_clusters=<span class="number">2</span>,</span><br><span class="line">                            affinity=<span class="string">&#x27;euclidean&#x27;</span>,</span><br><span class="line">                            linkage=<span class="string">&#x27;complete&#x27;</span>)</span><br><span class="line">y_ac = ac.fit_predict(X)</span><br><span class="line">ax2.scatter(X[y_ac==<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">            X[y_ac==<span class="number">0</span>,<span class="number">1</span>],</span><br><span class="line">            c=<span class="string">&#x27;lightblue&#x27;</span>,</span><br><span class="line">            edgecolor=<span class="string">&#x27;black&#x27;</span>,</span><br><span class="line">            marker=<span class="string">&#x27;o&#x27;</span>,</span><br><span class="line">            s=<span class="number">40</span>,</span><br><span class="line">            label=<span class="string">&#x27;cluster 1&#x27;</span>)</span><br><span class="line">ax2.scatter(X[y_ac==<span class="number">1</span>,<span class="number">0</span>],</span><br><span class="line">            X[y_ac==<span class="number">1</span>,<span class="number">1</span>],</span><br><span class="line">            c=<span class="string">&#x27;red&#x27;</span>,</span><br><span class="line">            edgecolor=<span class="string">&#x27;black&#x27;</span>,</span><br><span class="line">            marker=<span class="string">&#x27;s&#x27;</span>,</span><br><span class="line">            s=<span class="number">40</span>,</span><br><span class="line">            label=<span class="string">&#x27;cluster 2&#x27;</span>)</span><br><span class="line">ax2.set_title(<span class="string">&#x27;Agglomerative clustering&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>得到的图像如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="Sun,%2009%20Feb%202020%20152445.png" class="lazyload" data-srcset="Sun,%2009%20Feb%202020%20152445.png" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><p>可以发现，上述两个算法无法有效分开两个数组。最后我们试一下DBSCAN算法在此数据集上的效果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> DBSCAN</span><br><span class="line">db = DBSCAN(eps=<span class="number">0.2</span>,</span><br><span class="line">            min_samples=<span class="number">5</span>,</span><br><span class="line">            metric=<span class="string">&#x27;euclidean&#x27;</span>)</span><br><span class="line">y_db = db.fit_predict(X)</span><br><span class="line">plt.scatter(X[y_db==<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">            X[y_db==<span class="number">0</span>,<span class="number">1</span>],</span><br><span class="line">            c=<span class="string">&#x27;lightblue&#x27;</span>,</span><br><span class="line">            edgecolor=<span class="string">&#x27;black&#x27;</span>,</span><br><span class="line">            marker=<span class="string">&#x27;o&#x27;</span>,</span><br><span class="line">            s=<span class="number">40</span>,</span><br><span class="line">            label=<span class="string">&#x27;cluster 1&#x27;</span>)</span><br><span class="line">plt.scatter(X[y_db==<span class="number">1</span>,<span class="number">0</span>],</span><br><span class="line">            X[y_db==<span class="number">1</span>,<span class="number">1</span>],</span><br><span class="line">            c=<span class="string">&#x27;red&#x27;</span>,</span><br><span class="line">            edgecolor=<span class="string">&#x27;black&#x27;</span>,</span><br><span class="line">            marker=<span class="string">&#x27;s&#x27;</span>,</span><br><span class="line">            s=<span class="number">40</span>,</span><br><span class="line">            label=<span class="string">&#x27;cluster 2&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>得到的图像如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="Sun,%2009%20Feb%202020%20152755.png" class="lazyload" data-srcset="Sun,%2009%20Feb%202020%20152755.png" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><p>可以发现，DBSCAN算法可以成功地对半月形数据进行划分，这也是DBSCAN算法的优势。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>使用回归分析预测连续型目标变量</title>
      <link href="2020/02/08/%E4%BD%BF%E7%94%A8%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90%E9%A2%84%E6%B5%8B%E8%BF%9E%E7%BB%AD%E5%9E%8B%E7%9B%AE%E6%A0%87%E5%8F%98%E9%87%8F/"/>
      <url>2020/02/08/%E4%BD%BF%E7%94%A8%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90%E9%A2%84%E6%B5%8B%E8%BF%9E%E7%BB%AD%E5%9E%8B%E7%9B%AE%E6%A0%87%E5%8F%98%E9%87%8F/</url>
      
        <content type="html"><![CDATA[<p>本章将会介绍监督学习的另外一个分支，<strong>回归分析</strong>（regression analysis）。回归模型可以用于连续型目标变量的预测分析，这使得它在探寻变量间关系，评估趋势，做出预测等领域极具吸引力。具体的例子如预测公司在未来几个月的销售情况等。</p><a id="more"></a><h2 id="简单线性回归模型初探"><a href="#简单线性回归模型初探" class="headerlink" title="简单线性回归模型初探"></a>简单线性回归模型初探</h2><p>简单（单变量）线性回归的目标是：通过模型来描述某一特征（解释变量x）与输出变量（目标变量y）之间的关系。当只有一个解释变量时，线性模型函数定义如下：<br>$$<br>y = w_0 + w_1x<br>$$<br>其中，$ w_0 $为函数在y轴上的截距，$ w_1 $为解释变量的系数。</p><p>基于前面定义的线性方程，线性回归可以看作是求解样本点的最佳拟合直线，如下图：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="1581137289049.png" class="lazyload" data-srcset="1581137289049.png" srcset="data:image/png;base64,666" alt="1581137289049"/></div><span class="image-caption">1581137289049</span></div><p>这条最佳拟合线称作是<strong>回归线</strong>，回归线和样本点之间的垂直连线就是偏移或<strong>残差</strong>。</p><p>多元线性回归函数定义如下：<br>$$<br>y = w_0x_0+w_1x_1+\cdots+w_mx_m<br>$$<br>其中，$ w_0 $时$ x_0 =1 $时在y轴上的截距。</p><h2 id="波士顿房屋数据集"><a href="#波士顿房屋数据集" class="headerlink" title="波士顿房屋数据集"></a>波士顿房屋数据集</h2><p>在本章的后续内容中，我们将会使用房屋价格（MEDV）作为目标变量，使用其他13个变量中的一个或多个值作为解释变量对其进行预测：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.read_csv(<span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data&#x27;</span>, header=<span class="literal">None</span>, sep=<span class="string">&#x27;\s+&#x27;</span>)</span><br><span class="line">df.columns = [<span class="string">&#x27;CRIM&#x27;</span>, <span class="string">&#x27;ZN&#x27;</span>, <span class="string">&#x27;INDUS&#x27;</span>, <span class="string">&#x27;CHAS&#x27;</span>, <span class="string">&#x27;NOX&#x27;</span>, <span class="string">&#x27;RM&#x27;</span>, <span class="string">&#x27;AGE&#x27;</span>, </span><br><span class="line">              <span class="string">&#x27;DIS&#x27;</span>, <span class="string">&#x27;RAD&#x27;</span>, <span class="string">&#x27;TAX&#x27;</span>, <span class="string">&#x27;PTRATIO&#x27;</span>, <span class="string">&#x27;B&#x27;</span>, <span class="string">&#x27;LSTAT&#x27;</span>, <span class="string">&#x27;MEDV&#x27;</span>]</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure><p> 输出如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="1581140075569.png" class="lazyload" data-srcset="1581140075569.png" srcset="data:image/png;base64,666" alt="1581140075569"/></div><span class="image-caption">1581140075569</span></div><p>搜索性数据分析（EDA）是机器学习模型训练前的一个重要步骤。首先，借助散点图矩阵，我们可以以可视化的方法汇总显示各不同特征两两之间的关系：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line">sns.set(style=<span class="string">&#x27;whitegrid&#x27;</span>, context=<span class="string">&#x27;notebook&#x27;</span>)</span><br><span class="line">cols = [<span class="string">&#x27;LSTAT&#x27;</span>, <span class="string">&#x27;INDUS&#x27;</span>, <span class="string">&#x27;NOX&#x27;</span>, <span class="string">&#x27;RM&#x27;</span>, <span class="string">&#x27;MEDV&#x27;</span>]</span><br><span class="line">sns.pairplot(df[cols], size=<span class="number">2.5</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>得到的图像如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="fig.png" class="lazyload" data-srcset="fig.png" srcset="data:image/png;base64,666" alt="fig"/></div><span class="image-caption">fig</span></div><p>通过此散点图矩阵，我们可以快速了解数据是如何分布的，以及其中是否包含异常值。从右下角子图可以发现：MEDV看似呈正态分布，但是包含几个异常值。</p><p>为了量化特征之间的关系，我们创建一个相关系数矩阵。相关系数矩阵是一个包含<strong>皮尔逊积矩相关系数</strong>，它是用来衡量两两特征间的线性依赖关系。计算公式如下：<br>$$<br>r = \frac{\sum_{i=1}^{n}[(x^i - \mu_x)(y^i-\mu_y)]}{\sqrt{\sum_{i=1}^n(x^i-\mu_x)^2}\sqrt{\sum_{i=1}^n(y^i-\mu_y)^2}}=<br>\frac{\sigma_{xy}}{\sigma_x\sigma_y}<br>$$<br>其中，$ \mu $为样本特征的均值，$ \sigma_{xy} $为相应的协方差，$ \sigma_x,\sigma_y $分别为两个特征的标准差。</p><p>通过以下代码，我们计算前5个特征间的相关系数矩阵：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">cm = np.corrcoef(df[cols].values.T)</span><br><span class="line"><span class="comment"># sns.set(font_scale=1.5)</span></span><br><span class="line">hm = sns.heatmap(cm, </span><br><span class="line">                cbar=<span class="literal">True</span>,</span><br><span class="line">                annot=<span class="literal">True</span>,</span><br><span class="line">                square=<span class="literal">True</span>,</span><br><span class="line">                fmt=<span class="string">&#x27;.2f&#x27;</span>,</span><br><span class="line">                annot_kws=&#123;<span class="string">&#x27;size&#x27;</span>: <span class="number">15</span>&#125;,</span><br><span class="line">                yticklabels=cols,</span><br><span class="line">                xticklabels=cols)</span><br><span class="line">hm.set_ylim([<span class="number">5</span>, <span class="number">0</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>得到的图像如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="Sat,%2008%20Feb%202020%20141210.png" class="lazyload" data-srcset="Sat,%2008%20Feb%202020%20141210.png" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><p>为了拟合线性回归模型，我们主要关注那些跟目标变量MEDV高度相关的特征。观察前面的相关系数矩阵，可以发现MEDV与变量LSTAT的相关性最大（-0.74）。另一方面，RM和MEDV间的相关性也较高（0.70）。</p><h2 id="基于最小二乘法构建线性回归模型"><a href="#基于最小二乘法构建线性回归模型" class="headerlink" title="基于最小二乘法构建线性回归模型"></a>基于最小二乘法构建线性回归模型</h2><p>接下来我们需要对最优拟合做出判断，在此使用<strong>最小二乘法</strong>（Ordinary Least Square，OLS）估计回归曲线的参数，使得回归曲线到样本点垂直距离的平方和最小。</p><h3 id="通过梯度下降计算回归参数"><a href="#通过梯度下降计算回归参数" class="headerlink" title="通过梯度下降计算回归参数"></a>通过梯度下降计算回归参数</h3><p>在第二章中介绍的Adaline中使用了一个线性激励函数，同时定义了一个激励函数，可以通过梯度下降（GD），随机梯度下降（SGD）等优化算法使得代价函数最小，从而得到相应的权重。Adaline中的代价函数就是误差平方和（SSE），他等同于我们定义的OLS代价函数：<br>$$<br>J(w) = \frac{1}{2}\sum_{i=1}^n(y^i - \hat{y^i})^2<br>$$<br>本质上，OLS线性回归可以理解为无单位阶跃函数的Adaline，这样我们的得到的是连续型的输出值，而不是-1或者1的类标。接下来可以看一下线性回归梯度下降代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LinearRegressionGD</span>(<span class="params">object</span>):</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, eta=<span class="number">0.001</span>, n_iter=<span class="number">20</span></span>):</span></span><br><span class="line">        self.eta = eta</span><br><span class="line">        self.n_iter = n_iter</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, X, y</span>):</span></span><br><span class="line">        self.w_  = np.zeros(<span class="number">1</span> + X.shape[<span class="number">1</span>])</span><br><span class="line">        self.cost_ = []</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(self.n_iter):</span><br><span class="line">            output = self.net_input(X)</span><br><span class="line">            errors = (y - output)</span><br><span class="line">            self.w_[<span class="number">1</span>:] += self.eta * X.T.dot(errors)</span><br><span class="line">            self.w_[<span class="number">0</span>] +=self.eta * errors.sum()</span><br><span class="line">            cost = (errors**<span class="number">2</span>).sum() / <span class="number">2.0</span></span><br><span class="line">            self.cost_.append(cost)</span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">net_input</span>(<span class="params">self, X</span>):</span></span><br><span class="line">        <span class="keyword">return</span> np.dot(X, self.w_[<span class="number">1</span>:] + self.w_[<span class="number">0</span>])</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self, X</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.net_input(X)</span><br></pre></td></tr></table></figure><p>接下来我们使用房屋数据集中的RM（房间数量）作为解释变量来训练模型以预测MEDV（房屋价格）。此外，为了使得梯度下降算法收敛性更佳，在此对相关变量做了标准化处理：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">X = df[[<span class="string">&#x27;RM&#x27;</span>]].values</span><br><span class="line">y = df[<span class="string">&#x27;MEDV&#x27;</span>].values</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">sc_x = StandardScaler()</span><br><span class="line">sc_y = StandardScaler()</span><br><span class="line">X_std = sc_x.fit_transform(X)</span><br><span class="line">y_std = sc_y.fit_transform(y[:, np.newaxis]).flatten()</span><br><span class="line">lr = LinearRegressionGD()</span><br><span class="line">lr.fit(X_std, y_std)</span><br></pre></td></tr></table></figure><p>接下来看一下代价函数和迭代次数的图像：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(range(<span class="number">1</span>, lr.n_iter+<span class="number">1</span>), lr.cost_)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;SSE&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Epoch&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>得到的图像如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="Sat,%2008%20Feb%202020%20161004.png" class="lazyload" data-srcset="Sat,%2008%20Feb%202020%20161004.png" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><p>接下来，绘制房间数和房屋价格的关系：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lin_regplot</span>(<span class="params">X, y, model</span>):</span></span><br><span class="line">    plt.scatter(X, y, c=<span class="string">&#x27;b&#x27;</span>)</span><br><span class="line">    plt.plot(X, model.predict(X), color=<span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">lin_regplot(X_std, y_std, lr)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Average Number&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Price&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>得到的图像如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="Sat,%2008%20Feb%202020%20161429.png" class="lazyload" data-srcset="Sat,%2008%20Feb%202020%20161429.png" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><p>从图中可知，随着房间数的增加，房价呈现上涨趋势。但是从图中可以看到，房间数在很多的情况下并不能很好解释房价。对于经过标准化处理的变量，它们的截距必定是0：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">&#x27;Slope: %.3f&#x27;</span> % lr.w_[<span class="number">1</span>])</span><br><span class="line">print(<span class="string">&#x27;Intercept: %.3f&#x27;</span> % lr.w_[<span class="number">0</span>])</span><br></pre></td></tr></table></figure><h3 id="使用scikit-learn估计回归模型的系数"><a href="#使用scikit-learn估计回归模型的系数" class="headerlink" title="使用scikit-learn估计回归模型的系数"></a>使用scikit-learn估计回归模型的系数</h3><p>下面，我们使用scikit-learn中的库实现回归分析：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line">slr = LinearRegression()</span><br><span class="line">slr.fit(X, y)</span><br><span class="line">print(<span class="string">&#x27;Slope: %.3f&#x27;</span> % slr.coef_[<span class="number">0</span>])</span><br><span class="line">print(<span class="string">&#x27;Intercept: %.3f&#x27;</span> % slr.intercept_)</span><br><span class="line">&gt;&gt; Slope: <span class="number">9.102</span></span><br><span class="line">&gt;&gt; Intercept: <span class="number">-34.671</span></span><br></pre></td></tr></table></figure><p>执行代码发现得到了不同的模型系数，现在绘制出图像：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">lin_regplot(X, y, slr)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Average Number&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Price&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>得到的图像如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="Sat,%2008%20Feb%202020%20162851.png" class="lazyload" data-srcset="Sat,%2008%20Feb%202020%20162851.png" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><p>从图中可以看出，总体结果与GD算法实现的模型是一致的。</p><h2 id="使用RANSAC拟合高鲁棒性回归模型"><a href="#使用RANSAC拟合高鲁棒性回归模型" class="headerlink" title="使用RANSAC拟合高鲁棒性回归模型"></a>使用RANSAC拟合高鲁棒性回归模型</h2><p>作为清除异常值的一种高鲁棒性回归方法，在此我们将学习<strong>随机抽样一致性（RANSAC）</strong>算法，使用数据的一个子集来进行回归模型的拟合。该算法流程如下：</p><ol><li>从数据集中随机抽取样本构建内点集合类拟合模型</li><li>使用剩余数据对上一步得到的模型进行测试，并将落在预定公差范围内的样本点增至内带你集合中</li><li>使用全部内点集合数据再次进行模型的拟合</li><li>使用内点集合来估计模型的误差</li><li>如果模型性能达到了特定阈值或者迭代达到了预定次数，则算法中止，否则跳转到第1步</li></ol><p>首先我们用RANSACRegressor对象来实现我们的线性模型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> RANSACRegressor</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line">ransac = RANSACRegressor(LinearRegression(),</span><br><span class="line">                        max_trials=<span class="number">100</span>,</span><br><span class="line">                        min_samples=<span class="number">50</span>,</span><br><span class="line">                        residual_threshold=<span class="number">5.0</span>,</span><br><span class="line">                        random_state=<span class="number">0</span>)</span><br><span class="line">ransac.fit(X, y)</span><br></pre></td></tr></table></figure><p>完成拟合后，我们接着来绘制内点和异常值图像：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">inlier_mask = ransac.inlier_mask_</span><br><span class="line">outlier_mask = np.logical_not(inlier_mask)</span><br><span class="line">line_X = np.arange(<span class="number">3</span>, <span class="number">10</span>, <span class="number">1</span>)</span><br><span class="line">line_y_ransac = ransac.predict(line_X[:, np.newaxis])</span><br><span class="line">plt.scatter(X[inlier_mask], y[inlier_mask], c=<span class="string">&#x27;b&#x27;</span>, marker=<span class="string">&#x27;o&#x27;</span>, label=<span class="string">&#x27;Inliers&#x27;</span>)</span><br><span class="line">plt.scatter(X[outlier_mask], y[outlier_mask], c=<span class="string">&#x27;r&#x27;</span>, marker=<span class="string">&#x27;s&#x27;</span>, label=<span class="string">&#x27;Outliers&#x27;</span>)</span><br><span class="line">plt.plot(line_X, line_y_ransac, color=<span class="string">&#x27;g&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Average Number&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Price&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>图像如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="Sat,%2008%20Feb%202020%20162353.png" class="lazyload" data-srcset="Sat,%2008%20Feb%202020%20162353.png" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><p>接下来看一下模型的截距和斜率：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">&#x27;Slope: %.3f&#x27;</span> % ransac.estimator_.coef_[<span class="number">0</span>])</span><br><span class="line">print(<span class="string">&#x27;Intercept: %.3f&#x27;</span> % ransac.estimator_.intercept_)</span><br><span class="line">&gt;&gt; Slope: <span class="number">10.735</span></span><br><span class="line">&gt;&gt; Intercept: <span class="number">-44.089</span></span><br></pre></td></tr></table></figure><h2 id="线性回归模型性能的评估"><a href="#线性回归模型性能的评估" class="headerlink" title="线性回归模型性能的评估"></a>线性回归模型性能的评估</h2><p>现在我们使用数据集中的所有变量训练多元回归模型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X = df.iloc[:, :<span class="number">-1</span>].values</span><br><span class="line">y = df[<span class="string">&#x27;MEDV&#x27;</span>].values</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.3</span>, random_state=<span class="number">0</span>)</span><br><span class="line">slr = LinearRegression()</span><br><span class="line">slr.fit(X_train, y_train)</span><br><span class="line">y_train_pred = slr.predict(X_train)</span><br><span class="line">y_test_pred = slr.predict(X_test)</span><br></pre></td></tr></table></figure><p>使用如下代码，我们会绘制出<strong>残差图</strong>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">plt.scatter(y_train_pred, y_train_pred - y_train, c&#x3D;&#39;b&#39;, marker&#x3D;&#39;o&#39;, label&#x3D;&#39;Training data&#39;)</span><br><span class="line">plt.scatter(y_test_pred, y_test_pred - y_test, c&#x3D;&#39;r&#39;, marker&#x3D;&#39;s&#39;, label&#x3D;&#39;Test data&#39;)</span><br><span class="line">plt.xlabel(&#39;Predicted values&#39;)</span><br><span class="line">plt.ylabel(&#39;Residuals&#39;)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.hlines(y&#x3D;0, xmin&#x3D;-10, xmax&#x3D;50, lw&#x3D;2, color&#x3D;&#39;red&#39;)</span><br><span class="line">plt.xlim([-10, 50])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>得到的残差图如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="Sat,%2008%20Feb%202020%20185508.png" class="lazyload" data-srcset="Sat,%2008%20Feb%202020%20185508.png" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><p>完美的预测结果其残差为0，但是在实际的应用中，这种情况不会出现。不过，对于一个好的回归模型，我们期望误差是随机分布在中心线附近的。</p><p>另外一种对模型性能进行定量评估的方法是<strong>均方误差</strong>（Mean Squared Error，MSE），计算公式如下：<br>$$<br>MSE = \frac{1}{n}\sum_{i=1}^{n}(y^i - \hat{y^i})^2<br>$$<br>执行如下代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line">print(<span class="string">&#x27;MSE train: %.3f, test: %.3f&#x27;</span> % (mean_squared_error(y_train, y_train_pred), mean_squared_error(y_test, y_test_pred)))</span><br><span class="line">&gt;&gt; MSE train: <span class="number">19.958</span>, test: <span class="number">27.196</span></span><br></pre></td></tr></table></figure><p>从结果而知，训练集上的MSE值为19.96，测试集上的MSE值骤升为27.20，这意味着我们的模型过拟合于训练数据。</p><p>某些情况下也可以使用<strong>决定系数</strong>来进行评估，它的计算公式如下：<br>$$<br>R^2 = 1 - \frac{MSE}{Var(y)}<br>$$<br>可以使用如下代码来计算$ R^2 $：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> r2_score</span><br><span class="line">print(<span class="string">&#x27;R^2 train: %.3f, test: %.3f&#x27;</span> % (r2_score(y_train, y_train_pred), r2_score(y_test, y_test_pred)))</span><br><span class="line">&gt;&gt; R^<span class="number">2</span> train: <span class="number">0.765</span>, test: <span class="number">0.673</span></span><br></pre></td></tr></table></figure><h2 id="回归中的正则化方法"><a href="#回归中的正则化方法" class="headerlink" title="回归中的正则化方法"></a>回归中的正则化方法</h2><p>正则化是通过在模型中加入额外信息来解决过拟合问题的一种方法，引入罚项增加了模型的复杂度但却降低了模型了模型参数的影响。最常见的正则化线性回归方法就是所谓的<strong>岭回归</strong>（Ridge Regression），<strong>最小绝对收缩及算子选择</strong>（LASSO）以及<strong>弹性网络</strong>（Elastic Net）。</p><p>岭回归是基于L2罚项的模型，我们只是在最小二乘代价函数中加入了权重的平方和：<br>$$<br>J(w)<em>{Ridge} = \sum</em>{i=1}^{n}(y^i-\hat{y^i})^2+\lambda||w||^2_2<br>$$<br>其中：<br>$$<br>L2： \lambda||w||^2_2=\lambda\sum_{j=1}^{m}w_j^2<br>$$<br>对于稀疏数据训练的模型，还可以使用LASSO：<br>$$<br>J(w)<em>{LASSO}= = \sum</em>{i=1}^{n}(y^i-\hat{y^i})^2+\lambda||w||<em>1<br>$$<br>其中：<br>$$<br>L1： \lambda||w||<em>1 = \lambda\sum</em>{j=1}^{m}|w_j|<br>$$<br>弹性网络如下：<br>$$<br>J(w)_{ElasticNet} = \sum</em>{i=1}^{n}(y^i-\hat{y^i})^2+<br>\lambda_1\sum_{j=1}^{m}w_j^2+<br>\lambda_2\sum_{j=1}^{m}|w_j|<br>$$<br>scikit-learn中岭回归模型的初始化方法如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Ridge</span><br><span class="line">ridge = Ridge(alpha=<span class="number">1.0</span>)</span><br></pre></td></tr></table></figure><p>正则化强度通过alpha参数来调节，类似于参数$ \lambda $。</p><p>LASSO对象的初始化如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Lasso</span><br><span class="line">lasso = Lasso(alpha=<span class="number">1.0</span>)</span><br></pre></td></tr></table></figure><p>最后，scikit-learn下面的ElasticNet允许我们调整L1与L2的比率：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> ElasticNet</span><br><span class="line">lasso = ElasticNet(alpha=<span class="number">1.0</span>, l1_ratio=<span class="number">0.5</span>)</span><br></pre></td></tr></table></figure><h2 id="线性回归模型的曲线化—-多项式回归"><a href="#线性回归模型的曲线化—-多项式回归" class="headerlink" title="线性回归模型的曲线化—-多项式回归"></a>线性回归模型的曲线化—-多项式回归</h2><p>对于不符合线性假设的问题，一种常用的解释方法就是：<br>$$<br>y = w_0+w_1x+w_2x^2+\cdots+w_dx^d<br>$$<br>接下来我们讨论一下如何使用scikit-learn中的PolynomialFeatures转化类在只含有一个解释变量的简单回归问题中加入二次项。步骤如下：</p><ol><li><p>增加一个二次多项式：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> PolynomialFeatures</span><br><span class="line">X = np.array([ <span class="number">258.0</span>, <span class="number">270.0</span>, <span class="number">294.0</span>, <span class="number">320.0</span>, <span class="number">342.0</span>,</span><br><span class="line">            <span class="number">368.0</span>, <span class="number">396.0</span>, <span class="number">446.0</span>, <span class="number">480.0</span>, <span class="number">586.0</span>])[:, np.newaxis]</span><br><span class="line">y = np.array([ <span class="number">236.4</span>, <span class="number">234.4</span>, <span class="number">252.8</span>, <span class="number">298.6</span>, <span class="number">314.2</span>, <span class="number">342.2</span>, <span class="number">360.8</span>, <span class="number">368.0</span>, <span class="number">391.2</span>, <span class="number">390.8</span>])</span><br><span class="line">lr = LinearRegression()</span><br><span class="line">pr = LinearRegression()</span><br><span class="line">quadratic = PolynomialFeatures(degree=<span class="number">2</span>)</span><br><span class="line">X_quad = quadratic.fit_transform(X)</span><br></pre></td></tr></table></figure></li><li><p>拟合一个用于对比的简单线性回归模型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">lr.fit(X, y)</span><br><span class="line">X_fit = np.arange(<span class="number">250</span>, <span class="number">600</span>, <span class="number">10</span>)[:, np.newaxis]</span><br><span class="line">y_lin_fit = lr.predict(X_fit)</span><br></pre></td></tr></table></figure></li><li><p>使用经过转换后的特征针对多项式回归拟合一个多元线性回归模型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">pr.fit(X_quad, y)</span><br><span class="line">y_quad_fit = pr.predict(quadratic.fit_transform(X_fit))</span><br><span class="line">plt.scatter(X, y, label=<span class="string">&#x27;training points&#x27;</span>)</span><br><span class="line">plt.plot(X_fit, y_lin_fit, label=<span class="string">&#x27;linear fit&#x27;</span>, linestyle=<span class="string">&#x27;--&#x27;</span>)</span><br><span class="line">plt.plot(X_fit, y_quad_fit, label=<span class="string">&#x27;quadratic fit&#x27;</span>)</span><br><span class="line">plt.legend(loc=<span class="string">&#x27;upper left&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>得到的图像如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="Sat,%2008%20Feb%202020%20194224.png" class="lazyload" data-srcset="Sat,%2008%20Feb%202020%20194224.png" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><p>从图像可以看出，和线性拟合相比，多项式拟合可以更好地捕捉到解释变量和响应变量之间的关系。</p></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">y_lin_pred = lr.predict(X)</span><br><span class="line">y_quad_pred = pr.predict(X_quad)</span><br><span class="line">print(<span class="string">&#x27;Training MSE linear: %.3f, quadratic: %.3f&#x27;</span> % (</span><br><span class="line">        mean_squared_error(y, y_lin_pred),</span><br><span class="line">        mean_squared_error(y, y_quad_pred)))</span><br><span class="line">print(<span class="string">&#x27;Training R^2 linear: %.3f, quadratic: %.3f&#x27;</span> % (</span><br><span class="line">        r2_score(y, y_lin_pred),</span><br><span class="line">        r2_score(y, y_quad_pred)))</span><br><span class="line">&gt;&gt; Training MSE linear: <span class="number">569.780</span>, quadratic: <span class="number">61.330</span></span><br><span class="line">&gt;&gt; Training R^<span class="number">2</span> linear: <span class="number">0.832</span>, quadratic: <span class="number">0.982</span>        </span><br></pre></td></tr></table></figure><p>执行上述代码后，MSE的值由线性拟合的570下降到了61。同时和线性拟合结果相比，二次模型的判定系数结果更好，说明二次拟合的效果更好。</p><h3 id="房屋数据中的非线性关系建模"><a href="#房屋数据中的非线性关系建模" class="headerlink" title="房屋数据中的非线性关系建模"></a>房屋数据中的非线性关系建模</h3><p>接下来，我们将会使用二次核三次多项式对房屋价格核LSTAT之间的关系进行建模，并且和线性拟合进行对比：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">X = df[[<span class="string">&#x27;LSTAT&#x27;</span>]].values</span><br><span class="line">y = df[<span class="string">&#x27;MEDV&#x27;</span>].values</span><br><span class="line">regr = LinearRegression()</span><br><span class="line"></span><br><span class="line"><span class="comment"># create polynomial features</span></span><br><span class="line">quadratic = PolynomialFeatures(degree=<span class="number">2</span>)</span><br><span class="line">cubic = PolynomialFeatures(degree=<span class="number">3</span>)</span><br><span class="line">X_quad = quadratic.fit_transform(X)</span><br><span class="line">X_cubic = cubic.fit_transform(X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># linear fit</span></span><br><span class="line">X_fit = np.arange(X.min(), X.max(), <span class="number">1</span>)[:, np.newaxis]</span><br><span class="line">regr = regr.fit(X, y)</span><br><span class="line">y_lin_fit = regr.predict(X_fit)</span><br><span class="line">linear_r2 = r2_score(y, regr.predict(X))</span><br><span class="line"></span><br><span class="line"><span class="comment"># quadratic fit</span></span><br><span class="line">regr = regr.fit(X_quad, y)</span><br><span class="line">y_quad_fit = regr.predict(quadratic.fit_transform(X_fit))</span><br><span class="line">quadratic_r2 = r2_score(y, regr.predict(X_quad))</span><br><span class="line"></span><br><span class="line"><span class="comment"># cubic fit</span></span><br><span class="line">regr = regr.fit(X_cubic, y)</span><br><span class="line">y_cubic_fit = regr.predict(cubic.fit_transform(X_fit))</span><br><span class="line">cubic_r2 = r2_score(y, regr.predict(X_cubic))</span><br><span class="line"></span><br><span class="line"><span class="comment"># plot results</span></span><br><span class="line">plt.scatter(X, y, label=<span class="string">&#x27;training points&#x27;</span>, color=<span class="string">&#x27;lightgray&#x27;</span>)</span><br><span class="line">plt.plot(X_fit, y_lin_fit, label=<span class="string">&#x27;linear(d=1), R^2 = %.2f&#x27;</span> % linear_r2, color=<span class="string">&#x27;b&#x27;</span>, lw=<span class="number">2</span>, linestyle=<span class="string">&#x27;:&#x27;</span>)</span><br><span class="line">plt.plot(X_fit, y_quad_fit, label=<span class="string">&#x27;quadratic(d=2), R^2 = %.2f&#x27;</span> % quadratic_r2, color=<span class="string">&#x27;g&#x27;</span>, lw=<span class="number">2</span>, linestyle=<span class="string">&#x27;-&#x27;</span>)</span><br><span class="line">plt.plot(X_fit, y_cubic_fit, label=<span class="string">&#x27;cubic(d=3), R^2 = %.2f&#x27;</span> % cubic_r2, color=<span class="string">&#x27;r&#x27;</span>, lw=<span class="number">2</span>, linestyle=<span class="string">&#x27;--&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;LSTAT&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Price&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>图像如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="Sat,%2008%20Feb%202020%20200734.png" class="lazyload" data-srcset="Sat,%2008%20Feb%202020%20200734.png" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><p>从图像而知，相较于线性拟合和二次拟合，三次拟合更好地捕获了房屋价格与LSTAT之间的关系。不过，加入越来越多的多项式特征会增加模型复杂度，容易造成过拟合。</p><p>此外，多项式特征并非总是非线性关系建模的最佳选择。例如，我们仅就MEDV-LSTAT的散点图来说，我们可以将LSTAT特征变量的对数值以及MEDV的平方根映射到一个特征空间，并用线性回归进行拟合：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># transform features</span></span><br><span class="line">X_log = np.log(X)</span><br><span class="line">y_sqrt = np.sqrt(y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># fit features</span></span><br><span class="line">X_fit = np.arange(X_log.min()<span class="number">-1</span>, X_log.max()+<span class="number">1</span>, <span class="number">1</span>)[:, np.newaxis]</span><br><span class="line">regr = regr.fit(X_log, y_sqrt)</span><br><span class="line">y_lin_fit = regr.predict(X_fit)</span><br><span class="line">linear_r2 = r2_score(y_sqrt, regr.predict(X_log))</span><br><span class="line"></span><br><span class="line"><span class="comment"># plot results</span></span><br><span class="line">plt.scatter(X_log, y_sqrt, label=<span class="string">&#x27;training points&#x27;</span>,color=<span class="string">&#x27;lightgray&#x27;</span>)</span><br><span class="line">plt.plot(X_fit, y_lin_fit, label=<span class="string">&#x27;linear(d=1), R^2=%.2f&#x27;</span> % linear_r2, color=<span class="string">&#x27;blue&#x27;</span>, lw=<span class="number">2</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;LSTAT&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Price&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>得到的图像如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="Sat,%2008%20Feb%202020%20201959.png" class="lazyload" data-srcset="Sat,%2008%20Feb%202020%20201959.png" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><p>从$ R^2 $的值可以看出，这种拟合形式优于前面的任何一种多项式回归。</p><h3 id="使用随机森林处理非线性关系"><a href="#使用随机森林处理非线性关系" class="headerlink" title="使用随机森林处理非线性关系"></a>使用随机森林处理非线性关系</h3><p>本节中，我们将会学习<strong>随机森林</strong>回归，他从概念上异于本章中介绍的其他回归模型。随机森林是多颗<strong>决策树</strong>的集合，它可以被理解成分段线性函数的集成。</p><ol><li><p>决策树回归</p><p>决策树算法的一个优点是我们无需对数据进行特征转换。在scikit-learn中对其进行建模：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeRegressor</span><br><span class="line">X = df[[<span class="string">&#x27;LSTAT&#x27;</span>]].values</span><br><span class="line">y = df[<span class="string">&#x27;MEDV&#x27;</span>].values</span><br><span class="line">tree = DecisionTreeRegressor(max_depth=<span class="number">3</span>)</span><br><span class="line">tree.fit(X, y)</span><br><span class="line">sort_idx = X.flatten().argsort()</span><br><span class="line">lin_regplot(X[sort_idx], y[sort_idx], tree)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;LSTAT&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Price&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>图像如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="Sat,%2008%20Feb%202020%20203210.png" class="lazyload" data-srcset="Sat,%2008%20Feb%202020%20203210.png" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><p>在此例中，深度为3的树看起来是比较合适的。</p></li><li><p>随机森林回归</p><p>随机森林算法是组合多颗决策树的一种集成技术。随机森林的一个优势是：它对数据集中的异常值不敏感，且无需过多的参数调优。接下来使用scikit-learn中的库来拟合一个随机森林回归模型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">X = df.iloc[:, :<span class="number">-1</span>].values</span><br><span class="line">y = df[<span class="string">&#x27;MEDV&#x27;</span>].values</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.4</span>, random_state=<span class="number">1</span>)</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestRegressor</span><br><span class="line">forest = RandomForestRegressor(n_estimators=<span class="number">1000</span>, criterion=<span class="string">&#x27;mse&#x27;</span>, random_state=<span class="number">1</span>, n_jobs=<span class="number">-1</span>)</span><br><span class="line">forest.fit(X_train, y_train)</span><br><span class="line">y_train_pred = forest.predict(X_train)</span><br><span class="line">y_test_pred = forest.predict(X_test)</span><br><span class="line">print(<span class="string">&#x27;MSE train: %.3f, test: %.3f&#x27;</span> % (mean_squared_error(y_train, y_train_pred), mean_squared_error(y_test, y_test_pred)))</span><br><span class="line">print(<span class="string">&#x27;R^2 train: %.3f, test: %.3f&#x27;</span> % (r2_score(y_train, y_train_pred), r2_score(y_test, y_test_pred)))</span><br><span class="line">&gt;&gt; MSE train: <span class="number">1.641</span>, test: <span class="number">11.056</span></span><br><span class="line">&gt;&gt; R^<span class="number">2</span> train: <span class="number">0.979</span>, test: <span class="number">0.878</span></span><br></pre></td></tr></table></figure><p>遗憾的是，我们发现随机森林对于训练数据有些过拟合，接下来看一下预测的残差图：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">plt.scatter(y_train_pred, y_train_pred - y_train, c=<span class="string">&#x27;black&#x27;</span>, marker=<span class="string">&#x27;o&#x27;</span>, s=<span class="number">35</span>, alpha=<span class="number">0.5</span>, label=<span class="string">&#x27;Training data&#x27;</span>)</span><br><span class="line">plt.scatter(y_test_pred, y_test_pred - y_test, c=<span class="string">&#x27;lightgreen&#x27;</span>, marker=<span class="string">&#x27;s&#x27;</span>, s=<span class="number">35</span>, alpha=<span class="number">0.7</span>, label=<span class="string">&#x27;Test data&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Predicted values&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Residuals&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.hlines(y=<span class="number">0</span>, xmin=<span class="number">-10</span>, xmax=<span class="number">50</span>, lw=<span class="number">2</span>, color=<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">plt.xlim([<span class="number">-10</span>, <span class="number">50</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>图像如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="Sat,%2008%20Feb%202020%20204701.png" class="lazyload" data-srcset="Sat,%2008%20Feb%202020%20204701.png" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><p>可以发现，随机森林的残差图相比线性拟合产生的残差图有了很大的改进。</p></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>在Web中嵌入机器学习模型</title>
      <link href="2020/02/08/%E5%9C%A8Web%E4%B8%AD%E5%B5%8C%E5%85%A5%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B/"/>
      <url>2020/02/08/%E5%9C%A8Web%E4%B8%AD%E5%B5%8C%E5%85%A5%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<p>本章中，我们将学习如何将机器学习模型嵌入到Web应用中，不仅仅是分类，还包括从实时数据中学习。</p><a id="more"></a><h2 id="序列化通过scikit-laern拟合的模型"><a href="#序列化通过scikit-laern拟合的模型" class="headerlink" title="序列化通过scikit-laern拟合的模型"></a>序列化通过scikit-laern拟合的模型</h2><p>正如我们上一章所述，训练机器模型会带来很高的计算成本。当然，我们不希望每次进行预测分析都需要训练模型。模型持久化的一个方法是使用Python内嵌的pickle模块，它使得我们可以在Python对象与字节码之间进行转换（序列化和反序列化），这样我们就可以将分类器当前的状态保存下来。当需要对新的数据进行分类时，可以直接加载已经保存的分类器，而不必再次用训练数据对模型进行训练：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">dest = os.path.join(os.getcwd(), <span class="string">&#x27;movieclassifier&#x27;</span>, <span class="string">&#x27;pkl_objects&#x27;</span>)</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(dest):</span><br><span class="line">    os.makedirs(dest)</span><br><span class="line">pickle.dump(stop,</span><br><span class="line">           open(os.path.join(dest, <span class="string">&#x27;stopwords.pkl&#x27;</span>), <span class="string">&#x27;wb&#x27;</span>),</span><br><span class="line">           protocol=<span class="number">4</span>)</span><br><span class="line">pickle.dump(clf,</span><br><span class="line">           open(os.path.join(dest, <span class="string">&#x27;classifier.pkl&#x27;</span>), <span class="string">&#x27;wb&#x27;</span>),</span><br><span class="line">           protocol=<span class="number">4</span>)</span><br></pre></td></tr></table></figure><p>由于无需拟合HashingVectorizer，也就不必对其进行持久化操作。相反，我们创建一个新的脚本文件，通过此脚本可以将向量数据导入到当前Python会话中，下面代码以vectorizer.py作为文件名，保存在movieclassifier目录下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> HashingVectorizer</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"></span><br><span class="line">cur_dir = os.path.dirname(__file__)</span><br><span class="line">stop = pickle.load(open(os.path.join(cur_dir, <span class="string">&#x27;pkl_objects&#x27;</span>, <span class="string">&#x27;stopwords.pkl&#x27;</span>), <span class="string">&#x27;rb&#x27;</span>))</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tokenizer</span>(<span class="params">text</span>):</span></span><br><span class="line">    text = re.sub(<span class="string">&#x27;&lt;[^&gt;]*&gt;&#x27;</span>, <span class="string">&#x27;&#x27;</span>, text)</span><br><span class="line">    text = re.sub(<span class="string">&#x27;[\W]+&#x27;</span>, <span class="string">&#x27; &#x27;</span>, text.lower())</span><br><span class="line">    tokenized = [w <span class="keyword">for</span> w <span class="keyword">in</span> text.split() <span class="keyword">if</span> w <span class="keyword">not</span> <span class="keyword">in</span> stop]</span><br><span class="line">    <span class="keyword">return</span> tokenized</span><br><span class="line"></span><br><span class="line">vect = HashingVectorizer(decode_error=<span class="string">&#x27;ignore&#x27;</span>,</span><br><span class="line">                        n_features=<span class="number">2</span>**<span class="number">21</span>,</span><br><span class="line">                        preprocessor=<span class="literal">None</span>,</span><br><span class="line">                        tokenizer=tokenizer)</span><br></pre></td></tr></table></figure><p>接下来定位到movieclassifer目录，就可以导入vectorizer及对分类器进行持久化处理：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> vectorizer <span class="keyword">import</span> vect</span><br><span class="line">clf = pickle.load(open(os.path.join(<span class="string">&#x27;pkl_objects&#x27;</span>, <span class="string">&#x27;classifier.pkl&#x27;</span>), <span class="string">&#x27;rb&#x27;</span>))</span><br></pre></td></tr></table></figure><p>在成功加载vectorizer以及反序列化分类器后，我们现在使用这些对象对文档样本进行预处理，并且对其进行预测：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">label = &#123;<span class="number">0</span>: <span class="string">&#x27;negative&#x27;</span>, <span class="number">1</span>: <span class="string">&#x27;postive&#x27;</span>&#125;</span><br><span class="line">example = [<span class="string">&#x27;I love this movie&#x27;</span>]</span><br><span class="line">X = vect.transform(example)</span><br><span class="line">print(<span class="string">&#x27;Prediction: %s\nProbability: %.3f%%&#x27;</span> % (label[clf.predict(X)[<span class="number">0</span>]], np.max(clf.predict_proba(X))*<span class="number">100</span>))</span><br><span class="line">&gt;&gt; Prediction: postive</span><br><span class="line">&gt;&gt; Probability: <span class="number">81.483</span>%</span><br></pre></td></tr></table></figure><h2 id="使用SQLite数据库存储数据"><a href="#使用SQLite数据库存储数据" class="headerlink" title="使用SQLite数据库存储数据"></a>使用SQLite数据库存储数据</h2><p>本节中，我们将创建一个简单的SQLite数据库以收集Web应用的用户对于预测结果的反馈。SQLite是一个进程内的库，实现了自给自足的、无服务器的、零配置的、事务性的 SQL 数据库引擎。它是一个零配置的数据库，这意味着与其他数据库一样，我们不需要在系统中配置。就像其他数据库，SQLite 引擎不是一个独立的进程，可以按应用程序需求进行静态或动态连接。SQLite 可以直接访问其存储文件。</p><p>通过如下代码，我们将在movieclassifier所在目录创建一个新的SQLite数据库，并且向其中插入两条电影评论的示例数据：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sqlite3</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">conn = sqlite3.connect(<span class="string">&#x27;reviews.sqlite&#x27;</span>)</span><br><span class="line">c = conn.cursor()</span><br><span class="line">c.execute(<span class="string">&quot;CREATE TABLE review_db&quot;</span>\</span><br><span class="line">         <span class="string">&quot;(review TEXT, sentiment INTEGER, date TEXT)&quot;</span>)</span><br><span class="line">example1 = <span class="string">&#x27;I love this movie&#x27;</span></span><br><span class="line">c.execute(<span class="string">&quot;INSERT INTO review_db&quot;</span>\</span><br><span class="line">         <span class="string">&quot;(review, sentiment, date) VALUES&quot;</span>\</span><br><span class="line">         <span class="string">&quot;(?, ?, DATETIME(&#x27;now&#x27;))&quot;</span>, (example1, <span class="number">1</span>))</span><br><span class="line">example2 = <span class="string">&#x27;I dislike this movie&#x27;</span></span><br><span class="line">c.execute(<span class="string">&quot;INSERT INTO review_db&quot;</span>\</span><br><span class="line">         <span class="string">&quot;(review, sentiment, date) VALUES&quot;</span>\</span><br><span class="line">         <span class="string">&quot;(?, ?, DATETIME(&#x27;now&#x27;))&quot;</span>, (example2, <span class="number">0</span>))</span><br><span class="line">conn.commit()</span><br><span class="line">conn.close()</span><br></pre></td></tr></table></figure><h2 id="使用Flask开发Web应用"><a href="#使用Flask开发Web应用" class="headerlink" title="使用Flask开发Web应用"></a>使用Flask开发Web应用</h2><p>上一节中完成了用于电影评论分类的代码，现在来讨论使用Flask框架开发Web应用的基础知识。</p><h3 id="第一个Flask-Web应用"><a href="#第一个Flask-Web应用" class="headerlink" title="第一个Flask Web应用"></a>第一个Flask Web应用</h3><p>首先，按照如下目录结构创建Web应用的框架：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1st_flask_app_1&#x2F;</span><br><span class="line">-app.py</span><br><span class="line">-templates&#x2F;</span><br><span class="line">-first_app.html</span><br></pre></td></tr></table></figure><p>app.py文件中包含了运行Flask Web应用程序而需要在Python解释器中执行的入口代码。templates目录下面是Flask用到的静态HTML文件。首先，看一下app.py的内容：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> Flask, render_template</span><br><span class="line"></span><br><span class="line">app = Flask(__name__)</span><br><span class="line"></span><br><span class="line"><span class="meta">@app.route(&#x27;/&#x27;)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">index</span>():</span></span><br><span class="line">    <span class="keyword">return</span> render_template(<span class="string">&#x27;first_app.html&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    app.run()</span><br></pre></td></tr></table></figure><p>其中需要注意的是路由注解（@app.route(‘/‘)）指定触发index函数的URL路径。接下里通过终端窗口执行下列命令启动Web应用：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">python3 app.py</span><br><span class="line">&gt;&gt; Running on http://127.0.0.1:5000/</span><br></pre></td></tr></table></figure><p>接下来打开对应的网站，如果一切正常，将会看到如下内容网页：</p><p>“Hi, this is my first Flask Web app!”。</p><h3 id="表单验证"><a href="#表单验证" class="headerlink" title="表单验证"></a>表单验证</h3><p>本节中，我们使用HTML表单升级Flask Web应用，以及学习如何使用WTForms库收集数据。</p><p>新的应用程序所需的目标结构看起来如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">1st_flask_app_1&#x2F;</span><br><span class="line">-app.py</span><br><span class="line">-static</span><br><span class="line">-style.css</span><br><span class="line">-templates&#x2F;</span><br><span class="line">-_formhelpers.html</span><br><span class="line">-first_app.html</span><br><span class="line">-hello.html</span><br></pre></td></tr></table></figure><p>以下为修改后的app.py文件内容：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> Flask, render_template, request</span><br><span class="line"><span class="keyword">from</span> wtforms <span class="keyword">import</span> Form, TextAreaFiled, validators</span><br><span class="line"></span><br><span class="line">app = Flask(__name__)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HelloForm</span>(<span class="params">Form</span>):</span></span><br><span class="line">    sayhello = TextAreaFiled(<span class="string">&#x27;&#x27;</span>, [validators.DateRequired()])</span><br><span class="line"></span><br><span class="line"><span class="meta">@app.route(&#x27;/&#x27;)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">index</span>():</span></span><br><span class="line">    form = HelloForm(request.form)</span><br><span class="line">    <span class="keyword">return</span> render_template(<span class="string">&#x27;first_app.html&#x27;</span>, form=form)</span><br><span class="line"></span><br><span class="line"><span class="meta">@app.route(&#x27;/hello&#x27;, method=[&#x27;POST&#x27;])</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">hello</span>():</span></span><br><span class="line">    form = HelloForm(request.form)</span><br><span class="line">    <span class="keyword">if</span> request.method == <span class="string">&#x27;POST&#x27;</span> <span class="keyword">and</span> form.validate():</span><br><span class="line">        name = request.form[<span class="string">&#x27;sayhello&#x27;</span>]</span><br><span class="line">        <span class="keyword">return</span> render_template(<span class="string">&#x27;hello.html&#x27;</span>, name=name)</span><br><span class="line">    <span class="keyword">return</span> render_template(<span class="string">&#x27;first_app.html&#x27;</span>, form=form)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    app.run(debug=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p>现在通过Jinjia2模板引擎，在_formhelper.html文件中实现一个通用宏，后续它会被导入到first_app.html文件中用来渲染文本：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&#123;% macro render_field(field) %&#125;</span><br><span class="line">    &lt;dt&gt;&#123;&#123; field.label &#125;&#125;</span><br><span class="line">    &lt;dd&gt;&#123;&#123; field(**kwargs)|safe &#125;&#125;</span><br><span class="line">    &#123;% if field.errors %&#125;</span><br><span class="line">        &lt;ul class&#x3D;errors&gt;</span><br><span class="line">        &#123;% for error in field.errors %&#125;</span><br><span class="line">        &lt;li&gt;&#123;&#123; error &#125;&#125;&lt;&#x2F;li&gt;</span><br><span class="line">        &#123;% endfor %&#125;</span><br><span class="line">        &lt;&#x2F;ul&gt;</span><br><span class="line">    &#123;% endif %&#125;</span><br><span class="line">    &lt;&#x2F;dd&gt;</span><br><span class="line">&#123;% endmacro %&#125;</span><br></pre></td></tr></table></figure><p>接下来，我们创建一个style.css文件，用于控制样式：</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">body</span> &#123;</span><br><span class="line"><span class="attribute">font-size</span>: <span class="number">2em</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>下面是修改后的first_app.html文件内容：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;!doctype <span class="meta-keyword">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">title</span>&gt;</span>First app<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">link</span> <span class="attr">rel</span>=<span class="string">&quot;stylesheet&quot;</span> <span class="attr">href</span>=<span class="string">&quot;&#123;&#123; url_for(&#x27;static&#x27;, filename=&#x27;style.css&#x27;) &#125;&#125;&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">    &#123;% from &quot;_formhelpers.html&quot; import render_field %&#125;</span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span>&gt;</span>What&#x27;s your name?<span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">form</span> <span class="attr">method</span>=<span class="string">post</span> <span class="attr">action</span>=<span class="string">&quot;/hello&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dl</span>&gt;</span></span><br><span class="line">        &#123;&#123; render_field(form.sayhello) &#125;&#125;</span><br><span class="line">        <span class="tag">&lt;/<span class="name">dl</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">submit</span> <span class="attr">value</span>=<span class="string">&#x27;Say Hello&#x27;</span> <span class="attr">name</span>=<span class="string">&#x27;submit_btn&#x27;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">form</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure><p>最后我们创建一个hello.html的文件：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;!doctype <span class="meta-keyword">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">title</span>&gt;</span>First app<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">link</span> <span class="attr">rel</span>=<span class="string">&quot;stylesheet&quot;</span> <span class="attr">href</span>=<span class="string">&quot;&#123;&#123; url_for(&#x27;static&#x27;, filename=&#x27;style.css&#x27;) &#125;&#125;&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span>&gt;</span>Hello &#123;&#123; name &#125;&#125;<span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure><p>接下来通过如下代码来运行我们的Web应用：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python3 app.py</span><br></pre></td></tr></table></figure><h2 id="将电影分类器嵌入Web应用"><a href="#将电影分类器嵌入Web应用" class="headerlink" title="将电影分类器嵌入Web应用"></a>将电影分类器嵌入Web应用</h2><p>下面更进一步，将电影分类器嵌入到Web应用中。</p><p>首先，看一下此电影评论分类应用的目录结构，如下图：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="1581131990058.png" class="lazyload" data-srcset="1581131990058.png" srcset="data:image/png;base64,666" alt="1581131990058"/></div><span class="image-caption">1581131990058</span></div><p>在本章前面的小节中，我们已经创建了vectorizer.py文件，reviews.sqlite以及pkl_objects对象。</p><p>由于app.py文件较长，我们分两步来分析。首先导入所需的Python模块和对象，并且通过反序列化恢复我们的分类模型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> Flask, render_template, request</span><br><span class="line"><span class="keyword">from</span> wtforms <span class="keyword">import</span> Form, TextAreaField, validators</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">import</span> sqlite3</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># import HashingVectorizer from local dir</span></span><br><span class="line"><span class="keyword">from</span> vectorizer <span class="keyword">import</span> vect</span><br><span class="line">app = Flask(__name__)</span><br><span class="line"></span><br><span class="line"><span class="comment">######## Preparing the Classifier</span></span><br><span class="line">cur_dir = os.path.dirname(__file__)</span><br><span class="line">clf = pickle.load(open(os.path.join(cur_dir, <span class="string">&#x27;pkl_objects/classifier.pkl&#x27;</span>), <span class="string">&#x27;rb&#x27;</span>))</span><br><span class="line">db = os.path.join(cur_dir, <span class="string">&#x27;reviews.sqlite&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">classify</span>(<span class="params">document</span>):</span></span><br><span class="line">    label = &#123;<span class="number">0</span>: <span class="string">&#x27;negative&#x27;</span>, <span class="number">1</span>: <span class="string">&#x27;positive&#x27;</span>&#125;</span><br><span class="line">    X = vect.transform([document])</span><br><span class="line">    y = clf.predict(X)[<span class="number">0</span>]</span><br><span class="line">    proba = np.max(clf.predict_proba(X))</span><br><span class="line">    <span class="keyword">return</span> label[y], proba</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">document, y</span>):</span></span><br><span class="line">    X = vect.transform([document])</span><br><span class="line">    clf.partial_fit(X, [y])</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sqlite_entry</span>(<span class="params">path, document, y</span>):</span></span><br><span class="line">    conn = sqlite3.connect(path)</span><br><span class="line">    c = conn.cursor()</span><br><span class="line">    c.execute(<span class="string">&quot;INSERT INTO review_db (review, sentiment, date)&quot;</span>\</span><br><span class="line">    <span class="string">&quot; VALUES (?, ?, DATETIME(&#x27;now&#x27;))&quot;</span>, (document, y))</span><br><span class="line">    conn.commit()</span><br><span class="line">    conn.close()</span><br></pre></td></tr></table></figure><p>app.py的第二部分如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">app = Flask(__name__)</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ReviewForm</span>(<span class="params">Form</span>):</span></span><br><span class="line">moviereview = TextAreaField(<span class="string">&#x27;&#x27;</span>, [validators.DataRequired(), validators.length(min=<span class="number">15</span>)])</span><br><span class="line"></span><br><span class="line"><span class="meta">@app.route(&#x27;/&#x27;)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">index</span>():</span></span><br><span class="line">    form = ReviewForm(request.form)</span><br><span class="line">    <span class="keyword">return</span> render_template(<span class="string">&#x27;reviewform.html&#x27;</span>, form=form)</span><br><span class="line"></span><br><span class="line"><span class="meta">@app.route(&#x27;/results&#x27;, methods=[&#x27;POST&#x27;])</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">results</span>():</span></span><br><span class="line">    form = ReviewForm(request.form)</span><br><span class="line">    <span class="keyword">if</span> request.method == <span class="string">&#x27;POST&#x27;</span> <span class="keyword">and</span> form.validate():</span><br><span class="line">        review = request.form[<span class="string">&#x27;moviereview&#x27;</span>]</span><br><span class="line">        y, proba = classify(review)</span><br><span class="line">        <span class="keyword">return</span> render_template(<span class="string">&#x27;results.html&#x27;</span>,</span><br><span class="line">                                content=review,</span><br><span class="line">                                prediction=y,</span><br><span class="line">                                probability=round(proba*<span class="number">100</span>, <span class="number">2</span>))</span><br><span class="line"><span class="keyword">return</span> render_template(<span class="string">&#x27;reviewform.html&#x27;</span>, form=form)</span><br><span class="line"></span><br><span class="line"><span class="meta">@app.route(&#x27;/thanks&#x27;, methods=[&#x27;POST&#x27;])</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">feedback</span>():</span></span><br><span class="line">    feedback = request.form[<span class="string">&#x27;feedback_button&#x27;</span>]</span><br><span class="line">    review = request.form[<span class="string">&#x27;review&#x27;</span>]</span><br><span class="line">    prediction = request.form[<span class="string">&#x27;prediction&#x27;</span>]</span><br><span class="line">    </span><br><span class="line">    inv_label = &#123;<span class="string">&#x27;negative&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;positive&#x27;</span>: <span class="number">1</span>&#125;</span><br><span class="line">    y = inv_label[prediction]</span><br><span class="line">    <span class="keyword">if</span> feedback == <span class="string">&#x27;Incorrect&#x27;</span>:</span><br><span class="line">y = int(<span class="keyword">not</span>(y))</span><br><span class="line">    train(review, y)</span><br><span class="line">    sqlite_entry(db, review, y)</span><br><span class="line">    <span class="keyword">return</span> render_template(<span class="string">&#x27;thanks.html&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">app.run(debug=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p>接下来，看一下reviewform.html模板：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;!doctype <span class="meta-keyword">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">title</span>&gt;</span>Movie Classification<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">h2</span>&gt;</span>Please enter your movie review:<span class="tag">&lt;/<span class="name">h2</span>&gt;</span></span><br><span class="line">        &#123;% from &quot;_formhelpers.html&quot; import render_field %&#125;</span><br><span class="line">        <span class="tag">&lt;<span class="name">form</span> <span class="attr">method</span>=<span class="string">post</span> <span class="attr">action</span>=<span class="string">&quot;/results&quot;</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">dl</span>&gt;</span></span><br><span class="line">            &#123;&#123; render_field(form.moviereview, cols=&#x27;30&#x27;, rows=&#x27;10&#x27;) &#125;&#125;</span><br><span class="line">            <span class="tag">&lt;/<span class="name">dl</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">submit</span> <span class="attr">value</span>=<span class="string">&#x27;Submit review&#x27;</span> <span class="attr">name</span>=<span class="string">&#x27;submit_btn&#x27;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">form</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure><p>下一个模板是result.html，看上去很有趣：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;!doctype <span class="meta-keyword">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">title</span>&gt;</span>Movie Classification<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">link</span> <span class="attr">rel</span>=<span class="string">&quot;stylesheet&quot;</span> <span class="attr">href</span>=<span class="string">&quot;&#123;&#123; url_for(&#x27;static&#x27;, filename=&#x27;style.css&#x27;) &#125;&#125;&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">h3</span>&gt;</span>Your movie review:<span class="tag">&lt;/<span class="name">h3</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span>&gt;</span>&#123;&#123; content &#125;&#125;<span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">h3</span>&gt;</span>Prediction:<span class="tag">&lt;/<span class="name">h3</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span>&gt;</span>This movie review is <span class="tag">&lt;<span class="name">strong</span>&gt;</span>&#123;&#123; prediction &#125;&#125;<span class="tag">&lt;/<span class="name">strong</span>&gt;</span></span><br><span class="line">        (probability: &#123;&#123; probability &#125;&#125;%).<span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">&#x27;button&#x27;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">form</span> <span class="attr">action</span>=<span class="string">&quot;/thanks&quot;</span> <span class="attr">method</span>=<span class="string">&quot;post&quot;</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">submit</span> <span class="attr">value</span>=<span class="string">&#x27;Correct&#x27;</span> <span class="attr">name</span>=<span class="string">&#x27;feedback_button&#x27;</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">submit</span> <span class="attr">value</span>=<span class="string">&#x27;Incorrect&#x27;</span> <span class="attr">name</span>=<span class="string">&#x27;feedback_button&#x27;</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">hidden</span> <span class="attr">value</span>=<span class="string">&#x27;&#123;&#123; prediction &#125;&#125;&#x27;</span> <span class="attr">name</span>=<span class="string">&#x27;prediction&#x27;</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">hidden</span> <span class="attr">value</span>=<span class="string">&#x27;&#123;&#123; content &#125;&#125;&#x27;</span> <span class="attr">name</span>=<span class="string">&#x27;review&#x27;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">form</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">&#x27;button&#x27;</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">form</span> <span class="attr">action</span>=<span class="string">&quot;/&quot;</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">submit</span> <span class="attr">value</span>=<span class="string">&#x27;Submit another review&#x27;</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">form</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure><p>此外，style.css文件如下：</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">body</span>&#123;</span><br><span class="line"><span class="attribute">width</span>:<span class="number">600px</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-id">#button</span>&#123;</span><br><span class="line"><span class="attribute">padding-top</span>: <span class="number">20px</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>同样，thanks.html的内容如下：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;!doctype <span class="meta-keyword">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">title</span>&gt;</span>Movie Classification<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">h3</span>&gt;</span>Thank you for your feedback!<span class="tag">&lt;/<span class="name">h3</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">&#x27;button&#x27;</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">form</span> <span class="attr">action</span>=<span class="string">&quot;/&quot;</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">submit</span> <span class="attr">value</span>=<span class="string">&#x27;Submit another review&#x27;</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">form</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure><p>同样，最后我们启动Web应用：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python3 app.py</span><br></pre></td></tr></table></figure><p>接下来，我们就可以访问网站了。</p><h2 id="在公共服务器上部署Web应用"><a href="#在公共服务器上部署Web应用" class="headerlink" title="在公共服务器上部署Web应用"></a>在公共服务器上部署Web应用</h2><p>测试完Web应用后，我们可以将其托管到PythonAnywhere服务器上。托管到PythonAnywhere网站后，我们可以通过访问<code>&lt;username&gt;.pythonanywhere.com</code>。</p><p>当收到用户的反馈后，模型会自动即时更新，但是如果服务器崩溃或者重启，clfd对象的更新就会重置。使得更新能够持久化保存的一个方法就是：模型一旦被更新就立即序列化新的clf对象。但是随着用户的增多，此方案的效率会逐渐底下。另外一种解决方案就是使用SQLite数据库保存的反馈信息更新预测模型。为了更新clf对象，我们创建一个update.py脚本文件：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">import</span> sqlite3</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="comment"># import HashingVectorizer from local dir</span></span><br><span class="line"><span class="keyword">from</span> vectorizer <span class="keyword">import</span> vect</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">update_model</span>(<span class="params">db_path, model, batch_size=<span class="number">10000</span></span>):</span></span><br><span class="line">    conn = sqlite3.connect(db_path)</span><br><span class="line">    c = conn.cursor()</span><br><span class="line">    c.execute(<span class="string">&#x27;SELECT * from review_db&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    results = c.fetchmany(batch_size)</span><br><span class="line">    <span class="keyword">while</span> results:</span><br><span class="line">        data = np.array(results)</span><br><span class="line">        X = data[:, <span class="number">0</span>]</span><br><span class="line">        y = data[:, <span class="number">1</span>].astype(int)</span><br><span class="line">        </span><br><span class="line">        classes = np.array([<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">        X_train = vect.transform(X)</span><br><span class="line">        clf.partial_fit(X_train, y, classes=classes)</span><br><span class="line">        results = c.fetchmany(batch_size)</span><br><span class="line">    conn.close()</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">cur_dir = os.path.dirname(__file__)</span><br><span class="line"></span><br><span class="line">clf = pickle.load(open(os.path.join(cur_dir,</span><br><span class="line">                <span class="string">&#x27;pkl_objects&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;classifier.pkl&#x27;</span>), <span class="string">&#x27;rb&#x27;</span>))</span><br><span class="line">db = os.path.join(cur_dir, <span class="string">&#x27;reviews.sqlite&#x27;</span>)</span><br><span class="line"></span><br><span class="line">update_model(db_path=db, model=clf, batch_size=<span class="number">10000</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Uncomment the following lines if you are sure that</span></span><br><span class="line"><span class="comment"># you want to update your classifier.pkl file</span></span><br><span class="line"><span class="comment"># permanently.</span></span><br><span class="line"><span class="comment"># pickle.dump(clf, open(os.path.join(cur_dir,</span></span><br><span class="line"><span class="comment"># &#x27;pkl_objects&#x27;, &#x27;classifier.pkl&#x27;), &#x27;wb&#x27;)</span></span><br><span class="line"><span class="comment"># , protocol=4)</span></span><br></pre></td></tr></table></figure><p>创建好update.py的脚本中，我们需要在app.py开头增加一行导入update.py脚本中update_model函数的代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># import update function from local_dir</span></span><br><span class="line"><span class="keyword">from</span> update <span class="keyword">import</span> update_model</span><br></pre></td></tr></table></figure><p>然后在应用程序的主脚本中调用update_model函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">update_model(filepath=db, model=clf, batch_size=<span class="number">10000</span>)</span><br><span class="line"><span class="meta">... </span>   </span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>使用机器学习进行情感分析</title>
      <link href="2020/02/07/%E4%BD%BF%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%BF%9B%E8%A1%8C%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90/"/>
      <url>2020/02/07/%E4%BD%BF%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%BF%9B%E8%A1%8C%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<p>本章我们将深入研究<strong>自然语言处理</strong>（natural language processing，NLP）领域的一个分支—-<strong>情感分析</strong>（sentiment analysis），还将学习如何使用机器学习算法基于文档的情感倾向对文档进行分类。</p><a id="more"></a><h2 id="获取IMDB电影评论数据集"><a href="#获取IMDB电影评论数据集" class="headerlink" title="获取IMDB电影评论数据集"></a>获取IMDB电影评论数据集</h2><p>情感分析，又是也称作是观点挖掘，是NLP领域一个非常流行的分支，它分析的是文档的情感倾向。本章中，我们将要使用的是互联网电影数据库中的大量电影评论数据。可以访问<a href="http://ai.stanford.edu/~amaas/data/sentiment/%E6%9D%A5%E4%B8%8B%E8%BD%BD%E7%94%B5%E5%BD%B1%E8%AF%84%E8%AE%BA%E3%80%82">http://ai.stanford.edu/~amaas/data/sentiment/来下载电影评论。</a></p><p>在下载完成后对文档进行解压，接下来我们着手将从压缩文件中得到的各文本文档组合为一个CSV文件，在下面的代码中，我们把电影的评论读取到pandas的DataFrame对象中。同时使用PyPrid（Python Progress Indicator）包来预测剩余处理时间：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pyprind</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">pbar = pyprind.ProgBar(<span class="number">50000</span>)</span><br><span class="line">labels = &#123;<span class="string">&#x27;pos&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;neg&#x27;</span>: <span class="number">0</span>&#125;</span><br><span class="line">df = pd.DataFrame()</span><br><span class="line"><span class="keyword">for</span> s <span class="keyword">in</span> (<span class="string">&#x27;test&#x27;</span>, <span class="string">&#x27;train&#x27;</span>):</span><br><span class="line">    <span class="keyword">for</span> l <span class="keyword">in</span> (<span class="string">&#x27;pos&#x27;</span>, <span class="string">&#x27;neg&#x27;</span>):</span><br><span class="line">        path = <span class="string">&#x27;./aclImdb/%s/%s&#x27;</span> % (s, l)</span><br><span class="line">        <span class="keyword">for</span> file <span class="keyword">in</span> os.listdir(path):</span><br><span class="line">            <span class="keyword">with</span> open(os.path.join(path, file), <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> infile:</span><br><span class="line">                txt = infile.read()</span><br><span class="line">            df = df.append([[txt, labels[l]]], ignore_index=<span class="literal">True</span>)</span><br><span class="line">            pbar.update()</span><br><span class="line">df.columns = [<span class="string">&#x27;review&#x27;</span>, <span class="string">&#x27;sentiment&#x27;</span>]</span><br></pre></td></tr></table></figure><p>由于集成处理过后数据集中的对应类标是经过排序的，我们现在使用np.random子模块下的permutation函数对DataFrame对象进行重排，并且将其存储为CSV文件：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">np.random.seed(<span class="number">0</span>)</span><br><span class="line">df = df.reindex(np.random.permutation(df.index))</span><br><span class="line">df.to_csv(<span class="string">&#x27;./movie_data.csv&#x27;</span>, index=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><p>现在读取前三个样本的摘要：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df = pd.read_csv(<span class="string">&#x27;./movie_data.csv&#x27;</span>)</span><br><span class="line">df.head(<span class="number">3</span>)</span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="1581062367489.png" class="lazyload" data-srcset="1581062367489.png" srcset="data:image/png;base64,666" alt="1581062367489"/></div><span class="image-caption">1581062367489</span></div><h2 id="词袋模型简介"><a href="#词袋模型简介" class="headerlink" title="词袋模型简介"></a>词袋模型简介</h2><p>本节中，我们介绍<strong>词袋模型</strong>，它将文本以数值特征向量的形式来表示。词袋模型的理念很简单，可描述如下：</p><ol><li>我们在整个文档上为每个词汇创建了唯一的标记，如单词</li><li>我们为每个文档构建一个特征向量，其中包含每个单词在此文档中出现的次数</li></ol><p>下面讲解创建简单词袋模型的过程。</p><h3 id="将单词转换为特征向量"><a href="#将单词转换为特征向量" class="headerlink" title="将单词转换为特征向量"></a>将单词转换为特征向量</h3><p>我们可以使用scikit-learn中的CountVector类来根据每个文档中的单词数量构建词袋模型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> CountVectorizer</span><br><span class="line">count = CountVectorizer()</span><br><span class="line">docs = np.array([<span class="string">&#x27;The sun is shining&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;The weather is sweet&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;The sun is shining and the weather is sweet&#x27;</span>])</span><br><span class="line">bag = count.fit_transform(docs)</span><br><span class="line">print(count.vocabulary_)</span><br><span class="line">&gt;&gt; &#123;<span class="string">&#x27;the&#x27;</span>: <span class="number">5</span>, <span class="string">&#x27;sun&#x27;</span>: <span class="number">3</span>, <span class="string">&#x27;is&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;shining&#x27;</span>: <span class="number">2</span>, <span class="string">&#x27;weather&#x27;</span>: <span class="number">6</span>, <span class="string">&#x27;sweet&#x27;</span>: <span class="number">4</span>, <span class="string">&#x27;and&#x27;</span>: <span class="number">0</span>&#125;</span><br></pre></td></tr></table></figure><p>由上述命令的运行结果可见，词汇以Python字典的格式存储，将单个单词映射为一个整数索引。接下来看一下之前创建的特征向量：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">print(bag.toarray())</span><br><span class="line">&gt;&gt; [[<span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span>]</span><br><span class="line">&gt;&gt;  [<span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span>]</span><br><span class="line">&gt;&gt;  [<span class="number">1</span> <span class="number">2</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">2</span> <span class="number">1</span>]]</span><br></pre></td></tr></table></figure><p>出现在特征向量中的值也称作是<strong>原始词频</strong>：$ tf(t, d):=词汇t在文档d中出现的次数 $。</p><h3 id="通过词频–逆文档频率计算单词关联度"><a href="#通过词频–逆文档频率计算单词关联度" class="headerlink" title="通过词频–逆文档频率计算单词关联度"></a>通过词频–逆文档频率计算单词关联度</h3><p>当我们分析文档数据时，经常遇到的问题就是：一个单词出现在两种类型的多个文档中，这种频繁出现的单词通常不包含有用或具备辨识度的信息。本节中，我们将会学习<strong>词频–逆文档频率</strong>：<br>$$<br>tf-idf(t, d) = tf(t, d) \times idf(t, d)<br>$$<br>其中，逆文档频率计算公式如下：<br>$$<br>idf(t, d) = log\frac{n_d}{1+df(d, t)}<br>$$<br>这里的$ n_d $问文档的总数，$ df(d, f) $为词汇t在文档d中的数量。分母中的1是为了防止分母为0；取对数是为了出现频率较低的词汇不会被赋予过大的权重。</p><p>scikit-learn中还实现了TfidfTransformer转换器：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> TfidfTransformer</span><br><span class="line">​</span><br><span class="line">tfidf = TfidfTransformer()</span><br><span class="line">np.set_printoptions(precision=<span class="number">2</span>)</span><br><span class="line">print(tfidf.fit_transform(count.fit_transform(docs)).toarray())</span><br><span class="line">&gt;&gt; [[<span class="number">0.</span>   <span class="number">0.43</span> <span class="number">0.56</span> <span class="number">0.56</span> <span class="number">0.</span>   <span class="number">0.43</span> <span class="number">0.</span>  ]</span><br><span class="line">&gt;&gt;  [<span class="number">0.</span>   <span class="number">0.43</span> <span class="number">0.</span>   <span class="number">0.</span>   <span class="number">0.56</span> <span class="number">0.43</span> <span class="number">0.56</span>]</span><br><span class="line">&gt;&gt;  [<span class="number">0.4</span>  <span class="number">0.48</span> <span class="number">0.31</span> <span class="number">0.31</span> <span class="number">0.31</span> <span class="number">0.48</span> <span class="number">0.31</span>]]</span><br></pre></td></tr></table></figure><p>可以发现，is在第三个文档中具有较高的词频，但是在将特征向量转换为$ tf-idf $后，单词is在第三个文档中只得到了一个相对较小的$ tf-idf $。</p><blockquote><p>scikit-learn中计算$ tf-idf $之前都会对原始词频进行归一化处理。</p></blockquote><h3 id="清洗文本数据"><a href="#清洗文本数据" class="headerlink" title="清洗文本数据"></a>清洗文本数据</h3><p>在构建词袋模型之前，最重要的一步就是去除所有不需要的字符对文本数据进行清洗。我们先展示一下经过重排后数据集中第一个文档的最后50个字符：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df.loc[<span class="number">0</span>, <span class="string">&#x27;review&#x27;</span>][<span class="number">-50</span>:]</span><br><span class="line">&gt;&gt; <span class="string">&#x27;is seven.&lt;br /&gt;&lt;br /&gt;Title (Brazil): Not Available&#x27;</span></span><br></pre></td></tr></table></figure><p>接下来，我们将会去除标点符号和HTML标签：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">preprocessor</span>(<span class="params">text</span>):</span></span><br><span class="line">    text = re.sub(<span class="string">&#x27;&lt;[^&gt;]*&gt;&#x27;</span>, <span class="string">&#x27;&#x27;</span>, text)</span><br><span class="line">    text = re.sub(<span class="string">&#x27;[\W]+&#x27;</span>, <span class="string">&#x27; &#x27;</span>, text.lower())</span><br><span class="line">    <span class="keyword">return</span> text</span><br></pre></td></tr></table></figure><p>接下来我们看一下该函数是否能正常工作：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">preprocessor(df.loc[<span class="number">0</span>, <span class="string">&#x27;review&#x27;</span>][<span class="number">-50</span>:])</span><br><span class="line">&gt;&gt; <span class="string">&#x27;is seven title brazil not available&#x27;</span></span><br></pre></td></tr></table></figure><p>最后，我们在下一节中将会反复使用在此经过清洗的文本数据，现在通过preprocessor函数清洗所有的电影评论：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">&#x27;review&#x27;</span>] = df[<span class="string">&#x27;review&#x27;</span>].apply(preprocessor)</span><br></pre></td></tr></table></figure><h3 id="标记文档"><a href="#标记文档" class="headerlink" title="标记文档"></a>标记文档</h3><p>准备好电影评论数据集后，我们需要将文本语料拆分为单独的元素。<strong>标记</strong>（tokenize）文档的一个常用方法是通过文档的空白字符将其拆分为单独的单词：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tokenizer</span>(<span class="params">text</span>):</span></span><br><span class="line">    <span class="keyword">return</span> text.split()</span><br><span class="line">tokenizer(<span class="string">&#x27;runner likes running and thus he run&#x27;</span>)</span><br><span class="line">&gt;&gt; [<span class="string">&#x27;runner&#x27;</span>, <span class="string">&#x27;likes&#x27;</span>, <span class="string">&#x27;running&#x27;</span>, <span class="string">&#x27;and&#x27;</span>, <span class="string">&#x27;thus&#x27;</span>, <span class="string">&#x27;he&#x27;</span>, <span class="string">&#x27;run&#x27;</span>]</span><br></pre></td></tr></table></figure><p>在对文本标记的过程中，另外一种有用的技术就是<strong>词干提取</strong>（word stemming），这是一个提取单词原型的过程，这样，我们就能将一个单词映射到对应的词干上。Python的自然语言工具包（NLPK）实现了Porter Stemming算法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.stem <span class="keyword">import</span> PorterStemmer</span><br><span class="line">porter = PorterStemmer()</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tokenizer_porter</span>(<span class="params">text</span>):</span></span><br><span class="line">    <span class="keyword">return</span> [porter.stem(word) <span class="keyword">for</span> word <span class="keyword">in</span> text.split()]</span><br><span class="line">tokenizer_porter(<span class="string">&#x27;runner likes running and thus he run&#x27;</span>)</span><br><span class="line">&gt;&gt; [<span class="string">&#x27;runner&#x27;</span>, <span class="string">&#x27;like&#x27;</span>, <span class="string">&#x27;run&#x27;</span>, <span class="string">&#x27;and&#x27;</span>, <span class="string">&#x27;thu&#x27;</span>, <span class="string">&#x27;he&#x27;</span>, <span class="string">&#x27;run&#x27;</span>]</span><br></pre></td></tr></table></figure><p>可以发现，running被修改为run，但是thus被修改为不存在的单词thu。在实际应用中中，这种结果造成的影响不大。</p><p>另外，还有一种有用的技术：<strong>停用词移除</strong>（stop-word removal）。停用词在英文中太常见了，它们包含很少的有用信息，因此可以将他们删除：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line"><span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> stopwords</span><br><span class="line">nltk.download(<span class="string">&#x27;stopwords&#x27;</span>)</span><br><span class="line">stop = stopwords.words(<span class="string">&#x27;english&#x27;</span>)</span><br><span class="line">[w <span class="keyword">for</span> w <span class="keyword">in</span> tokenizer_porter(<span class="string">&#x27;a runner likes running and runs a lot&#x27;</span>)[<span class="number">-10</span>:] <span class="keyword">if</span> w <span class="keyword">not</span> <span class="keyword">in</span> stop]</span><br><span class="line">&gt;&gt; [<span class="string">&#x27;runner&#x27;</span>, <span class="string">&#x27;like&#x27;</span>, <span class="string">&#x27;run&#x27;</span>, <span class="string">&#x27;and&#x27;</span>, <span class="string">&#x27;thu&#x27;</span>, <span class="string">&#x27;he&#x27;</span>, <span class="string">&#x27;run&#x27;</span>]</span><br></pre></td></tr></table></figure><h2 id="训练用于文档分类的逻辑斯蒂回归模型"><a href="#训练用于文档分类的逻辑斯蒂回归模型" class="headerlink" title="训练用于文档分类的逻辑斯蒂回归模型"></a>训练用于文档分类的逻辑斯蒂回归模型</h2><p>本节中，我们将会使用逻辑斯蒂回归模型将电影评论分为正面评价和负面评价。首先，我们将文本对象划分为测试数据和训练数据：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">X_train = df.loc[:<span class="number">25000</span>, <span class="string">&#x27;review&#x27;</span>].values</span><br><span class="line">y_train = df.loc[:<span class="number">25000</span>, <span class="string">&#x27;sentiment&#x27;</span>].values</span><br><span class="line">X_test = df.loc[<span class="number">25000</span>:, <span class="string">&#x27;review&#x27;</span>].values</span><br><span class="line">y_test = df.loc[<span class="number">25000</span>:, <span class="string">&#x27;sentiment&#x27;</span>].values</span><br></pre></td></tr></table></figure><p>接着我们使用Grid Search CV对象，并且使用5折分层交叉验证找到最佳参数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> TfidfVectorizer</span><br><span class="line">tfidf =  TfidfVectorizer(strip_accents=<span class="literal">None</span>, lowercase=<span class="literal">False</span>, preprocessor=<span class="literal">None</span>)</span><br><span class="line">param_grid = [&#123;<span class="string">&#x27;vect__ngram_range&#x27;</span>: [(<span class="number">1</span>, <span class="number">1</span>)],</span><br><span class="line">              <span class="string">&#x27;vect__stop_words&#x27;</span>: [stop, <span class="literal">None</span>],</span><br><span class="line">              <span class="string">&#x27;vect__tokenizer&#x27;</span>: [tokenizer, tokenizer_porter],</span><br><span class="line">              <span class="string">&#x27;clf__penalty&#x27;</span>: [<span class="string">&#x27;l1&#x27;</span>, <span class="string">&#x27;l2&#x27;</span>],</span><br><span class="line">              <span class="string">&#x27;clf__C&#x27;</span>: [<span class="number">1.0</span>, <span class="number">10.0</span>, <span class="number">100.0</span>]&#125;,</span><br><span class="line">             &#123;<span class="string">&#x27;vect__ngram_range&#x27;</span>: [(<span class="number">1</span>, <span class="number">1</span>)],</span><br><span class="line">              <span class="string">&#x27;vect__stop_words&#x27;</span>: [stop, <span class="literal">None</span>],</span><br><span class="line">              <span class="string">&#x27;vect__tokenizer&#x27;</span>: [tokenizer, tokenizer_porter],</span><br><span class="line">              <span class="string">&#x27;vect__use_idf&#x27;</span>: [<span class="literal">False</span>],</span><br><span class="line">              <span class="string">&#x27;vect__norm&#x27;</span>: [<span class="literal">None</span>],</span><br><span class="line">              <span class="string">&#x27;clf__penalty&#x27;</span>: [<span class="string">&#x27;l1&#x27;</span>, <span class="string">&#x27;l2&#x27;</span>],</span><br><span class="line">              <span class="string">&#x27;clf__C&#x27;</span>: [<span class="number">1.0</span>, <span class="number">10.0</span>, <span class="number">100.0</span>]&#125;]</span><br><span class="line">lr_tfidf = Pipeline([(<span class="string">&#x27;vect&#x27;</span>, tfidf),</span><br><span class="line">                    (<span class="string">&#x27;clf&#x27;</span>, LogisticRegression(random_state=<span class="number">0</span>))])</span><br><span class="line">gs_lr_tfidf = GridSearchCV(lr_tfidf, param_grid, scoring=<span class="string">&#x27;accuracy&#x27;</span>, cv=<span class="number">5</span>, verbose=<span class="number">1</span>, n_jobs=<span class="number">-1</span>)</span><br><span class="line">gs_lr_tfidf.fit(X_train, y_train)</span><br></pre></td></tr></table></figure><p>在网格搜索结束后，我们可以输出最佳的参数集：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">&#x27;Best params: %s&#x27;</span> % gs_lr_tfidf.best_params_)</span><br><span class="line">&gt;&gt; Best params: &#123;<span class="string">&#x27;clf__C&#x27;</span>: <span class="number">10.0</span>, <span class="string">&#x27;clf__penalty&#x27;</span>: <span class="string">&#x27;l2&#x27;</span>, <span class="string">&#x27;vect__ngram_range&#x27;</span>: (<span class="number">1</span>, <span class="number">1</span>), <span class="string">&#x27;vect__stop_words&#x27;</span>: <span class="literal">None</span>, <span class="string">&#x27;vect__tokenizer&#x27;</span>: &lt;function tokenizer at <span class="number">0x000002517B0C5F78</span>&gt;&#125;</span><br></pre></td></tr></table></figure><p>使用网格搜索得到的最佳模型，我们分别输出5折交叉验证的准确率得分，以及在测试数据集上的分类准确率：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">&#x27;CV acc: %s&#x27;</span> % gs_lr_tfidf.best_score_)</span><br><span class="line">&gt;&gt; CV acc: <span class="number">0.8974041038358466</span></span><br><span class="line">clf = gs_lr_tfidf.best_estimator_</span><br><span class="line">print(<span class="string">&#x27;Test acc: %s&#x27;</span> % clf.score(X_test, y_test))</span><br><span class="line">&gt;&gt; Test acc: <span class="number">0.89844</span></span><br></pre></td></tr></table></figure><p>结果表明，我们的机器学习模型针对电影评论是正面评论还是负面评论的分类准确率为90%。</p><h2 id="使用大数据之在线算法与外存学习"><a href="#使用大数据之在线算法与外存学习" class="headerlink" title="使用大数据之在线算法与外存学习"></a>使用大数据之在线算法与外存学习</h2><p>在上一节中，使用网格搜索最佳参数的算法计算成本很高。回顾一下第2章中的<strong>随机梯度下降</strong>（stochastic gradient descent， SGD）概念，此优化算法每次使用一个样本来更新模型的权重信息。在本节中，我们将使用scikit-learn中SGDClassifier的partial_fit函数来读取本地存储设备，并且使用小型子批次（minibatches）文档来训练一个逻辑斯蒂回归模型。</p><p>首先，我们定义一个tokenizer函数来清理movie_data.csv文件中未经处理的文本数据：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> stopwords</span><br><span class="line">stop = stopwords.words(<span class="string">&#x27;english&#x27;</span>)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tokenizer</span>(<span class="params">text</span>):</span></span><br><span class="line">    text = re.sub(<span class="string">&#x27;&lt;[^&gt;]*&gt;&#x27;</span>, <span class="string">&#x27;&#x27;</span>, text)</span><br><span class="line">    text = re.sub(<span class="string">&#x27;[\W]+&#x27;</span>, <span class="string">&#x27; &#x27;</span>, text.lower())</span><br><span class="line">    tokenized = [w <span class="keyword">for</span> w <span class="keyword">in</span> text.split() <span class="keyword">if</span> w <span class="keyword">not</span> <span class="keyword">in</span> stop]</span><br><span class="line">    <span class="keyword">return</span> tokenized</span><br></pre></td></tr></table></figure><p>接下来我们定义一个生成器函数：stream_docs，它每次读取且返回一个文档的内容：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">stream_docs</span>(<span class="params">path</span>):</span></span><br><span class="line">    <span class="keyword">with</span> open(path, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> scv:</span><br><span class="line">        next(csv)</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> csv:</span><br><span class="line">            text, label = line[:<span class="number">-3</span>], int(line[<span class="number">-2</span>])</span><br><span class="line">            <span class="keyword">yield</span> text, label</span><br></pre></td></tr></table></figure><p>定义一个get_minibatch函数，它以stream_doc函数得到的文档数据流作为输入，并且通过size返回指定数量的文档内容：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_minibatch</span>(<span class="params">doc_stream, size</span>):</span></span><br><span class="line">    docs, y = [], []</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> range(size):</span><br><span class="line">            text, label = next(doc_stream)</span><br><span class="line">            docs.append(text)</span><br><span class="line">            y.append(label)</span><br><span class="line">    <span class="keyword">except</span> StopIteration:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line">    <span class="keyword">return</span> docs, y</span><br></pre></td></tr></table></figure><p>不幸的是，由于需要将所有的词汇加载到内存中，我们无法通过CountVectorizer来使用外存学习方法。另外，TfidfVectorizer需要将所有训练数据集中的特征向量加载到内存以计算逆文档频率。不过，scikit-learn提供了另外一个处理文本信息的向量处理器：HashingVectorizer。HashingVectorizer是独立数据的：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> HashingVectorizer</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> SGDClassifier</span><br><span class="line">vect = HashingVectorizer(decode_error=<span class="string">&#x27;ignore&#x27;</span>,</span><br><span class="line">                        n_features=<span class="number">2</span>**<span class="number">21</span>,</span><br><span class="line">                        preprocessor=<span class="literal">None</span>,</span><br><span class="line">                        tokenizer=tokenizer)</span><br><span class="line">clf = SGDClassifier(loss=<span class="string">&#x27;log&#x27;</span>, random_state=<span class="number">1</span>, n_iter=<span class="number">1</span>)</span><br><span class="line">doc_stream = stream_docs(path=<span class="string">&#x27;./movie_data.csv&#x27;</span>)</span><br></pre></td></tr></table></figure><p>接下来我们可以通过下述代码使用外存学习：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pyprind</span><br><span class="line">pbar = pyprind.ProgBar(<span class="number">45</span>)</span><br><span class="line">classes = np.array([<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">45</span>):</span><br><span class="line">    X_train, y_train = get_minibatch(doc_stream, size=<span class="number">1000</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> X_train:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    X_train = vect.transform(X_train)</span><br><span class="line">    clf.partial_fit(X_train, y_train, classes=classes)</span><br><span class="line">    pbar.update()</span><br></pre></td></tr></table></figure><p>完成增量学习后，我们将使用剩余的5000个文档来评估模型的性能：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">X_test, y_test = get_minibatch(doc_stream, size=<span class="number">5000</span>)</span><br><span class="line">X_test = vect.transform(X_test)</span><br><span class="line">print(<span class="string">&#x27;Acc: %.3f&#x27;</span> % clf.score(X_test, y_test))</span><br><span class="line">&gt;&gt; Acc: <span class="number">0.868</span></span><br></pre></td></tr></table></figure><p>可以看到，模型的准确率约为87%，略微低于我们上一节我们使用网格搜索进行超参调优得到的模型。不过外存学习的存储效率高，只用了不到一分钟的实践就完成了。最后，我们可以通过剩下的5000个文档进行升级：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">clf = clf.partial_fit(X_test, y_test)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>集成学习之组合不同的模型</title>
      <link href="2020/02/06/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E4%B9%8B%E7%BB%84%E5%90%88%E4%B8%8D%E5%90%8C%E7%9A%84%E6%A8%A1%E5%9E%8B/"/>
      <url>2020/02/06/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E4%B9%8B%E7%BB%84%E5%90%88%E4%B8%8D%E5%90%8C%E7%9A%84%E6%A8%A1%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<p>本章中，我们将会学习如何构建一组分类器的集合，使得整体分类效果优于其中任意一个单独的分类器。</p><a id="more"></a><h2 id="集成学习"><a href="#集成学习" class="headerlink" title="集成学习"></a>集成学习</h2><p><strong>集成方法</strong>（ensemble method）的目标是：将不同的分类器组合成一个元分类器，与包含于其中的单个分类器相比，元分类器具有更好的泛化性能。</p><p>本章中介绍的几种流行的集成方法，它们都使用了<strong>多数投票</strong>（majority voting）。多数投票原则是将大多数分类器预测的结果作为最终的预测指标。基于训练集，我们首先训练m个不同的成员分类器（$ C_1, \cdots, C_m $），接着我们将新的未知数据$ x $输入，然后对所有分类器$ C_j $的预测类标进行汇总，选择出得票率最高的类标$ \hat{y} $：<br>$$<br>\hat{y} = mode{C_1(x), \cdots, C_m(x)}<br>$$</p><blockquote><p>mode函数：众数函数，返回出现次数最多的值。</p></blockquote><p>另外，由统计学知识得到，当成员分类器出错率低于$ 50% $时，集成分类器的出错率要低于单个分类器。</p><h2 id="实现一个简单的多数投票分类器"><a href="#实现一个简单的多数投票分类器" class="headerlink" title="实现一个简单的多数投票分类器"></a>实现一个简单的多数投票分类器</h2><p>集成算法允许我们使用单独的权重对不同分类算法进行组合，可以将加权多数投票记为：<br>$$<br>\hat{y} = argmax_i\sum_{j=1}^{m}w_j\chi_A(C_j(x)=i)<br>$$<br>其中，$ w_j $是$ C_j $分类器的权重。</p><blockquote><p>argmax是一种函数，是对函数求参数(集合)的函数。当我们有另一个函数$ y=f(x) $时，若有结果$ x_0= argmax(f(x)) $，则表示当函数$ argmax(f(x)) $取$ x=x_0 $的时候，得到f(x)取值范围的最大值；若有多个点使得f(x)取得相同的最大值，那么$ argmax(f(x)) $的结果就是一个点集。</p></blockquote><p>为了使用Python代码实现加权多数投票，我们可以使用NumPy中的argmax和bincount函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">np.argmax(np.bincount([<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>],  weights=[<span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.6</span>]))</span><br><span class="line">&gt;&gt; <span class="number">1</span></span><br></pre></td></tr></table></figure><p>在实际应用中，我们可以将原来的类标转换为预测类表的概率，这样修正公式如下：<br>$$<br>\hat{y} = argmax_i\sum_{j=1}^mw_jp_{ij}<br>$$<br>其中，$ p_{ij} $是第j个分类器预测样本类标为i的概率。</p><p>为实现基于类别预测概率的加权多数投票，我们可以使用如下代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ex = np.array([[<span class="number">0.9</span>, <span class="number">0.1</span>],</span><br><span class="line">              [<span class="number">0.8</span>, <span class="number">0.2</span>],</span><br><span class="line">              [<span class="number">0.4</span>, <span class="number">0.6</span>]])</span><br><span class="line">p = np.average(ex, axis=<span class="number">0</span>, weights=[<span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.6</span>])</span><br><span class="line">print(p, np.argmax(p))</span><br><span class="line">&gt;&gt; [<span class="number">0.58</span> <span class="number">0.42</span>] <span class="number">0</span></span><br></pre></td></tr></table></figure><p>综上，我们可以实现<code>MajorityVoteClassifier</code>:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.base <span class="keyword">import</span> BaseEstimator</span><br><span class="line"><span class="keyword">from</span> sklearn.base <span class="keyword">import</span> ClassifierMixin</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"><span class="keyword">from</span> sklearn.externals <span class="keyword">import</span> six</span><br><span class="line"><span class="keyword">from</span> sklearn.base <span class="keyword">import</span> clone</span><br><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> _name_estimators</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> operator</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MajorityVoteClassifier</span>(<span class="params">BaseEstimator, ClassifierMixin</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, classifiers, vote=<span class="string">&#x27;classlabel&#x27;</span>, weights=None</span>):</span></span><br><span class="line">        self.classifiers = classifiers</span><br><span class="line">        self.named_classifiers = &#123;key: value <span class="keyword">for</span> key, value <span class="keyword">in</span> _name_estimators(classifiers)&#125;</span><br><span class="line">        self.vote = vote</span><br><span class="line">        self.weights = weights</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, X, y</span>):</span></span><br><span class="line">        self.labelenc_ = LabelEncoder()</span><br><span class="line">        self.labelenc_.fit(y)</span><br><span class="line">        self.classes_ = self.labelenc_.classes_</span><br><span class="line">        self.classifiers_ = []</span><br><span class="line">        <span class="keyword">for</span> clf <span class="keyword">in</span> self.classifiers:</span><br><span class="line">            fitted_clf = clone(clf).fit(X, self.labelenc_.transform(y))</span><br><span class="line">            self.classifiers_.append(fitted_clf)</span><br><span class="line">        <span class="keyword">return</span> self</span><br></pre></td></tr></table></figure><p>在这里，我们使用了两个基类<code>BaseEstimator</code>和<code>ClassifierMixIn</code>获取某些基本方法，包括设定分类器参数的<code>set_params</code>和返回参数的<code>get_params</code>方法，以及用于计算预测准确度的score方法。此外，导入six包是为了使得MajorityVoteClassifier与Python 2.7兼容。</p><p>接下来，我们加入predict方法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self, X</span>):</span></span><br><span class="line">    <span class="keyword">if</span> self.vote == <span class="string">&#x27;probability&#x27;</span>:</span><br><span class="line">        maj_vote = np.argmax(self.predict_proba(X), axis=<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        predictions = np.asarray([clf.predict(X) <span class="keyword">for</span> clf <span class="keyword">in</span> self.classifiers_]).T</span><br><span class="line">        maj_vote = np.apply_along_axis(<span class="keyword">lambda</span> x:</span><br><span class="line">                                      np.argmax(np.bincount(x, weights=self.weights)),</span><br><span class="line">                                      axis=<span class="number">1</span>,</span><br><span class="line">                                      arr=predictions)</span><br><span class="line">    maj_vote = self.labelenc_.inverse_transform(maj_vote)</span><br><span class="line">    <span class="keyword">return</span> maj_vote</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict_proba</span>(<span class="params">self, X</span>):</span></span><br><span class="line">    probas = np.asarray([clf.predict_proba(X) <span class="keyword">for</span> clf <span class="keyword">in</span> self.classifiers_])</span><br><span class="line">    avg_proba = np.average(probas, axis=<span class="number">0</span>, weights=self.weights)</span><br><span class="line">    <span class="keyword">return</span> avg_proba</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_params</span>(<span class="params">self, deep=True</span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> deep:</span><br><span class="line">        <span class="keyword">return</span> super(MajorityVoteClassifier, self).get_params(deep=<span class="literal">False</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        out = self.named_classifiers.copy()</span><br><span class="line">        <span class="keyword">for</span> name, step <span class="keyword">in</span> six.iteritems(self.named_classifiers):</span><br><span class="line">            <span class="keyword">for</span> key, value <span class="keyword">in</span> six.iteritems(step.get_params(deep=<span class="literal">True</span>)):</span><br><span class="line">                out[<span class="string">&#x27;%s__%s&#x27;</span> % (name, key)] = value</span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure><p>接下来我们可以将上述算法用于实战了。我们导入鸢尾花数据集，并且只是用其中的两个特征：<strong>萼片宽度</strong>和<strong>花瓣长度</strong>。同时我们只区分两个类别的样本：Iris-Versicolor和Iris-Virginica，并且绘制ROC AUC曲线：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"></span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line">X, y = iris.data[<span class="number">50</span>:, [<span class="number">1</span>, <span class="number">2</span>]], iris.target[<span class="number">50</span>:]</span><br><span class="line">le = LabelEncoder()</span><br><span class="line">y = le.fit_transform(y)</span><br></pre></td></tr></table></figure><p>下面划分数据集为测试数据集和训练数据集：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.5</span>, random_state=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>接下来将数据集训练三种不同类型的分类器：逻辑斯蒂回归分类器，决策树分类器和k-近邻分类器各一个：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> py</span><br><span class="line"></span><br><span class="line">clf1 = LogisticRegression(penalty=<span class="string">&#x27;l2&#x27;</span>, C=<span class="number">0.01</span>, random_state=<span class="number">0</span>)</span><br><span class="line">clf2 = DecisionTreeClassifier(max_depth=<span class="number">1</span>, criterion=<span class="string">&#x27;entropy&#x27;</span>, random_state=<span class="number">0</span>)</span><br><span class="line">clf3 = KNeighborsClassifier(n_neighbors=<span class="number">1</span>, p=<span class="number">2</span>, metric=<span class="string">&#x27;minkowski&#x27;</span>)</span><br><span class="line">pipe1 = Pipeline([[<span class="string">&#x27;sc&#x27;</span>, StandardScaler()], [<span class="string">&#x27;clf&#x27;</span>, clf1]])</span><br><span class="line">pipe3 = Pipeline([[<span class="string">&#x27;sc&#x27;</span>, StandardScaler()], [<span class="string">&#x27;clf&#x27;</span>, clf3]])</span><br><span class="line">clf_labels = [<span class="string">&#x27;LR&#x27;</span>, <span class="string">&#x27;DT&#x27;</span>, <span class="string">&#x27;KNN&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> clf, label <span class="keyword">in</span> zip([pipe1, clf2, pipe3], clf_labels):</span><br><span class="line">    scores = cross_val_score(estimator=clf, X=X_train, y=y_train, cv=<span class="number">10</span>, scoring=<span class="string">&#x27;roc_auc&#x27;</span>)</span><br><span class="line">    print(<span class="string">&#x27;ROC AUC: %.3f +/- %.3f [%s]&#x27;</span> % (scores.mean(), scores.std(), label))</span><br><span class="line">&gt;&gt; ROC AUC: <span class="number">0.917</span> +/- <span class="number">0.201</span> [LR]</span><br><span class="line">&gt;&gt; ROC AUC: <span class="number">0.917</span> +/- <span class="number">0.154</span> [DT]</span><br><span class="line">&gt;&gt; ROC AUC: <span class="number">0.933</span> +/- <span class="number">0.104</span> [KNN]</span><br></pre></td></tr></table></figure><p>在此，为什么将逻辑斯蒂回归和k-近邻分类器的训练作为流水线的一部分？不同于决策树，逻辑斯蒂回归和k-近邻算法对数据缩放不敏感，需要对其进行数据标准化处理。</p><p>接下来我们基于多数投票原则，在其中组合成员分类器：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">mv_clf = MajorityVoteClassifier(classifiers=[pipe1, clf2, pipe3])</span><br><span class="line">clf_labels += [<span class="string">&#x27;MV&#x27;</span>]</span><br><span class="line">all_clf = (pipe1, clf2, pipe3, mv_clf)</span><br><span class="line"><span class="keyword">for</span> clf, label <span class="keyword">in</span> zip(all_clf, clf_labels):</span><br><span class="line">    scores = cross_val_score(estimator=clf, X=X_train, y=y_train, cv=<span class="number">10</span>, scoring=<span class="string">&#x27;roc_auc&#x27;</span>)</span><br><span class="line">    print(<span class="string">&#x27;ROC AUC: %.3f +/- %.3f [%s]&#x27;</span> % (scores.mean(), scores.std(), label))</span><br><span class="line">&gt;&gt; ROC AUC: <span class="number">0.917</span> +/- <span class="number">0.201</span> [LR]</span><br><span class="line">&gt;&gt; ROC AUC: <span class="number">0.917</span> +/- <span class="number">0.154</span> [DT]</span><br><span class="line">&gt;&gt; ROC AUC: <span class="number">0.933</span> +/- <span class="number">0.104</span> [KNN]</span><br><span class="line">&gt;&gt; ROC AUC: <span class="number">0.967</span> +/- <span class="number">0.100</span> [MV]</span><br></pre></td></tr></table></figure><p>从上述输出来看，以10折交叉验证作为评估标准，MajorityVotingClassifier的性能与单个成员分类器相比有着质的提高。</p><h2 id="评估与调优集成分类器"><a href="#评估与调优集成分类器" class="headerlink" title="评估与调优集成分类器"></a>评估与调优集成分类器</h2><p>接下来，我们将在测试数据上计算多数投票的ROC曲线，以验证其在未知数据上的泛化性能：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_curve</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> auc</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">colors = [<span class="string">&#x27;black&#x27;</span>, <span class="string">&#x27;orange&#x27;</span>, <span class="string">&#x27;blue&#x27;</span>, <span class="string">&#x27;green&#x27;</span>]</span><br><span class="line">linestyles = [<span class="string">&#x27;:&#x27;</span>, <span class="string">&#x27;--&#x27;</span>, <span class="string">&#x27;-.&#x27;</span>, <span class="string">&#x27;-&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> clf, label, clr, ls <span class="keyword">in</span> zip(all_clf, clf_labels, colors, linestyles):</span><br><span class="line">    y_pred = clf.fit(X_train, y_train).predict_proba(X_test)[:, <span class="number">1</span>]</span><br><span class="line">    fpr, tpr, thresholds = roc_curve(y_true=y_test, y_score=y_pred)</span><br><span class="line">    roc_auc = auc(x=fpr, y=tpr)</span><br><span class="line">    plt.plot(fpr, tpr, color=clr, linestyle=ls, label=<span class="string">&#x27;%s (auc = %.3f)&#x27;</span> % (label, roc_auc))</span><br><span class="line">plt.legend()</span><br><span class="line">plt.xlim([<span class="number">-0.1</span>, <span class="number">1.1</span>])</span><br><span class="line">plt.ylim([<span class="number">-0.1</span>, <span class="number">1.1</span>])</span><br><span class="line">plt.grid()</span><br><span class="line">plt.xlabel(<span class="string">&#x27;False Positive Rate&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;True Postive Rate&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>得到的图像如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="Thu,%2006%20Feb%202020%20201055.png" class="lazyload" data-srcset="Thu,%2006%20Feb%202020%20201055.png" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><p>由ROC结果我们可以得到，继承分类器在测试集上表现优秀（ROC AUC = 0.95），而KNN分类器对于训练数据有些过拟合。</p><p>在学习集成分类的成员分类器调优之前，我们调用一下get_param方法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mv_clf.get_params()</span><br></pre></td></tr></table></figure><p>输出如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="string">&#x27;pipeline-1&#x27;</span>: Pipeline(memory=<span class="literal">None</span>,</span><br><span class="line">          steps=[(<span class="string">&#x27;sc&#x27;</span>,</span><br><span class="line">                  StandardScaler(copy=<span class="literal">True</span>, with_mean=<span class="literal">True</span>, with_std=<span class="literal">True</span>)),</span><br><span class="line">                 [<span class="string">&#x27;clf&#x27;</span>,</span><br><span class="line">                  LogisticRegression(C=<span class="number">0.01</span>, class_weight=<span class="literal">None</span>, dual=<span class="literal">False</span>,</span><br><span class="line">                                     fit_intercept=<span class="literal">True</span>, intercept_scaling=<span class="number">1</span>,</span><br><span class="line">                                     l1_ratio=<span class="literal">None</span>, max_iter=<span class="number">100</span>,</span><br><span class="line">                                     multi_class=<span class="string">&#x27;warn&#x27;</span>, n_jobs=<span class="literal">None</span>,</span><br><span class="line">                                     penalty=<span class="string">&#x27;l2&#x27;</span>, random_state=<span class="number">0</span>, solver=<span class="string">&#x27;warn&#x27;</span>,</span><br><span class="line">                                     tol=<span class="number">0.0001</span>, verbose=<span class="number">0</span>, warm_start=<span class="literal">False</span>)]],</span><br><span class="line">          verbose=<span class="literal">False</span>),</span><br><span class="line">...</span><br><span class="line"> <span class="string">&#x27;pipeline-2__clf__leaf_size&#x27;</span>: <span class="number">30</span>,</span><br><span class="line"> <span class="string">&#x27;pipeline-2__clf__metric&#x27;</span>: <span class="string">&#x27;minkowski&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;pipeline-2__clf__metric_params&#x27;</span>: <span class="literal">None</span>,</span><br><span class="line"> <span class="string">&#x27;pipeline-2__clf__n_jobs&#x27;</span>: <span class="literal">None</span>,</span><br><span class="line"> <span class="string">&#x27;pipeline-2__clf__n_neighbors&#x27;</span>: <span class="number">1</span>,</span><br><span class="line"> <span class="string">&#x27;pipeline-2__clf__p&#x27;</span>: <span class="number">2</span>,</span><br><span class="line"> <span class="string">&#x27;pipeline-2__clf__weights&#x27;</span>: <span class="string">&#x27;uniform&#x27;</span>&#125;</span><br></pre></td></tr></table></figure><p>接下来我们先通过网格搜索来调整逻辑斯蒂回归分类器的正则化系数倒数C以及决策深度：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line">params = &#123;<span class="string">&#x27;decisiontreeclassifier__max_depth&#x27;</span>: [<span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">         <span class="string">&#x27;pipeline-1__clf__C&#x27;</span>: [<span class="number">0.001</span>, <span class="number">0.1</span>, <span class="number">100.0</span>]&#125;</span><br><span class="line">grid = GridSearchCV(estimator=mv_clf, param_grid=params, cv=<span class="number">10</span>, scoring=<span class="string">&#x27;roc_auc&#x27;</span>)</span><br><span class="line">grid.fit(X_train, y_train)</span><br><span class="line">res = grid.cv_results_</span><br><span class="line"><span class="keyword">for</span> params, mean_score, std_score <span class="keyword">in</span> zip(res[<span class="string">&#x27;params&#x27;</span>], res[<span class="string">&#x27;mean_test_score&#x27;</span>], res[<span class="string">&#x27;std_test_score&#x27;</span>]):</span><br><span class="line">    print(<span class="string">&#x27;%.3f +/- %.3f %r&#x27;</span> % (mean_score, std_score, params))</span><br></pre></td></tr></table></figure><p>得到的结果如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0.967</span> +/- <span class="number">0.100</span> &#123;<span class="string">&#x27;decisiontreeclassifier__max_depth&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;pipeline-1__clf__C&#x27;</span>: <span class="number">0.001</span>&#125;</span><br><span class="line"><span class="number">0.967</span> +/- <span class="number">0.100</span> &#123;<span class="string">&#x27;decisiontreeclassifier__max_depth&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;pipeline-1__clf__C&#x27;</span>: <span class="number">0.1</span>&#125;</span><br><span class="line"><span class="number">1.000</span> +/- <span class="number">0.000</span> &#123;<span class="string">&#x27;decisiontreeclassifier__max_depth&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;pipeline-1__clf__C&#x27;</span>: <span class="number">100.0</span>&#125;</span><br><span class="line"><span class="number">0.967</span> +/- <span class="number">0.100</span> &#123;<span class="string">&#x27;decisiontreeclassifier__max_depth&#x27;</span>: <span class="number">2</span>, <span class="string">&#x27;pipeline-1__clf__C&#x27;</span>: <span class="number">0.001</span>&#125;</span><br><span class="line"><span class="number">0.967</span> +/- <span class="number">0.100</span> &#123;<span class="string">&#x27;decisiontreeclassifier__max_depth&#x27;</span>: <span class="number">2</span>, <span class="string">&#x27;pipeline-1__clf__C&#x27;</span>: <span class="number">0.1</span>&#125;</span><br><span class="line"><span class="number">1.000</span> +/- <span class="number">0.000</span> &#123;<span class="string">&#x27;decisiontreeclassifier__max_depth&#x27;</span>: <span class="number">2</span>, <span class="string">&#x27;pipeline-1__clf__C&#x27;</span>: <span class="number">100.0</span>&#125;</span><br></pre></td></tr></table></figure><p>最优的参数和准确度如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">&#x27;Best params: %s\nAcc: %.3f&#x27;</span> % (grid.best_score_, grid.best_score_))</span><br><span class="line">&gt;&gt; Best params: <span class="number">1.0</span></span><br><span class="line">&gt;&gt; Acc: <span class="number">1.000</span></span><br></pre></td></tr></table></figure><p>可以发现，当选择正则化强度较小时，我们能得到最佳的交叉验证结果，而决策树的深度似乎没有什么影响。注意在模型评估时，不止一次使用测试集并非一个好的做法。接下来将学习另外一种集成方法：bagging。</p><blockquote><p>在本节中我们实现的多数投票方法有时也成为堆叠（stocking）。</p></blockquote><h2 id="bagging–通过bootstrap样本构建集成分类器"><a href="#bagging–通过bootstrap样本构建集成分类器" class="headerlink" title="bagging–通过bootstrap样本构建集成分类器"></a>bagging–通过bootstrap样本构建集成分类器</h2><p>bagging是一种与上节实现的MajorityVoteClassifier关系紧密的集成学习技术，但是不同的是这个算法没有使用相同的训练数据集拟合集成分类器中的单个成员分类器。由于原始数据集使用了bootstrap抽样（有放回的随机抽样），这也是bagging被称为bootstrap aggregating的原因。</p><p>接下来为了检验bagging的实际效果，我们用葡萄酒数据集构建一个更复杂的分类问题，在此我们只考虑葡萄酒中的类别2和类别3，且只选择Alcohol和Hue这两个特征：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df_wine = pd.read_csv(<span class="string">&#x27;./wine.data&#x27;</span>, header=<span class="literal">None</span>)</span><br><span class="line">df_wine.columns = [<span class="string">&#x27;Class label&#x27;</span>, <span class="string">&#x27;Alcohol&#x27;</span>,</span><br><span class="line">                  <span class="string">&#x27;Malic acid&#x27;</span>, <span class="string">&#x27;Ash&#x27;</span>,</span><br><span class="line">                  <span class="string">&#x27;Alcalinity&#x27;</span>, <span class="string">&#x27;Magnesium&#x27;</span>,</span><br><span class="line">                  <span class="string">&#x27;Total phenols&#x27;</span>, <span class="string">&#x27;Flavanoids&#x27;</span>,</span><br><span class="line">                  <span class="string">&#x27;Nonflavanoids&#x27;</span>, <span class="string">&#x27;Proanthocyanins&#x27;</span>,</span><br><span class="line">                  <span class="string">&#x27;Color intensity&#x27;</span>, <span class="string">&#x27;Hue&#x27;</span>,</span><br><span class="line">                  <span class="string">&#x27;Diluted&#x27;</span>, <span class="string">&#x27;Proline&#x27;</span>]</span><br><span class="line">df_wine = df_wine[df_wine[<span class="string">&#x27;Class label&#x27;</span>] != <span class="number">1</span>]</span><br><span class="line">y = df_wine[<span class="string">&#x27;Class label&#x27;</span>].values</span><br><span class="line">X = df_wine[[<span class="string">&#x27;Alcohol&#x27;</span>, <span class="string">&#x27;Hue&#x27;</span>]].values</span><br></pre></td></tr></table></figure><p>接下来，对类标进行编码，同时将数据集划分为测试集和训练集：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line">le = LabelEncoder()</span><br><span class="line">y = le.fit_transform(y)</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.4</span>, random_state=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>scikit-learn中已经实现了Bagging Classifier相关算法，我们可以从ensemble子模块中导入使用：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> BaggingClassifier</span><br><span class="line"></span><br><span class="line">tree = DecisionTreeClassifier(criterion=<span class="string">&#x27;entropy&#x27;</span>, max_depth=<span class="literal">None</span>)</span><br><span class="line">bag = BaggingClassifier(base_estimator=tree,</span><br><span class="line">                       n_estimators=<span class="number">500</span>,</span><br><span class="line">                       max_samples=<span class="number">1.0</span>,</span><br><span class="line">                       max_features=<span class="number">1.0</span>,</span><br><span class="line">                       bootstrap=<span class="literal">True</span>,</span><br><span class="line">                       bootstrap_features=<span class="literal">False</span>,</span><br><span class="line">                       n_jobs=<span class="number">-1</span>,</span><br><span class="line">                       random_state=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>接下来我们将计算训练数据集和测试数据集上的预测准确率：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"></span><br><span class="line">tree = tree.fit(X_train, y_train)</span><br><span class="line">y_train_pred = tree.predict(X_train)</span><br><span class="line">y_test_pred = tree.predict(X_test)</span><br><span class="line">tree_train = accuracy_score(y_train, y_train_pred)</span><br><span class="line">tree_test = accuracy_score(y_test, y_test_pred)</span><br><span class="line">print(tree_train, tree_test)</span><br><span class="line">&gt;&gt; <span class="number">1.0</span> <span class="number">0.8333333333333334</span></span><br></pre></td></tr></table></figure><p>基于上述代码执行的结果可见，未经剪枝的决策树显现出过拟合的现象。接下来看一下bag的拟合效果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">bag = bag.fit(X_train, y_train)</span><br><span class="line">y_train_pred = bag.predict(X_train)</span><br><span class="line">y_test_pred = bag.predict(X_test)</span><br><span class="line">bag_train = accuracy_score(y_train, y_train_pred)</span><br><span class="line">bag_test = accuracy_score(y_test, y_test_pred)</span><br><span class="line">print(tree_train, tree_test)</span><br><span class="line">&gt;&gt; <span class="number">1.0</span> <span class="number">0.8958333333333334</span></span><br></pre></td></tr></table></figure><p>从上图可见bagging分类器在测试数据上的泛化性能稍有胜出。接下来看一下它们的决策区域：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">x_min = X_train[:, <span class="number">0</span>].min() - <span class="number">1</span></span><br><span class="line">x_max = X_train[:, <span class="number">0</span>].max() + <span class="number">1</span></span><br><span class="line">y_min = X_train[:, <span class="number">1</span>].min() - <span class="number">1</span></span><br><span class="line">y_max = X_train[:, <span class="number">1</span>].max() + <span class="number">1</span></span><br><span class="line">xx, yy = np.meshgrid(np.arange(x_min, x_max, <span class="number">0.1</span>), np.arange(y_min, y_max, <span class="number">0.1</span>))</span><br><span class="line">f, axarr = plt.subplots(nrows=<span class="number">1</span>, ncols=<span class="number">2</span>, sharex=<span class="string">&#x27;col&#x27;</span>, sharey=<span class="string">&#x27;row&#x27;</span>, figsize=(<span class="number">8</span>, <span class="number">3</span>))</span><br><span class="line"><span class="keyword">for</span> idx, clf, tt <span class="keyword">in</span> zip([<span class="number">0</span>, <span class="number">1</span>], [tree, bag], [<span class="string">&#x27;DT&#x27;</span>, <span class="string">&#x27;Bagging&#x27;</span>]):</span><br><span class="line">    clf.fit(X_train, y_train)</span><br><span class="line">    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])</span><br><span class="line">    Z = Z.reshape(xx.shape)</span><br><span class="line">    axarr[idx].contourf(xx, yy, Z, alpha=<span class="number">0.3</span>)</span><br><span class="line">    axarr[idx].scatter(X_train[y_train==<span class="number">0</span>, <span class="number">0</span>], X_train[y_train==<span class="number">0</span>, <span class="number">1</span>], c=<span class="string">&#x27;b&#x27;</span>, marker=<span class="string">&#x27;^&#x27;</span>)</span><br><span class="line">    axarr[idx].scatter(X_train[y_train==<span class="number">1</span>, <span class="number">0</span>], X_train[y_train==<span class="number">1</span>, <span class="number">1</span>], c=<span class="string">&#x27;r&#x27;</span>, marker=<span class="string">&#x27;o&#x27;</span>)</span><br><span class="line">    axarr[idx].set_title(tt)</span><br><span class="line">axarr[<span class="number">0</span>].set_ylabel(<span class="string">&#x27;Alcohol&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>可以得到图像如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="Fri,%2007%20Feb%202020%20124204.png" class="lazyload" data-srcset="Fri,%2007%20Feb%202020%20124204.png" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><p>从结果可见，和深度为3的决策树相比，bagging集成分类器的决策边界显得更加平滑。</p><p>bagging算法是降低模型方差的一种有效方法，但是它在降低模型偏差方面的作用不大。</p><h2 id="通过自适应boosting提高弱学习机的性能"><a href="#通过自适应boosting提高弱学习机的性能" class="headerlink" title="通过自适应boosting提高弱学习机的性能"></a>通过自适应boosting提高弱学习机的性能</h2><p>在本节中，重点讨论boosting算法的一个常用例子：<strong>Adaboost</strong>（Adaptive Boosting）。</p><p>在boosting中，集成分类器包含多个非常简单的成原分类器，这些成原分类器的性能仅仅好于随即猜测，常被称为弱学习机。原始的boosting过程如下：</p><ol><li>从训练集D中以无放回抽样方式随机抽取一个训练子集$ d_1 $，用于弱学习机$ C_1 $的训练</li><li>从D中无放回抽样抽取一个训练子集$ d_2 $，并且将$ C_1 $中误分类样本的50%加入到训练集中，训练得到弱学习机$ C_2 $</li><li>从训练集中抽取$ C_1 $和$ C_2 $分类结果不一致的样本生成训练样本$ d_3 $，以此训练第三个弱学习机$ C_3 $</li><li>通过多数投票组合三个弱学习机$ C_1,C_2,C_3 $</li></ol><p>和bagging模型相比，boosting可以同时降低偏差和方差。在实践中，boosting算法对训练数据有过拟合的倾向。</p><p>Adaboost和原始的boosting算法不同，它使用整个训练集来训练弱学习机，其中训练样本在每次迭代中都会重新被赋予一个权重，在上一弱学习机错误的基础上进行学习从而构建一个更加强大的分类器。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="1581052267970.png" class="lazyload" data-srcset="1581052267970.png" srcset="data:image/png;base64,666" alt="1581052267970"/></div><span class="image-caption">1581052267970</span></div><p>如上图，从图1开始，所有的样本都被赋予相同的权重，基于次训练集，我们得到了一个分类器（决策曲线是图中虚线）；在下一轮中，我们为前面误分类的样本赋予更高的权重，此外我们降低被正确分类的样本的权重，如子图2所示，弱学习机错误划分了圆形类的三个样本，它们将在子图3中被赋予更大的权重…重复以上过程，最终组合三个学习机得到新的决策区域如图4。</p><p>下面是AdaBoost算法的基本步骤：</p><ol><li>以等值的方式为权重向量$ w $赋值，其中$ \sum_iw_i=1 $</li><li>在m轮boosting操作中，对第j轮做如下操作<ol><li>训练一个加权的弱学习机：$ C_j = train(X, y, w) $</li><li>预测样本类标：$ \hat{y} = =predict(C_j, X) $</li><li>计算权重错误率：$ \epsilon  = w \cdot (\hat{y} == y)$</li><li>计算相关系数：$ a_j = 0.5log\frac{1-\epsilon} {\epsilon}$</li><li>更新权重：$ w = w \times exp(-a_j\times \hat{y} \times y) $</li><li>归一化权重：$ w:=w/\sum_i{w_i} $</li></ol></li><li>完成最终预测：$ \hat{y} = (\sum_{j=1}^{m}(a_j\times predict(C_j, X)) &gt; 0) $</li></ol><p>下面通过scikit-learn来训练一个AdaBoost集成分类器，我们仍然使用上一节中的葡萄酒数据集：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> AdaBoostClassifier</span><br><span class="line">tree = DecisionTreeClassifier(criterion=<span class="string">&#x27;entropy&#x27;</span>, max_depth=<span class="number">1</span>)</span><br><span class="line">ada = AdaBoostClassifier(base_estimator=tree, n_estimators=<span class="number">500</span>, learning_rate=<span class="number">0.1</span>, random_state=<span class="number">0</span>)</span><br><span class="line">tree = tree.fit(X_train, y_train)</span><br><span class="line">y_train_pred = tree.predict(X_train)</span><br><span class="line">y_test_pred = tree.predict(X_test)</span><br><span class="line">tree_train = accuracy_score(y_train, y_train_pred)</span><br><span class="line">tree_test = accuracy_score(y_test, y_test_pred)</span><br><span class="line">print(tree_train, tree_test)</span><br><span class="line">&gt;&gt; <span class="number">0.8450704225352113</span> <span class="number">0.8541666666666666</span></span><br></pre></td></tr></table></figure><p>和上一节中未剪枝决策树相比，单层决策树对于训练数据过拟合的成都更加严重一点，接下来看一下AdaBoost分类器的性能：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ada = ada.fit(X_train, y_train)</span><br><span class="line">y_train_pred = ada.predict(X_train)</span><br><span class="line">y_test_pred = ada.predict(X_test)</span><br><span class="line">ada_train = accuracy_score(y_train, y_train_pred)</span><br><span class="line">ada_test = accuracy_score(y_test, y_test_pred)</span><br><span class="line">print(ada_train, ada_test)</span><br><span class="line">&gt;&gt; <span class="number">1.0</span> <span class="number">0.875</span></span><br></pre></td></tr></table></figure><p>可以发现，A大Boost模型准确预测了所有的训练集类标，与单层决策树相比，它在测试集上的表现良好，不过，在代码中也可以看到，我们在降低模型偏差的同时使得方差额外的增加。</p><p>最后看一下决策区域的形状：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">x_min = X_train[:, <span class="number">0</span>].min() - <span class="number">1</span></span><br><span class="line">x_max = X_train[:, <span class="number">0</span>].max() + <span class="number">1</span></span><br><span class="line">y_min = X_train[:, <span class="number">1</span>].min() - <span class="number">1</span></span><br><span class="line">y_max = X_train[:, <span class="number">1</span>].max() + <span class="number">1</span></span><br><span class="line">xx, yy = np.meshgrid(np.arange(x_min, x_max, <span class="number">0.1</span>), np.arange(y_min, y_max, <span class="number">0.1</span>))</span><br><span class="line">f, axarr = plt.subplots(nrows=<span class="number">1</span>, ncols=<span class="number">2</span>, sharex=<span class="string">&#x27;col&#x27;</span>, sharey=<span class="string">&#x27;row&#x27;</span>, figsize=(<span class="number">8</span>, <span class="number">3</span>))</span><br><span class="line"><span class="keyword">for</span> idx, clf, tt <span class="keyword">in</span> zip([<span class="number">0</span>, <span class="number">1</span>], [tree, ada], [<span class="string">&#x27;DT&#x27;</span>, <span class="string">&#x27;AdaBoost&#x27;</span>]):</span><br><span class="line">    clf.fit(X_train, y_train)</span><br><span class="line">    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])</span><br><span class="line">    Z = Z.reshape(xx.shape)</span><br><span class="line">    axarr[idx].contourf(xx, yy, Z, alpha=<span class="number">0.5</span>)</span><br><span class="line">    axarr[idx].scatter(X_train[y_train==<span class="number">0</span>, <span class="number">0</span>], X_train[y_train==<span class="number">0</span>, <span class="number">1</span>], c=<span class="string">&#x27;b&#x27;</span>, marker=<span class="string">&#x27;^&#x27;</span>)</span><br><span class="line">    axarr[idx].scatter(X_train[y_train==<span class="number">1</span>, <span class="number">0</span>], X_train[y_train==<span class="number">1</span>, <span class="number">1</span>], c=<span class="string">&#x27;r&#x27;</span>, marker=<span class="string">&#x27;o&#x27;</span>)</span><br><span class="line">    axarr[idx].set_title(tt)</span><br><span class="line">axarr[<span class="number">0</span>].set_ylabel(<span class="string">&#x27;Alcohol&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>得到的图像如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="Fri,%2007%20Feb%202020%20140636.png" class="lazyload" data-srcset="Fri,%2007%20Feb%202020%20140636.png" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><p>从上图可知，AdaBoost的决策区域比单层决策树的决策区域复杂得多。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>模型评估与参数调优实战</title>
      <link href="2020/02/05/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E4%B8%8E%E5%8F%82%E6%95%B0%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/"/>
      <url>2020/02/05/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E4%B8%8E%E5%8F%82%E6%95%B0%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/</url>
      
        <content type="html"><![CDATA[<p>本章中，我们将使用代码进行实践，通过对算法进行调优来构建性能良好的机器学习模型，并对模型的性能进行评估。</p><a id="more"></a><h2 id="基于流水线的工作流"><a href="#基于流水线的工作流" class="headerlink" title="基于流水线的工作流"></a>基于流水线的工作流</h2><p>本节学习scikit-learn中的Pipeline类，它使得我们可以拟合出包含任意多个处理步骤的模型，并将模型用于新数据的预测。</p><h3 id="加载威斯康辛乳腺癌数据集"><a href="#加载威斯康辛乳腺癌数据集" class="headerlink" title="加载威斯康辛乳腺癌数据集"></a>加载威斯康辛乳腺癌数据集</h3><p>首先获取乳腺癌数据集：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.read_csv(<span class="string">&#x27;http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data&#x27;</span>, header=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure><p>该数据集划分为32列，前两列是样本唯一ID和对样本的诊断结果（M代表恶性，B代表良性），后面的几列是包含了30个从细胞核照片中提取的特征。接下来，将数据集的30个特征赋值给数组对象X，同时转换诊断结果为数字：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line">X = df.loc[:, <span class="number">2</span>:].values</span><br><span class="line">y = df.loc[:, <span class="number">1</span>].values</span><br><span class="line">le = LabelEncoder()</span><br><span class="line">y = le.fit_transform(y)</span><br><span class="line">le.transform([<span class="string">&#x27;M&#x27;</span>, <span class="string">&#x27;B&#x27;</span>])</span><br><span class="line">&gt;&gt; array([<span class="number">1</span>, <span class="number">0</span>], dtype=int64)</span><br></pre></td></tr></table></figure><p>此时良性肿瘤和恶性肿瘤分别被标记为类0和类1。接下来将数据集划分为训练数据集和测试数据集：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><h3 id="在流水线中集成数据转换及评估操作"><a href="#在流水线中集成数据转换及评估操作" class="headerlink" title="在流水线中集成数据转换及评估操作"></a>在流水线中集成数据转换及评估操作</h3><p>接下来可以直接使用Pipeline将上述步骤串联起来：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline</span><br><span class="line">pipe_lr = Pipeline([(<span class="string">&#x27;scl&#x27;</span>, StandardScaler()),</span><br><span class="line">                   (<span class="string">&#x27;pca&#x27;</span>, PCA(n_components=<span class="number">2</span>)),</span><br><span class="line">                   (<span class="string">&#x27;clf&#x27;</span>, LogisticRegression(random_state=<span class="number">1</span>))])</span><br><span class="line">pipe_lr.fit(X_train, y_train)</span><br><span class="line">print(pipe_lr.score(X_test, y_test))</span><br><span class="line">&gt;&gt; <span class="number">0.9473684210526315</span></span><br></pre></td></tr></table></figure><p>Pipeline对象使用元组的序列作为输入，其中每个元组的第一个值为字符串，它可以是任意的标识符，我们通过它来访问流水线中的元素，而元组的第二个值为scikit-learn中的以恶转换器或者是评估器。</p><h2 id="使用k折交叉验证评估模型性能"><a href="#使用k折交叉验证评估模型性能" class="headerlink" title="使用k折交叉验证评估模型性能"></a>使用k折交叉验证评估模型性能</h2><p>本节中，我们学习两种有用的交叉验证技术：<strong>holdout交叉验证</strong>和<strong>k折交叉验证</strong>。借助于这两种方法，我们可以得到模型泛化误差的可靠估计，即模型在新数据上的性能表现。</p><h3 id="holdout方法"><a href="#holdout方法" class="headerlink" title="holdout方法"></a>holdout方法</h3><p>使用holdout进行模型选择更好的方法是将数据分为三个部分：训练数据集，验证数据集和测试数据集。训练数据集用于不同模型的拟合，模型在验证数据集上的性能表现作为模型选择的标准。使用模型训练和模型选择阶段不曾使用的数据作为测试数据集的优势在于：评估模型应用于新数据上能够获得较小偏差。</p><p>holdout方法的一个缺点是：模型性能的评估对训练数据集划分为训练及验证子集的方法是敏感的，评价的结果会随着样本的不同而发生变化。下一节介绍鲁棒性更好的性能评价技术：k折交叉验证，我们将在k个训练数据子集上重复holdout方法k次。</p><h3 id="k折交叉验证"><a href="#k折交叉验证" class="headerlink" title="k折交叉验证"></a>k折交叉验证</h3><p>在k折交叉验证中，我们不重复地随机将训练数据集划分为k个，其中$ k-1 $个用于模型的训练，剩余的1个用于测试。重复此过程k次，我们就得到了k个模型及对模型性能的评价。</p><p>由于k折交叉验证使用了无重复抽样技术，该方法的优势在于每个样本点只有一次被划入训练数据集或者测试数据集的机会，与holdout方法相比，这将会使得模型性能的评估具有较小的方差。</p><blockquote><p>留一（LOO）交叉验证：在LOO中，我们将数据子集划分的数量等同于样本数（k = n），这样每次只有一个样本用于测试。</p></blockquote><p>分层k折交叉验证相对于k折交叉验证做了稍许改进，它可以得到更低的偏差或方差。接下来通过scikit-learn中的<code>StratifiedKFold</code>迭代器来演示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> StratifiedKFold</span><br><span class="line">kfold = StratifiedKFold(n_splits=<span class="number">10</span>, random_state=<span class="number">1</span>)</span><br><span class="line">scores = []</span><br><span class="line">k = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> train, test <span class="keyword">in</span> kfold.split(X_train, y_train):</span><br><span class="line">    pipe_lr.fit(X_train[train], y_train[train])</span><br><span class="line">    score = pipe_lr.score(X_train[test], y_train[test])</span><br><span class="line">    scores.append(score)</span><br><span class="line">    k += <span class="number">1</span></span><br><span class="line">    print(<span class="string">&#x27;Fold: %s, Class dist.: %s, Acc: %.3f&#x27;</span> % (k, np.bincount(y_train[train]), score))</span><br></pre></td></tr></table></figure><p>得到的结果如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Fold: <span class="number">1</span>, Class dist.: [<span class="number">256</span> <span class="number">153</span>], Acc: <span class="number">0.891</span></span><br><span class="line">Fold: <span class="number">2</span>, Class dist.: [<span class="number">256</span> <span class="number">153</span>], Acc: <span class="number">0.978</span></span><br><span class="line">Fold: <span class="number">3</span>, Class dist.: [<span class="number">256</span> <span class="number">153</span>], Acc: <span class="number">0.978</span></span><br><span class="line">Fold: <span class="number">4</span>, Class dist.: [<span class="number">256</span> <span class="number">153</span>], Acc: <span class="number">0.913</span></span><br><span class="line">Fold: <span class="number">5</span>, Class dist.: [<span class="number">256</span> <span class="number">153</span>], Acc: <span class="number">0.935</span></span><br><span class="line">Fold: <span class="number">6</span>, Class dist.: [<span class="number">257</span> <span class="number">153</span>], Acc: <span class="number">0.978</span></span><br><span class="line">Fold: <span class="number">7</span>, Class dist.: [<span class="number">257</span> <span class="number">153</span>], Acc: <span class="number">0.933</span></span><br><span class="line">Fold: <span class="number">8</span>, Class dist.: [<span class="number">257</span> <span class="number">153</span>], Acc: <span class="number">0.956</span></span><br><span class="line">Fold: <span class="number">9</span>, Class dist.: [<span class="number">257</span> <span class="number">153</span>], Acc: <span class="number">0.978</span></span><br><span class="line">Fold: <span class="number">10</span>, Class dist.: [<span class="number">257</span> <span class="number">153</span>], Acc: <span class="number">0.956</span></span><br></pre></td></tr></table></figure><p>尽管之前的代码清楚介绍了k折交叉验证的工作方式，scikit-learn同样实现了k折交叉验证评分的计算，这时的我们可以更加高效地使用分层k折交叉验证对模型进行评估：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line">scores = cross_val_score(estimator=pipe_lr, X=X_train, y=y_train, cv=<span class="number">10</span>, n_jobs=<span class="number">1</span>)</span><br><span class="line">print(scores)</span><br><span class="line">&gt;&gt; [<span class="number">0.89130435</span> <span class="number">0.97826087</span> <span class="number">0.97826087</span> <span class="number">0.91304348</span> <span class="number">0.93478261</span> <span class="number">0.97777778</span> <span class="number">0.93333333</span> <span class="number">0.95555556</span> <span class="number">0.97777778</span> <span class="number">0.95555556</span>]</span><br><span class="line">print(<span class="string">&#x27;CV Acc: %.3f +/- %.3f&#x27;</span> % (np.mean(scores), np.std(scores)))</span><br><span class="line">&gt;&gt; CV Acc: <span class="number">0.950</span> +/- <span class="number">0.029</span></span><br></pre></td></tr></table></figure><h2 id="通过学习及验证曲线来调试算法"><a href="#通过学习及验证曲线来调试算法" class="headerlink" title="通过学习及验证曲线来调试算法"></a>通过学习及验证曲线来调试算法</h2><p>在本节中，我们将会学习两个有助于提高学习算法性能的简单但功能强大的判定工具：<strong>学习曲线</strong>（learning curve）与<strong>验证曲线</strong>（validation curve）。</p><h3 id="使用学习曲线判定偏差和方差问题"><a href="#使用学习曲线判定偏差和方差问题" class="headerlink" title="使用学习曲线判定偏差和方差问题"></a>使用学习曲线判定偏差和方差问题</h3><p>通过将模型的训练及准确性验证看作是训练数据集大小的函数，并且绘制其图像，可以很容易地看出来模型面临高方差还是高偏差。</p><p>高偏差模型的训练准确率和交叉验证准确率都很低，这表明此模型未能很好地拟合数据。而高方差模型训练准确率和交叉验证准确率之间相差很大。</p><p>接下来，使用scikit-learn中的学习曲线函数评估模型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> learning_curve</span><br><span class="line">pipe_lr = Pipeline([(<span class="string">&#x27;scl&#x27;</span>, StandardScaler()),</span><br><span class="line">                   (<span class="string">&#x27;clf&#x27;</span>, LogisticRegression(penalty=<span class="string">&#x27;l2&#x27;</span>, random_state=<span class="number">0</span>))])</span><br><span class="line">train_sizes, train_scores, test_scores = learning_curve(estimator=pipe_lr, </span><br><span class="line">                                                       X=X_train,</span><br><span class="line">                                                       y=y_train,</span><br><span class="line">                                                       train_sizes=np.linspace(<span class="number">0.1</span>, <span class="number">1.0</span>, <span class="number">10</span>),</span><br><span class="line">                                                       cv=<span class="number">10</span>,</span><br><span class="line">                                                       n_jobs=<span class="number">1</span>)</span><br><span class="line">train_mean = np.mean(train_scores, axis=<span class="number">1</span>)</span><br><span class="line">train_std = np.std(train_scores, axis=<span class="number">1</span>)</span><br><span class="line">test_mean = np.mean(test_scores, axis=<span class="number">1</span>)</span><br><span class="line">test_std = np.std(test_scores, axis=<span class="number">1</span>)</span><br><span class="line">plt.plot(train_sizes, train_mean, color=<span class="string">&#x27;b&#x27;</span>, marker=<span class="string">&#x27;o&#x27;</span>, label=<span class="string">&#x27;training acc.&#x27;</span>)</span><br><span class="line">plt.fill_between(train_sizes, train_mean + train_std, train_mean - train_std, alpha=<span class="number">0.15</span>, color=<span class="string">&#x27;b&#x27;</span>)</span><br><span class="line">plt.plot(train_sizes, test_mean, color=<span class="string">&#x27;r&#x27;</span>, marker=<span class="string">&#x27;s&#x27;</span>, label=<span class="string">&#x27;validation acc&#x27;</span>)</span><br><span class="line">plt.fill_between(train_sizes, test_mean + test_std, test_mean - test_std, alpha=<span class="number">0.15</span>, color=<span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">plt.grid()</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Number of training samples&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Accuracy&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.ylim([<span class="number">0.8</span>, <span class="number">1.0</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>可以得到如下图像：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="Wed,%2005%20Feb%202020%20194743.png" class="lazyload" data-srcset="Wed,%2005%20Feb%202020%20194743.png" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><p>从图像可知，模型在测试数据集上表现良好。</p><h3 id="通过验证曲线来判定过拟合和欠拟合"><a href="#通过验证曲线来判定过拟合和欠拟合" class="headerlink" title="通过验证曲线来判定过拟合和欠拟合"></a>通过验证曲线来判定过拟合和欠拟合</h3><p>验证曲线和学习曲线类似，不过绘制的不是样本大小和训练准确率，测试准确率之间的关系，而是准确率与模型参数之间的关系，例如逻辑斯蒂回归模型中的正则化参数倒数C。下面使用scikit-learn来绘制验证曲线：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> validation_curve</span><br><span class="line">param_range = [<span class="number">0.001</span>, <span class="number">0.01</span>, <span class="number">0.1</span>, <span class="number">1.0</span>, <span class="number">10.0</span>, <span class="number">100.0</span>]</span><br><span class="line">train_scores, test_scores = validation_curve(estimator=pipe_lr,</span><br><span class="line">                                            X=X_train,</span><br><span class="line">                                            y=y_train,</span><br><span class="line">                                            param_name=<span class="string">&#x27;clf__C&#x27;</span>,</span><br><span class="line">                                            param_range=param_range,</span><br><span class="line">                                            cv=<span class="number">10</span>)</span><br><span class="line">train_mean = np.mean(train_scores, axis=<span class="number">1</span>)</span><br><span class="line">train_std = np.std(train_scores, axis=<span class="number">1</span>)</span><br><span class="line">test_mean = np.mean(test_scores, axis=<span class="number">1</span>)</span><br><span class="line">test_std = np.std(test_scores, axis=<span class="number">1</span>)</span><br><span class="line">plt.plot(param_range, train_mean, color=<span class="string">&#x27;b&#x27;</span>, marker=<span class="string">&#x27;o&#x27;</span>, label=<span class="string">&#x27;training acc.&#x27;</span>)</span><br><span class="line">plt.fill_between(param_range, train_mean + train_std, train_mean - train_std, alpha=<span class="number">0.5</span>, color=<span class="string">&#x27;b&#x27;</span>)</span><br><span class="line">plt.plot(param_range, test_mean, color=<span class="string">&#x27;r&#x27;</span>, marker=<span class="string">&#x27;s&#x27;</span>, label=<span class="string">&#x27;validation acc.&#x27;</span>)</span><br><span class="line">plt.fill_between(param_range, test_mean + test_std, test_mean - test_std, alpha=<span class="number">0.5</span>, color=<span class="string">&#x27;b&#x27;</span>)</span><br><span class="line">plt.grid()</span><br><span class="line">plt.xscale(<span class="string">&#x27;log&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Parameter C&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Acc.&#x27;</span>)</span><br><span class="line">plt.ylim([<span class="number">0.8</span>, <span class="number">1.0</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>得到的图像如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="Wed,%2005%20Feb%202020%20200503.png" class="lazyload" data-srcset="Wed,%2005%20Feb%202020%20200503.png" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><p>在本例中，需要验证的是参数C，即定义在scikit-learn流水线中的逻辑斯蒂回归分类器的正则化参数，我们将其记为<code>clf__C</code>，并且通过param_range参数来设定其值的范围。</p><p>从上图可以看到，如果加大正则化强度（较小的C值），会导致模型的欠拟合；如果增加C的值，模型又会趋向于过拟合，在本例中，最优点在$ C=0.1 $附近。</p><h2 id="使用网格搜索调优机器学习模型"><a href="#使用网格搜索调优机器学习模型" class="headerlink" title="使用网格搜索调优机器学习模型"></a>使用网格搜索调优机器学习模型</h2><p>机器学习中，有两类参数：通过训练数据学习得到的参数，如逻辑斯蒂回归中的回归系数；以及学习算法中需要单独进行优化的参数。后者是调优参数，也称为超参，对模型来说，就如逻辑斯蒂回归中的正则化系数，或者决策树中的深度参数。</p><p>接下来，我们学习一种更加强大的超参数优化技巧：<strong>网格搜索</strong>（grid search），它通过寻找最优的超参数值的组合以进一步提高模型的性能。</p><h3 id="使用网络搜索调优参数"><a href="#使用网络搜索调优参数" class="headerlink" title="使用网络搜索调优参数"></a>使用网络搜索调优参数</h3><p>网格搜索法很简单，它通过对我们指定的不同超参列表进行暴力穷举法，来计算评估每个组合对模型性能的影响，以获得参数的最优组合：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line">pipe_svc = Pipeline([(<span class="string">&#x27;scl&#x27;</span>, StandardScaler()),</span><br><span class="line">                    (<span class="string">&#x27;clf&#x27;</span>, SVC(random_state=<span class="number">1</span>))])</span><br><span class="line">param_range = [<span class="number">0.0001</span>, <span class="number">0.001</span>, <span class="number">0.01</span>, <span class="number">0.1</span>, <span class="number">1.0</span>, <span class="number">10.0</span>, <span class="number">100.0</span>, <span class="number">1000.0</span>]</span><br><span class="line">param_grid = [&#123;<span class="string">&#x27;clf__C&#x27;</span>: param_range, <span class="string">&#x27;clf__kernel&#x27;</span>: [<span class="string">&#x27;linear&#x27;</span>]&#125;,</span><br><span class="line">             &#123;<span class="string">&#x27;clf__C&#x27;</span>: param_range, <span class="string">&#x27;clf__gamma&#x27;</span>: param_range, <span class="string">&#x27;clf__kernel&#x27;</span>: [<span class="string">&#x27;rbf&#x27;</span>]&#125;]</span><br><span class="line">gs = GridSearchCV(estimator=pipe_svc, param_grid=param_grid, scoring=<span class="string">&#x27;accuracy&#x27;</span>, cv=<span class="number">10</span>, n_jobs=<span class="number">-1</span>)</span><br><span class="line">gs.fit(X_train, y_train)</span><br><span class="line">print(gs.best_score_, gs.best_params_)</span><br><span class="line">&gt;&gt; <span class="number">0.978021978021978</span> &#123;<span class="string">&#x27;clf__C&#x27;</span>: <span class="number">0.1</span>, <span class="string">&#x27;clf__kernel&#x27;</span>: <span class="string">&#x27;linear&#x27;</span>&#125;</span><br></pre></td></tr></table></figure><p>在本例中，线性SVM模型可得到的最优k折交叉验证准确率为$ 97.8% $。</p><p>最后，我们使用独立的测试数据集，通过GridSearchCV对象的<code>best_estimator_</code>属性对最优模型进行评估：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">clf = gs.best_estimator_</span><br><span class="line">clf.fit(X_train, y_train)</span><br><span class="line">print(clf.score(X_test, y_test))</span><br><span class="line">&gt;&gt; <span class="number">0.9649122807017544</span></span><br></pre></td></tr></table></figure><blockquote><p>虽然网格搜索时寻找最优参数集合的一种功能强大的方法，但是他的计算成本时很高的，此时可以尝试使用另外一种方法：随即搜索（randomized search）。该方法在scikit-learn中的<code>RandomizedSearchCV</code>类已经实现。</p></blockquote><h3 id="通过嵌套交叉验证选择算法"><a href="#通过嵌套交叉验证选择算法" class="headerlink" title="通过嵌套交叉验证选择算法"></a>通过嵌套交叉验证选择算法</h3><p>上一节的方法由于在同一个算法中找到最优超参，而本节中介绍的方法用于在不同的机器学习算法中找到最优的机器算法，它就是嵌套交叉验证。</p><p>在嵌套交叉验证中，我们将数据划分为训练块和测试块；而在用于模型选择的内部循环中，我们则基于这些训练块使用k折交叉验证。在完成模型的选择后，测试块用于模型性能的评估。</p><p>借助于scikit-learn，我们可以通过如下方法使用嵌套交叉验证：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">gs = GridSearchCV(estimator=pipe_svc, param_grid=param_grid, scoring=<span class="string">&#x27;accuracy&#x27;</span>, cv=<span class="number">10</span>, n_jobs=<span class="number">-1</span>)</span><br><span class="line">scores = cross_val_score(gs, X, y, scoring=<span class="string">&#x27;accuracy&#x27;</span>, cv=<span class="number">5</span>)</span><br><span class="line">print(<span class="string">&#x27;CV acc: %.3f +/- %.3f&#x27;</span> % (np.mean(scores), np.std(scores)))</span><br><span class="line">&gt;&gt; CV acc: <span class="number">0.972</span> +/- <span class="number">0.012</span></span><br></pre></td></tr></table></figure><p>代码返回的交叉验证准确率平均值对模型超参调优的预期值给出了很好的估计，且使用该值优化过的模型呢能够预测未知数据。例如，我们可以使用嵌套交叉验证方法比较SVM模型与决策树分类器；为了简单起见，我们只调优数的深度参数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line">gs = GridSearchCV(estimator=DecisionTreeClassifier(random_state=<span class="number">0</span>),</span><br><span class="line">                 param_grid=[&#123;<span class="string">&#x27;max_depth&#x27;</span>: [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="literal">None</span>]&#125;],</span><br><span class="line">                 scoring=<span class="string">&#x27;accuracy&#x27;</span>,</span><br><span class="line">                 cv=<span class="number">5</span>)</span><br><span class="line">scores = cross_val_score(gs, X_train, y_train, scoring=<span class="string">&#x27;accuracy&#x27;</span>, cv=<span class="number">5</span>)</span><br><span class="line">print(<span class="string">&#x27;CV acc: %.3f +/- %.3f&#x27;</span> % (np.mean(scores), np.std(scores)))</span><br><span class="line">&gt;&gt; CV acc: <span class="number">0.908</span> +/- <span class="number">0.045</span></span><br></pre></td></tr></table></figure><p>从两个算法的输出看，嵌套交叉验证对SVM的评价高于决策树。由此可见，SVM是用于对测数据集未知数据进行分类的一个更好的选择。</p><h2 id="了解不同的性能评价指标"><a href="#了解不同的性能评价指标" class="headerlink" title="了解不同的性能评价指标"></a>了解不同的性能评价指标</h2><p>前面的几个章节中，我们使用的都是模型准确性来对模型进行评估，接下来学习其他几个性能指标：<strong>准确率</strong>（precision），<strong>召回率</strong>（recall），<strong>F1分数</strong>（F1-score）。</p><h3 id="读取混淆矩阵"><a href="#读取混淆矩阵" class="headerlink" title="读取混淆矩阵"></a>读取混淆矩阵</h3><p>首先，了解一下混淆矩阵：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="1580967439551.png" class="lazyload" data-srcset="1580967439551.png" srcset="data:image/png;base64,666" alt="1580967439551"/></div><span class="image-caption">1580967439551</span></div><p>虽然这些指标可以人工比较的到结果，但是scikit-learn提供了一个<code>confusion_matrix</code>函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line">pipe_svc.fit(X_train, y_train)</span><br><span class="line">y_pred = pipe_svc.predict(X_test)</span><br><span class="line">conmat = confusion_matrix(y_true=y_test, y_pred=y_pred)</span><br><span class="line">print(conmat)</span><br><span class="line">&gt;&gt; [[<span class="number">71</span>  <span class="number">1</span>]</span><br><span class="line">&gt;&gt;  [ <span class="number">2</span> <span class="number">40</span>]]</span><br></pre></td></tr></table></figure><p> 在执行上述代码后，我们可以得到混淆矩阵。在本例中，假定类别1是正类，模型正确预测了71个属于类别0的样本（真负），以及40个属于类别1的样本（真正）。</p><h3 id="优化分类模型的准确率和召回率"><a href="#优化分类模型的准确率和召回率" class="headerlink" title="优化分类模型的准确率和召回率"></a>优化分类模型的准确率和召回率</h3><p>预测准确率（ACC）和预测误差率（ERR）都提供了样本分类的相关信息。他们的计算方法如下：<br>$$<br>ERR =  \frac{FP + FN}{FP + FN + TP + TN}\<br>ACC =  \frac{TP + TN}{FP + FN + TP + TN}<br>$$<br>对于 类别数量不均衡的分类问题爱来说，真正率（TPR）和假正率（FPR）是非常有用的指标：<br>$$<br>FPR = \frac{FP}{N} = {FP}{FP + TN}\<br>TPR = \frac{TP}{P} = {TP}{TP + FN}<br>$$<br>准确率（PRE）和召回率（REC）是和真正率，真负率相关的性能指标，实际上，召回率和真正率含义相同：<br>$$<br>PRE = \frac{TP}{TP+FP}\<br>REC = TPR = \frac{TP}{FN + TP}<br>$$<br>在实践中，常常用准确率和召回率的结合，称为F1分数：<br>$$<br>F1 = 2\frac{PRE \times REC}{PRE + REC}<br>$$<br>所有的这些评分指标在scikit-learn中已经实现，他们使用方法如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> precision_score</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> recall_score, f1_score</span><br><span class="line">print(<span class="string">&#x27;Pre.: %.3f&#x27;</span> % precision_score(y_true=y_test, y_pred=y_pred))</span><br><span class="line">print(<span class="string">&#x27;Rec.: %.3f&#x27;</span> % recall_score(y_true=y_test, y_pred=y_pred))</span><br><span class="line">print(<span class="string">&#x27;F1.: %.3f&#x27;</span> % f1_score(y_true=y_test, y_pred=y_pred))</span><br><span class="line">&gt;&gt; Pre.: <span class="number">0.976</span></span><br><span class="line">&gt;&gt; Rec.: <span class="number">0.952</span></span><br><span class="line">&gt;&gt; F1.: <span class="number">0.964</span></span><br></pre></td></tr></table></figure><p><strong>请记住scikit-learn中将正类类标标识为1</strong>。如果我们想要指定一个不同的类标，可以通过<code>make_scorer</code>来构建我们自己的评分，这样我们可以将其应用于GridSearchCV：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> make_scorer, f1_score</span><br><span class="line">scorer = make_scorer(f1_score, pos_label=<span class="number">0</span>)</span><br><span class="line">gs = GridSearchCV(estimator=pipe_svc, param_grid=param_grid, scoring=scorer, cv=<span class="number">10</span>)</span><br></pre></td></tr></table></figure><h3 id="ROC曲线"><a href="#ROC曲线" class="headerlink" title="ROC曲线"></a>ROC曲线</h3><p><strong>受试者工作特征曲线</strong>（receiver operator characteristic，ROC）是基于假正率和真正率等性能指标进行分类模型选择的有用工具，假正率和真正率通过移动分类器的阈值实现。基于ROC曲线，我们可以计算所谓的ROC线下区域（AUC），用来刻画分类模型的性能。</p><p>在scikit-learn中ROC AUC得分可以通过<code>roc_auc_score</code>函数计算得到：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score, accuracy_score</span><br><span class="line">print(<span class="string">&quot;ACC: %.3f&quot;</span> % (accuracy_score(y_true=y_test, y_pred=y_pred)))</span><br><span class="line">print(<span class="string">&#x27;ROC AUC: %.3f&#x27;</span> % (roc_auc_score(y_true=y_test, y_score=y_pred)))</span><br><span class="line">&gt;&gt; ACC: <span class="number">0.974</span></span><br><span class="line">&gt;&gt; ROC AUC: <span class="number">0.969</span></span><br></pre></td></tr></table></figure><p>通过ROC AUC得到的分类器性能可以让我们进一步洞悉分类器在类别不均衡样本集合上的性能。</p><h3 id="多类别分类的评价标准"><a href="#多类别分类的评价标准" class="headerlink" title="多类别分类的评价标准"></a>多类别分类的评价标准</h3><p>本节中讨论的评分标准都是基于二分类系统的。不同，scikit-learn实现了macro（宏）和micro（微）均值方法，计算公式如下：<br>$$<br>PRE_{micro} =  \frac{\sum_i^kTP_i}{\sum_i^kTP_i+FP_i}\<br>PRE_{macro} = \frac{\sum_i^kPRE_i}{k}<br>$$</p>]]></content>
      
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>通过降维压缩数据</title>
      <link href="2020/02/04/%E9%80%9A%E8%BF%87%E9%99%8D%E7%BB%B4%E5%8E%8B%E7%BC%A9%E6%95%B0%E6%8D%AE/"/>
      <url>2020/02/04/%E9%80%9A%E8%BF%87%E9%99%8D%E7%BB%B4%E5%8E%8B%E7%BC%A9%E6%95%B0%E6%8D%AE/</url>
      
        <content type="html"><![CDATA[<p>在本章中，我们将会学习到三种<strong>特征提取</strong>的方法，它们都可以将原始数据集变换到一个维度更低的新的特征子空间。</p><a id="more"></a><h2 id="无监督数据降维技术之主成分分析"><a href="#无监督数据降维技术之主成分分析" class="headerlink" title="无监督数据降维技术之主成分分析"></a>无监督数据降维技术之主成分分析</h2><p><strong>主成分分析</strong>（PCA）是一种广泛应用于不同领域的无监督线性数据转换技术，突出作用是降维。PCA的目标是在高维数据中找到最大方差的方向，并且将数据映射到一个维度不大于原始数据的新的子空间上。</p><p>如果使用PCA技术，我们需要构建一个$ d * k $维的转换矩阵$ W $，从而将原来的d维特征向量转换为k维特征向量（k&lt;d）。PCA算法的步骤如下：</p><ol><li>对原始d维数据做标准化处理</li><li>构造样本的协方差矩阵</li><li>计算协方差矩阵的特征值和相应的特征向量</li><li>选择前k个最大特征对应的特征向量（k为新的特征空间维度）</li><li>通过前k个特征向量构建映射矩阵$ W $</li><li>将原始的d维特征$ x $通过$ W $转换为新的k维特征$ x’ $</li></ol><h3 id="总体方差和贡献方差"><a href="#总体方差和贡献方差" class="headerlink" title="总体方差和贡献方差"></a>总体方差和贡献方差</h3><p>这一小节完成PCA的前四个步骤。</p><p>首先，使用前面用到的葡萄酒数据集：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df_wine = pd.read_csv(<span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data&#x27;</span>, header=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure><p>接着，将数据集划分为训练集和测试集，同时使用<code>StandardScaler</code>来将其标准化：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"></span><br><span class="line">X, y = df_wine.iloc[:, <span class="number">1</span>:].values, df_wine.iloc[:, <span class="number">0</span>].values</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.3</span>, random_state=<span class="number">0</span>)</span><br><span class="line">sc = StandardScaler()</span><br><span class="line">X_train_std = sc.fit_transform(X_train)</span><br><span class="line">X_test_std = sc.fit_transform(X_test)</span><br></pre></td></tr></table></figure><p>接下来构造协方差矩阵，同时求解协方差矩阵的特征值和特征向量：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">cov_mat = np.cov(X_train_std.T)</span><br><span class="line">eigen_vals, eigen_vecs = np.linalg.eig(cov_mat)</span><br><span class="line">print(eigen_vals)</span><br><span class="line">&gt;&gt; [<span class="number">4.8923083</span>  <span class="number">2.46635032</span> <span class="number">1.42809973</span> <span class="number">1.01233462</span> <span class="number">0.84906459</span> <span class="number">0.60181514</span></span><br><span class="line">&gt;&gt; <span class="number">0.52251546</span> <span class="number">0.08414846</span> <span class="number">0.33051429</span> <span class="number">0.29595018</span> <span class="number">0.16831254</span> <span class="number">0.21432212</span></span><br><span class="line">&gt;&gt; <span class="number">0.2399553</span> ]</span><br></pre></td></tr></table></figure><p>通过使用<code>np.linalg.elg</code>函数，可以得到一个包含有13个特征值的向量（eigen_vals）和一个13 * 13的特征矩阵（eigen_vecs），其中，特征向量以列的方式存在于特征矩阵中。</p><p>由于我们需要将数据压缩到一个新的特征子空间上实现降维，我们只需要选择那些包含最多信息的特征向量组成的子集。在此衡量函数是特征值$ \lambda_j $的方差贡献率：<br>$$<br>\frac{\lambda_j}{\sum_{i=1}^{d}j}<br>$$<br>接下来看一下不同特征值对应的方差贡献率：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tot = sum(eigen_vals)</span><br><span class="line">var_exp = [(i / tot) <span class="keyword">for</span> i <span class="keyword">in</span> sorted(eigen_vals, reverse=<span class="literal">True</span>)]</span><br><span class="line">print(var_exp)</span><br><span class="line">&gt;&gt; [<span class="number">0.3732964772349068</span>, <span class="number">0.18818926106599568</span>, <span class="number">0.10896790724757796</span>, <span class="number">0.07724389477124863</span>, <span class="number">0.0647859460182618</span>, <span class="number">0.045920138114781475</span>, <span class="number">0.03986935597634714</span>, <span class="number">0.025219142607261574</span>, <span class="number">0.022581806817679666</span>, <span class="number">0.01830924471952691</span>, <span class="number">0.016353362655051454</span>, <span class="number">0.01284270583749274</span>, <span class="number">0.006420756933868311</span>]</span><br></pre></td></tr></table></figure><p>可以知道，第一主成分占方差总和的$ 40% $左右。</p><h3 id="特征转换"><a href="#特征转换" class="headerlink" title="特征转换"></a>特征转换</h3><p>接下来继续执行PCA方法的最后三个步骤。</p><p>首先，按照特征值的降序排列特征对：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">eigen_pairs = [(np.abs(eigen_vals[i]), eigen_vecs[:, i]) <span class="keyword">for</span> i <span class="keyword">in</span> range(len(eigen_vals))]</span><br><span class="line">eigen_pairs.sort(reverse=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p>接下来，我们只选择两个对应的最大的特征向量：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">w = np.hstack((eigen_pairs[<span class="number">0</span>][<span class="number">1</span>][:, np.newaxis],</span><br><span class="line">              eigen_pairs[<span class="number">1</span>][<span class="number">1</span>][:, np.newaxis]))</span><br><span class="line">print(w)</span><br><span class="line">&gt;&gt; [[ <span class="number">0.14669811</span>  <span class="number">0.50417079</span>]</span><br><span class="line">&gt;&gt;  [<span class="number">-0.24224554</span>  <span class="number">0.24216889</span>]</span><br><span class="line">&gt;&gt;  [<span class="number">-0.02993442</span>  <span class="number">0.28698484</span>]</span><br><span class="line">&gt;&gt;  [<span class="number">-0.25519002</span> <span class="number">-0.06468718</span>]</span><br><span class="line">&gt;&gt;  [ <span class="number">0.12079772</span>  <span class="number">0.22995385</span>]</span><br><span class="line">&gt;&gt;  [ <span class="number">0.38934455</span>  <span class="number">0.09363991</span>]</span><br><span class="line">&gt;&gt;  [ <span class="number">0.42326486</span>  <span class="number">0.01088622</span>]</span><br><span class="line">&gt;&gt;  [<span class="number">-0.30634956</span>  <span class="number">0.01870216</span>]</span><br><span class="line">&gt;&gt;  [ <span class="number">0.30572219</span>  <span class="number">0.03040352</span>]</span><br><span class="line">&gt;&gt;  [<span class="number">-0.09869191</span>  <span class="number">0.54527081</span>]</span><br><span class="line">&gt;&gt;  [ <span class="number">0.30032535</span> <span class="number">-0.27924322</span>]</span><br><span class="line">&gt;&gt;  [ <span class="number">0.36821154</span> <span class="number">-0.174365</span>  ]</span><br><span class="line">&gt;&gt;  [ <span class="number">0.29259713</span>  <span class="number">0.36315461</span>]]</span><br></pre></td></tr></table></figure><p>从而我们现在得到了一个13*2的映射矩阵$ W $。接下来转换原始的数据集：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X_train_pca = X_train_std.dot(w)</span><br></pre></td></tr></table></figure><p>最后，新的数据集被保存在124*2的矩阵中，接下来对其进行可视化：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">colors = [<span class="string">&#x27;r&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;g&#x27;</span>]</span><br><span class="line">markers = [<span class="string">&#x27;s&#x27;</span>, <span class="string">&#x27;x&#x27;</span>, <span class="string">&#x27;o&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> l, c, m <span class="keyword">in</span> zip(np.unique(y_train), colors, markers):</span><br><span class="line">    plt.scatter(X_train_pca[y_train==l, <span class="number">0</span>], X_train_pca[y_train==l, <span class="number">1</span>], c=c, label=l, marker=m)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;PC 1&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;PC 2&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>得到的图像如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="Tue,%2004%20Feb%202020%20184309.png" class="lazyload" data-srcset="Tue,%2004%20Feb%202020%20184309.png" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><p>从上图可以很直观的看到，线性分类器能够对其有很好的划分。</p><h3 id="使用scikit-learn进行主成分分析"><a href="#使用scikit-learn进行主成分分析" class="headerlink" title="使用scikit-learn进行主成分分析"></a>使用scikit-learn进行主成分分析</h3><p>我们先使用PCA对葡萄酒数据做预处理，然后再使用逻辑斯蒂回归模型对转换后的数据进行分类，最后绘制出散点图：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"></span><br><span class="line">pca = PCA(n_components=<span class="number">2</span>)</span><br><span class="line">X_train_pca = pca.fit_transform(X_train_std)</span><br><span class="line">X_test_pca = pca.transform(X_test_std)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">colors = [<span class="string">&#x27;r&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;g&#x27;</span>]</span><br><span class="line">markers = [<span class="string">&#x27;s&#x27;</span>, <span class="string">&#x27;x&#x27;</span>, <span class="string">&#x27;o&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> l, c, m <span class="keyword">in</span> zip(np.unique(y_train), colors, markers):</span><br><span class="line">    plt.scatter(X_train_pca[y_train==l, <span class="number">0</span>], X_train_pca[y_train==l, <span class="number">1</span>], c=c, label=l, marker=m)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;PC 1&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;PC 2&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>得到的图像如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="Tue,%2004%20Feb%202020%20193047.png" class="lazyload" data-srcset="Tue,%2004%20Feb%202020%20193047.png" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><p>比较该图和上一节中的图像，可以发现上图实际上就是我们自己完成的PCA图沿着PC1轴翻转的结果。出现此差异的原因在于特征分析方法：特征向量为正或者为负。</p><p>接下来使用逻辑斯蒂回归模型进行训练，并且得到训练结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"></span><br><span class="line">lr = LogisticRegression()</span><br><span class="line">lr.fit(X_train_pca, y_train)</span><br><span class="line">y_pred = lr.predict(X_test_pca)</span><br><span class="line">accuracy_score(y_test, y_pred)</span><br><span class="line">&gt;&gt; <span class="number">0.9814814814814815</span></span><br></pre></td></tr></table></figure><p>可以发现的逻辑斯蒂回归模型的拟合率很优良。</p><h2 id="通过线性判别分析压缩无监督数据"><a href="#通过线性判别分析压缩无监督数据" class="headerlink" title="通过线性判别分析压缩无监督数据"></a>通过线性判别分析压缩无监督数据</h2><p><strong>线性判别分析</strong>（LDA）是一种可作为特征抽取的技术，它可以提高数据分析过程中的计算效率，同时，对于不适用于正则化的模型，它可以降低因维度灾难带来的过拟合。</p><p>LDA方法的步骤如下：</p><ol><li>对d为数据集进行标准化处理</li><li>对于每一类别，计算d维的均值向量</li><li>构造类间的散布矩阵$ S_{B} $以及类内的散布举证$ S_{W} $</li><li>计算矩阵$ s_{W}^{-1}S_{B} $的特征值及对应的特征向量</li><li>选取前k个特征值对应的特征向量，构造一个d*k维的转换矩阵$ W $</li><li>使用转换矩阵$ W $将样本映射到新的特征子空间中</li></ol><h3 id="计算散布矩阵"><a href="#计算散布矩阵" class="headerlink" title="计算散布矩阵"></a>计算散布矩阵</h3><p>葡萄酒数据我们已经经过标准化处理，接下来求解均值向量$ m_i $：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">np.set_printoptions(precision=<span class="number">4</span>)</span><br><span class="line">mean_vecs = []</span><br><span class="line"><span class="keyword">for</span> label <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">4</span>):</span><br><span class="line">    mean_vecs.append(np.mean(X_train_std[y_train==label], axis=<span class="number">0</span>))</span><br><span class="line">print(mean_vecs)</span><br><span class="line">&gt;&gt; [array([ <span class="number">0.9259</span>, <span class="number">-0.3091</span>,  <span class="number">0.2592</span>, <span class="number">-0.7989</span>,  <span class="number">0.3039</span>,  <span class="number">0.9608</span>,  <span class="number">1.0515</span>,</span><br><span class="line">&gt;&gt;         <span class="number">-0.6306</span>,  <span class="number">0.5354</span>,  <span class="number">0.2209</span>,  <span class="number">0.4855</span>,  <span class="number">0.798</span> ,  <span class="number">1.2017</span>]),</span><br><span class="line">&gt;&gt;  array([<span class="number">-0.8727</span>, <span class="number">-0.3854</span>, <span class="number">-0.4437</span>,  <span class="number">0.2481</span>, <span class="number">-0.2409</span>, <span class="number">-0.1059</span>,  <span class="number">0.0187</span>,</span><br><span class="line">&gt;&gt;         <span class="number">-0.0164</span>,  <span class="number">0.1095</span>, <span class="number">-0.8796</span>,  <span class="number">0.4392</span>,  <span class="number">0.2776</span>, <span class="number">-0.7016</span>]),</span><br><span class="line">&gt;&gt;  array([ <span class="number">0.1637</span>,  <span class="number">0.8929</span>,  <span class="number">0.3249</span>,  <span class="number">0.5658</span>, <span class="number">-0.01</span>  , <span class="number">-0.9499</span>, <span class="number">-1.228</span> ,</span><br><span class="line">&gt;&gt;          <span class="number">0.7436</span>, <span class="number">-0.7652</span>,  <span class="number">0.979</span> , <span class="number">-1.1698</span>, <span class="number">-1.3007</span>, <span class="number">-0.3912</span>])]</span><br></pre></td></tr></table></figure><p>通过均值向量，我们计算一下类内散布矩阵$ S_W $:<br>$$<br>S_W = \sum_{i=1}^cS_i<br>$$<br>这可以通过累加各类别i的散步矩阵$ S_i $来计算：<br>$$<br>S_i = \sum_{x \in D_i}^{c}(x-m_i)(x-m_i)^T<br>$$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">d = <span class="number">13</span></span><br><span class="line">S_W = np.zeros((d, d))</span><br><span class="line"><span class="keyword">for</span> label, mv <span class="keyword">in</span> zip(range(<span class="number">1</span>, <span class="number">4</span>), mean_vecs):</span><br><span class="line">    class_scater = np.zeros((d, d))</span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> X[y==label]:</span><br><span class="line">        row, mv = row.reshape(d, <span class="number">1</span>), mv.reshape(d, <span class="number">1</span>)</span><br><span class="line">        class_scater += (row - mv).dot((row - mv).T)</span><br><span class="line">    S_W += class_scater</span><br><span class="line">S_W.shape</span><br><span class="line">&gt;&gt; (<span class="number">13</span>, <span class="number">13</span>)</span><br></pre></td></tr></table></figure><p>此前，我们假定对散步矩阵计算时，曾假设训练集的类标是均匀分布的，但是，通过以下程序，我们发现其不遵守这个假设：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">np.bincount(y_train)</span><br><span class="line">&gt;&gt; array([ <span class="number">0</span>, <span class="number">40</span>, <span class="number">49</span>, <span class="number">35</span>], dtype=int64)</span><br></pre></td></tr></table></figure><p>因此，在我们通过累加方式计算散布矩阵$ S_{W} $前，需要对各类别的散步矩阵$ S_i $做缩放处理。但采用此种方式时，此时散布矩阵和协方差矩阵计算方式相同。协方差矩阵可以看作是归一化的散布矩阵：<br>$$<br>\frac{1}{N_i}S_{W} = \frac{1}{N_i}\sum_{x \in D_i}^c(x-m_i)(x-m_i)^T<br>$$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">d = <span class="number">13</span></span><br><span class="line">S_W = np.zeros((d, d))</span><br><span class="line"><span class="keyword">for</span> label, mv <span class="keyword">in</span> zip(range(<span class="number">1</span>, <span class="number">4</span>), mean_vecs):</span><br><span class="line">    class_scater = np.cov(X_train_std[y_train==label].T)</span><br><span class="line">    S_W += class_scater</span><br><span class="line">S_W.shape</span><br><span class="line">&gt;&gt; (<span class="number">13</span>, <span class="number">13</span>)</span><br></pre></td></tr></table></figure><p>接下来计算类间散布矩阵$ S_B $:<br>$$<br>S_B = \sum_{i=1}^cN_i(m_i-m)(m_i-m)^T<br>$$<br>其中，m是全局均值，他在计算时用到了所有类别中的全部样本：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">mean_overall = np.mean(X_train_std, axis=<span class="number">0</span>)</span><br><span class="line">d = <span class="number">13</span></span><br><span class="line">S_B = np.zeros((d, d))</span><br><span class="line"><span class="keyword">for</span> i, mean_vec <span class="keyword">in</span> enumerate(mean_vecs):</span><br><span class="line">    n = X[y==i+<span class="number">1</span>, :].shape[<span class="number">0</span>]</span><br><span class="line">    mean_vec = mean_vec.reshape(d, <span class="number">1</span>)</span><br><span class="line">    mean_overall = mean_overall.reshape(d, <span class="number">1</span>)</span><br><span class="line">    S_B += n * (mean_vec - mean_overall).dot((mean_vec - mean_overall).T)</span><br><span class="line">S_B.shape</span><br><span class="line">&gt;&gt; (<span class="number">13</span>, <span class="number">13</span>)</span><br></pre></td></tr></table></figure><h3 id="在新特征子空间上选取线性判别算法"><a href="#在新特征子空间上选取线性判别算法" class="headerlink" title="在新特征子空间上选取线性判别算法"></a>在新特征子空间上选取线性判别算法</h3><p>LDA余下的步骤和PCA的步骤相似：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">eigen_vals, eigen_vecs = np.linalg.eig(np.linalg.inv(S_W).dot(S_B))</span><br><span class="line">eigen_pairs = [(np.abs(eigen_vals[i]), eigen_vecs[:, i]) <span class="keyword">for</span> i <span class="keyword">in</span> range(len(eigen_vals))]</span><br><span class="line">eigen_pairs = sorted(eigen_pairs, key=<span class="keyword">lambda</span> k: k[<span class="number">0</span>], reverse=<span class="literal">True</span>)</span><br><span class="line"><span class="keyword">for</span> eigen_pair <span class="keyword">in</span> eigen_pairs:</span><br><span class="line">    print(eigen_pair[<span class="number">0</span>])</span><br></pre></td></tr></table></figure><p>得到的结果如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">643.0153843460517</span></span><br><span class="line"><span class="number">225.08698185416256</span></span><br><span class="line"><span class="number">8.002675183788468e-14</span></span><br><span class="line"><span class="number">5.757534614184537e-14</span></span><br><span class="line"><span class="number">3.5105079604736804e-14</span></span><br><span class="line"><span class="number">3.4638958368304884e-14</span></span><br><span class="line"><span class="number">2.587811510007498e-14</span></span><br><span class="line"><span class="number">2.587811510007498e-14</span></span><br><span class="line"><span class="number">2.4449817310582036e-14</span></span><br><span class="line"><span class="number">1.6532199129716054e-14</span></span><br><span class="line"><span class="number">8.331225171347768e-15</span></span><br><span class="line"><span class="number">2.3238388797036527e-15</span></span><br><span class="line"><span class="number">6.522430076120113e-16</span></span><br></pre></td></tr></table></figure><p>从上述输出来看，我们只得到了两个非零特征值（实际得到的3-13个特征值并未严格为0，这是由numpy的浮点数运算导致的），说明只有前面两个特征值对应的特征几乎包含了葡萄酒训练数据集中的全部有用信息。</p><p>接下来构造转换矩阵：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">w = np.hstack((eigen_pairs[<span class="number">0</span>][<span class="number">1</span>][:, np.newaxis].real, eigen_pairs[<span class="number">1</span>][<span class="number">1</span>][:, np.newaxis].real))</span><br><span class="line">w</span><br><span class="line">&gt;&gt; array([[<span class="number">-0.0707</span>,  <span class="number">0.3778</span>],</span><br><span class="line">&gt;&gt;        [ <span class="number">0.0359</span>,  <span class="number">0.2223</span>],</span><br><span class="line">&gt;&gt;        [<span class="number">-0.0263</span>,  <span class="number">0.3813</span>],</span><br><span class="line">&gt;&gt;        [ <span class="number">0.1875</span>, <span class="number">-0.2955</span>],</span><br><span class="line">&gt;&gt;        [<span class="number">-0.0033</span>, <span class="number">-0.0143</span>],</span><br><span class="line">&gt;&gt;        [ <span class="number">0.2328</span>, <span class="number">-0.0151</span>],</span><br><span class="line">&gt;&gt;        [<span class="number">-0.7719</span>, <span class="number">-0.2149</span>],</span><br><span class="line">&gt;&gt;        [<span class="number">-0.0803</span>, <span class="number">-0.0726</span>],</span><br><span class="line">&gt;&gt;        [ <span class="number">0.0896</span>, <span class="number">-0.1767</span>],</span><br><span class="line">&gt;&gt;        [ <span class="number">0.1815</span>,  <span class="number">0.2909</span>],</span><br><span class="line">&gt;&gt;        [<span class="number">-0.0631</span>, <span class="number">-0.2376</span>],</span><br><span class="line">&gt;&gt;        [<span class="number">-0.3794</span>, <span class="number">-0.0867</span>],</span><br><span class="line">&gt;&gt;        [<span class="number">-0.3355</span>,  <span class="number">0.586</span> ]])</span><br></pre></td></tr></table></figure><h3 id="将样本映射到新的特征空间"><a href="#将样本映射到新的特征空间" class="headerlink" title="将样本映射到新的特征空间"></a>将样本映射到新的特征空间</h3><p>通过上一节中构建的转换矩阵$ W $，我们来对原始数据进行转换：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">X_train_lda = X_train_std.dot(w)</span><br><span class="line">colors = [<span class="string">&#x27;r&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;g&#x27;</span>]</span><br><span class="line">markers = [<span class="string">&#x27;s&#x27;</span>, <span class="string">&#x27;x&#x27;</span>, <span class="string">&#x27;o&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> l, c, m <span class="keyword">in</span> zip(np.unique(y_train), colors, markers):</span><br><span class="line">    plt.scatter(X_train_lda[y_train==l, <span class="number">0</span>], X_train_lda[y_train==l, <span class="number">1</span>], c=c, label=l, marker=m)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;LD 1&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;LD 2&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>得到的图像如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="Tue,%2004%20Feb%202020%20211842.png" class="lazyload" data-srcset="Tue,%2004%20Feb%202020%20211842.png" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><p>通过图像可知，三个葡萄酒类在新的特征子空间上是线性可分的。</p><h3 id="使用scikit-laern进行LDA分析"><a href="#使用scikit-laern进行LDA分析" class="headerlink" title="使用scikit-laern进行LDA分析"></a>使用scikit-laern进行LDA分析</h3><p>接下来，看一下scikit-laern中对LDA类的实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.discriminant_analysis <span class="keyword">import</span> LinearDiscriminantAnalysis <span class="keyword">as</span> LDA</span><br><span class="line">lda = LDA(n_components=<span class="number">2</span>)</span><br><span class="line">X_train_lda = lda.fit_transform(X_train_std, y_train)</span><br><span class="line">colors = [<span class="string">&#x27;r&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;g&#x27;</span>]</span><br><span class="line">markers = [<span class="string">&#x27;s&#x27;</span>, <span class="string">&#x27;x&#x27;</span>, <span class="string">&#x27;o&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> l, c, m <span class="keyword">in</span> zip(np.unique(y_train), colors, markers):</span><br><span class="line">    plt.scatter(X_train_lda[y_train==l, <span class="number">0</span>], X_train_lda[y_train==l, <span class="number">1</span>], c=c, label=l, marker=m)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;LD 1&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;LD 2&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>得到的图像如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="Tue,%2004%20Feb%202020%20212606.png" class="lazyload" data-srcset="Tue,%2004%20Feb%202020%20212606.png" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><p>此时看一下逻辑斯蒂回归模型的预测准确度：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">lr = LogisticRegression()</span><br><span class="line">lr = lr.fit(X_train_lda, y_train)</span><br><span class="line">X_test_lda = lda.fit_transform(X_test_std, y_test)</span><br><span class="line">y_pred = lr.predict(X_test_lda)</span><br><span class="line">accuracy_score(y_pred, y_test)</span><br><span class="line">&gt;&gt; <span class="number">1.0</span></span><br></pre></td></tr></table></figure><p>可以看到，逻辑斯蒂回归模型在测试数据集上对样本分类可谓完美。</p><h2 id="使用核主成分分析进行非线性映射"><a href="#使用核主成分分析进行非线性映射" class="headerlink" title="使用核主成分分析进行非线性映射"></a>使用核主成分分析进行非线性映射</h2><p>许多机器学习算法都假定输入数据是线性可分的，但是在现实世界中，大多数的数据是线性不可分的，针对此类问题，使用PCA或者LDA等降维技术，将其转化为线性问题并不是最好的方法。在本节中，我们将了解一下利用核技巧的PCA，或者称其为核PCA，这和第三章中我们介绍的核支持向量机的概念有一定的联系。使用核PCA，我们将学习如何将非线性可分的数据转换到一个适合对其进行线性分类的新的低维子空间中。</p><h3 id="核函数"><a href="#核函数" class="headerlink" title="核函数"></a>核函数</h3><p>通过核PCA，我们能够得到已经映射到各成分的样本，而不像标准PCA那样去构建一个转换矩阵。简单地说，可以将核函数理解为：通过两个向量点积来度量向量间相似度的函数。最常用的核函数有：</p><ul><li><p>多项式核：<br>$$<br>k(x^i, x^j) = (x^{iT}x^j + \theta)^p<br>$$<br>其中，阈值$ \theta $和幂的值$ p $需要自行定义。</p></li><li><p>双曲正切（sigmoid）核：<br>$$<br>k(x^i, x^j) = thah(\eta x^{iT}x^j+\theta)<br>$$</p></li><li><p>径向基核函数（RBF）或者称为高斯核函数：<br>$$<br>k(x^i, x^j) = exp\left(-\frac{||x^i-x^j||^2}{2\sigma^2}\right)<br>= exp(-\gamma||x^i - x^j||^2)<br>$$</p><p>基于RBF核的PCA可以通过如下三个步骤实现：</p></li></ul><ol><li><p>为了计算核矩阵$ k $，我们需要做如下计算：<br>$$<br>k(x^i,x^j) = = exp(-\gamma||x^i - x^j||^2)<br>$$<br>我们需要计算任意两个样本对之间的值：<br>$$<br>K = \begin{bmatrix}<br>k(x^1,x^1) &amp; k(x^1, x^2) &amp; \cdots &amp; k(x^1, x^n)\<br>k(x^2,x^1) &amp; k(x^2, x^2) &amp; \cdots &amp; k(x^2, x^n)\<br>\vdots &amp; \vdots &amp; \ddots &amp; \vdots\<br>k(x^n,x^1) &amp; k(x^n, x^2) &amp; \cdots &amp; k(x^n, x^n)\<br>\end{bmatrix}<br>$$</p></li><li><p>通过如下公式，使得核矩阵$ k $更为聚集：<br>$$<br>K’ = K-l_nK-Kl_n+l_nKl_n<br>$$<br>其中， $ l_n $是一个n*n的矩阵，其所有的值都是$ \frac{1}{n} $。</p></li><li><p>将聚集后的核矩阵的特征值按照降序排列，选择前k个特征值对应的特征向量。和标准PCA不同，这里的特征向量不是主成分轴，而是将样本映射到这些轴上。</p></li></ol><h3 id="使用Python实现主成分分析"><a href="#使用Python实现主成分分析" class="headerlink" title="使用Python实现主成分分析"></a>使用Python实现主成分分析</h3><p>接下来，借助SciPy和NumPy的函数，我们手动实现一个核PCA：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.spatial.distance <span class="keyword">import</span> pdist, squareform</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> exp</span><br><span class="line"><span class="keyword">from</span> scipy.linalg <span class="keyword">import</span> eigh</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rbf_kernel_pca</span>(<span class="params">X, gamma, n_components</span>):</span></span><br><span class="line">    sq_dists = pdist(X, <span class="string">&#x27;sqeuclidean&#x27;</span>)</span><br><span class="line">    mat_sq_dists = squareform(sq_dists)</span><br><span class="line">    K = exp(-gamma * mat_sq_dists)</span><br><span class="line">    N = K.shape[<span class="number">0</span>]</span><br><span class="line">    one_n = np.ones((N, N)) / N</span><br><span class="line">    K = K - one_n.dot(K) - k.dot(one_n) + one_n.dot(K).dot(one_n)</span><br><span class="line">    eigvals, eigvecs = eigh(K)</span><br><span class="line">    X_pc = np.column_stack((eigvecs[:, -i] <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, n_components + <span class="number">1</span>)))</span><br><span class="line">    <span class="keyword">return</span> X_pc</span><br></pre></td></tr></table></figure><p>接下来查看几个实例。</p><ol><li><p>实例一：分离半月形数据</p><p>首先创建一个包含100个样本点的二维数据集，以两个半月形状表示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_moons</span><br><span class="line">X, y = make_moons(n_samples=<span class="number">100</span>, random_state=<span class="number">123</span>)</span><br><span class="line">plt.scatter(X[y==<span class="number">0</span>, <span class="number">0</span>], X[y==<span class="number">0</span>, <span class="number">1</span>], color=<span class="string">&#x27;r&#x27;</span>, marker=<span class="string">&#x27;^&#x27;</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line">plt.scatter(X[y==<span class="number">1</span>, <span class="number">0</span>], X[y==<span class="number">1</span>, <span class="number">1</span>], color=<span class="string">&#x27;b&#x27;</span>, marker=<span class="string">&#x27;o&#x27;</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>得到的图像如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="Wed,%2005%20Feb%202020%20130704.png" class="lazyload" data-srcset="Wed,%2005%20Feb%202020%20130704.png" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><p>显然，这两个半月形不是线性可分的，我们的目标是通过核PCA将这两个半月形数据展开，使得数据集成为适用于某一线性分类器的输入数据。</p><p>首先，我们看一下经过标准PCA处理的数据集的图像：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line">scikit_pca = PCA(n_components=<span class="number">2</span>)</span><br><span class="line">X_spca = scikit_pca.fit_transform(X)</span><br><span class="line">plt.scatter(X_spca[y==<span class="number">0</span>, <span class="number">0</span>], X_spca[y==<span class="number">0</span>, <span class="number">1</span>], color=<span class="string">&#x27;r&#x27;</span>, marker=<span class="string">&#x27;^&#x27;</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line">plt.scatter(X_spca[y==<span class="number">1</span>, <span class="number">0</span>], X_spca[y==<span class="number">1</span>, <span class="number">1</span>], color=<span class="string">&#x27;b&#x27;</span>, marker=<span class="string">&#x27;o&#x27;</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>得到的图像如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="Wed,%2005%20Feb%202020%20131323.png" class="lazyload" data-srcset="Wed,%2005%20Feb%202020%20131323.png" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><p>可以发现，经过标准化PCA处理后，线性分类器未必能很好地发挥作用。</p><p>接下来尝试一下核PCA函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">X_kpca = rbf_kernel_pca(X, gamma=<span class="number">15</span>, n_components=<span class="number">2</span>)</span><br><span class="line">plt.scatter(X_kpca[y==<span class="number">0</span>, <span class="number">0</span>], X_kpca[y==<span class="number">0</span>, <span class="number">1</span>], color=<span class="string">&#x27;r&#x27;</span>, marker=<span class="string">&#x27;^&#x27;</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line">plt.scatter(X_kpca[y==<span class="number">1</span>, <span class="number">0</span>], X_kpca[y==<span class="number">1</span>, <span class="number">1</span>], color=<span class="string">&#x27;b&#x27;</span>, marker=<span class="string">&#x27;o&#x27;</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>得到的图像如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="Wed,%2005%20Feb%202020%20131739.png" class="lazyload" data-srcset="Wed,%2005%20Feb%202020%20131739.png" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><p>可以看到，此时两个类别是线性可分的。</p></li><li><p>示例二：分离同心圆</p><p>接下俩看一下非线性相关的另外一个例子：同心圆：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_circles</span><br><span class="line">X, y = make_circles(n_samples=<span class="number">1000</span>, random_state=<span class="number">123</span>, noise=<span class="number">0.1</span>, factor=<span class="number">0.2</span>)</span><br><span class="line">plt.scatter(X[y==<span class="number">0</span>, <span class="number">0</span>], X[y==<span class="number">0</span>, <span class="number">1</span>], color=<span class="string">&#x27;r&#x27;</span>, marker=<span class="string">&#x27;^&#x27;</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line">plt.scatter(X[y==<span class="number">1</span>, <span class="number">0</span>], X[y==<span class="number">1</span>, <span class="number">1</span>], color=<span class="string">&#x27;b&#x27;</span>, marker=<span class="string">&#x27;o&#x27;</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>得到的图像如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="Wed,%2005%20Feb%202020%20132116.png" class="lazyload" data-srcset="Wed,%2005%20Feb%202020%20132116.png" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><p>接下来使用核PCA，观察数据集分布：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">X_kpca = rbf_kernel_pca(X, gamma=<span class="number">15</span>, n_components=<span class="number">2</span>)</span><br><span class="line">plt.scatter(X_kpca[y==<span class="number">0</span>, <span class="number">0</span>], X_kpca[y==<span class="number">0</span>, <span class="number">1</span>], color=<span class="string">&#x27;r&#x27;</span>, marker=<span class="string">&#x27;^&#x27;</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line">plt.scatter(X_kpca[y==<span class="number">1</span>, <span class="number">0</span>], X_kpca[y==<span class="number">1</span>, <span class="number">1</span>], color=<span class="string">&#x27;b&#x27;</span>, marker=<span class="string">&#x27;o&#x27;</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>得到的图像如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="Wed,%2005%20Feb%202020%20132252.png" class="lazyload" data-srcset="Wed,%2005%20Feb%202020%20132252.png" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><p>可以发现，此时两个类别的数据是线性可分的。</p></li></ol><h3 id="映射新的数据点"><a href="#映射新的数据点" class="headerlink" title="映射新的数据点"></a>映射新的数据点</h3><p>在标准PCA方法中，我们通过转换矩阵和输入样本之间的点积来对数据进行映射。但是在核PCA中，该如何转换型的数据点呢？实际上，如果我们希望将新的样本$ x’ $映射到此主成分轴，需要进行如下计算：<br>$$<br>\phi(x’)^Tv<br>$$<br>幸运的是，我们可以使用核技巧，这样就无需精确计算映射$ \phi(x’)^Tv $。通过以下公式计算：<br>$$<br>\phi(x’)^Tv = \sum_ia^ik(x’, x^i)^T<br>$$<br>其中，核矩阵K的特征向量$ a $和特征值$ \lambda $关系如下：<br>$$<br>Ka = \lambda a<br>$$<br>通过如下程序实现映射：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">project_x</span>(<span class="params">x_new, X, gamma, alphas, lambdas</span>):</span></span><br><span class="line">    pair_dist = np.array([np.sum(x_new - row)**<span class="number">2</span> <span class="keyword">for</span> row <span class="keyword">in</span> X])</span><br><span class="line">    k = np.exp(-gamma * pair_dist)</span><br><span class="line">    <span class="keyword">return</span> k.dot(alphas / lambdas)</span><br></pre></td></tr></table></figure><p>其中，alphas是前k个特征向量，lambdas是前k个对应的特征值：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">alphas = np.column_stack((eigvecs[:, i] <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, n_components+<span class="number">1</span>)))</span><br><span class="line">lambdas = [eigvals[-i] <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, n_components+<span class="number">1</span>)]</span><br></pre></td></tr></table></figure><p>将上述两条语句加到<code>rbf_kernel_pca</code>函数末端并且返回他们的值即可。</p><h3 id="scikit-learn中的核主成分分析"><a href="#scikit-learn中的核主成分分析" class="headerlink" title="scikit-learn中的核主成分分析"></a>scikit-learn中的核主成分分析</h3><p>使用scikit-learn中的API实现核PCA如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> KernelPCA</span><br><span class="line">X, y = make_moons(n_samples=<span class="number">100</span>, random_state=<span class="number">123</span>)</span><br><span class="line">scikit_kpca = KernelPCA(n_components=<span class="number">2</span>, kernel=<span class="string">&#x27;rbf&#x27;</span>, gamma=<span class="number">15</span>)</span><br><span class="line">X_skpca = scikit_kpca.fit_transform(X)</span><br><span class="line">plt.scatter(X_skpca[y==<span class="number">0</span>, <span class="number">0</span>], X_skpca[y==<span class="number">0</span>, <span class="number">1</span>], color=<span class="string">&#x27;r&#x27;</span>, marker=<span class="string">&#x27;^&#x27;</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line">plt.scatter(X_skpca[y==<span class="number">1</span>, <span class="number">0</span>], X_skpca[y==<span class="number">1</span>, <span class="number">1</span>], color=<span class="string">&#x27;b&#x27;</span>, marker=<span class="string">&#x27;o&#x27;</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>得到的图像如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="Wed,%2005%20Feb%202020%20141751.png" class="lazyload" data-srcset="Wed,%2005%20Feb%202020%20141751.png" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><p>从上图来看，scikit-learn中KernelPCA得到的结果核我们手动实现的结果相一致。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据预处理</title>
      <link href="2020/01/31/%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/"/>
      <url>2020/01/31/%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/</url>
      
        <content type="html"><![CDATA[<p>在本节中，我们将会学习主要的数据预处理技术，使用这些技术可以高效地构建好的机器学习模型。</p><a id="more"></a><h2 id="缺失数据的处理"><a href="#缺失数据的处理" class="headerlink" title="缺失数据的处理"></a>缺失数据的处理</h2><p>在采集数据的时候，可能有的数据会有缺失的情况。通常我们见到的缺失值是数据表中的空值，或者是类似于NaN的占位符。</p><p>首先构造一个含有缺失值的CSV文件：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> io <span class="keyword">import</span> StringIO</span><br><span class="line"></span><br><span class="line">csv_data = <span class="string">&quot;&quot;&quot;A, B, C, D</span></span><br><span class="line"><span class="string">1.0, 2.0, 3.0, 4.0</span></span><br><span class="line"><span class="string">5.0, 6.0, , 8.0</span></span><br><span class="line"><span class="string">10.0, 11.0, 12.0, </span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">df = pd.read_csv(StringIO(csv_data))</span><br><span class="line">print(df) </span><br><span class="line">&gt;&gt;       A     B      C     D</span><br><span class="line">&gt;&gt;  <span class="number">0</span>   <span class="number">1.0</span>   <span class="number">2.0</span>    <span class="number">3.0</span>   <span class="number">4.0</span></span><br><span class="line">&gt;&gt;  <span class="number">1</span>   <span class="number">5.0</span>   <span class="number">6.0</span>    NaN   <span class="number">8.0</span></span><br><span class="line">&gt;&gt;  <span class="number">2</span>  <span class="number">10.0</span>  <span class="number">11.0</span>   <span class="number">12.0</span>   NaN </span><br></pre></td></tr></table></figure><p>上述代码中，我们通过<code>read_csv</code>将CSV格式的数据读取到pandas库的<code>DataFrame</code>中，可以看到有两个缺失值。</p><p>对于大的DataFrame来说，我们可以使用内置的<code>isnull</code>方法来判断某单元中是否含有缺失值：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">df.isnull().sum()</span><br><span class="line">&gt;&gt; A    <span class="number">0</span></span><br><span class="line">&gt;&gt; B    <span class="number">0</span></span><br><span class="line">&gt;&gt; C    <span class="number">1</span></span><br><span class="line">&gt;&gt; D    <span class="number">1</span></span><br><span class="line">&gt;&gt; dtype: int64</span><br></pre></td></tr></table></figure><p>通过这个方式我们可以得到每列中缺失值的数量。</p><h3 id="将存在缺失值的特征或样本删除"><a href="#将存在缺失值的特征或样本删除" class="headerlink" title="将存在缺失值的特征或样本删除"></a>将存在缺失值的特征或样本删除</h3><p>这是最简单的数据处理方式：将含有缺失值的特征（列）或者样本（行）从数据中删除。</p><p>可通过 <code>dropna</code>方法来删除包含缺失值的行：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">df.dropna()</span><br><span class="line">&gt;&gt;       A     B      C     D</span><br><span class="line">&gt;&gt;  <span class="number">0</span>   <span class="number">1.0</span>   <span class="number">2.0</span>    <span class="number">3.0</span>   <span class="number">4.0</span></span><br></pre></td></tr></table></figure><p>类似地，我们可以通过将<code>axis</code>参数设置为1，以删除包含缺失值的列：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">df.dropna(axis=<span class="number">1</span>)</span><br><span class="line">&gt;&gt;       A     B     </span><br><span class="line">&gt;&gt;  <span class="number">0</span>   <span class="number">1.0</span>   <span class="number">2.0</span>    </span><br><span class="line">&gt;&gt;  <span class="number">1</span>   <span class="number">5.0</span>   <span class="number">6.0</span>    </span><br><span class="line">&gt;&gt;  <span class="number">2</span>  <span class="number">10.0</span>  <span class="number">11.0</span>   </span><br></pre></td></tr></table></figure><p>同样地， <code>dropna</code>方法还有其他的参数，以应对各种缺失值的情况：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># only drop rows where all columns are NaN</span></span><br><span class="line">df.dropna(how=<span class="string">&#x27;any&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># drop rows that hava not at least 4 non-NaN value</span></span><br><span class="line">df.dropna(thresh=<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># only drop rows where NaN in specific columns(here is &#x27;C&#x27;)</span></span><br><span class="line">df.dropna(subset=[<span class="string">&#x27;C&#x27;</span>])</span><br></pre></td></tr></table></figure><p>删除数据是一种简单的方法，但是如果删除过多的样本，会导致分析结果可靠性不高。接下来学习另外一种最常用的处理缺失数据的方法：插值技术。</p><h3 id="缺失数据填充"><a href="#缺失数据填充" class="headerlink" title="缺失数据填充"></a>缺失数据填充</h3><p>所谓插值技术是指通过数据集中的其他训练样本的数据来估计缺失值，最常用的插值技术是<strong>均值插值</strong>（meaneinputation），即使用相应的特征均值来替换缺失值。我们可以使用scikit-learn中的<code>Impute</code>类来实现此方法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> Imputer</span><br><span class="line"></span><br><span class="line">imr = Imputer(missing_values=<span class="string">&#x27;NaN&#x27;</span>, strategy=<span class="string">&#x27;mean&#x27;</span>, axis=<span class="number">0</span>)</span><br><span class="line">imr = imr.fit(df)</span><br><span class="line">imputed_data = imr.transform(df.values)</span><br><span class="line">imputed_data</span><br><span class="line">&gt;&gt; array([[ <span class="number">1.</span> ,  <span class="number">2.</span> ,  <span class="number">3.</span> ,  <span class="number">4.</span> ],</span><br><span class="line">          [ <span class="number">5.</span> ,  <span class="number">6.</span> ,  <span class="number">7.5</span>,  <span class="number">8.</span> ],</span><br><span class="line">          [<span class="number">10.</span> , <span class="number">11.</span> , <span class="number">12.</span> ,  <span class="number">6.</span> ]]) </span><br><span class="line"></span><br></pre></td></tr></table></figure><p>首先计算各个特征列的均值，然后将均值插入到NaN处。参数<code>axis</code>用来控制按列计算均值还是按行计算均值，参数<code>strategy</code>还有median和most_frequent可选值。</p><h3 id="理解scikit-learn预估器的API"><a href="#理解scikit-learn预估器的API" class="headerlink" title="理解scikit-learn预估器的API"></a>理解scikit-learn预估器的API</h3><p>上一节中，我们使用的<code>Imputer</code>类来填充我们数据集中的缺失值，这个类属于<code>scikit-learn</code>中的转换器类，主要用于数据的转换。这些类中常用的两个方法是<code>fit</code>和<code>transform</code>。其中，fit方法用于对数据集中的参数进行识别并且构建相应的数据补齐模型，而transform方法则使用刚创建的数据补齐模型对数据集中的缺失值进行补齐。</p><p>在前面的章节中，我们用到了分类器，它们在scikit-learn中属于预估器类别，其API的设计与转换器非常相似。预估器包含一个predict方法，同时也包含一个transform方法。</p><h2 id="处理类别数据"><a href="#处理类别数据" class="headerlink" title="处理类别数据"></a>处理类别数据</h2><p>目前我们只学习了处理数值型数据的方法，但是在真实的数据集中，常常会出现类别数据。类别数据可以进一步划分为<strong>标称特征</strong>和<strong>有序特征</strong>。有序特征可以理解为类别的值是可以排序的，如T恤的尺寸；相反，标称数据不具备排序的特征，如T恤的颜色。</p><p>首先构造一个数据集：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">df = pd.DataFrame([</span><br><span class="line">    [<span class="string">&#x27;green&#x27;</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">10.1</span>, <span class="string">&#x27;class1&#x27;</span>],</span><br><span class="line">    [<span class="string">&#x27;red&#x27;</span>, <span class="string">&#x27;L&#x27;</span>, <span class="number">13.5</span>, <span class="string">&#x27;class2&#x27;</span>],</span><br><span class="line">    [<span class="string">&#x27;blue&#x27;</span>, <span class="string">&#x27;XL&#x27;</span>, <span class="number">15.3</span>, <span class="string">&#x27;class1&#x27;</span>]</span><br><span class="line">])</span><br><span class="line">df.columns = [<span class="string">&#x27;color&#x27;</span>, <span class="string">&#x27;size&#x27;</span>, <span class="string">&#x27;price&#x27;</span>, <span class="string">&#x27;classlabel&#x27;</span>]</span><br><span class="line">df</span><br><span class="line">&gt;&gt;  colorsizepriceclasslabel</span><br><span class="line">&gt;&gt; <span class="number">0</span>greenM <span class="number">10.1</span>class1</span><br><span class="line">&gt;&gt; <span class="number">1</span>red    L    <span class="number">13.5</span>class2</span><br><span class="line">&gt;&gt; <span class="number">2</span>blueXL<span class="number">15.3</span>class1</span><br></pre></td></tr></table></figure><p>我们构造的数据包括一个标称特征（颜色），一个有序特征（大小）以及一个数据特征（价格）。类标存储在最后一类。</p><h3 id="有序特征的映射"><a href="#有序特征的映射" class="headerlink" title="有序特征的映射"></a>有序特征的映射</h3><p>对于有序特征，scikit-learn中没有实现相应的自动转换方法，因此，我们需要手动构造相应的映射。假设尺寸之间的关系是：XL = L + 1 = M + 2.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">size_mapping = &#123;<span class="string">&#x27;XL&#x27;</span>: <span class="number">3</span>, <span class="string">&#x27;L&#x27;</span>: <span class="number">2</span>, <span class="string">&#x27;M&#x27;</span>: <span class="number">1</span>&#125;</span><br><span class="line">df[<span class="string">&#x27;size&#x27;</span>] = df[<span class="string">&#x27;size&#x27;</span>].map(size_mapping)</span><br><span class="line">df</span><br><span class="line">&gt;&gt;  colorsizepriceclasslabel</span><br><span class="line">&gt;&gt; <span class="number">0</span>green<span class="number">1</span> <span class="number">10.1</span>class1</span><br><span class="line">&gt;&gt; <span class="number">1</span>red    <span class="number">2</span>    <span class="number">13.5</span>class2</span><br><span class="line">&gt;&gt; <span class="number">2</span>blue<span class="number">3</span><span class="number">15.3</span>class1</span><br></pre></td></tr></table></figure><p>如果在后续的过程中需要将整数值还原为有序字符串，可以简单定义一个逆映射字典<code>inv_size_mapping = &#123;v : k for k, v in size_mapping.items()&#125;</code>，然后再使用pandas提供的map方法即可。</p><h3 id="类标的编码"><a href="#类标的编码" class="headerlink" title="类标的编码"></a>类标的编码</h3><p>许多机器学习库中要求类标以整数值的方式进行编码。需要注意的一点是，类标不是有序的，因此，我们只需要简单的以枚举的方式从0开始设定类标：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">class_mapping = &#123;label: idx <span class="keyword">for</span> idx, label <span class="keyword">in</span> enumerate(np.unique(df[<span class="string">&#x27;classlabel&#x27;</span>]))&#125;</span><br><span class="line">class_mapping</span><br><span class="line">&gt;&gt; &#123;<span class="string">&#x27;class1&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;class2&#x27;</span>: <span class="number">1</span>&#125;</span><br></pre></td></tr></table></figure><p>接下来映射一下就行：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">&#x27;classlabel&#x27;</span>] = df[<span class="string">&#x27;classlabel&#x27;</span>].map(class_mapping)</span><br><span class="line">df</span><br><span class="line">&gt;&gt;  colorsizepriceclasslabel</span><br><span class="line">&gt;&gt; <span class="number">0</span>green<span class="number">1</span> <span class="number">10.1</span><span class="number">0</span></span><br><span class="line">&gt;&gt; <span class="number">1</span>red    <span class="number">2</span>    <span class="number">13.5</span><span class="number">1</span></span><br><span class="line">&gt;&gt; <span class="number">2</span>blue<span class="number">3</span><span class="number">15.3</span><span class="number">0</span></span><br></pre></td></tr></table></figure><p>同样可以构造一个逆映射来将类表还原为字符串。</p><p>此外，可以使用scikit-learn中的LabelEncoder类可以更加方便完成对类标的编码工作：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"></span><br><span class="line">class_le = LabelEncoder()</span><br><span class="line">y = class_le.fit_transform(df[<span class="string">&#x27;classlabel&#x27;</span>].values)</span><br><span class="line">y</span><br><span class="line">&gt;&gt; array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>], dtype=int64)</span><br></pre></td></tr></table></figure><p>同样可以使用<code>inverse_transform</code>方法将类标转换为原始的字符串。</p><h3 id="标称特征的独热编码"><a href="#标称特征的独热编码" class="headerlink" title="标称特征的独热编码"></a>标称特征的独热编码</h3><p>常见的思路如下，使用LabelEncoder类将字符串转换为整数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">X = df[[<span class="string">&#x27;color&#x27;</span>, <span class="string">&#x27;size&#x27;</span>, <span class="string">&#x27;price&#x27;</span>]].values</span><br><span class="line">color_le = LabelEncoder()</span><br><span class="line">X[:, <span class="number">0</span>] = color_le.fit_transform(X[:, <span class="number">0</span>])</span><br><span class="line">X</span><br><span class="line">&gt;&gt; array([[<span class="number">1</span>, <span class="number">1</span>, <span class="number">10.1</span>],</span><br><span class="line">         [<span class="number">2</span>, <span class="number">2</span>, <span class="number">13.5</span>],</span><br><span class="line">          [<span class="number">0</span>, <span class="number">3</span>, <span class="number">15.3</span>]], dtype=object)</span><br></pre></td></tr></table></figure><p>这样的数据处理是常见的错误处理方式，因为学习算法将会假定green大于blue，red大于green，这显然是不合理的。</p><p>标称特征不能像有序特征一样简单赋予一个整数值，最常用的转换方法是<strong>独热编码</strong>技术。这个方法的思想就是创建一个新的虚拟特征，虚拟特征的每一列各代表标称数据的一个值。在此，我们将color特征转换为三个新的特征：blue，green和red。此时可以通过二进制值来标识样本的颜色。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> OneHotEncoder</span><br><span class="line"></span><br><span class="line">ohe = OneHotEncoder(categorical_features=[<span class="number">0</span>])</span><br><span class="line">ohe.fit_transform(X).toarray()</span><br><span class="line">&gt;&gt; array([[ <span class="number">0.</span> ,  <span class="number">1.</span> ,  <span class="number">0.</span> ,  <span class="number">1.</span> , <span class="number">10.1</span>],</span><br><span class="line">          [ <span class="number">0.</span> ,  <span class="number">0.</span> ,  <span class="number">1.</span> ,  <span class="number">2.</span> , <span class="number">13.5</span>],</span><br><span class="line">          [ <span class="number">1.</span> ,  <span class="number">0.</span> ,  <span class="number">0.</span> ,  <span class="number">3.</span> , <span class="number">15.3</span>]])</span><br></pre></td></tr></table></figure><p>另外，我们可以通过pandas中的get_dummies方法，更加方便地实现虚拟特征。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">pd.get_dummies(df[[<span class="string">&#x27;price&#x27;</span>, <span class="string">&#x27;color&#x27;</span>, <span class="string">&#x27;size&#x27;</span>]])</span><br><span class="line">&gt;&gt; pricesizecolor_bluecolor_greencolor_red</span><br><span class="line">&gt;&gt;<span class="number">0</span><span class="number">10.1</span><span class="number">1</span><span class="number">0</span><span class="number">1</span><span class="number">0</span></span><br><span class="line">&gt;&gt;<span class="number">1</span><span class="number">13.5</span><span class="number">2</span><span class="number">0</span><span class="number">0</span><span class="number">1</span></span><br><span class="line">&gt;&gt;<span class="number">2</span><span class="number">15.3</span><span class="number">3</span><span class="number">1</span><span class="number">0</span><span class="number">0</span></span><br></pre></td></tr></table></figure><h2 id="将数据集划分为训练数据集和测试数据集"><a href="#将数据集划分为训练数据集和测试数据集" class="headerlink" title="将数据集划分为训练数据集和测试数据集"></a>将数据集划分为训练数据集和测试数据集</h2><p>接下来，我们将会使用葡萄酒数据集，可以通过UCI机器学习样本数据库来获得。通过pandas库，我们可以在线获取数据集：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">df_wine = pd.read_csv(<span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data&#x27;</span>, header=<span class="literal">None</span>)</span><br><span class="line">df_wine.columns = [<span class="string">&#x27;Class label&#x27;</span>, <span class="string">&#x27;Alcohol&#x27;</span>, <span class="string">&#x27;Malic acid&#x27;</span>, <span class="string">&#x27;Ash&#x27;</span>, <span class="string">&#x27;Alcalinity of ash&#x27;</span>, <span class="string">&#x27;Magnesium&#x27;</span>, <span class="string">&#x27;Total phenols&#x27;</span>, <span class="string">&#x27;Flavanoids&#x27;</span>,</span><br><span class="line">                  <span class="string">&#x27;Nonflavanoid phenols&#x27;</span>, <span class="string">&#x27;Proanthocyanins&#x27;</span>, <span class="string">&#x27;Color intensity&#x27;</span>, <span class="string">&#x27;Hue&#x27;</span>, <span class="string">&#x27;diluted wines&#x27;</span>, <span class="string">&#x27;Proline&#x27;</span>]</span><br><span class="line">df_wine.head()</span><br></pre></td></tr></table></figure><p>得到数据集如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="1580709518611.png" class="lazyload" data-srcset="1580709518611.png" srcset="data:image/png;base64,666" alt="1580709518611"/></div><span class="image-caption">1580709518611</span></div><p>葡萄酒样本库通过13个不同的特征，对178个葡萄酒样本划分为类标为1，2，3的三个不同的类别，想要将这些样本划分为训练数据集和测试数据集，可以使用scikit-learn中的<code>train_test_split</code>函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line">X, y = df_wine.iloc[:, <span class="number">1</span>:].values, df_wine.iloc[:, <span class="number">0</span>].values</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.3</span>, random_state=<span class="number">0</span>)</span><br></pre></td></tr></table></figure><p>这样，我们就得到了$ 30% $的测试样本和$ 70% $的训练样本。</p><h2 id="将特征的值缩放到相同的区间"><a href="#将特征的值缩放到相同的区间" class="headerlink" title="将特征的值缩放到相同的区间"></a>将特征的值缩放到相同的区间</h2><p> <strong>特征缩放</strong>(peature scaling)是数据预处理中至关重要的一步，除了决策树和随机森林不需要特征缩放，其他的机器学习算法几乎都需要这个处理使得算法准确度提高。</p><p>特征缩放有两个常用的方法：归一化和标准化。归一化指的是将特征的值缩放到区间$ [0,1] $上，可以使用min-max缩放来实现：<br>$$<br>x_{norm}^i = \frac{x^i - x_{min}}{x^i - x_{max}}<br>$$<br>在scikit-learn中，已经实现了min-max缩放：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler</span><br><span class="line"></span><br><span class="line">mms = MinMaxScaler()</span><br><span class="line">X_train_norm = mms.fit_transform(X_train)</span><br><span class="line">X_test_norm = mms.fit_transform(X_test)</span><br></pre></td></tr></table></figure><p>而标准化的过程可以使用如下方程：<br>$$<br>x_{std}^i = \frac{x^i - \mu_x}{\sigma_x}<br>$$<br>其中，$ \mu_x $和$ \sigma_x $分别表示某个特征列的均值和样本。同样地，可以使用scikit-learn中的方法实现标准化：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"></span><br><span class="line">stdsc = StandardScaler()</span><br><span class="line">X_train_std = stdsc.fit_transform(X_train)</span><br><span class="line">X_test_std = stdsc.fit_transform(X_test)</span><br></pre></td></tr></table></figure><h2 id="选择有意义的特征"><a href="#选择有意义的特征" class="headerlink" title="选择有意义的特征"></a>选择有意义的特征</h2><p>如果一个模型在训练数据集上面的表现比在测试数据集上面好很多，那么很可能产生了过拟合。在本节中，我们将会学习使用正则化和特征选择降维这两种常用的减少过拟合问题的方法。</p><h3 id="使用L1正则化满足数据稀疏化"><a href="#使用L1正则化满足数据稀疏化" class="headerlink" title="使用L1正则化满足数据稀疏化"></a>使用L1正则化满足数据稀疏化</h3><p>在第三章节中，权重向量的L2范数如下：<br>$$<br>L2：||w||<em>2^2=\sum</em>{j=1}^{m}w_j^2<br>$$<br>而降低模型复杂度的L1正则化公式：<br>$$<br>L1：||w||<em>1 = \sum</em>{j=1}^m|w_j|<br>$$<br>对于scikit-learn来说，已经支持了 L1的正则化模型，可以将<code>penalty</code>参数设置为’l1’来进行简单的数据稀处理：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"></span><br><span class="line">LogisticRegression(penalty=<span class="string">&#x27;l1&#x27;</span>)</span><br></pre></td></tr></table></figure><p>我们将L1正则化用于标准化处理的葡萄酒数据，经过L1正则化的逻辑斯蒂回归模型可以产生如下稀疏化结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">lr = LogisticRegression(penalty=<span class="string">&#x27;l1&#x27;</span>, C=<span class="number">0.1</span>)</span><br><span class="line">lr.fit(X_train_std, y_train)</span><br><span class="line">print(<span class="string">&#x27;Training accuracy: &#x27;</span>, lr.score(X_train_std, y_train))</span><br><span class="line">print(<span class="string">&#x27;Test accuracy: &#x27;</span>, lr.score(X_test_std, y_test))</span><br><span class="line">&gt;&gt; Training accuracy:  <span class="number">0.9838709677419355</span></span><br><span class="line">&gt;&gt; Test accuracy:  <span class="number">0.9814814814814815</span></span><br></pre></td></tr></table></figure><p>训练和测试的精确度显示此模型未出现过拟合，通过如下代码可以获得截距项：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">lr.intercept_</span><br><span class="line">&gt;&gt; array([<span class="number">-0.38381104</span>, <span class="number">-0.1580416</span> , <span class="number">-0.70043119</span>])</span><br></pre></td></tr></table></figure><p>由于我们lr对象默认使用了一对多(One vs Rest, OvR)的方法，因此，第一项截距是类别1相对于类别2和类别3的匹配结果。同样，我们可以查看系数矩阵：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">lr.coef_</span><br><span class="line">&gt;&gt; array([[ <span class="number">0.2801916</span> ,  <span class="number">0.</span>        ,  <span class="number">0.</span>        , <span class="number">-0.02793952</span>,  <span class="number">0.</span>        ,</span><br><span class="line">&gt;&gt;         <span class="number">0.</span>        ,  <span class="number">0.71018709</span>,  <span class="number">0.</span>        ,  <span class="number">0.</span>        ,  <span class="number">0.</span>        ,</span><br><span class="line">&gt;&gt;         <span class="number">0.</span>        ,  <span class="number">0.</span>        ,  <span class="number">1.2362193</span> ],</span><br><span class="line">&gt;&gt;       [<span class="number">-0.64408995</span>, <span class="number">-0.06876656</span>, <span class="number">-0.05722202</span>,  <span class="number">0.</span>        ,  <span class="number">0.</span>        ,</span><br><span class="line">&gt;&gt;         <span class="number">0.</span>        ,  <span class="number">0.</span>        ,  <span class="number">0.</span>        ,  <span class="number">0.</span>        , <span class="number">-0.92643033</span>,</span><br><span class="line">&gt;&gt;         <span class="number">0.06037655</span>,  <span class="number">0.</span>        , <span class="number">-0.37111071</span>],</span><br><span class="line">&gt;&gt;       [ <span class="number">0.</span>        ,  <span class="number">0.06151885</span>,  <span class="number">0.</span>        ,  <span class="number">0.</span>        ,  <span class="number">0.</span>        ,</span><br><span class="line">&gt;&gt;         <span class="number">0.</span>        , <span class="number">-0.6360538</span> ,  <span class="number">0.</span>        ,  <span class="number">0.</span>        ,  <span class="number">0.49810762</span>,</span><br><span class="line">&gt;&gt;        <span class="number">-0.35817768</span>, <span class="number">-0.57128442</span>,  <span class="number">0.</span>        ]])</span><br></pre></td></tr></table></figure><p>可以发现，权重向量是稀疏的，这意味着只有少数几个特征被考虑进来，符合L1的作用效果。</p><p>最后，对L1正则化来说，在强的正则化参数(C&lt;0.1)的作用下，罚项使得所有的特征权重趋于0。</p><blockquote><p>在前面已经介绍过，$ \lambda $是正则化参数，而C是正则化参数的倒数。</p></blockquote><h3 id="序列特征选择算法"><a href="#序列特征选择算法" class="headerlink" title="序列特征选择算法"></a>序列特征选择算法</h3><p>另外一种降低模型复杂度从而解决过拟合问题的方法是通过特征选择进行<strong>降维</strong>，该方法对未经正则化处理的模型特别有效。降维技术主要分为两个大类：<strong>特征选择</strong>和<strong>特征提取</strong>。通过特征选择，可以选择原始特征的一个子集；而在特征提取中，通过对现有的特征信息进行推演，构造出一个新的特征子空间。</p><p>在本节中，我们着眼于一些经 </p><p>序列特征选择算法是一种贪婪搜索方法，用于将原始的d维特征空间压缩到一个k维空间中，其中$ k &lt; d $。一个经典的序列特征选择算法是<strong>序列后向选择算法</strong>（SBS），其目的是在分类行性能衰弱最小的约束小，降低原始数据的维度，提高计算效率。</p><p>SBS算法的理念很简单：SBS依次从特征集合中删除某些特征，直到新的特征子空间包含指定数量的特征。为了确定每一步需要删除的特征，为此我们需要定义一个最小化的标准衡量函数J。该函数的计算准则是：比较判定分类器在删除某个特征前后的差异，每次删除的特征，就是那些能够使得标准衡量函数值尽可能大的特征，或者说，每一步特征被删除后，所引起的模型性能损失最小。</p><p>基于上述对SBS的定义，总结出以下四个步骤：</p><ol><li>设$ k = d $进行算法初始化，其中 d 是特征空间$ X_d $的维度。</li><li>定义$ x^- $为满足标准$ x^- = argmaxJ(X_k - x) $最大化的特征，其中$ x \in X_k $。</li><li>将特征$ x^- $从特征集中删除：$ X_{k-1}  = X_k - x^- , k = k -1$。</li><li>如果k的值等于目标特征数量，算法终止，否则跳转到第2步。</li></ol><p>遗憾的是，scikit-learn并没有实现SBS算法，我们可以手动实现它：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.base <span class="keyword">import</span> clone</span><br><span class="line"><span class="keyword">from</span> itertools <span class="keyword">import</span> combinations</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SBS</span>():</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, estimator, k_features, scoring=accuracy_score, test_size=<span class="number">0.25</span>, random_state=<span class="number">1</span></span>):</span></span><br><span class="line">        self.scoring = scoring</span><br><span class="line">        self.estimator = clone(estimator)</span><br><span class="line">        self.k_features = k_features</span><br><span class="line">        self.test_size = test_size</span><br><span class="line">        slef.random_state = random_state</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, X, y</span>):</span></span><br><span class="line">        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=self.test_size, random_state=self.random_state)</span><br><span class="line">        dim = X_train.shape[<span class="number">1</span>]</span><br><span class="line">        self.indices_ = tuple(range(dim))</span><br><span class="line">        self.subsets_ = [self.indices_]</span><br><span class="line">        score = self._calc_score(X_train, y_train, X_test, y_test, self.indices_)</span><br><span class="line">        self.scores_ = [score]</span><br><span class="line">        <span class="keyword">while</span> dim &gt; self.k_features:</span><br><span class="line">            scores = []</span><br><span class="line">            subsets = []</span><br><span class="line">            <span class="keyword">for</span> p <span class="keyword">in</span> combinations(self.indices_, r=dim<span class="number">-1</span>):</span><br><span class="line">                score = self._calc_score(X_train, y_train, X_test, y_test, p)</span><br><span class="line">                scores.append(score)</span><br><span class="line">                subsets.append(p)</span><br><span class="line">            best = np.argmax(scores)</span><br><span class="line">            self.indices_ = subsets[best]</span><br><span class="line">            self.subsets_.append(self.indices_)</span><br><span class="line">            dim -= <span class="number">1</span></span><br><span class="line">            self.scores_.append(scores[best])</span><br><span class="line">        self.k_score_ = self.scores_[<span class="number">-1</span>]</span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">transform</span>(<span class="params">self, X</span>):</span></span><br><span class="line">        <span class="keyword">return</span> X[:, self.indices_]</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_calc_score</span>(<span class="params">self, X_train, y_train, X_test, y_test, indices</span>):</span></span><br><span class="line">        self.estimator.fit(X_train[:, indices], y_train)</span><br><span class="line">        y_pred = self.estimator.predict(X_test[:, indices])</span><br><span class="line">        score = self.scoring(y_test, y_pred)</span><br><span class="line">        <span class="keyword">return</span> score</span><br><span class="line">            </span><br></pre></td></tr></table></figure><p>我们使用k_features来指定需要返回的特征数量，并且最终特征子集的列标被赋值给self.indices_。注意，在fit方法中，我们没有在fit方法中明确地计算评价标准，只是简单的删除了那些没有包含在最优特征子集中的特征。</p><p>接下来我们看一下SBS应用于KNN分类器的效果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">knn = KNeighborsClassifier(n_neighbors=<span class="number">2</span>)</span><br><span class="line">sbs = SBS(knn, k_features=<span class="number">1</span>)</span><br><span class="line">sbs.fit(X_train_std, y_train)</span><br><span class="line">k_feat = [len(k) <span class="keyword">for</span> k <span class="keyword">in</span> sbs.subsets_]</span><br><span class="line">plt.plot(k_feat, sbs.scores_, marker=<span class="string">&#x27;o&#x27;</span>)</span><br><span class="line">plt.ylim([<span class="number">0.7</span>, <span class="number">1.1</span>])</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Accuracy&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Number of features&#x27;</span>)</span><br><span class="line">plt.grid()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>得到的图像如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="Mon,%2003%20Feb%202020%20201354.png" class="lazyload" data-srcset="Mon,%2003%20Feb%202020%20201354.png" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><p>可以发现，当k = {5, 6, 7, 8, 9, 10}时，算法可以达到百分百的准确率。</p><p>接下来看一下是哪五个特征在验证数据集上有如此良好的表现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">k5 = list(sbs.subsets_[<span class="number">8</span>])</span><br><span class="line">print(df_wine.columns[<span class="number">1</span>:][k5])</span><br><span class="line">&gt;&gt; Index([<span class="string">&#x27;Alcohol&#x27;</span>, <span class="string">&#x27;Malic acid&#x27;</span>, <span class="string">&#x27;Alcalinity of ash&#x27;</span>, <span class="string">&#x27;Hue&#x27;</span>, <span class="string">&#x27;Proline&#x27;</span>], dtype=<span class="string">&#x27;object&#x27;</span>)</span><br></pre></td></tr></table></figure><h2 id="通过随机森林判定特征的重要性"><a href="#通过随机森林判定特征的重要性" class="headerlink" title="通过随机森林判定特征的重要性"></a>通过随机森林判定特征的重要性</h2><p>接下来使用随机森林来从数据集中选择相关特征，下面的代码根据葡萄酒数据集特征重要程度对这13个特征给出重要性等级。但是注意：<strong>无需对基于树的模型做标准化或者归一化处理</strong>。代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line">feat_labels = df_wine.columns[<span class="number">1</span>:]</span><br><span class="line">forest = RandomForestClassifier(n_estimators=<span class="number">10000</span>, random_state=<span class="number">0</span>, n_jobs=<span class="number">-1</span>)</span><br><span class="line">forest.fit(X_train, y_train)</span><br><span class="line">importances = forest.feature_importances_</span><br><span class="line">indices = np.argsort(importances)[::<span class="number">-1</span>]</span><br><span class="line"><span class="keyword">for</span> f <span class="keyword">in</span> range(X_train.shape[<span class="number">1</span>]):</span><br><span class="line">    print(<span class="string">&quot;%2d) %-*s %f&quot;</span> % (f + <span class="number">1</span>, <span class="number">30</span>, feat_labels[f], importances[indices[f]]))</span><br></pre></td></tr></table></figure><p>得到的输出数据如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"> 1) Alcohol                        0.182483</span><br><span class="line"> 2) Malic acid                     0.158610</span><br><span class="line"> 3) Ash                            0.150948</span><br><span class="line"> 4) Alcalinity of ash              0.131987</span><br><span class="line"> 5) Magnesium                      0.106589</span><br><span class="line"> 6) Total phenols                  0.078243</span><br><span class="line"> 7) Flavanoids                     0.060718</span><br><span class="line"> 8) Nonflavanoid phenols           0.032033</span><br><span class="line"> 9) Proanthocyanins                0.025400</span><br><span class="line">10) Color intensity                0.022351</span><br><span class="line">11) Hue                            0.022078</span><br><span class="line">12) diluted wines                  0.014645</span><br><span class="line">13) Proline                        0.013916</span><br></pre></td></tr></table></figure><p>从上述输出我们可以得到最具有判别效果的特征是‘Alcohol’。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>使用scikit-learn实现分类算法</title>
      <link href="2020/01/30/%E4%BD%BF%E7%94%A8scikit-learn%E5%AE%9E%E7%8E%B0%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95/"/>
      <url>2020/01/30/%E4%BD%BF%E7%94%A8scikit-learn%E5%AE%9E%E7%8E%B0%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<p>在本节中，我们将会介绍常用分类算法的概念，以及如何使用 scikit-learn 机器学习库和选择机器学习算法时需要注意的问题。</p><a id="more"></a><h2 id="分类算法的选择"><a href="#分类算法的选择" class="headerlink" title="分类算法的选择"></a>分类算法的选择</h2><p>机器学习算法涉及到的五个步骤可以描述如下：</p><ol><li>特征的选择</li><li>确定性能评价标准</li><li>选择分类器及其优化算法</li><li>对模型性能的评估</li><li>算法的调优</li></ol><p>在本节中集中学习不同分类算法的概念，并再次回顾特征选择，预处理及性能评价指标等内容。</p><h2 id="初涉-scikit-learn-的使用"><a href="#初涉-scikit-learn-的使用" class="headerlink" title="初涉 scikit-learn 的使用"></a>初涉 scikit-learn 的使用</h2><p>首先，使用 scikit-learn 来实现一个感知器模型，这个模型和前面讲的感知器模型类似。仍旧使用鸢尾花数据集中的两个特征。</p><p>提取150朵鸢尾花的花瓣长度和宽度两个特征的值，并且由此构建矩阵$ X $，同时将对应的类标赋值给$ y $：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line">X = iris.data[:, [<span class="number">2</span>, <span class="number">3</span>]]</span><br><span class="line">y = iris.target</span><br></pre></td></tr></table></figure><p>为了评估训练得到的模型在位置数据上的表现，我们进一步将数据集划分为训练数据集和测试数据集：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="comment"># sklearn.cross_validation 已经废弃，改用sklearn.model_selection</span></span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.3</span>, random_state=<span class="number">0</span>)</span><br></pre></td></tr></table></figure><p>由此，我们得到45个测试样本和105个训练样本。为了优化性能，还需要对数据进行特征缩放：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"></span><br><span class="line">sc = StandardScaler()</span><br><span class="line">sc.fit(X_train)</span><br><span class="line">X_train_std = sc.transform(X_train)</span><br><span class="line">X_test_std = sc.transform(X_test)</span><br></pre></td></tr></table></figure><p>通过调用 <code>sc.fit</code>可以计算出<code>X_train</code>的每个特征的样本均值$ \mu $和标准差$ \sigma $。通过调用<code>transform</code>方法，可以使用已经计算出来的$ \mu $和$ \sigma $来对训练集数据做标准化处理。在特征缩放后，我们就可以训练感知器模型了：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Perceptron</span><br><span class="line"></span><br><span class="line">ppn = Perceptron(max_iter=<span class="number">40</span>, eta0=<span class="number">0.1</span>, random_state=<span class="number">0</span>)</span><br><span class="line">ppn.fit(X_train_std, y_train)</span><br></pre></td></tr></table></figure><p>训练好后，就可以进行预测了：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">y_pred = ppn.predict(X_test_std)</span><br><span class="line">print(<span class="string">&#x27;Misclassified samples: %d&#x27;</span> % (y_test != y_pred).sum())</span><br><span class="line">&gt;&gt; Misclassified samples: <span class="number">5</span></span><br></pre></td></tr></table></figure><p>最终可以看到有5个预测错误，从而准确率是$ 89% $。同样地，scikit-learn还实现了许多不同 的性能矩阵，可以通过如下代码计算准确率：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"></span><br><span class="line">print(<span class="string">&#x27;Accuracy: %.2f&#x27;</span> % accuracy_score(y_test, y_pred))</span><br><span class="line">&gt;&gt; Accuracy: <span class="number">0.89</span></span><br></pre></td></tr></table></figure><p>最后，我们可以在第二章中实现的<code>plot_decision_regions</code>函数来绘制刚刚训练过的<strong>决策区域</strong>，并且观察不同分类的效果，代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> matplotlib.colors <span class="keyword">import</span> ListedColormap</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_decision_regions</span>(<span class="params">X, y, classifier, test_idx=None, resolution=<span class="number">0.02</span></span>):</span></span><br><span class="line">    <span class="comment"># setup marker generator and color map</span></span><br><span class="line">    markers = (<span class="string">&#x27;s&#x27;</span>, <span class="string">&#x27;x&#x27;</span>, <span class="string">&#x27;o&#x27;</span>, <span class="string">&#x27;^&#x27;</span>, <span class="string">&#x27;v&#x27;</span>)</span><br><span class="line">    colors = (<span class="string">&#x27;red&#x27;</span>, <span class="string">&#x27;blue&#x27;</span>, <span class="string">&#x27;lightgreen&#x27;</span>, <span class="string">&#x27;gray&#x27;</span>, <span class="string">&#x27;cyan&#x27;</span>)</span><br><span class="line">    cmap = ListedColormap(colors[:len(np.unique(y))])</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># plot the decision surface</span></span><br><span class="line">    x1_min, x1_max = X[:, <span class="number">0</span>].min() - <span class="number">1</span>, X[:, <span class="number">0</span>].max() + <span class="number">1</span></span><br><span class="line">    x2_min, x2_max = X[:, <span class="number">1</span>].min() - <span class="number">1</span>, X[:, <span class="number">1</span>].max() + <span class="number">1</span></span><br><span class="line">    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution), np.arange(x2_min, x2_max, resolution))</span><br><span class="line">    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)</span><br><span class="line">    Z = Z.reshape(xx1.shape)</span><br><span class="line">    plt.contourf(xx1, xx2, Z, alpha=<span class="number">0.4</span>, cmap=cmap)</span><br><span class="line">    plt.xlim(xx1.min(), xx1.max())</span><br><span class="line">    plt.ylim(xx2.min(), xx2.max())</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># plot all samples</span></span><br><span class="line">    X_test, y_test = X[test_idx, :], y[test_idx]</span><br><span class="line">    <span class="keyword">for</span> idx, cl <span class="keyword">in</span> enumerate(np.unique(y)):</span><br><span class="line">        plt.scatter(x=X[y == cl, <span class="number">0</span>], y=X[y == cl, <span class="number">1</span>], alpha=<span class="number">0.8</span>, c=cmap(idx), marker=markers[idx], label=cl)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> test_idx:</span><br><span class="line">        X_test, y_test = X[test_idx, :], y[test_idx]</span><br><span class="line">        plt.scatter(X_test[:, <span class="number">0</span>], X_test[:, <span class="number">1</span>], c=<span class="string">&#x27;orange&#x27;</span>, alpha=<span class="number">1</span>, linewidth=<span class="number">1</span>, marker=<span class="string">&#x27;+&#x27;</span>, s=<span class="number">55</span>, label=<span class="string">&#x27;test set&#x27;</span>)</span><br><span class="line">        </span><br></pre></td></tr></table></figure><p>接下来，就可以回值决策区域图了：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">X_combined_std = np.vstack((X_train_std, X_test_std))</span><br><span class="line">y_combined = np.hstack((y_train, y_test))</span><br><span class="line">plot_decision_regions(X=X_combined_std, y=y_combined, classifier=ppn, test_idx=range(<span class="number">105</span>, <span class="number">150</span>))</span><br><span class="line">plt.xlabel(<span class="string">&#x27;petal length&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;petal width&#x27;</span>)</span><br><span class="line">plt.legend(loc=<span class="string">&#x27;upper left&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>绘图如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="Thu,%2030%20Jan%202020%20144855.png" class="lazyload" data-srcset="Thu,%2030%20Jan%202020%20144855.png" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><p>从图中我们发现无法通过一个线性的决策边界完美划分三类样本。对于无法完美线性可分的数据集，感知器算法将会永远无法收敛，这也是实践中一般不使用感知器算法的原因。</p><h2 id="逻辑斯蒂回归中的类别概率"><a href="#逻辑斯蒂回归中的类别概率" class="headerlink" title="逻辑斯蒂回归中的类别概率"></a>逻辑斯蒂回归中的类别概率</h2><h3 id="初识逻辑斯蒂回归模型"><a href="#初识逻辑斯蒂回归模型" class="headerlink" title="初识逻辑斯蒂回归模型"></a>初识逻辑斯蒂回归模型</h3><p>逻辑斯蒂回归模型和Adaline模型类似，不同的是在Adaline中，我们使用$ \phi(z)=z $作为激励函数，而在逻辑斯蒂回归中使用的是sigmoid函数作为激励模型：<br>$$<br>sigmoid(z) = \phi(z) = \frac{1}{1+e^{-z}}<br>$$<br>它的函数图像如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="timg-1580368063667.jfif" class="lazyload" data-srcset="timg-1580368063667.jfif" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><p>在给定特征$ x $和权重$ w $的情况下，sigmoid函数的输出值给出了特定样本$ x $属于类别1的概率$ \phi(z) = P(y=1|x;w) $。预测到的概率可以通过一个量化器进行二元输出：<br>$$<br>\hat{y}=\begin{cases}<br>1 &amp; \phi(z) \ge 0.5\<br>0 &amp; others<br>\end{cases}<br>$$<br>对应的，逻辑斯蒂回归模型图如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="th-1580368751444.jfif" class="lazyload" data-srcset="th-1580368751444.jfif" srcset="data:image/png;base64,666" alt="See the source image"/></div><span class="image-caption">See the source image</span></div><h3 id="逻辑斯蒂回归模型的代价函数"><a href="#逻辑斯蒂回归模型的代价函数" class="headerlink" title="逻辑斯蒂回归模型的代价函数"></a>逻辑斯蒂回归模型的代价函数</h3><p>在构建逻辑斯蒂回归模型时，需要先定义一个最大似然函数，公式如下:<br>$$<br>L(w) = \prod_{i=1}^{n}P(y^i|x^i;w)=(\phi(z^i))^{y^i}(1-\phi(z))^{1-y^i}<br>$$<br>然后取对数并且改写一下，得到如下：<br>$$<br>J(w) = \sum_i^n-y^ilog(\phi(z^i)) - (1-y^i)log(1-\phi(z^i))<br>$$<br>我们可以对单个样本实例进行成本分析：<br>$$<br>J(\phi(z),y;w) = \begin{cases}<br>-log(\phi(z)) &amp; y=1\<br>-log(1-\phi(z)) &amp; y=0<br>\end{cases}<br>$$<br><img src="1580370420597.png" class="lazyload" data-srcset="1580370420597.png" srcset="data:image/png;base64,666" alt="1580370420597"></p><p>可以看到，如果正确将样本划分到类别1和0中，代价都将会趋于0，但是如果错误分类，代价将会区域无穷，这也就意味着错误预测带来的代价将会越来越大。</p><h3 id="使用scikit-learn训练逻辑斯蒂回归模型"><a href="#使用scikit-learn训练逻辑斯蒂回归模型" class="headerlink" title="使用scikit-learn训练逻辑斯蒂回归模型"></a>使用scikit-learn训练逻辑斯蒂回归模型</h3><p>接下来，我们使用逻辑斯蒂回归模型来训练鸢尾花数据集：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"></span><br><span class="line">lr = LogisticRegression(C=<span class="number">1000.0</span>, random_state=<span class="number">0</span>)</span><br><span class="line">lr.fit(X_train_std, y_train)</span><br><span class="line">plot_decision_regions(X_combined_std, y_combined, classifier=lr, test_idx=range(<span class="number">105</span>, <span class="number">150</span>))</span><br><span class="line">plt.xlabel(<span class="string">&#x27;length&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;width&#x27;</span>)</span><br><span class="line">plt.legend(loc=<span class="string">&#x27;upper left&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>得到的决策区域图如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="Thu,%2030%20Jan%202020%20155618.png" class="lazyload" data-srcset="Thu,%2030%20Jan%202020%20155618.png" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><p>此外，可以通过<code>predict_proba</code>来预测样本属于某个类别的概率：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">lr.predict_proba(X_test_std[<span class="number">0</span>:<span class="number">1</span>, :])</span><br><span class="line">&gt;&gt; array([[<span class="number">1.78177322e-11</span>, <span class="number">6.12453348e-02</span>, <span class="number">9.38754665e-01</span>]])</span><br></pre></td></tr></table></figure><p>此结果表示模型预测此样本属于类标1的概率是$ 6.1% $，属于类标2的概率是$ 93.9% $。</p><h3 id="通过正则化解决过拟合问题"><a href="#通过正则化解决过拟合问题" class="headerlink" title="通过正则化解决过拟合问题"></a>通过正则化解决过拟合问题</h3><p>过拟合是机器学习中常见的问题，过拟合具有高方差，这可能是使用了较多的参数，使得模型过于复杂。同样地，模型也会面临着欠拟合问题，欠拟合具有高偏差，这意味着模型过于简单，使得我们在预测时性能不佳。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="u=1743534219,2796932966&fm=173&app=49&f=JPEG.jfif" class="lazyload" data-srcset="u=1743534219,2796932966&fm=173&app=49&f=JPEG.jfif" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><p>偏差-方差权衡（bias-variance tradeoff）就是通过正则化来调整模型的复杂度。正则化时解决共线性（特征间高度相关）的一个很有用的方法，最常用的正则化形式是<strong>L2正则化</strong>，可以写作：<br>$$<br>\frac{\lambda}{2}||w||^2=\frac{\lambda}{2}\sum_{j=1}^m w_j^2<br>$$<br>其中，$ \lambda $是正则化系数。</p><blockquote><p>特征缩放之所以很重要，其中一个原因是正则化。为了使得正则化起作用，需要确保所有特征的衡量标准保持统一。</p></blockquote><p>使用正则化方法时，我们只需要在逻辑斯蒂回归的代价函数中加入正则化项，以降低系数带来的副作用：<br>$$<br>J(w) = \left(\sum_i^n-y^ilog(\phi(z^i)) - (1-y^i)log(1-\phi(z^i))\right)+\frac{\lambda}{2}||w||^2<br>$$<br>前面用到的scikit-learn中的LogisticRegression类，其中的参数<code>C</code>时正则化系数的倒数：<br>$$<br>C = \frac{1}{\lambda}<br>$$</p><h2 id="使用支持向量机最大化分类间隔"><a href="#使用支持向量机最大化分类间隔" class="headerlink" title="使用支持向量机最大化分类间隔"></a>使用支持向量机最大化分类间隔</h2><p>另外一种性能强大且广泛应用的学习算法时支持向量机（SVM），它可以看作是对感知器的扩展。在SVM中，我们的目标是最大化分类间隔。在此处间隔指的是两个分离的决策边界间的距离，而最靠近决策边界的训练样本称作是支持向量：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="v2-197913c461c1953c30b804b4a7eddfcc_1200x500-1580373915538.jpg" class="lazyload" data-srcset="v2-197913c461c1953c30b804b4a7eddfcc_1200x500-1580373915538.jpg" srcset="data:image/png;base64,666" alt="支持向量机（SVM）——原理篇"/></div><span class="image-caption">支持向量机（SVM）——原理篇</span></div><h3 id="对分类间隔最大化的直观认识"><a href="#对分类间隔最大化的直观认识" class="headerlink" title="对分类间隔最大化的直观认识"></a>对分类间隔最大化的直观认识</h3><p>我们将平面分为正平面和负平面，对于正平面来说：<br>$$<br>w_0+w^TX_{pos}=1<br>$$<br>对于负平面：<br>$$<br>w_0+w^TX_{neg}=-1<br>$$<br>对以上两式，相减得<br>$$<br>w^T(X_{pos}-X_{neg})=2<br>$$<br>定义$ ||w|| =  \sqrt{\sum_{j=1}^{m}w_j^2} $，于是可得到如下等式：<br>$$<br>\frac{w^T(X_{pos}-X_{neg})}{||w||}=\frac{2}{||w||}<br>$$<br>上述等式的左侧可以解释为正负平面间的距离，也就是我们要最大化的距离。在样本正确分类的前提下，最大化分类间隔就是$ \frac{2}{||w||} $最大化，这也是SVM的目标函数，记作：<br>$$<br>w_0+w^Tx^i \ge 1, if\ y^i=1\<br>w_0+w^Tx^i \lt -1, if\ y^i=-1<br>$$<br>这两个方程可以解释为：所有的负样本都落在负超平面一侧，所有的正样本都落在正超平面一侧划分的区域中。实践中，使用二次规划方法很容易求出$ \frac{||w||}{2} $的最小值。</p><h3 id="使用松弛变量解决非线性可分问题"><a href="#使用松弛变量解决非线性可分问题" class="headerlink" title="使用松弛变量解决非线性可分问题"></a>使用松弛变量解决非线性可分问题</h3><p>引入松弛变量$ \xi $的目的是：放松线性约束条件，以保证在适当的惩罚项样本下，对错误分类的情况进行优化时能够收敛。</p><p>取值为正的松弛变量可以简单的加到线性约束条件中：<br>$$<br>w^Tx^i \ge 1, if\ y^i=1 - \xi^i\<br>w^Tx^i \lt -1, if\ y^i=-1 + \xi^i<br>$$<br>由此，新的优化目标为<br>$$<br>\frac{||w||}{2}+C(\sum_i\xi^i)<br>$$<br>通过变量C，我们可以控制对错误分类的惩罚程度，进而在偏差和方差之间取得平衡。</p><h3 id="使用scikit-learn实现SVM"><a href="#使用scikit-learn实现SVM" class="headerlink" title="使用scikit-learn实现SVM"></a>使用scikit-learn实现SVM</h3><p>接下来，我们使用SVM模型来对鸢尾花数据集中的样本进行分类：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line"></span><br><span class="line">svm = SVC(kernel=<span class="string">&#x27;linear&#x27;</span>, C=<span class="number">1.0</span>, random_state=<span class="number">0</span>)</span><br><span class="line">svm.fit(X_train_std, y_train)</span><br><span class="line">plot_decision_regions(X_combined_std, y_combined, classifier=svm, test_idx=range(<span class="number">105</span>, <span class="number">150</span>))</span><br><span class="line">plt.xlabel(<span class="string">&#x27;length&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;width&#x27;</span>)</span><br><span class="line">plt.legend(loc=<span class="string">&#x27;upper left&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>得到图像如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="Fri,%2031%20Jan%202020%20123057.png" class="lazyload" data-srcset="Fri,%2031%20Jan%202020%20123057.png" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><blockquote><p>在实际的分类任务中，线性逻辑斯蒂回归和支持向量机往往得到相似的结果。但是逻辑斯蒂回归比SVM更容易处理离群点，而SVM更关注接近决策边界的点。</p></blockquote><p>在有些数据集很大的时候，可以使用scikit-learn提供的SGDClassifier类供用户选择，这个流泪还提供了<code>partial-fit</code>方法支持在线学习。SGDClassifier类的概念类似于随机梯度算法。</p><p>我们可以使用以下方式分别构建基于随机梯度下降的感知器，逻辑斯蒂回归以及支持向量机模型。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> SGDClassifier</span><br><span class="line"></span><br><span class="line">ppn = SGDClassifier(loss=<span class="string">&#x27;perceptron&#x27;</span>)</span><br><span class="line">lr = SGDClassifier(loss=<span class="string">&#x27;log&#x27;</span>)</span><br><span class="line">svm = SGDClassifier(loss=<span class="string">&#x27;hinge&#x27;</span>)</span><br></pre></td></tr></table></figure><h2 id="使用核SVM解决非线性问题"><a href="#使用核SVM解决非线性问题" class="headerlink" title="使用核SVM解决非线性问题"></a>使用核SVM解决非线性问题</h2><p>SVM受欢迎的一个原因是：通过“核技巧”可以很容易解决非线性可分问题。</p><p>首先来了解非线性可分问题到底是什么。通过NumPy的<code>logicol_xor</code>来创建数据集，其中100个样本属于类别1，另外的100个样本属于类别-1：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">np.random.seed(<span class="number">0</span>)</span><br><span class="line">X_xor = np.random.randn(<span class="number">200</span>, <span class="number">2</span>)</span><br><span class="line">y_xor = np.logical_xor(X_xor[:, <span class="number">0</span>] &gt; <span class="number">0</span>, X_xor[:, <span class="number">1</span>] &gt; <span class="number">0</span>)</span><br><span class="line">y_xor = np.where(y_xor, <span class="number">1</span>, <span class="number">-1</span>)</span><br><span class="line">plt.scatter(X_xor[y_xor==<span class="number">1</span>, <span class="number">0</span>], X_xor[y_xor==<span class="number">1</span>, <span class="number">1</span>], c=<span class="string">&#x27;b&#x27;</span>, marker=<span class="string">&#x27;x&#x27;</span>, label=<span class="string">&#x27;1&#x27;</span>)</span><br><span class="line">plt.scatter(X_xor[y_xor==<span class="number">-1</span>, <span class="number">0</span>], X_xor[y_xor==<span class="number">-1</span>, <span class="number">1</span>], c=<span class="string">&#x27;r&#x27;</span>, marker=<span class="string">&#x27;s&#x27;</span>, label=<span class="string">&#x27;-1&#x27;</span>)</span><br><span class="line">plt.ylim(<span class="number">-3.0</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>执行以上代码后，我们得到了一个“异或”数据集，二维分布如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="Fri,%2031%20Jan%202020%20134018.png" class="lazyload" data-srcset="Fri,%2031%20Jan%202020%20134018.png" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><p>显然，使用前面提到的线性逻辑斯蒂回归或者是线性SVM模型，都无法将样本正确划分为正类别和负类别。</p><p>核方法的基本思想是：通过映射函数$ \phi(\cdot) $将样本的原始特征映射到一个使样本线性可分的更高维的空间中，然后找到分界面后作反变换$ \phi^{-1}(\cdot) $可得到最初的划分平面。</p><p>但是这种映射会带来非常大的计算成本，这个时候我们就可以使用<strong>核技巧</strong>的方法。在实践中，我们所需要做的就是将点积$ x^{iT}x^j $映射为$ \phi((x^i)^T \phi(x^j) $，为此定义<br>$$<br>k(x^i, x^j) = \phi((x^i)^T \phi(x^j)<br>$$<br>一个最常使用的核函数就是径向基核函数（RBF kernel）：<br>$$<br>k(x^i, x^j) = exp(-\frac{||x^i-x^j||^2}{2\sigma^2}) = exp(-\gamma ||x^i-x^j||^2)<br>$$<br>其中，$ \gamma = \frac{1}{2\sigma^2} $是待优化的自由参数。接下来，就使用scikit-learn来训练一个核SVM使之可以对“异或”数据集进行分类：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">svm = SVC(kernel=<span class="string">&#x27;rbf&#x27;</span>, random_state=<span class="number">0</span>, gamma=<span class="number">0.10</span>, C=<span class="number">10.0</span>)</span><br><span class="line">svm.fit(X_xor, y_xor)</span><br><span class="line">plot_decision_regions(X_xor, y_xor, classifier=svm)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>得到的决策边界如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="Fri,%2031%20Jan%202020%20140538.png" class="lazyload" data-srcset="Fri,%2031%20Jan%202020%20140538.png" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><p>正如图像所示，核SVM较好地完成了对“异或”数据的划分。</p><p>在此，我们将$ \gamma $参数设置为了0.1，可以将其理解为高斯球面的截止参数（cut-off parameter）。为了更好的理解$ \gamma $参数，我们将基于RBF的SVM应用于鸢尾花数据集：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">svm = SVC(kernel=<span class="string">&#x27;rbf&#x27;</span>, random_state=<span class="number">0</span>, gamma=<span class="number">0.20</span>, C=<span class="number">10.0</span>)</span><br><span class="line">svm.fit(X_train_std, y_train)</span><br><span class="line">plot_decision_regions(X_combined_std, y_combined, classifier=svm, test_idx=range(<span class="number">105</span>, <span class="number">150</span>))</span><br><span class="line">plt.xlabel(<span class="string">&#x27;length&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;width&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>得到的图像如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="Fri,%2031%20Jan%202020%20141237.png" class="lazyload" data-srcset="Fri,%2031%20Jan%202020%20141237.png" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><p>现在改变$ \gamma = 5.0 $，得到的图像如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="Fri,%2031%20Jan%202020%20141428.png" class="lazyload" data-srcset="Fri,%2031%20Jan%202020%20141428.png" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><p>通过图像可以看出，使用一个较大的$ \gamma $值，会使得类别0核类别1的决策边界变得紧凑了许多。</p><p>虽然模型对训练数据的你和很好，但是类似的分类器对未知数据会有较大的泛化误差。</p><h2 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h2><p>基于训练集的特征，决策树模型通过一系列的问题来推断样本的类标。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="v2-ff4fe0d16ec17c5520837b3aad52ed54_hd.jpg" class="lazyload" data-srcset="v2-ff4fe0d16ec17c5520837b3aad52ed54_hd.jpg" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><p>从树根开始，基于可获得最大<strong>信息增益（Information Gain, IG）</strong>的特征来对数据进行划分，通过迭代处理，在每个节点重复此过程，直到叶子节点。</p><h3 id="最大化信息增益—-获知尽可能准确的结果"><a href="#最大化信息增益—-获知尽可能准确的结果" class="headerlink" title="最大化信息增益—-获知尽可能准确的结果"></a>最大化信息增益—-获知尽可能准确的结果</h3><p>就目前来说，大多数的库中实现的树算法都是二叉决策树。二叉决策树中常用的三个不纯度衡量标准或者划分标准分别是：基尼系数（Gini index, $ I_G $），熵（entropy， $ I_H $）以及误分类率（classification error， $ I_E $）。</p><p>非空类别熵的定义是<br>$$<br>I_H(t) = -\sum_{i=1}^c p(i|t)\log_2p(i|t)<br>$$<br>其中，$ p(i|t) $为在特定节点t中，属于类别i的样本占特定样本t中样本总数的比例。如果某一个节点中所有样本都属于同一个类别，那么它的熵是0，当样本以相同的比例分属于不同的类时，熵的值最大。</p><p>直观地说，基尼系数可以理解为降低误分类可能性的标准：<br>$$<br>I_G(t) = \sum_{i=1}^{c}p(i|t)(1-p(i|t)) = 1 - \sum_{i=1}^c p(i|t)^2<br>$$<br>和熵类似，当所有样本时等比例分布时，基尼系数的值最大。</p><p>误分类率的定义如下：<br>$$<br>I_E = 1 - max{p(i|t)}<br>$$<br>这是对于剪枝方法很有用的准则，但不建议用于决策树的构建过程，因为它对节点中各类别样本数量的变动不敏感。</p><h3 id="构建决策树"><a href="#构建决策树" class="headerlink" title="构建决策树"></a>构建决策树</h3><p>通过使用scikit-learn来构建一颗二叉决策树，需要注意的是，决策树的深度不是越大越好，深度过大的决策树，很容易产生过拟合的现象。在此，构建一棵深度是3的决策树：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"></span><br><span class="line">tree = DecisionTreeClassifier(criterion=<span class="string">&#x27;entropy&#x27;</span>, max_depth=<span class="number">3</span>, random_state=<span class="number">0</span>)</span><br><span class="line">tree.fit(X_train, y_train)</span><br><span class="line">X_combined = np.vstack((X_train, X_test))</span><br><span class="line">y_combined = np.hstack((y_train, y_test))</span><br><span class="line">plot_decision_regions(X_combined, y_combined, classifier=tree, test_idx=range(<span class="number">105</span>, <span class="number">150</span>))</span><br><span class="line">plt.xlabel(<span class="string">&#x27;length&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;width&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>得到的决策边界如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="Fri,%2031%20Jan%202020%20145128.png" class="lazyload" data-srcset="Fri,%2031%20Jan%202020%20145128.png" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><h3 id="通过随机森林将弱分类器集成为强分类器"><a href="#通过随机森林将弱分类器集成为强分类器" class="headerlink" title="通过随机森林将弱分类器集成为强分类器"></a>通过随机森林将弱分类器集成为强分类器</h3><p>直观上，随机森林可以看作是多颗决策树的集成。随机森林算法可以概括为一下几个步骤：</p><ol><li>使用bootstrap抽样方法随机选择 n 个样本用于训练（从训练集中随机可重复选择n个样本）</li><li>使用第 1 步选定的样本构建一棵决策树，节点划分如下：<ol><li>不重复选择d个特征</li><li>根据目标函数的要求，使用选定的特征对节点进行划分</li></ol></li><li>重复上述过程1~2000次</li><li>汇总每棵树的类标进行多数投票</li></ol><p>使用scikit-learn来实现随机森林：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"></span><br><span class="line">forest = RandomForestClassifier(criterion=<span class="string">&#x27;entropy&#x27;</span>, n_estimators=<span class="number">10</span>, random_state=<span class="number">1</span>, n_jobs=<span class="number">2</span>)</span><br><span class="line">forest.fit(X_train, y_train)</span><br><span class="line">plot_decision_regions(X_combined, y_combined, classifier=forest, test_idx=range(<span class="number">105</span>, <span class="number">150</span>))</span><br><span class="line">plt.xlabel(<span class="string">&#x27;length&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;width&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>得到的决策区域如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="Fri,%2031%20Jan%202020%20150555.png" class="lazyload" data-srcset="Fri,%2031%20Jan%202020%20150555.png" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><p>上述代码中，我们以熵作为不纯度衡量标准，且使用了10棵决策树进行随机森林的训练，同时我们还规定算法中使用的处理器内核数量为2。</p><h2 id="惰性学习算法之k-近临算法"><a href="#惰性学习算法之k-近临算法" class="headerlink" title="惰性学习算法之k-近临算法"></a>惰性学习算法之k-近临算法</h2><p>k-近临算法（k-nearest neighbor classifier，KNN）是惰性学习算法的典型例子。KNN算法本身是简单的，可以归纳为以下几步：</p><ol><li>选择近临数量k和距离衡量方法</li><li>找到待分类样本的k个最近邻居</li><li>根据最近临的类标进行多数投票</li></ol><p>下图说明了当k=3时，范围内红色三角形多，这个待分类点属于红色三角形；当K = 5 时，范围内蓝色正方形多，这个待分类点属于蓝色正方形。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="v2-e780b42d95a9d577c264fa1183b571ef_hd.jpg" class="lazyload" data-srcset="v2-e780b42d95a9d577c264fa1183b571ef_hd.jpg" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><p>KNN算法可以快速适应新的训练数据，不过它的缺点也是显而易见的，在最坏情况下，计算复杂度随着样本的增多而线性增长。</p><p>接下来使用scikit-learn实现KNN模型，在此，我们选择欧几里得距离作为度量标准：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"></span><br><span class="line">knn = KNeighborsClassifier(n_neighbors=<span class="number">5</span>, p=<span class="number">2</span>, metric=<span class="string">&#x27;minkowski&#x27;</span>)</span><br><span class="line">knn.fit(X_train_std, y_train)</span><br><span class="line">plot_decision_regions(X_combined_std, y_combined, classifier=knn, test_idx=range(<span class="number">105</span>, <span class="number">150</span>))</span><br><span class="line">plt.xlabel(<span class="string">&#x27;length&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;width&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>得到的决策区域如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="Fri,%2031%20Jan%202020%20152419.png" class="lazyload" data-srcset="Fri,%2031%20Jan%202020%20152419.png" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><p>在代码中用到的“闵可夫斯基（minkowski）”距离是对欧几里得距离和曼哈顿距离的一种泛化，可写作：<br>$$<br>d(x^i, x^j) = \sqrt[p]{\sum_k|x^i_kx^j_k|^p}<br>$$<br>如果将参数p设置为2，那么就是欧几里得距离，设置为1，则为曼哈顿距离。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器学习分类算法</title>
      <link href="2020/01/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95/"/>
      <url>2020/01/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<p>介绍最早以算法方式描述的分类机器学习算法：<strong>感知器</strong>和<strong>自适应线性神经元</strong>。同时我们也会使用Python来实现一个感知器。</p><a id="more"></a><h2 id="早期机器学习概述"><a href="#早期机器学习概述" class="headerlink" title="早期机器学习概述"></a>早期机器学习概述</h2><p>罗森布拉特基于MCP模型提出了第一个感知器学习法则。在这个感知器规则中，他提出了一个自学习算法，此算法通过优化得到权重系数，此系数和输入值的乘机决定了神经元是否被激活。在监督学习中，类似算法可以用于预测样本所属的类别。</p><p>我们将类别问题看作是二值分类问题，为了简单起见，分为<strong>1</strong>(正类别)和**-1<strong>（负类别）。同时定义一个激励函数$ \phi(z) $，这个函数将会以特定的输入值</strong>x<strong>和相应的权值向量</strong>w**的线性组合作为输入，也就是说：$ z=w_1x_1 + \cdots + w_nx_n $。此时定义法治函数为阶跃函数：<br>$$<br>\begin{equation}<br>\phi(z)=<br>\begin{cases}<br>    1, &amp; z \ge \theta \<br>    -1, &amp; z \lt \theta<br>\end{cases}<br>\end{equation}<br>$$<br>其中，我们称$\theta$是阈值。</p><p>为了简单起见，可以将阈值移动到等式的左边，同时初始权重是$w_0=-\theta$同时$x_0=1$，这样激励函数就变为<br>$$<br>\begin{equation}<br>\phi(z)=<br>\begin{cases}<br>    1, &amp; z \ge 0 \<br>    -1, &amp; z \lt 0<br>\end{cases}<br>\end{equation}<br>$$<br>同时感知器最初的规则很简单，可以归纳为如下几步：</p><ol><li>将权重初始化为零或者一个极小的随机数。</li><li>迭代所有训练样本$x^i$,执行如下操作：<ol><li>计算输出值$\hat{y}$。</li><li>更新权值。</li></ol></li></ol><p>每次对权重向量$w$的更新方式为：<br>$$<br>w_j:=w_j+\Delta{w_j}<br>$$<br>而对于$\Delta{w_j}$,可以通过感知器的学习规划计算获得：<br>$$<br>\Delta{w_j}=\eta(y^i-\hat{y^i})x_j^i<br>$$<br>其中，$\eta$是学习速率，一个在0到1之间的常数，$y^i$是第i个样本的真实样标，$\hat{y^i}$是相应的预测值。对于一个二维数据，可以得到如下更新公式：<br>$$<br>\Delta{w_0} = \eta(y^i-\hat{output^i})\<br>\Delta{w_1} = \eta(y^i-\hat{output^i})x_1^i\<br>\cdots<br>$$<br>需要注意的是，感知器收敛的前提是两个类别必须是线性可分的，并且学习速率足够小。</p><p>感应器的模型如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="136-1580108354123.jpg" class="lazyload" data-srcset="136-1580108354123.jpg" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><h2 id="使用Python实现感知器学习算法"><a href="#使用Python实现感知器学习算法" class="headerlink" title="使用Python实现感知器学习算法"></a>使用Python实现感知器学习算法</h2><p>使用面向对象的方法实现感知器的接口，同时按照Python开发惯例，对于那些并非在初始化对象时创建但是又被对象中其他方法调用的属性，可以在后面加上一个下划线，如<code>self.w_</code>。</p><p>Python算法如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Perceptron</span>(<span class="params">object</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, eta=<span class="number">0.01</span>, n_iter=<span class="number">10</span></span>):</span></span><br><span class="line">        self.eta = eta</span><br><span class="line">        self.n_iter = n_iter</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, X, y</span>):</span></span><br><span class="line">        self.w_ = np.zeros(<span class="number">1</span> + X.shape[<span class="number">1</span>])</span><br><span class="line">        self.errors_ = []</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> range(self.n_iter):</span><br><span class="line">            errors = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> xi, target <span class="keyword">in</span> zip(X, y):</span><br><span class="line">                update = self.eta * (target - self.predict(xi))</span><br><span class="line">                self.w_[<span class="number">1</span>:] += update * xi</span><br><span class="line">                self.w_[<span class="number">0</span>] += update</span><br><span class="line">                errors += int(update != <span class="number">0.0</span>)</span><br><span class="line">            self.errors_.append(errors)</span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">net_input</span>(<span class="params">self, X</span>):</span></span><br><span class="line">        <span class="keyword">return</span> np.dot(X, self.w[<span class="number">1</span>:]) + self.w_[<span class="number">0</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self, X</span>):</span></span><br><span class="line">        <span class="keyword">return</span> np.where(self.net_input(X) &gt;= <span class="number">0.0</span>, <span class="number">1</span>, <span class="number">-1</span>)</span><br></pre></td></tr></table></figure><p>接下来就可以使用相关的数据集来训练我们的感知器模型。</p><p>首先我们从<code>pandas</code>库直接从UCI机器学习库中将鸢尾花数据集转化为<code>DataFrame</code>对象并且加载到内存中，并且使用<code>tail</code>方法显示数据确保数据加载正确。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">df = pd.read_csv(<span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span>, header=<span class="literal">None</span>)</span><br><span class="line">df.tail()</span><br></pre></td></tr></table></figure><table><thead><tr><th></th><th>0</th><th>1</th><th>2</th><th>3</th><th>4</th></tr></thead><tbody><tr><td>145</td><td>6.7</td><td>3.0</td><td>5.2</td><td>2.3</td><td>Iris-virginica</td></tr><tr><td>146</td><td>6.3</td><td>2.5</td><td>5.0</td><td>1.9</td><td>Iris-virginica</td></tr><tr><td>147</td><td>6.5</td><td>3.0</td><td>5.2</td><td>2.0</td><td>Iris-virginica</td></tr><tr><td>148</td><td>6.2</td><td>3.4</td><td>5.4</td><td>2.3</td><td>Iris-virginica</td></tr><tr><td>149</td><td>5.9</td><td>3.0</td><td>5.1</td><td>1.8</td><td>Iris-virginica</td></tr></tbody></table><blockquote><p>鸢尾花数据集时机器学习中一个经典的实例，它包含了Setosa，Versicolor和Virginica三个品种总共150个鸢尾花的测量数据，每个品种的数量是50个。每个数据项包括序号，萼片长度，萼片宽度，花瓣长度，花瓣宽度，类标。</p></blockquote><p>接下来提取前100个类标，其中分别包含50个山鸢尾类标和50个变色鸢尾类标，并且将变色鸢尾表示为1，山鸢尾表示为-1。同时提取萼片长度和花瓣长度作为输入变量$X$。</p><p>首先可视化$X$：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">y = df.iloc[<span class="number">0</span>:<span class="number">100</span>, <span class="number">4</span>].values</span><br><span class="line">y = np.where(y == <span class="string">&#x27;Iris-setosa&#x27;</span>, <span class="number">-1</span>, <span class="number">1</span>)</span><br><span class="line">X = df.iloc[<span class="number">0</span>:<span class="number">100</span>, [<span class="number">0</span>, <span class="number">2</span>]].values</span><br><span class="line">plt.scatter(X[:<span class="number">50</span>, <span class="number">0</span>], X[:<span class="number">50</span>, <span class="number">1</span>], color=<span class="string">&#x27;red&#x27;</span>, marker=<span class="string">&#x27;o&#x27;</span>, label=<span class="string">&#x27;setosa&#x27;</span>)</span><br><span class="line">plt.scatter(X[<span class="number">50</span>:<span class="number">100</span>, <span class="number">0</span>], X[<span class="number">50</span>:<span class="number">100</span>, <span class="number">1</span>], color=<span class="string">&#x27;blue&#x27;</span>, marker=<span class="string">&#x27;x&#x27;</span>, label=<span class="string">&#x27;versicolor&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;petal length&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;sepal length&#x27;</span>)</span><br><span class="line">plt.legend(loc=<span class="string">&#x27;upper left&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>可视化的图形如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="Mon,%2027%20Jan%202020%20113718.png" class="lazyload" data-srcset="Mon,%2027%20Jan%202020%20113718.png" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><p>现在，我们可以使用提取出的数据来训练我们的感知器了。同时我们还会绘制每次迭代的错误分类数量的折线图，以检验算法是否收敛并且找到决策边界。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ppn = Perceptron(eta=<span class="number">0.1</span>, n_iter=<span class="number">10</span>)</span><br><span class="line">ppn.fit(X, y)</span><br><span class="line">plt.plot(range(<span class="number">1</span>, len(ppn.errors_) + <span class="number">1</span>), ppn.errors_, marker=<span class="string">&#x27;o&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Epochs&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Number of misclassifications&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>得到的每次迭代的错误数量折线图如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="Mon,%2027%20Jan%202020%20120738.png" class="lazyload" data-srcset="Mon,%2027%20Jan%202020%20120738.png" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><p>如上图所示，我们的迭代器在第六次的时候就已经收敛，下面通过一个简单的函数实现二维数据决策边界的可视化。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> matplotlib.colors <span class="keyword">import</span> ListedColormap</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_decision_regions</span>(<span class="params">X, y, classifier, resolution=<span class="number">0.02</span></span>):</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># setup marker generator and color map</span></span><br><span class="line">    markers = (<span class="string">&#x27;s&#x27;</span>, <span class="string">&#x27;x&#x27;</span>, <span class="string">&#x27;o&#x27;</span>, <span class="string">&#x27;^&#x27;</span>, <span class="string">&#x27;v&#x27;</span>)</span><br><span class="line">    colors = (<span class="string">&#x27;red&#x27;</span>, <span class="string">&#x27;blue&#x27;</span>, <span class="string">&#x27;lightgreen&#x27;</span>, <span class="string">&#x27;gray&#x27;</span>, <span class="string">&#x27;cyan&#x27;</span>)</span><br><span class="line">    cmap = ListedColormap(colors[:len(np.unique(y))])</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># plt the decision surface</span></span><br><span class="line">    x1_min, x1_max = X[:, <span class="number">0</span>].min() - <span class="number">1</span>, X[:, <span class="number">0</span>].max() + <span class="number">1</span></span><br><span class="line">    x2_min, x2_max = X[:, <span class="number">1</span>].min() - <span class="number">1</span>, X[:, <span class="number">1</span>].max() + <span class="number">1</span></span><br><span class="line">    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution), np.arange(x2_min, x2_max, resolution))</span><br><span class="line">    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)</span><br><span class="line">    Z = Z.reshape(xx1.shape)</span><br><span class="line">    plt.contourf(xx1, xx2, Z, alpha=<span class="number">0.4</span>, cmap=cmap)</span><br><span class="line">    plt.xlim(xx1.min(), xx1.max())</span><br><span class="line">    plt.ylim(xx2.min(), xx2.max())</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># plot class sample</span></span><br><span class="line">    <span class="keyword">for</span> idx, cl <span class="keyword">in</span> enumerate(np.unique(y)):</span><br><span class="line">        plt.scatter(x=X[y == cl, <span class="number">0</span>], y=X[y == cl, <span class="number">1</span>], alpha=<span class="number">0.8</span>, c=cmap(idx), marker=markers[idx], label=cl)</span><br><span class="line">   </span><br></pre></td></tr></table></figure><p>接着调用该函数就可以画出图像：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">plot_decision_regions(X, y, classifier=ppn)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;sepal length&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;petal length&#x27;</span>)</span><br><span class="line">plt.legend(loc=<span class="string">&#x27;upper left&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="Tue,%2028%20Jan%202020%20093315.png" class="lazyload" data-srcset="Tue,%2028%20Jan%202020%20093315.png" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><p>通过图中可看出来，感知器能够对训练集中的所有数据进行正确的分类。</p><h2 id="自适应线性神经元和学习的收敛性"><a href="#自适应线性神经元和学习的收敛性" class="headerlink" title="自适应线性神经元和学习的收敛性"></a>自适应线性神经元和学习的收敛性</h2><p>在感知器算法出现之后，又有人提出了Adaline算法，这个算法可以看作是对之前算法的改进。</p><p>基于Adaline规则的权重更新是通过一个连续的线性激励函数来完成的，而不像感知器中使用单位阶跃函数，这是二者主要的区别。在Adaline是算法中，激励函数是简单的恒等函数，即$ \phi(w^Tx)=w^Tx $。线性激励函数在更新权重的同时，我们使用量化器对类标进行预测，量化器和前面提到的单位阶跃函数类似，如下图所示：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="1207849-93a03f14c2401c5c.webp" class="lazyload" data-srcset="1207849-93a03f14c2401c5c.webp" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><p>对比前面的感知器算法模型而可以得到差别：使用线性激励函数的连续型输出值，而不是二类别分类类标来计算模型的误差以及更新权重。</p><h3 id="通过梯度下降最小化代价函数"><a href="#通过梯度下降最小化代价函数" class="headerlink" title="通过梯度下降最小化代价函数"></a>通过梯度下降最小化代价函数</h3><p>在Adaline中，我们可以定义代价函数$J$为通过模型得到的输出值和实际值之间的误差平方和：<br>$$<br>J(w) = \frac{1}{2}\sum_i(y^i-\phi(z^i))^2<br>$$<br>这里，系数1/2是为了方便的角度，是我们容易求梯度。这个代价函数是一个凸函数，这样我们可以通过简单高效的梯度下降优化算法得到权重，并且保证对训练数据进行分类时代价最小。</p><p>如下图所示，我们将梯度学习的原理形象地描述为下山：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="1207849-d4695ed1848fce85.webp" class="lazyload" data-srcset="1207849-d4695ed1848fce85.webp" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><p>这样，权重更新公式如下：<br>$$<br>w:=w+\Delta{w}<br>$$<br>对应的权重增量$ \Delta{w} $定义为下：<br>$$<br>\Delta{w}=-\eta\Delta{J(w)}<br>$$<br>化简得到：<br>$$<br>\Delta{w_j} = \eta\sum_i(y^i-\phi(z^i))x^i_j<br>$$<br>这样权重的更行是根据训练集中所有数据完成的，而不是每次一个样本渐进更新权重，这也是该方法被称为批量下降的原因。</p><h3 id="使用Python实现自适应线性神经元"><a href="#使用Python实现自适应线性神经元" class="headerlink" title="使用Python实现自适应线性神经元"></a>使用Python实现自适应线性神经元</h3><p>我们将会根据感知器模型的代码来复写我们的Adaline模型，如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AdalineGD</span>(<span class="params">object</span>):</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, eta=<span class="number">0.01</span>, n_iter=<span class="number">50</span></span>):</span></span><br><span class="line">        self.eta = eta</span><br><span class="line">        self.n_iter = n_iter</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, X, y</span>):</span></span><br><span class="line">        self.w_ = np.zeros(<span class="number">1</span> + X.shape[<span class="number">1</span>])</span><br><span class="line">        self.cost_ = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(self.n_iter):</span><br><span class="line">            output = self.net_input(X)</span><br><span class="line">            errors = (y - output)</span><br><span class="line">            self.w_[<span class="number">1</span>:] += self.eta * X.T.dot(errors)</span><br><span class="line">            self.w_[<span class="number">0</span>] += self.eta * errors.sum()</span><br><span class="line">            cost = (errors**<span class="number">2</span>).sum()/<span class="number">2.0</span></span><br><span class="line">            self.cost_.append(cost)</span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">net_input</span>(<span class="params">self, X</span>):</span></span><br><span class="line">        <span class="keyword">return</span> np.dot(X, self.w_[<span class="number">1</span>:]) + self.w_[<span class="number">0</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">activation</span>(<span class="params">self, X</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.net_input(X)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self, X</span>):</span></span><br><span class="line">        <span class="keyword">return</span> np.where(self.activation(X) &gt;= <span class="number">0.0</span>, <span class="number">1</span>, <span class="number">-1</span>)</span><br></pre></td></tr></table></figure><p>感知器通过<code>self.eta * errors.sum()</code>来更新第0个位置的权重，通过<code>self.eta * X.T.dot(errors)</code>来更新第1到m个位置的权重，同时，我们设置一个列表<code>self.cost_</code>用于追踪本轮训练的误差值。</p><p>实践中，我们常常需要进行调参的工作，我们分别让$\eta = 0.1$和$\eta = 0.0001$来训练，同时绘制迭代次数和代价函数的图像，观察Adaline通过数据训练进行学习的效果。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">fig, ax = plt.subplots(nrows=<span class="number">1</span>, ncols=<span class="number">2</span>, figsize=(<span class="number">8</span>,<span class="number">4</span>))</span><br><span class="line">ada1 = AdalineGD(n_iter=<span class="number">10</span>, eta=<span class="number">0.1</span>).fit(X, y)</span><br><span class="line">ax[<span class="number">0</span>].plot(range(<span class="number">1</span>, len(ada1.cost_) + <span class="number">1</span>), np.log10(ada1.cost_), marker=<span class="string">&#x27;o&#x27;</span>)</span><br><span class="line">ax[<span class="number">0</span>].set_xlabel(<span class="string">&#x27;Epochs&#x27;</span>)</span><br><span class="line">ax[<span class="number">0</span>].set_ylabel(<span class="string">&#x27;log(SSE)&#x27;</span>)</span><br><span class="line">ax[<span class="number">0</span>].set_title(<span class="string">&#x27;Adaline - 0.1&#x27;</span>)</span><br><span class="line"></span><br><span class="line">ada2 = AdalineGD(n_iter=<span class="number">10</span>, eta=<span class="number">0.0001</span>).fit(X, y)</span><br><span class="line">ax[<span class="number">1</span>].plot(range(<span class="number">1</span>, len(ada2.cost_) + <span class="number">1</span>), ada2.cost_, marker=<span class="string">&#x27;o&#x27;</span>)</span><br><span class="line">ax[<span class="number">1</span>].set_xlabel(<span class="string">&#x27;Epochs&#x27;</span>)</span><br><span class="line">ax[<span class="number">1</span>].set_ylabel(<span class="string">&#x27;log(SSE)&#x27;</span>)</span><br><span class="line">ax[<span class="number">1</span>].set_title(<span class="string">&#x27;Adaline - 0.0001&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>图像如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="Mon,%2027%20Jan%202020%20155947.png" class="lazyload" data-srcset="Mon,%2027%20Jan%202020%20155947.png" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><p>从图中可以看出，我们面临着这两种问题：左边图像显示了学习速率过大可能会导致并没有使得代价函数尽可能低，反而因为算法跳过了全局最优解，导致误差越来越大；右边图像虽然代价函数逐渐减少，但是学习速率太小，使得到算法收敛的目标需要更多次数的迭代。</p><p>为了提高算法优化的性能，我们将使用<strong>特征缩放</strong>的方法，也就是：<br>$$<br>x_j^{‘}=\frac{x_j - \mu_j}{\sigma_j}<br>$$<br>标准化可以通过Numpy的<code>mean</code>和<code>std</code>方法实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">X_std = np.copy(X)</span><br><span class="line">X_std[:, <span class="number">0</span>] = (X[:, <span class="number">0</span>] - X[:, <span class="number">0</span>].mean()) / X[:, <span class="number">0</span>].std()</span><br><span class="line">X_std[:, <span class="number">1</span>] = (X[:, <span class="number">1</span>] - X[:, <span class="number">1</span>].mean()) / X[:, <span class="number">1</span>].std()</span><br></pre></td></tr></table></figure><p>接下来，按照$\eta = 0.01$的学习速率来对Adaline进行训练：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">ada = AdalineGD(n_iter=<span class="number">15</span>, eta=<span class="number">0.01</span>)</span><br><span class="line">ada.fit(X_std, y)</span><br><span class="line">plot_decision_regions(X_std, y, classifier=ada)</span><br><span class="line">plt.title(<span class="string">&#x27;Adaline - 0.01&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;sepal length&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;petal length&#x27;</span>)</span><br><span class="line">plt.legend(loc=<span class="string">&#x27;upper left&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line">plt.plot(range(<span class="number">1</span>, len(ada.cost_) + <span class="number">1</span>), ada.cost_, marker=<span class="string">&#x27;o&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Epochs&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;SSE&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>得到的图像如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="Mon,%2027%20Jan%202020%20162036.png" class="lazyload" data-srcset="Mon,%2027%20Jan%202020%20162036.png" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="Mon,%2027%20Jan%202020%20162052.png" class="lazyload" data-srcset="Mon,%2027%20Jan%202020%20162052.png" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><p>如上图，虽然所有样本都被正确分类，但是误差平方和（SSE）的值仍然不为零。</p><h3 id="大规模机器学习和随机梯度下降"><a href="#大规模机器学习和随机梯度下降" class="headerlink" title="大规模机器学习和随机梯度下降"></a>大规模机器学习和随机梯度下降</h3><p>上一节中，我们对所有的数据进行计算，利用计算出来的结果来实现权重的更新。但是，机器学习面临的数据往往是包含着几百万数据的巨大数据集，这种情况下使用批量梯度下降的计算成本很高。</p><p>为了解决这个问题，我们引入<strong>随机梯度下降</strong>，和基于所有样本的累计误差更新权重的策略不同，我们每次使用一个训练样本渐进地更新权重：<br>$$<br>\eta(y^i-\phi(z^i))x^i<br>$$</p><blockquote><p>当实现梯度随即下降时，通常规定学习速率如下：<br>$$<br>\eta = \frac{c_1}{c_2 + [迭代次数]}<br>$$</p></blockquote><p>为了让随机梯度下降得到更加准确的结果，让数据以随机的方式提供给算法时很重要的，因此，我们需要在每次迭代的时候打乱训练集。</p><p>随机梯度下降的另外一个优势是我们可以将其用于在线学习。通过在线学习，当有新的数据输入时模型会被实时训练。</p><blockquote><p>小批次学习：介于梯度下降和随机梯度下降之间的一种技术。将数据分成一组组的训练数据，在对每组数进行训练。</p></blockquote><p>随机梯度下降的Adaline算法如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy.random <span class="keyword">import</span> seed</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AdalineSGD</span>(<span class="params">object</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, eta=<span class="number">0.01</span>, n_iter=<span class="number">10</span>, shuffle=True, random_state=None</span>):</span></span><br><span class="line">        self.eta = eta</span><br><span class="line">        self.n_iter = n_iter</span><br><span class="line">        self.w_initialized = <span class="literal">False</span></span><br><span class="line">        self.shuffle = shuffle</span><br><span class="line">        <span class="keyword">if</span> random_state:</span><br><span class="line">            seed(random_state)</span><br><span class="line">            </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, X, y</span>):</span></span><br><span class="line">        self._initialize_weights(X.shape[<span class="number">1</span>])</span><br><span class="line">        self.cost_ = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(self.n_iter):</span><br><span class="line">            <span class="keyword">if</span> self.shuffle:</span><br><span class="line">                X, y = self._shuffle(X, y)</span><br><span class="line">            cost = []</span><br><span class="line">            <span class="keyword">for</span> xi, target <span class="keyword">in</span> zip(X, y):</span><br><span class="line">                cost.append(self._update_weights(xi, target))</span><br><span class="line">            avg_cost = sum(cost) / len(y)</span><br><span class="line">            self.cost_.append(avg_cost)</span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">partial_fit</span>(<span class="params">self, X, y</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.w_initialized:</span><br><span class="line">            self._initialize_weights(X.shape[<span class="number">1</span>])</span><br><span class="line">        <span class="keyword">if</span> y.ravel().shape[<span class="number">0</span>] &gt; <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">for</span> xi, target <span class="keyword">in</span> zip(X, y):</span><br><span class="line">                self._update_weights(xi, target)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self._update_weights(X, y)</span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_shuffle</span>(<span class="params">self, X, y</span>):</span></span><br><span class="line">        r = np.random.permutation(len(y))</span><br><span class="line">        <span class="keyword">return</span> X[r], y[r]</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_initialize_weights</span>(<span class="params">self, m</span>):</span></span><br><span class="line">        self.w_ = np.zeros(<span class="number">1</span> + m)</span><br><span class="line">        self.w_initialized = <span class="literal">True</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_update_weights</span>(<span class="params">self, xi, target</span>):</span></span><br><span class="line">        output = self.net_input(xi)</span><br><span class="line">        errors = (target - output)</span><br><span class="line">        self.w_[<span class="number">1</span>:] += self.eta * xi.dot(errors)</span><br><span class="line">        self.w_[<span class="number">0</span>] += self.eta * errors</span><br><span class="line">        cost = <span class="number">0.5</span> * errors**<span class="number">2</span></span><br><span class="line">        <span class="keyword">return</span> cost</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">net_input</span>(<span class="params">self, X</span>):</span></span><br><span class="line">        <span class="keyword">return</span> np.dot(X, self.w_[<span class="number">1</span>:]) + self.w_[<span class="number">0</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">activation</span>(<span class="params">self, X</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.net_input(X)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self, X</span>):</span></span><br><span class="line">        <span class="keyword">return</span> np.where(self.activation(X) &gt;= <span class="number">0.0</span>, <span class="number">1</span>, <span class="number">-1</span>) </span><br><span class="line">        </span><br></pre></td></tr></table></figure><p>绘图程序如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">ada = AdalineSGD(n_iter=<span class="number">15</span>, eta=<span class="number">0.01</span>, random_state=<span class="number">1</span>)</span><br><span class="line">ada.fit(X_std, y)</span><br><span class="line">plot_decision_regions(X_std, y, classifier=ada)</span><br><span class="line">plt.title(<span class="string">&#x27;Adaline - 0.01&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;sepal length&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;petal length&#x27;</span>)</span><br><span class="line">plt.legend(loc=<span class="string">&#x27;upper left&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line">plt.plot(range(<span class="number">1</span>, len(ada.cost_) + <span class="number">1</span>), ada.cost_, marker=<span class="string">&#x27;o&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Epochs&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Average Cost&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>图像如下：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="Mon,%2027%20Jan%202020%20170728.png" class="lazyload" data-srcset="Mon,%2027%20Jan%202020%20170728.png" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="Mon,%2027%20Jan%202020%20170740.png" class="lazyload" data-srcset="Mon,%2027%20Jan%202020%20170740.png" srcset="data:image/png;base64,666" alt="img"/></div><span class="image-caption">img</span></div><p>可以发现，代价函数的均值下降得很快，经过15次迭代后，基本趋势和梯度下降得到的图像类似。</p><p>如果改进模型，如用于数据流的在线学习，可以对单个样本简单调用<code>partial_fit</code>方法，如：<code>ada.partial_fit(X_std[0, :], y[0])</code>。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>赋予计算机学习数据的能力</title>
      <link href="2020/01/24/%E8%B5%8B%E4%BA%88%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%AD%A6%E4%B9%A0%E6%95%B0%E6%8D%AE%E7%9A%84%E8%83%BD%E5%8A%9B/"/>
      <url>2020/01/24/%E8%B5%8B%E4%BA%88%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%AD%A6%E4%B9%A0%E6%95%B0%E6%8D%AE%E7%9A%84%E8%83%BD%E5%8A%9B/</url>
      
        <content type="html"><![CDATA[<p> 主要了解机器学习的主要概念和几种不同类型的学习算法。</p><!--  More --><h2 id="机器学习的三种方法"><a href="#机器学习的三种方法" class="headerlink" title="机器学习的三种方法"></a>机器学习的三种方法</h2><h3 id="监督学习"><a href="#监督学习" class="headerlink" title="监督学习"></a>监督学习</h3><p>使用有类标的数据构建模型，使用经训练得到的模型对未来的数据进行预测。预测方法主要有两种：</p><ul><li><p>使用分类进行预测</p><p>分类是监督学习的一个子类，目的是对过往已知示例的观察与学习，实现对新样本类标的预测。检测垃圾邮件的例子就是一种二类标的方法，当然还有多类别分类的例子，比如字母表中每个字母的识别。</p></li><li><p>使用回归预测连续输出值</p><p>这种方法用于对连续型输出变量进行预测，比如学习成绩分数和自习时间多少之间进行预测。</p></li></ul><h3 id="强化（半监督）学习"><a href="#强化（半监督）学习" class="headerlink" title="强化（半监督）学习"></a>强化（半监督）学习</h3><p>强化学习的目标在于构建一个系统，在于环境的交互过程中逐步提高系统的性能。环境的当前状态中通常包含者一个反馈信号。常用的例子是象棋对弈的例子，在这个例子中，系统根据棋盘上的局势（环境）来决定落子的位置，而游戏结束的输赢可以当做是反馈信号。</p><h3 id="无监督学习"><a href="#无监督学习" class="headerlink" title="无监督学习"></a>无监督学习</h3><p>在这种学习方法下，我们将会处理无类标数据或者是总体趋势不明朗的数据，来提取出有效信息探索数据的整体结构。</p><ul><li><p>通过聚类发现数据的子群</p><p>聚类是一种探索性的数据分析技术，在没有任何相关先验信息的情况下，它可以帮我们将数据分成有意义的小组别。</p></li><li><p>数据压缩中的降维</p><p>讲高维数据压缩，是之转变为相对容易处理的维度数据。</p></li></ul><h2 id="机器学习系统的蓝图"><a href="#机器学习系统的蓝图" class="headerlink" title="机器学习系统的蓝图"></a>机器学习系统的蓝图</h2><h3 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h3><p>为了尽可能发回机器学习算法的性能，往往需要对原始数据进行处理使得它能达到算法要求的标准，同时选择较高关联的属性作为训练数据。</p><h3 id="选择预测模型类型并进行训练和校正"><a href="#选择预测模型类型并进行训练和校正" class="headerlink" title="选择预测模型类型并进行训练和校正"></a>选择预测模型类型并进行训练和校正</h3><p>选择合适的机器学习算法来对训练数据集进行学习得到模型，同时利用反馈信号来对模型进行校正。</p><h3 id="使用未知数据进行预测"><a href="#使用未知数据进行预测" class="headerlink" title="使用未知数据进行预测"></a>使用未知数据进行预测</h3><p>对未来的数据进行预测。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>git 常见错误</title>
      <link href="2019/10/27/git-%E5%B8%B8%E8%A7%81%E9%94%99%E8%AF%AF/"/>
      <url>2019/10/27/git-%E5%B8%B8%E8%A7%81%E9%94%99%E8%AF%AF/</url>
      
        <content type="html"><![CDATA[<p>整理在使用 git 过程中遇到的问题以及解决方法。</p><!--  More --><h2 id="shallow-update-not-allowed"><a href="#shallow-update-not-allowed" class="headerlink" title="shallow update not allowed"></a>shallow update not allowed</h2><p>这个问题的产生原因是在克隆远程仓库的时候采用了以下命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> --depth=&lt;num&gt; &lt;remote-url&gt;</span><br></pre></td></tr></table></figure><p>这将会导致<code>shallow clone</code>(浅复制)。这将会使得这个仓库不能向远程仓库进行<code>push</code>。<br>通过以下命令可修复：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git fetch --unshallow &lt;remote-repo&gt;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> git </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
